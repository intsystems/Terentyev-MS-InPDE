{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f32abb7",
   "metadata": {},
   "source": [
    "# Обратная задача ЭЭГ\n",
    "\n",
    "Обратная задача ЭЭГ заключается в восстановлении распределения источников (тока и заряда) внутри области (например, головы) на основе измерений электрического потенциала на границе.\n",
    "\n",
    "В данном ноутбуке мы используем нейросеть для моделирования распределения заряда и тока, а также обновляем функцию потерь и пайплайн для решения этой задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee54cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "using NeuralPDE, Lux, ModelingToolkit, Optimization, OptimizationOptimJL, LineSearches,\n",
    "      OptimizationOptimisers, LuxCUDA, Random, ComponentArrays\n",
    "using ModelingToolkit: Interval, infimum, supremum\n",
    "using Distributions, Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1339f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::CPUDevice) (generic function with 4 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const gpud = gpu_device()\n",
    "const cpud = cpu_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c97391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dalembert_operator (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Определение прямой задачи\n",
    "@parameters x, y, z, t\n",
    "@variables φ(..), Ax(..),Ay(..),Az(..), ρ(..), jx(..), jy(..), jz(..)\n",
    "A = [Ax, Ay, Az]\n",
    "j = [jx, jy, jz]\n",
    "Dxx = Differential(x)^2\n",
    "Dyy = Differential(y)^2\n",
    "Dzz = Differential(z)^2\n",
    "\n",
    "# Определение физических постоянных\n",
    "const ε₀ = 8.854187817e-12 # Электрическая постоянная в вакууме (Ф/м)\n",
    "const ε = ε₀ # Электрическая постоянная (Ф/м)\n",
    "const μ₀ = 1.2566370614e-6 # Магнитная постоянная в вакууме (Гн/м)\n",
    "const μ = μ₀ # Магнитная постоянная (Гн/м)\n",
    "const c = 299792458.0 # Скорость света в вакууме (м/с)\n",
    "\n",
    "# Определение оператора Лапласа как функции\n",
    "function laplacian(F, params)\n",
    "    return sum((Differential(param)^2)(F) for param in params)\n",
    "end\n",
    "\n",
    "# Определение оператора Даламбера как функции\n",
    "function dalembert_operator(F, params, ε, μ, c)\n",
    "    Δ = laplacian(F, params)\n",
    "    return Δ  - (ε * μ / c^2) * (Differential(t)^2)(F)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb18d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\varphi\\left( x, y, z, t \\right) - 1.238 \\cdot 10^{-34} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\varphi\\left( x, y, z, t \\right)\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "Differential(y)(Differential(y)(φ(x, y, z, t))) + Differential(x)(Differential(x)(φ(x, y, z, t))) - 1.2379901471139933e-34Differential(t)(Differential(t)(φ(x, y, z, t))) + Differential(z)(Differential(z)(φ(x, y, z, t)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dalembert_operator(φ(x,y,z,t), [x, y, z], ε, μ, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ba867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{align}\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\varphi\\left( x, y, z, t \\right) - 1.238 \\cdot 10^{-34} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\varphi\\left( x, y, z, t \\right) &=  - 1.2756 \\cdot 10^{22} \\rho\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ax}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Ax}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ax}\\left( x, y, z, t \\right) - 1.238 \\cdot 10^{-34} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Ax}\\left( x, y, z, t \\right) &=  - 1.5791 \\cdot 10^{-12} \\mathtt{jx}\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Ay}\\left( x, y, z, t \\right) - 1.238 \\cdot 10^{-34} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ay}\\left( x, y, z, t \\right) &=  - 1.5791 \\cdot 10^{-12} \\mathtt{jy}\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Az}\\left( x, y, z, t \\right) - 1.238 \\cdot 10^{-34} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Az}\\left( x, y, z, t \\right) &=  - 1.5791 \\cdot 10^{-12} \\mathtt{jz}\\left( x, y, z, t \\right)\n",
       "\\end{align}\n",
       " $$"
      ],
      "text/plain": [
       "4-element Vector{Equation}:\n",
       " Differential(y)(Differential(y)(φ(x, y, z, t))) + Differential(x)(Differential(x)(φ(x, y, z, t))) - 1.2379901471139933e-34Differential(t)(Differential(t)(φ(x, y, z, t))) + Differential(z)(Differential(z)(φ(x, y, z, t))) ~ -1.27556484025426e22ρ(x, y, z, t)\n",
       " Differential(x)(Differential(x)(Ax(x, y, z, t))) + Differential(z)(Differential(z)(Ax(x, y, z, t))) + Differential(y)(Differential(y)(Ax(x, y, z, t))) - 1.2379901471139933e-34Differential(t)(Differential(t)(Ax(x, y, z, t))) ~ -1.5791367040840272e-12jx(x, y, z, t)\n",
       " Differential(y)(Differential(y)(Ay(x, y, z, t))) + Differential(z)(Differential(z)(Ay(x, y, z, t))) - 1.2379901471139933e-34Differential(t)(Differential(t)(Ay(x, y, z, t))) + Differential(x)(Differential(x)(Ay(x, y, z, t))) ~ -1.5791367040840272e-12jy(x, y, z, t)\n",
       " Differential(z)(Differential(z)(Az(x, y, z, t))) + Differential(y)(Differential(y)(Az(x, y, z, t))) - 1.2379901471139933e-34Differential(t)(Differential(t)(Az(x, y, z, t))) + Differential(x)(Differential(x)(Az(x, y, z, t))) ~ -1.5791367040840272e-12jz(x, y, z, t)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Уравнение\n",
    "eqs = [\n",
    "    [dalembert_operator(φ(x, y, z, t), [x, y, z], ε, μ, c) ~ -ρ(x, y, z, t) / (ε * ε₀)];\n",
    "    [dalembert_operator(A[i](x, y, z, t), [x, y, z], ε, μ, c) ~ -μ * μ₀ * j[i](x, y, z, t) for i in 1:3]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a6dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{align}\n",
       "\\varphi\\left( -10, y, z, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( 10, y, z, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( x, -10, z, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( x, 10, z, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( x, y, -10, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( x, y, 10, t \\right) &= 0 \\\\\n",
       "\\mathtt{Ax}\\left( -10, y, z, t \\right) &= 0 \\\\\n",
       "\\mathtt{Ay}\\left( -10, y, z, t \\right) &= 0 \\\\\n",
       "\\mathtt{Az}\\left( -10, y, z, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( 0.5, 0.5, 0.5, 0 \\right) &= 1 \\\\\n",
       "\\varphi\\left( 0.2, 0.3, 0.4, 0 \\right) &= 0 \\\\\n",
       "\\varphi\\left( 0.8, 0.7, 0.6, 0 \\right) &= -1\n",
       "\\end{align}\n",
       " $$"
      ],
      "text/plain": [
       "12-element Vector{Equation}:\n",
       " φ(-10.0, y, z, t) ~ 0.0\n",
       " φ(10.0, y, z, t) ~ 0.0\n",
       " φ(x, -10.0, z, t) ~ 0.0\n",
       " φ(x, 10.0, z, t) ~ 0.0\n",
       " φ(x, y, -10.0, t) ~ 0.0\n",
       " φ(x, y, 10.0, t) ~ 0.0\n",
       " Ax(-10.0, y, z, t) ~ 0.0\n",
       " Ay(-10.0, y, z, t) ~ 0.0\n",
       " Az(-10.0, y, z, t) ~ 0.0\n",
       " φ(0.5, 0.5, 0.5, 0) ~ 1.0\n",
       " φ(0.2, 0.3, 0.4, 0) ~ 0.0\n",
       " φ(0.8, 0.7, 0.6, 0) ~ -1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Границы области\n",
    "const x_min, x_max = -10.0, 10.0\n",
    "const y_min, y_max = -10.0, 10.0\n",
    "const z_min, z_max = -10.0, 10.0\n",
    "const t_min, t_max = 0.0, 1.0\n",
    "# Область\n",
    "domains = [x ∈ Interval(x_min, x_max),\n",
    "           y ∈ Interval(y_min, y_max),\n",
    "           z ∈ Interval(z_min, z_max), \n",
    "           t ∈ Interval(t_min, t_max)]\n",
    "# Граничные условия\n",
    "measured_points = [\n",
    "    ((0.5, 0.5, 0.5, 0), 1.0),\n",
    "    ((0.2, 0.3, 0.4, 0), 0.0),\n",
    "    ((0.8, 0.7, 0.6, 0),  -1.0)\n",
    "]\n",
    "\n",
    "bcs = [\n",
    "    [φ(x_min, y, z, t) ~ 0.0, φ(x_max, y, z, t) ~ 0.0,\n",
    "    φ(x, y_min, z, t) ~ 0.0, φ(x, y_max, z, t) ~ 0.0,\n",
    "    φ(x, y, z_min, t) ~ 0.0, φ(x, y, z_max, t) ~ 0.0];\n",
    "    [A[i](x_min, y, z, t)  ~ 0.0 for i in 1:3]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a7fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "additional_loss_weightened (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function additional_loss_weightened(lambda)\n",
    "    function additional_loss(phi_pred_fun, θ)\n",
    "        return lambda * sum(abs2(phi_pred_fun(x, y, z, t, θ) - phi) for ((x, y, z, t, θ), phi) in measured_points) / length(measured_points)\n",
    "    end\n",
    "    return additional_loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d660e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhysicsInformedNN{Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}, ComponentVector{Float64, CuArray{Float64, 1, CUDA.DeviceMemory}, Tuple{Axis{(layer_1 = ViewAxis(1:160, Axis(weight = ViewAxis(1:128, ShapedAxis((32, 4))), bias = ViewAxis(129:160, Shaped1DAxis((32,))))), layer_2 = ViewAxis(161:1216, Axis(weight = ViewAxis(1:1024, ShapedAxis((32, 32))), bias = ViewAxis(1025:1056, Shaped1DAxis((32,))))), layer_3 = ViewAxis(1217:2272, Axis(weight = ViewAxis(1:1024, ShapedAxis((32, 32))), bias = ViewAxis(1025:1056, Shaped1DAxis((32,))))), layer_4 = ViewAxis(2273:2536, Axis(weight = ViewAxis(1:256, ShapedAxis((8, 32))), bias = ViewAxis(257:264, Shaped1DAxis((8,))))))}}}, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, typeof(NeuralPDE.numeric_derivative), Bool, Nothing, Nothing, Nothing, Base.RefValue{Int64}, Base.Pairs{Symbol, Union{}, Tuple{}, @NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0), (layer_1 = (weight = [0.6801638007164001 0.31217271089553833 -0.7113919258117676 0.3005101978778839; -0.47935646772384644 0.25891703367233276 -0.3421252369880676 -0.16944631934165955; … ; -0.3868759274482727 0.43289634585380554 0.5991119146347046 0.40560221672058105; 0.571575403213501 0.6087958812713623 -0.18336862325668335 -0.2638322114944458], bias = [0.24106889963150024, -0.17392855882644653, 0.4361080527305603, -0.2882238030433655, -0.31736642122268677, -0.2935361862182617, -0.46094846725463867, 0.16689497232437134, -0.3853933811187744, -0.32995325326919556  …  -0.3187251091003418, -0.4626254439353943, 0.19331204891204834, -0.27462875843048096, -0.29094552993774414, 0.21727555990219116, 0.02360779047012329, 0.2866835594177246, -0.17656338214874268, -0.3783490061759949]), layer_2 = (weight = [0.2436264604330063 -0.0680389329791069 … 0.04271404445171356 0.06893505156040192; 0.14572003483772278 -0.21583612263202667 … -0.03750962018966675 -0.1946410834789276; … ; -0.04651452228426933 -0.03647108003497124 … -0.1372247040271759 0.2776201069355011; -0.06958559900522232 0.02185145393013954 … 0.15379008650779724 -0.1415681689977646], bias = [0.04782143607735634, -0.1012996956706047, -0.1567249596118927, -0.15964087843894958, 0.05925853177905083, -0.11047711223363876, -0.1458110213279724, 0.05297053977847099, -0.055408038198947906, -0.07372841238975525  …  -0.17655904591083527, 0.13326048851013184, -0.11741387099027634, 0.0318475067615509, 0.03633865341544151, 0.050737977027893066, -0.13936328887939453, 0.1765834093093872, 0.15287524461746216, 0.16996905207633972]), layer_3 = (weight = [0.2569832503795624 0.044006261974573135 … 0.2960079312324524 0.26922568678855896; -0.23582160472869873 -0.1548907458782196 … 0.1921408623456955 0.1450984627008438; … ; -0.1138150542974472 0.2908233106136322 … -0.06212691590189934 0.05998731032013893; 0.047481339424848557 0.010993288829922676 … 0.24803538620471954 0.08838599175214767], bias = [0.1743733137845993, 0.1512034833431244, 0.06931287050247192, -0.08792513608932495, 0.016885502263903618, -0.047577153891325, -0.014746191911399364, 0.12522418797016144, 0.018794501200318336, -0.15208648145198822  …  -0.03305258974432945, 0.07404419779777527, -0.045243650674819946, -0.16815847158432007, 0.030172569677233696, 0.0471804253757, -0.06609272956848145, 0.1692200005054474, -0.1101473718881607, 0.16186214983463287]), layer_4 = (weight = [-0.30527234077453613 -0.09309124201536179 … -0.02350020594894886 -0.19887332618236542; 0.1241290420293808 -0.004951805341988802 … -0.2885815501213074 -0.16537760198116302; … ; -0.29496872425079346 -0.28880730271339417 … 0.16195683181285858 0.10213395953178406; 0.09368415176868439 -0.16355587542057037 … -0.29843971133232117 -0.12237031012773514], bias = [-0.13972108066082, -0.1584814488887787, -0.09499998390674591, -0.07104304432868958, 0.03547034412622452, 0.06126215308904648, -0.04893474653363228, 0.11462417244911194])), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), NeuralPDE.numeric_derivative, false, nothing, nothing, nothing, LogOptions(50), Base.RefValue{Int64}(1), true, false, Base.Pairs{Symbol, Union{}, Tuple{}, @NamedTuple{}}())"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Нейросеть\n",
    "# Определение новой нейросети для моделирования распределения заряда и тока\n",
    "input_ = 4  # x, y, z\n",
    "n = 32      # число нейронов в скрытых слоях\n",
    "# Функция для разделения выхода сети на переменные\n",
    "\"\"\"\n",
    "function split_outputs(out)\n",
    "    φ_pred = out[1]\n",
    "    A_pred = out[2:4]\n",
    "    ρ_pred = out[5]\n",
    "    j_pred = out[6:8]\n",
    "    return φ_pred, A_pred, ρ_pred, j_pred\n",
    "end\n",
    "\n",
    "chain = [Chain(\n",
    "    Dense(input_, n, σ),\n",
    "    Dense(n, n, σ),\n",
    "    Dense(n, 1)\n",
    ") for _ in 1:8] \n",
    "\n",
    "# Определение системы\n",
    "ps = [Lux.setup(Random.default_rng(), chain[i])[1] |> ComponentArray |> gpud .|> Float64 for i in 1:8]\n",
    "\"\"\"\n",
    "chain = Chain(\n",
    "    Dense(input_, n, σ),\n",
    "    Dense(n, n, σ),\n",
    "    Dense(n, n, σ),\n",
    "    Dense(n, 8)\n",
    ")\n",
    "\n",
    "# Определение системы\n",
    "ps = Lux.setup(Random.default_rng(), chain)[1] |> ComponentArray |> gpud .|> Float64\n",
    "\n",
    "strategy = QuasiRandomTraining(4096)\n",
    "discretization = PhysicsInformedNN(chain, strategy; init_params = ps, additional_loss = additional_loss_weightened(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e01addc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{c}\n",
       "\\varphi\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{Ax}\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{Ay}\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{Az}\\left( x, y, z, t \\right) \\\\\n",
       "\\rho\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{jx}\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{jy}\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{jz}\\left( x, y, z, t \\right) \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "8-element Vector{Num}:\n",
       "  φ(x, y, z, t)\n",
       " Ax(x, y, z, t)\n",
       " Ay(x, y, z, t)\n",
       " Az(x, y, z, t)\n",
       "  ρ(x, y, z, t)\n",
       " jx(x, y, z, t)\n",
       " jy(x, y, z, t)\n",
       " jz(x, y, z, t)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allvars = [φ(x, y, z, t); [A_(x, y, z, t) for A_ in A]; ρ(x, y, z, t); [j_(x, y, z, t) for j_ in j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3610692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{align}\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\varphi\\left( x, y, z, t \\right) - 1.238 \\cdot 10^{-34} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\varphi\\left( x, y, z, t \\right) &=  - 1.2756 \\cdot 10^{22} \\rho\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ax}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Ax}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ax}\\left( x, y, z, t \\right) - 1.238 \\cdot 10^{-34} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Ax}\\left( x, y, z, t \\right) &=  - 1.5791 \\cdot 10^{-12} \\mathtt{jx}\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Ay}\\left( x, y, z, t \\right) - 1.238 \\cdot 10^{-34} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ay}\\left( x, y, z, t \\right) &=  - 1.5791 \\cdot 10^{-12} \\mathtt{jy}\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Az}\\left( x, y, z, t \\right) - 1.238 \\cdot 10^{-34} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Az}\\left( x, y, z, t \\right) &=  - 1.5791 \\cdot 10^{-12} \\mathtt{jz}\\left( x, y, z, t \\right)\n",
       "\\end{align}\n",
       " $$"
      ],
      "text/plain": [
       "PDESystem\n",
       "Equations: Equation[Differential(y)(Differential(y)(φ(x, y, z, t))) + Differential(x)(Differential(x)(φ(x, y, z, t))) - 1.2379901471139933e-34Differential(t)(Differential(t)(φ(x, y, z, t))) + Differential(z)(Differential(z)(φ(x, y, z, t))) ~ -1.27556484025426e22ρ(x, y, z, t), Differential(x)(Differential(x)(Ax(x, y, z, t))) + Differential(z)(Differential(z)(Ax(x, y, z, t))) + Differential(y)(Differential(y)(Ax(x, y, z, t))) - 1.2379901471139933e-34Differential(t)(Differential(t)(Ax(x, y, z, t))) ~ -1.5791367040840272e-12jx(x, y, z, t), Differential(y)(Differential(y)(Ay(x, y, z, t))) + Differential(z)(Differential(z)(Ay(x, y, z, t))) - 1.2379901471139933e-34Differential(t)(Differential(t)(Ay(x, y, z, t))) + Differential(x)(Differential(x)(Ay(x, y, z, t))) ~ -1.5791367040840272e-12jy(x, y, z, t), Differential(z)(Differential(z)(Az(x, y, z, t))) + Differential(y)(Differential(y)(Az(x, y, z, t))) - 1.2379901471139933e-34Differential(t)(Differential(t)(Az(x, y, z, t))) + Differential(x)(Differential(x)(Az(x, y, z, t))) ~ -1.5791367040840272e-12jz(x, y, z, t)]\n",
       "Boundary Conditions: Equation[φ(-10.0, y, z, t) ~ 0.0, φ(10.0, y, z, t) ~ 0.0, φ(x, -10.0, z, t) ~ 0.0, φ(x, 10.0, z, t) ~ 0.0, φ(x, y, -10.0, t) ~ 0.0, φ(x, y, 10.0, t) ~ 0.0, Ax(-10.0, y, z, t) ~ 0.0, Ay(-10.0, y, z, t) ~ 0.0, Az(-10.0, y, z, t) ~ 0.0, φ(0.5, 0.5, 0.5, 0) ~ 1.0, φ(0.2, 0.3, 0.4, 0) ~ 0.0, φ(0.8, 0.7, 0.6, 0) ~ -1.0]\n",
       "Domain: Symbolics.VarDomainPairing[Symbolics.VarDomainPairing(x, -10.0 .. 10.0), Symbolics.VarDomainPairing(y, -10.0 .. 10.0), Symbolics.VarDomainPairing(z, -10.0 .. 10.0), Symbolics.VarDomainPairing(t, 0.0 .. 1.0)]\n",
       "Dependent Variables: Num[φ(x, y, z, t), Ax(x, y, z, t), Ay(x, y, z, t), Az(x, y, z, t), ρ(x, y, z, t), jx(x, y, z, t), jy(x, y, z, t), jz(x, y, z, t)]\n",
       "Independent Variables: Num[x, y, z, t]\n",
       "Parameters: SciMLBase.NullParameters()\n",
       "Default Parameter ValuesDict{Any, Any}()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@named pde_system = PDESystem(eqs, bcs, domains, [x, y, z, t], allvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5817f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralPDE.PINNRepresentation(Equation[Differential(y)(Differential(y)(φ(x, y, z, t))) + Differential(x)(Differential(x)(φ(x, y, z, t))) - 1.2379901471139933e-34Differential(t)(Differential(t)(φ(x, y, z, t))) + Differential(z)(Differential(z)(φ(x, y, z, t))) ~ -1.27556484025426e22ρ(x, y, z, t), Differential(x)(Differential(x)(Ax(x, y, z, t))) + Differential(z)(Differential(z)(Ax(x, y, z, t))) + Differential(y)(Differential(y)(Ax(x, y, z, t))) - 1.2379901471139933e-34Differential(t)(Differential(t)(Ax(x, y, z, t))) ~ -1.5791367040840272e-12jx(x, y, z, t), Differential(y)(Differential(y)(Ay(x, y, z, t))) + Differential(z)(Differential(z)(Ay(x, y, z, t))) - 1.2379901471139933e-34Differential(t)(Differential(t)(Ay(x, y, z, t))) + Differential(x)(Differential(x)(Ay(x, y, z, t))) ~ -1.5791367040840272e-12jy(x, y, z, t), Differential(z)(Differential(z)(Az(x, y, z, t))) + Differential(y)(Differential(y)(Az(x, y, z, t))) - 1.2379901471139933e-34Differential(t)(Differential(t)(Az(x, y, z, t))) + Differential(x)(Differential(x)(Az(x, y, z, t))) ~ -1.5791367040840272e-12jz(x, y, z, t)], Equation[φ(-10.0, y, z, t) ~ 0.0, φ(10.0, y, z, t) ~ 0.0, φ(x, -10.0, z, t) ~ 0.0, φ(x, 10.0, z, t) ~ 0.0, φ(x, y, -10.0, t) ~ 0.0, φ(x, y, 10.0, t) ~ 0.0, Ax(-10.0, y, z, t) ~ 0.0, Ay(-10.0, y, z, t) ~ 0.0, Az(-10.0, y, z, t) ~ 0.0, φ(0.5, 0.5, 0.5, 0) ~ 1.0, φ(0.2, 0.3, 0.4, 0) ~ 0.0, φ(0.8, 0.7, 0.6, 0) ~ -1.0], Symbolics.VarDomainPairing[Symbolics.VarDomainPairing(x, -10.0 .. 10.0), Symbolics.VarDomainPairing(y, -10.0 .. 10.0), Symbolics.VarDomainPairing(z, -10.0 .. 10.0), Symbolics.VarDomainPairing(t, 0.0 .. 1.0)], SciMLBase.NullParameters(), Dict{Any, Any}(), nothing, false, nothing, NonAdaptiveLoss{Float64}([1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], Float64[]), [:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz], [:x, :y, :z, :t], Dict(:y => 2, :z => 3, :t => 4, :x => 1), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:φ => [:x, :y, :z, :t], :ρ => [:x, :y, :z, :t], :Az => [:x, :y, :z, :t], :jx => [:x, :y, :z, :t], :Ax => [:x, :y, :z, :t], :jz => [:x, :y, :z, :t], :jy => [:x, :y, :z, :t], :Ay => [:x, :y, :z, :t]), nothing, false, Base.RefValue{Int64}(1), (layer_1 = (weight = [0.6801638007164001 0.31217271089553833 -0.7113919258117676 0.3005101978778839; -0.47935646772384644 0.25891703367233276 -0.3421252369880676 -0.16944631934165955; … ; -0.3868759274482727 0.43289634585380554 0.5991119146347046 0.40560221672058105; 0.571575403213501 0.6087958812713623 -0.18336862325668335 -0.2638322114944458], bias = [0.24106889963150024, -0.17392855882644653, 0.4361080527305603, -0.2882238030433655, -0.31736642122268677, -0.2935361862182617, -0.46094846725463867, 0.16689497232437134, -0.3853933811187744, -0.32995325326919556  …  -0.3187251091003418, -0.4626254439353943, 0.19331204891204834, -0.27462875843048096, -0.29094552993774414, 0.21727555990219116, 0.02360779047012329, 0.2866835594177246, -0.17656338214874268, -0.3783490061759949]), layer_2 = (weight = [0.2436264604330063 -0.0680389329791069 … 0.04271404445171356 0.06893505156040192; 0.14572003483772278 -0.21583612263202667 … -0.03750962018966675 -0.1946410834789276; … ; -0.04651452228426933 -0.03647108003497124 … -0.1372247040271759 0.2776201069355011; -0.06958559900522232 0.02185145393013954 … 0.15379008650779724 -0.1415681689977646], bias = [0.04782143607735634, -0.1012996956706047, -0.1567249596118927, -0.15964087843894958, 0.05925853177905083, -0.11047711223363876, -0.1458110213279724, 0.05297053977847099, -0.055408038198947906, -0.07372841238975525  …  -0.17655904591083527, 0.13326048851013184, -0.11741387099027634, 0.0318475067615509, 0.03633865341544151, 0.050737977027893066, -0.13936328887939453, 0.1765834093093872, 0.15287524461746216, 0.16996905207633972]), layer_3 = (weight = [0.2569832503795624 0.044006261974573135 … 0.2960079312324524 0.26922568678855896; -0.23582160472869873 -0.1548907458782196 … 0.1921408623456955 0.1450984627008438; … ; -0.1138150542974472 0.2908233106136322 … -0.06212691590189934 0.05998731032013893; 0.047481339424848557 0.010993288829922676 … 0.24803538620471954 0.08838599175214767], bias = [0.1743733137845993, 0.1512034833431244, 0.06931287050247192, -0.08792513608932495, 0.016885502263903618, -0.047577153891325, -0.014746191911399364, 0.12522418797016144, 0.018794501200318336, -0.15208648145198822  …  -0.03305258974432945, 0.07404419779777527, -0.045243650674819946, -0.16815847158432007, 0.030172569677233696, 0.0471804253757, -0.06609272956848145, 0.1692200005054474, -0.1101473718881607, 0.16186214983463287]), layer_4 = (weight = [-0.30527234077453613 -0.09309124201536179 … -0.02350020594894886 -0.19887332618236542; 0.1241290420293808 -0.004951805341988802 … -0.2885815501213074 -0.16537760198116302; … ; -0.29496872425079346 -0.28880730271339417 … 0.16195683181285858 0.10213395953178406; 0.09368415176868439 -0.16355587542057037 … -0.29843971133232117 -0.12237031012773514], bias = [-0.13972108066082, -0.1584814488887787, -0.09499998390674591, -0.07104304432868958, 0.03547034412622452, 0.06126215308904648, -0.04893474653363228, 0.11462417244911194])), (layer_1 = (weight = [0.6801638007164001 0.31217271089553833 -0.7113919258117676 0.3005101978778839; -0.47935646772384644 0.25891703367233276 -0.3421252369880676 -0.16944631934165955; … ; -0.3868759274482727 0.43289634585380554 0.5991119146347046 0.40560221672058105; 0.571575403213501 0.6087958812713623 -0.18336862325668335 -0.2638322114944458], bias = [0.24106889963150024, -0.17392855882644653, 0.4361080527305603, -0.2882238030433655, -0.31736642122268677, -0.2935361862182617, -0.46094846725463867, 0.16689497232437134, -0.3853933811187744, -0.32995325326919556  …  -0.3187251091003418, -0.4626254439353943, 0.19331204891204834, -0.27462875843048096, -0.29094552993774414, 0.21727555990219116, 0.02360779047012329, 0.2866835594177246, -0.17656338214874268, -0.3783490061759949]), layer_2 = (weight = [0.2436264604330063 -0.0680389329791069 … 0.04271404445171356 0.06893505156040192; 0.14572003483772278 -0.21583612263202667 … -0.03750962018966675 -0.1946410834789276; … ; -0.04651452228426933 -0.03647108003497124 … -0.1372247040271759 0.2776201069355011; -0.06958559900522232 0.02185145393013954 … 0.15379008650779724 -0.1415681689977646], bias = [0.04782143607735634, -0.1012996956706047, -0.1567249596118927, -0.15964087843894958, 0.05925853177905083, -0.11047711223363876, -0.1458110213279724, 0.05297053977847099, -0.055408038198947906, -0.07372841238975525  …  -0.17655904591083527, 0.13326048851013184, -0.11741387099027634, 0.0318475067615509, 0.03633865341544151, 0.050737977027893066, -0.13936328887939453, 0.1765834093093872, 0.15287524461746216, 0.16996905207633972]), layer_3 = (weight = [0.2569832503795624 0.044006261974573135 … 0.2960079312324524 0.26922568678855896; -0.23582160472869873 -0.1548907458782196 … 0.1921408623456955 0.1450984627008438; … ; -0.1138150542974472 0.2908233106136322 … -0.06212691590189934 0.05998731032013893; 0.047481339424848557 0.010993288829922676 … 0.24803538620471954 0.08838599175214767], bias = [0.1743733137845993, 0.1512034833431244, 0.06931287050247192, -0.08792513608932495, 0.016885502263903618, -0.047577153891325, -0.014746191911399364, 0.12522418797016144, 0.018794501200318336, -0.15208648145198822  …  -0.03305258974432945, 0.07404419779777527, -0.045243650674819946, -0.16815847158432007, 0.030172569677233696, 0.0471804253757, -0.06609272956848145, 0.1692200005054474, -0.1101473718881607, 0.16186214983463287]), layer_4 = (weight = [-0.30527234077453613 -0.09309124201536179 … -0.02350020594894886 -0.19887332618236542; 0.1241290420293808 -0.004951805341988802 … -0.2885815501213074 -0.16537760198116302; … ; -0.29496872425079346 -0.28880730271339417 … 0.16195683181285858 0.10213395953178406; 0.09368415176868439 -0.16355587542057037 … -0.29843971133232117 -0.12237031012773514], bias = [-0.13972108066082, -0.1584814488887787, -0.09499998390674591, -0.07104304432868958, 0.03547034412622452, 0.06126215308904648, -0.04893474653363228, 0.11462417244911194])), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), NeuralPDE.numeric_derivative, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0), Vector{Any}[[:x, :y, :z, :t], [:x, :y, :z, :t], [:x, :y, :z, :t], [:x, :y, :z, :t]], Vector{Any}[[:y, :z, :t], [:y, :z, :t], [:x, :z, :t], [:x, :z, :t], [:x, :y, :t], [:x, :y, :t], [:y, :z, :t], [:y, :z, :t], [:y, :z, :t], [], [], []], [[:t, :x, :y, :z], [:t, :x, :y, :z], [:t, :x, :y, :z], [:t, :x, :y, :z]], [[:t, :y, :z], [:t, :y, :z], [:t, :x, :z], [:t, :x, :z], [:t, :x, :y], [:t, :x, :y], [:t, :y, :z], [:t, :y, :z], [:t, :y, :z], Symbol[], Symbol[], Symbol[]], NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), Expr[:((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord5 = vcat(x, y, z, t)\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  (+).((+).((+).(derivative(phi, u, cord1, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord1, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord1, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))), derivative(phi, u, cord1, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\")) .- (*).(-1.27556484025426e22, u(cord5, var\"##θ#230\", phi))\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord6 = vcat(x, y, z, t)\n",
       "                      cord2 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  (+).((+).((+).(derivative(phi, u, cord2, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord2, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\")), derivative(phi, u, cord2, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord2, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))) .- (*).(-1.5791367040840272e-12, u(cord6, var\"##θ#230\", phi))\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord7 = vcat(x, y, z, t)\n",
       "                      cord3 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  (+).((+).((+).(derivative(phi, u, cord3, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord3, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord3, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))), derivative(phi, u, cord3, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-1.5791367040840272e-12, u(cord7, var\"##θ#230\", phi))\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord4 = vcat(x, y, z, t)\n",
       "                      cord8 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  (+).((+).((+).(derivative(phi, u, cord4, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord4, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord4, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))), derivative(phi, u, cord4, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-1.5791367040840272e-12, u(cord8, var\"##θ#230\", phi))\n",
       "              end\n",
       "          end\n",
       "      end)], Expr[:((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord2 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord2, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord3 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord3, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord4 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord4, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 1.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- -1.0\n",
       "              end\n",
       "          end\n",
       "      end)], NeuralPDE.PINNLossFunctions(NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function[NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-10.0, -9.999755859375, -9.999755859375, 0.000244140625], [-10.0, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([10.0, -9.999755859375, -9.999755859375, 0.000244140625], [10.0, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, -10.0, -9.999755859375, 0.000244140625], [9.999755859375, -10.0, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, 10.0, -9.999755859375, 0.000244140625], [9.999755859375, 10.0, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, -9.999755859375, -10.0, 0.000244140625], [9.999755859375, 9.999755859375, -10.0, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, -9.999755859375, 10.0, 0.000244140625], [9.999755859375, 9.999755859375, 10.0, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord2, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-10.0, -9.999755859375, -9.999755859375, 0.000244140625], [-10.0, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord3, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-10.0, -9.999755859375, -9.999755859375, 0.000244140625], [-10.0, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord4, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-10.0, -9.999755859375, -9.999755859375, 0.000244140625], [-10.0, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xee6fc6f6, 0x2b8aa29e, 0xa9079ea6, 0x7e4f5774, 0x3a9b766b), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xee6fc6f6, 0x2b8aa29e, 0xa9079ea6, 0x7e4f5774, 0x3a9b766b), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xee6fc6f6, 0x2b8aa29e, 0xa9079ea6, 0x7e4f5774, 0x3a9b766b), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 1.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([0.5, 0.5, 0.5, 0.0], [0.5, 0.5, 0.5, 0.0]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([0.2, 0.3, 0.4, 0.0], [0.2, 0.3, 0.4, 0.0]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x56ef1bbb, 0x52d6cc1a, 0x8bf3e6cd, 0x62c0a9ed, 0xc339932a), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x56ef1bbb, 0x52d6cc1a, 0x8bf3e6cd, 0x62c0a9ed, 0xc339932a), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x56ef1bbb, 0x52d6cc1a, 0x8bf3e6cd, 0x62c0a9ed, 0xc339932a), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- -1.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([0.8, 0.7, 0.6, 0.0], [0.8, 0.7, 0.6, 0.0]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()))], NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function[NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x52d789fe, 0xe3bd821f, 0x80eac8bc, 0xe46a910f, 0x8d48122f), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x52d789fe, 0xe3bd821f, 0x80eac8bc, 0xe46a910f, 0x8d48122f), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x52d789fe, 0xe3bd821f, 0x80eac8bc, 0xe46a910f, 0x8d48122f), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord5 = vcat(x, y, z, t)\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord1, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord1, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord1, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))), derivative(phi, u, cord1, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\")) .- (*).(-1.27556484025426e22, u(cord5, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, -9.999755859375, -9.999755859375, 0.000244140625], [9.999755859375, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xace7eea2, 0x047e59de, 0x96bc610f, 0x08ef332a, 0x681d5ca6), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xace7eea2, 0x047e59de, 0x96bc610f, 0x08ef332a, 0x681d5ca6), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xace7eea2, 0x047e59de, 0x96bc610f, 0x08ef332a, 0x681d5ca6), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord6 = vcat(x, y, z, t)\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord2, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord2, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\")), derivative(phi, u, cord2, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord2, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))) .- (*).(-1.5791367040840272e-12, u(cord6, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, -9.999755859375, -9.999755859375, 0.000244140625], [9.999755859375, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x92c5b462, 0x905f0d07, 0xb877a947, 0xaea1c1f8, 0xcef0a9fe), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x92c5b462, 0x905f0d07, 0xb877a947, 0xaea1c1f8, 0xcef0a9fe), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x92c5b462, 0x905f0d07, 0xb877a947, 0xaea1c1f8, 0xcef0a9fe), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord7 = vcat(x, y, z, t)\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord3, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord3, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord3, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))), derivative(phi, u, cord3, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-1.5791367040840272e-12, u(cord7, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, -9.999755859375, -9.999755859375, 0.000244140625], [9.999755859375, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x856ba2a0, 0xd7245214, 0x5176c3ea, 0xa1796bc1, 0xb488eb0c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x856ba2a0, 0xd7245214, 0x5176c3ea, 0xa1796bc1, 0xb488eb0c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x856ba2a0, 0xd7245214, 0x5176c3ea, 0xa1796bc1, 0xb488eb0c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "                cord8 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord4, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord4, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord4, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))), derivative(phi, u, cord4, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-1.5791367040840272e-12, u(cord8, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, -9.999755859375, -9.999755859375, 0.000244140625], [9.999755859375, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()))], NeuralPDE.var\"#full_loss_function#283\"{Returns{Nothing}, Vector{NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function}, Vector{NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function}, NeuralPDE.PINNRepresentation, Int64, Bool, Base.RefValue{Int64}, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing, Bool}(Returns{Nothing}(nothing), NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function[NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-10.0, -9.999755859375, -9.999755859375, 0.000244140625], [-10.0, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([10.0, -9.999755859375, -9.999755859375, 0.000244140625], [10.0, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, -10.0, -9.999755859375, 0.000244140625], [9.999755859375, -10.0, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, 10.0, -9.999755859375, 0.000244140625], [9.999755859375, 10.0, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, -9.999755859375, -10.0, 0.000244140625], [9.999755859375, 9.999755859375, -10.0, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, -9.999755859375, 10.0, 0.000244140625], [9.999755859375, 9.999755859375, 10.0, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord2, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-10.0, -9.999755859375, -9.999755859375, 0.000244140625], [-10.0, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord3, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-10.0, -9.999755859375, -9.999755859375, 0.000244140625], [-10.0, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord4, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-10.0, -9.999755859375, -9.999755859375, 0.000244140625], [-10.0, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xee6fc6f6, 0x2b8aa29e, 0xa9079ea6, 0x7e4f5774, 0x3a9b766b), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xee6fc6f6, 0x2b8aa29e, 0xa9079ea6, 0x7e4f5774, 0x3a9b766b), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xee6fc6f6, 0x2b8aa29e, 0xa9079ea6, 0x7e4f5774, 0x3a9b766b), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 1.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([0.5, 0.5, 0.5, 0.0], [0.5, 0.5, 0.5, 0.0]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([0.2, 0.3, 0.4, 0.0], [0.2, 0.3, 0.4, 0.0]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x56ef1bbb, 0x52d6cc1a, 0x8bf3e6cd, 0x62c0a9ed, 0xc339932a), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x56ef1bbb, 0x52d6cc1a, 0x8bf3e6cd, 0x62c0a9ed, 0xc339932a), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x56ef1bbb, 0x52d6cc1a, 0x8bf3e6cd, 0x62c0a9ed, 0xc339932a), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- -1.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([0.8, 0.7, 0.6, 0.0], [0.8, 0.7, 0.6, 0.0]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()))], NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function[NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x52d789fe, 0xe3bd821f, 0x80eac8bc, 0xe46a910f, 0x8d48122f), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x52d789fe, 0xe3bd821f, 0x80eac8bc, 0xe46a910f, 0x8d48122f), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x52d789fe, 0xe3bd821f, 0x80eac8bc, 0xe46a910f, 0x8d48122f), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord5 = vcat(x, y, z, t)\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord1, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord1, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord1, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))), derivative(phi, u, cord1, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\")) .- (*).(-1.27556484025426e22, u(cord5, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, -9.999755859375, -9.999755859375, 0.000244140625], [9.999755859375, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xace7eea2, 0x047e59de, 0x96bc610f, 0x08ef332a, 0x681d5ca6), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xace7eea2, 0x047e59de, 0x96bc610f, 0x08ef332a, 0x681d5ca6), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xace7eea2, 0x047e59de, 0x96bc610f, 0x08ef332a, 0x681d5ca6), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord6 = vcat(x, y, z, t)\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord2, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord2, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\")), derivative(phi, u, cord2, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord2, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))) .- (*).(-1.5791367040840272e-12, u(cord6, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, -9.999755859375, -9.999755859375, 0.000244140625], [9.999755859375, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x92c5b462, 0x905f0d07, 0xb877a947, 0xaea1c1f8, 0xcef0a9fe), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x92c5b462, 0x905f0d07, 0xb877a947, 0xaea1c1f8, 0xcef0a9fe), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x92c5b462, 0x905f0d07, 0xb877a947, 0xaea1c1f8, 0xcef0a9fe), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord7 = vcat(x, y, z, t)\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord3, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord3, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord3, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))), derivative(phi, u, cord3, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-1.5791367040840272e-12, u(cord7, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, -9.999755859375, -9.999755859375, 0.000244140625], [9.999755859375, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x856ba2a0, 0xd7245214, 0x5176c3ea, 0xa1796bc1, 0xb488eb0c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float64}, Vector{Float64}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x856ba2a0, 0xd7245214, 0x5176c3ea, 0xa1796bc1, 0xb488eb0c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x856ba2a0, 0xd7245214, 0x5176c3ea, 0xa1796bc1, 0xb488eb0c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "                cord8 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord4, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord4, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord4, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))), derivative(phi, u, cord4, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-1.5791367040840272e-12, u(cord8, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), ([-9.999755859375, -9.999755859375, -9.999755859375, 0.000244140625], [9.999755859375, 9.999755859375, 9.999755859375, 0.999755859375]), Float64, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()))], NeuralPDE.PINNRepresentation(#= circular reference @-3 =#), Core.Box(NonAdaptiveLoss{Float64}([1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], Float64[])), 50, true, Base.RefValue{Int64}(1), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing, false), nothing, NeuralPDE.var\"#197#198\"{_loss_function, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing} where _loss_function[NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x52d789fe, 0xe3bd821f, 0x80eac8bc, 0xe46a910f, 0x8d48122f), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x52d789fe, 0xe3bd821f, 0x80eac8bc, 0xe46a910f, 0x8d48122f), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord5 = vcat(x, y, z, t)\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord1, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord1, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord1, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))), derivative(phi, u, cord1, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\")) .- (*).(-1.27556484025426e22, u(cord5, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xace7eea2, 0x047e59de, 0x96bc610f, 0x08ef332a, 0x681d5ca6), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xace7eea2, 0x047e59de, 0x96bc610f, 0x08ef332a, 0x681d5ca6), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord6 = vcat(x, y, z, t)\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord2, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord2, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\")), derivative(phi, u, cord2, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord2, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))) .- (*).(-1.5791367040840272e-12, u(cord6, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x92c5b462, 0x905f0d07, 0xb877a947, 0xaea1c1f8, 0xcef0a9fe), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x92c5b462, 0x905f0d07, 0xb877a947, 0xaea1c1f8, 0xcef0a9fe), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord7 = vcat(x, y, z, t)\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord3, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord3, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord3, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))), derivative(phi, u, cord3, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-1.5791367040840272e-12, u(cord7, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x856ba2a0, 0xd7245214, 0x5176c3ea, 0xa1796bc1, 0xb488eb0c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x856ba2a0, 0xd7245214, 0x5176c3ea, 0xa1796bc1, 0xb488eb0c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "                cord8 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord4, [[0.0, 0.0, 0.0001220703125, 0.0], [0.0, 0.0, 0.0001220703125, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord4, [[0.0, 0.0001220703125, 0.0, 0.0], [0.0, 0.0001220703125, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.2379901471139933e-34, derivative(phi, u, cord4, [[0.0, 0.0, 0.0, 0.0001220703125], [0.0, 0.0, 0.0, 0.0001220703125]], 2, var\"##θ#230\"))), derivative(phi, u, cord4, [[0.0001220703125, 0.0, 0.0, 0.0], [0.0001220703125, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-1.5791367040840272e-12, u(cord8, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing)], NeuralPDE.var\"#197#198\"{_loss_function, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing} where _loss_function[NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord2, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord3, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord4, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xee6fc6f6, 0x2b8aa29e, 0xa9079ea6, 0x7e4f5774, 0x3a9b766b), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xee6fc6f6, 0x2b8aa29e, 0xa9079ea6, 0x7e4f5774, 0x3a9b766b), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 1.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x56ef1bbb, 0x52d6cc1a, 0x8bf3e6cd, 0x62c0a9ed, 0xc339932a), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x56ef1bbb, 0x52d6cc1a, 0x8bf3e6cd, 0x62c0a9ed, 0xc339932a), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- -1.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing)]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = discretize(pde_system, discretization)\n",
    "sym_prob = symbolic_discretize(pde_system, discretization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21235add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#13 (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pde_inner_loss_functions = sym_prob.loss_functions.pde_loss_functions\n",
    "bcs_inner_loss_functions = sym_prob.loss_functions.bc_loss_functions\n",
    "\n",
    "callback = function (p, l)\n",
    "    println(\"loss: \", l)\n",
    "    println(\"pde_losses: \", map(l_ -> l_(p.u), pde_inner_loss_functions))\n",
    "    println(\"bcs_losses: \", map(l_ -> l_(p.u), bcs_inner_loss_functions))\n",
    "    return false\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d8b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam(0.01, (0.9, 0.999), 1.0e-8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оптимизация\n",
    "opt = OptimizationOptimisers.Adam(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.024886251979774e43\n",
      "pde_losses: [4.025020562575494e43, 5.6009600936029174e-6, 5.733427505257786e-6, 5.6484676277153615e-6]\n",
      "bcs_losses: [0.251062689842218, 0.24394682346423113, 0.2554834235095773, 0.23974781742980156, 0.2432677703734727, 0.2510249410183376, 0.2510555644320924, 0.25101565940565396, 0.2509814971880835, 0.9769096582995062, 0.24820225852728864, 1.5169892307817319]\n",
      "loss: 1.3955180412244277e43\n",
      "pde_losses: [1.3961030161793641e43, 5.5798397864884894e-6, 5.549310916626425e-6, 5.544727151750137e-6]\n",
      "bcs_losses: [0.08649250353215895, 0.08492788334675747, 0.09070473808633045, 0.08134360462062673, 0.08510908584907098, 0.08622714532303652, 0.08647719602488878, 0.08646429368163902, 0.08644195831745372, 0.9445412799252517, 0.08563853013848145, 1.225573940915099]\n",
      "loss: 3.159434331876468e42\n",
      "pde_losses: [3.156448437105992e42, 5.164011393871908e-6, 5.2233375437172946e-6, 5.280756116591959e-6]\n",
      "bcs_losses: [0.019009597858451195, 0.019389877199159647, 0.021032191824273197, 0.018097929829597417, 0.01924329145841902, 0.019575771507255837, 0.019008422700913005, 0.019025311747519112, 0.01901672626922263, 0.9932093718000408, 0.01914713240723288, 1.0449326133804497]\n",
      "loss: 2.2590447777324267e42\n",
      "pde_losses: [2.2656381841959597e42, 4.862220980070399e-6, 4.843620955495154e-6, 4.969753233449091e-6]\n",
      "bcs_losses: [0.013286573049832532, 0.014084739464360077, 0.012927950057603856, 0.01516119125229915, 0.013102902094451562, 0.014632396253555818, 0.013326373206201827, 0.013312830712773045, 0.013313168249903452, 1.0443163060313525, 0.013850607351403232, 0.9840040283825816]\n",
      "loss: 4.95152749931144e42\n",
      "pde_losses: [4.94763677570944e42, 4.567020159635388e-6, 4.525002892808267e-6, 4.550163191387855e-6]\n",
      "bcs_losses: [0.029986385085459467, 0.03063458648185636, 0.02774827545404162, 0.0331899328278829, 0.029125652739957996, 0.031454361301227085, 0.02999882825765006, 0.030032498527033807, 0.030012546538494132, 1.0789626206936846, 0.03053922868104516, 0.9832521852994038]\n",
      "loss: 7.217455207351039e42\n",
      "pde_losses: [7.220323021027804e42, 4.342528309595038e-6, 4.399271692951174e-6, 4.312152561974577e-6]\n",
      "bcs_losses: [0.04429745022823382, 0.044512671604861054, 0.04091065555436257, 0.048001706177475525, 0.04296498953922474, 0.04552572787461981, 0.044303425956670694, 0.04428553530764266, 0.044298289420904746, 1.102726832797695, 0.04457388868706173, 0.9878094300901183]\n",
      "loss: 7.883767320817198e42\n",
      "pde_losses: [7.884159474129853e42, 4.127627231955595e-6, 4.137386977260784e-6, 4.129126270861974e-6]\n",
      "bcs_losses: [0.04874845544712807, 0.048331763593822394, 0.044645452739852, 0.05247359399945005, 0.04704860525777402, 0.04960112971665134, 0.048782934756512825, 0.04874896950493302, 0.04876894210168316, 1.1212573601993618, 0.04867613614571185, 0.9775076565931664]\n",
      "loss: 7.254274400701853e42\n",
      "pde_losses: [7.256028349979489e42, 4.0140904753645635e-6, 3.979301971716922e-6, 4.017179315525983e-6]\n",
      "bcs_losses: [0.04521649114880136, 0.04417150579343313, 0.040791552632670244, 0.04865108157698754, 0.043273739890401314, 0.045672115976371996, 0.045220620184773644, 0.045205594808258046, 0.04523273193767861, 1.1337628779061577, 0.04478161985015786, 0.9570880632684691]\n",
      "loss: 5.927690700482651e42\n",
      "pde_losses: [5.928336719873899e42, 3.9354556436717395e-6, 3.9178454327063014e-6, 3.995694393763811e-6]\n",
      "bcs_losses: [0.03724673086837783, 0.035839474936862875, 0.03300664171725443, 0.04016661177551705, 0.0354258181827793, 0.03731038798918247, 0.03725277276196509, 0.03725387166189253, 0.037242951700438814, 1.1357030282605984, 0.03655403758385614, 0.9384868906600771]\n",
      "loss: 4.293962247173737e42\n",
      "pde_losses: [4.292053243472027e42, 3.9729910925621124e-6, 3.98169828921473e-6, 3.899899145496845e-6]\n",
      "bcs_losses: [0.02720513036281961, 0.025725730669469808, 0.023620607841825295, 0.029458417675068488, 0.025856508098119874, 0.02688981671457068, 0.0271992679405486, 0.02720355954470427, 0.027194695712708314, 1.125081375430432, 0.02637213882347688, 0.9285067455697403]\n",
      "loss: 2.6796458655985312e42\n",
      "pde_losses: [2.6816385660789765e42, 3.971547417616067e-6, 3.879346067526289e-6, 3.903484769530424e-6]\n",
      "bcs_losses: [0.017150655860330592, 0.01589428383295479, 0.014622477313353824, 0.018642684018587652, 0.01649308844423408, 0.01651738727755645, 0.017162054533763765, 0.017149522272917998, 0.017144466356631, 1.1031229288186595, 0.016323358629559262, 0.9301333327076016]\n",
      "loss: 1.4249131871492447e42\n",
      "pde_losses: [1.4222462699230895e42, 3.830223877226405e-6, 3.899745184235668e-6, 3.89408402274429e-6]\n",
      "bcs_losses: [0.009192718635535587, 0.008335686843908785, 0.007878379355523147, 0.009917782903909106, 0.009206030987355483, 0.008345977265228115, 0.009196312739684664, 0.009194696662890814, 0.00920609421071336, 1.0738570557614824, 0.00846894242113586, 0.9434844569706383]\n",
      "loss: 7.291261161597954e41\n",
      "pde_losses: [7.251548405603447e41, 3.824866111117933e-6, 3.786632257224585e-6, 3.8348924022783194e-6]\n",
      "bcs_losses: [0.004698089776477287, 0.004283207834714572, 0.00456449216532744, 0.0046966358549719225, 0.005257578987956225, 0.003790781392527999, 0.004687867119216543, 0.004701566917991052, 0.004700346407318186, 1.0432006561829545, 0.004152137791894182, 0.9653435021650576]\n",
      "loss: 6.0524516145988445e41\n",
      "pde_losses: [6.0803645667203684e41, 3.7769042015761735e-6, 3.8067390967128636e-6, 3.7213647417905066e-6]\n",
      "bcs_losses: [0.003762468696637003, 0.0036988378400258236, 0.004555338468371691, 0.0031438269037766483, 0.004541844136507933, 0.0028984903379869415, 0.00377131055910821, 0.003771794631123532, 0.0037702134883637484, 1.0167332263173026, 0.0034084161855227487, 0.9902072326185414]\n",
      "loss: 8.901357164030993e41\n",
      "pde_losses: [8.871168446451612e41, 3.7653545601736916e-6, 3.7332879254644837e-6, 3.7656568638609837e-6]\n",
      "bcs_losses: [0.0053767954012945655, 0.005547644661955982, 0.006777921748945355, 0.004336365986551904, 0.006101128460345034, 0.004726261253731395, 0.00539712420838415, 0.005400122376467566, 0.005386785013186521, 0.9971718253771373, 0.005215177995001094, 1.0133136288103968]\n",
      "loss: 1.3544350620943814e42\n",
      "pde_losses: [1.355207866232395e42, 3.7251607175951415e-6, 3.6222065656256217e-6, 3.599013205321916e-6]\n",
      "bcs_losses: [0.008225934623403678, 0.00846365333917241, 0.009878677483324626, 0.006915437550332143, 0.008702810035090767, 0.007803796056466062, 0.008233740551310523, 0.008226824821102329, 0.008230847991906418, 0.9839162627308184, 0.008186951992651275, 1.0324881150349714]\n",
      "loss: 1.7995890816520745e42\n",
      "pde_losses: [1.7979474747234733e42, 3.5638249197941992e-6, 3.5293406372264646e-6, 3.535564991432522e-6]\n",
      "bcs_losses: [0.01096050103485198, 0.011179090937856578, 0.012612640327105278, 0.00957427587065126, 0.011125754707362202, 0.010787134151880356, 0.01095298427005785, 0.010957519014870807, 0.010959036855409852, 0.9742777993867919, 0.011009893175544235, 1.0477852632611526]\n",
      "loss: 2.0513509743515227e42\n",
      "pde_losses: [2.0537270312222876e42, 3.4661908397588258e-6, 3.465584244148137e-6, 3.4509628986444247e-6]\n",
      "bcs_losses: [0.012545113555916433, 0.012723088361744973, 0.01403592956336116, 0.011234580887871645, 0.0124306992089241, 0.0125923963494315, 0.01253866075089624, 0.012543417877591282, 0.012550554437088114, 0.9649604264412268, 0.012642162789843847, 1.0604104834676598]\n",
      "loss: 2.028536273240663e42\n",
      "pde_losses: [2.0296274742808126e42, 3.4489935836434092e-6, 3.3877088497361665e-6, 3.430485036835367e-6]\n",
      "bcs_losses: [0.01243277288078142, 0.01254849928147768, 0.013679175426455878, 0.011280085871309494, 0.012111291757729074, 0.012637878455353309, 0.01243516206151786, 0.012428627085609689, 0.012427825443108286, 0.9539956351566639, 0.012535753936652289, 1.0712287001847602]\n",
      "loss: 1.7487948423057777e42\n",
      "pde_losses: [1.7488740427295624e42, 3.35349429541144e-6, 3.2647155317909945e-6, 3.329984982145546e-6]\n",
      "bcs_losses: [0.010730073473713346, 0.010810821436592628, 0.011709334651519798, 0.009802631321164651, 0.01029324863201789, 0.011031984492365421, 0.010736049365285785, 0.01073535278244096, 0.010734686130798157, 0.9422187326054076, 0.010822773127569765, 1.079660192056592]\n",
      "loss: 1.3225627923520485e42\n",
      "pde_losses: [1.3235333102232807e42, 3.2056101347925806e-6, 3.2272581285083038e-6, 3.17983864057976e-6]\n",
      "bcs_losses: [0.00814115803659762, 0.00818080200500525, 0.008827494525113732, 0.007452315958689681, 0.007655333173555866, 0.008475698391306505, 0.00814055014596356, 0.008139776626223203, 0.008140389568368506, 0.9329082024374739, 0.008200004500366651, 1.0838094914726284]\n",
      "loss: 8.871610893053798e41\n",
      "pde_losses: [8.860882841890593e41, 3.1544576097131237e-6, 3.1713368825738794e-6, 3.0812422041004285e-6]\n",
      "bcs_losses: [0.005471031307243657, 0.005493852681227998, 0.005889684361230519, 0.005052220917691133, 0.00500828692392105, 0.005799325156773706, 0.005470841543965802, 0.005471870769478448, 0.005470162393823041, 0.9299122813818734, 0.005503868800140115, 1.0814911821093331]\n",
      "loss: 5.378405725235952e41\n",
      "pde_losses: [5.382525629692081e41, 3.1306732224144083e-6, 3.0732824074349795e-6, 3.0902506664859643e-6]\n",
      "bcs_losses: [0.0033329056161899963, 0.003349078175845323, 0.0034970253261926813, 0.003179313283537554, 0.0029244912615319757, 0.0036317798252701455, 0.003334934990164374, 0.003332980720800237, 0.0033319455394066515, 0.9359895398729222, 0.0033431881063679266, 1.0711559856889488]\n",
      "loss: 3.202604921387754e41\n",
      "pde_losses: [3.210338910728258e41, 2.971470372570287e-6, 2.941824199610723e-6, 3.009733817568726e-6]\n",
      "bcs_losses: [0.00199644737462019, 0.002007323683247458, 0.001936178515284805, 0.0020810280127086765, 0.0016562033370137222, 0.002260779800803188, 0.001992324280387371, 0.001991367482747738, 0.001992100034151484, 0.951555113973104, 0.0019913650271558407, 1.052929564885146]\n",
      "loss: 2.350190333024548e41\n",
      "pde_losses: [2.3502947004224412e41, 2.9483797590206163e-6, 2.9665209974673527e-6, 2.9634299945115897e-6]\n",
      "bcs_losses: [0.001460199458492574, 0.0014778852201115667, 0.0012296942191796587, 0.001753200251322579, 0.0011889868838699078, 0.0017066917215889682, 0.0014604454254216106, 0.0014604012140947784, 0.0014595186277797149, 0.9744397000181116, 0.0014566545322857206, 1.0289961689789546]\n",
      "loss: 2.5547927008524382e41\n",
      "pde_losses: [2.5523391851200873e41, 2.886691265138248e-6, 2.8993707672823196e-6, 2.9116452971250255e-6]\n",
      "bcs_losses: [0.001572865235080806, 0.0015939895113368141, 0.00122555350812555, 0.0020066514514801063, 0.0013549461752204077, 0.0018096532444143382, 0.0015710790212759044, 0.001572313901880703, 0.00157191415075922, 1.0005814967013769, 0.0015713764440661603, 1.0030871193208073]\n",
      "loss: 3.357101271670073e41\n",
      "pde_losses: [3.3579117337142804e41, 2.7982352079496375e-6, 2.8550891630542e-6, 2.8293332768758297e-6]\n",
      "bcs_losses: [0.002051551270810016, 0.002084679355496286, 0.0016531167430864338, 0.0025677056309291583, 0.0018791594554677183, 0.0022878100408290506, 0.00205250611652324, 0.0020511980195895467, 0.0020524488538081935, 1.0252469331589111, 0.0020554309790214815, 0.9793824407761738]\n",
      "loss: 4.265339348693164e41\n",
      "pde_losses: [4.269748394562197e41, 2.8223747967076074e-6, 2.8394088634478068e-6, 2.772387444306501e-6]\n",
      "bcs_losses: [0.0025954647041666968, 0.002638994276423231, 0.0022037758511868604, 0.003126156460249413, 0.002473119476870327, 0.0028210863138325073, 0.0025958329863447036, 0.0025959408324297897, 0.002597135395490939, 1.0442556728538133, 0.0025960226214737946, 0.9614438627536117]\n",
      "loss: 4.8744256691844755e41\n",
      "pde_losses: [4.868833836022054e41, 2.777063208736621e-6, 2.7934115276963426e-6, 2.761368580276754e-6]\n",
      "bcs_losses: [0.0029614475591339846, 0.003007109416651287, 0.002617120609753514, 0.0034456289858486224, 0.0028965094951053775, 0.0031576097791124165, 0.002960579875351053, 0.002959043428312211, 0.0029577857254860134, 1.0551252547348824, 0.002944542913184904, 0.951260815734577]\n",
      "loss: 5.004143007183181e41\n",
      "pde_losses: [5.002168007762749e41, 2.7001402578995355e-6, 2.735434675310553e-6, 2.6891340391366257e-6]\n",
      "bcs_losses: [0.003032085714878014, 0.0030765860721866743, 0.002769869017922303, 0.003434354238049983, 0.003046811251472481, 0.0031683222214250375, 0.0030307367426209127, 0.00303221616327034, 0.00303341324453412, 1.0574317932646535, 0.0029902470625570387, 0.9490381635997144]\n",
      "loss: 4.691719092221037e41\n",
      "pde_losses: [4.692848717816556e41, 2.699827632536012e-6, 2.697580488481909e-6, 2.7431463628741773e-6]\n",
      "bcs_losses: [0.00284312312752297, 0.0028814940710367946, 0.0026789417964449332, 0.0031424196269866766, 0.002950556620202405, 0.0029040634579002803, 0.0028425706450592725, 0.0028444205314919566, 0.002842613702041918, 1.0525112593634174, 0.002771933130385499, 0.9535173414234641]\n",
      "loss: 4.164409731391649e41\n",
      "pde_losses: [4.164297030554577e41, 2.6518998129604944e-6, 2.660829213082489e-6, 2.6240101237575987e-6]\n",
      "bcs_losses: [0.0025176242878210426, 0.0025460547768250547, 0.0024458900499147417, 0.0027075666496478665, 0.002712483548135608, 0.0024928134108475088, 0.0025191585576826666, 0.0025228902563392726, 0.0025177511210883264, 1.0427397378918837, 0.002416742014127754, 0.9625759715282631]\n",
      "loss: 3.585214107957165e41\n",
      "pde_losses: [3.5761867156258716e41, 2.603409989173501e-6, 2.610922887400011e-6, 2.640706813289885e-6]\n",
      "bcs_losses: [0.0021647580335118735, 0.0021814084480744167, 0.0021813598874584664, 0.0022568947284973633, 0.002423619495227848, 0.0020621564589434205, 0.0021592051956080198, 0.00216410867473849, 0.002160558296674338, 1.0306609827005475, 0.0020410906708350687, 0.9739029437824055]\n",
      "loss: 3.011041988521077e41\n",
      "pde_losses: [3.007371504917594e41, 2.571972844543572e-6, 2.5603336964439513e-6, 2.5846320248358596e-6]\n",
      "bcs_losses: [0.001807458721137014, 0.0018295094759317927, 0.0018977518112015268, 0.0018279393585399215, 0.0021163233988886736, 0.001664751047886424, 0.001811606903749431, 0.0018117488947147061, 0.0018052359263274337, 1.0184424401439802, 0.0016822715019948879, 0.9854054489790285]\n",
      "loss: 2.405448414909033e41\n",
      "pde_losses: [2.399173796115034e41, 2.573416745078557e-6, 2.571378078920719e-6, 2.6074152285131694e-6]\n",
      "bcs_losses: [0.0014365170196121782, 0.0014677526275379818, 0.0015858291690547094, 0.0013991696750905026, 0.0017484711657314526, 0.0012855149318083334, 0.0014377041001653035, 0.0014340543842388783, 0.0014403365484729146, 1.007609133907697, 0.00132004737361159, 0.9955179534254759]\n",
      "loss: 1.773075179537287e41\n",
      "pde_losses: [1.778333046161078e41, 2.556968286010858e-6, 2.5482113566615333e-6, 2.5219182915160505e-6]\n",
      "bcs_losses: [0.001052297238505094, 0.001092153391413312, 0.001232022834353698, 0.0009761189045346477, 0.00133079653036818, 0.000922587156715931, 0.0010516308236720767, 0.0010517911776954047, 0.0010512506751495134, 0.999125803263216, 0.0009525433843849639, 1.0032706586553424]\n",
      "loss: 1.2104194234800493e41\n",
      "pde_losses: [1.2097474384119758e41, 2.52516419941784e-6, 2.5516005040575275e-6, 2.5179236051954105e-6]\n",
      "bcs_losses: [0.0007084243097256846, 0.0007554114417795091, 0.0009022303726551241, 0.0006077781563647471, 0.0009286676054086592, 0.0006209904761010399, 0.0007104716699738203, 0.0007074705804476715, 0.0007105494675285213, 0.9933275317142692, 0.0006331377355104214, 1.0084341670543506]\n",
      "loss: 8.292024092596238e40\n",
      "pde_losses: [8.268650892307269e40, 2.505126712090707e-6, 2.5394846786617234e-6, 2.5729005340671778e-6]\n",
      "bcs_losses: [0.0004868725058920975, 0.0005254934550801965, 0.000669547677754391, 0.0003721352976708907, 0.0006211861440379967, 0.0004419187763611245, 0.00048821863032615185, 0.00048818036502941935, 0.0004882223282624053, 0.9901417939369305, 0.0004325400741912909, 1.0112211291962976]\n",
      "loss: 6.950751504623971e40\n",
      "pde_losses: [6.948836071955862e40, 2.4937478597704802e-6, 2.496156658691333e-6, 2.537932451600249e-6]\n",
      "bcs_losses: [0.00042620473914201085, 0.000442252066010669, 0.0005750612858452912, 0.00030385957556870193, 0.0004658204733289375, 0.0004145467652661638, 0.0004283715770740228, 0.00042743796109044905, 0.0004257805684572342, 0.9890744242289335, 0.0003866387921252519, 1.0121971396332565]\n",
      "loss: 7.94401821992019e40\n",
      "pde_losses: [7.938822229408395e40, 2.516903540938348e-6, 2.5476177127486398e-6, 2.436549915351916e-6]\n",
      "bcs_losses: [0.0005079952295502896, 0.0004972220000669819, 0.0006141807008139043, 0.00038865349854513197, 0.000465461077863971, 0.0005203534901484299, 0.0005118807630467771, 0.0005086755713320962, 0.0005100139789378782, 0.9892994679515728, 0.0004810477946468858, 1.012160628555791]\n",
      "loss: 1.0403974233932828e41\n",
      "pde_losses: [1.0432319091720447e41, 2.501170591488384e-6, 2.434399280467784e-6, 2.4700621727011754e-6]\n",
      "bcs_losses: [0.0006858896624582116, 0.0006371463717778571, 0.000739133958183532, 0.0005723871877202899, 0.0005723661686302513, 0.0007030412000620834, 0.0006854117476999733, 0.0006907253709755903, 0.0006884533829649268, 0.989905091539075, 0.0006622962853503579, 1.011918760127886]\n",
      "loss: 1.3142255578625572e41\n",
      "pde_losses: [1.3180282918817796e41, 2.450647129527069e-6, 2.412999277879015e-6, 2.4357805366213353e-6]\n",
      "bcs_losses: [0.0008678976358076232, 0.0007990046465448399, 0.0008784134699487035, 0.0007732652406513238, 0.0007150996164428027, 0.00088539562984076, 0.0008735007560817514, 0.0008721034722440732, 0.0008733111042427716, 0.9902264038678844, 0.0008507276809162857, 1.0119789992115524]\n",
      "loss: 1.4851837413834191e41\n",
      "pde_losses: [1.492081664178594e41, 2.386038638980362e-6, 2.399000988270766e-6, 2.3714981137058223e-6]\n",
      "bcs_losses: [0.0009867105436686253, 0.0008959615047664752, 0.0009556496863324025, 0.0009063893484610873, 0.0008079574412495959, 0.0009902965044236883, 0.0009844878400123431, 0.000980292359713341, 0.0009792808576474733, 0.9899285466741411, 0.0009616594246315676, 1.0125072804700348]\n",
      "loss: 1.4639537727254686e41\n",
      "pde_losses: [1.4600549684913976e41, 2.3921710273568666e-6, 2.385173208262705e-6, 2.350456111663749e-6]\n",
      "bcs_losses: [0.0009623480206413172, 0.0008853636356940639, 0.0009179796846133066, 0.0009065675173518843, 0.0007977036841254261, 0.0009602911207348419, 0.0009630904202752809, 0.0009662919969645925, 0.0009603141668174278, 0.9891886398425112, 0.0009440926458665966, 1.0132229709056177]\n",
      "loss: 1.2562660872266369e41\n",
      "pde_losses: [1.2562982029878277e41, 2.353314123681266e-6, 2.3405743432780994e-6, 2.33478035518101e-6]\n",
      "bcs_losses: [0.000828661565043774, 0.0007665678928335279, 0.0007774261451658045, 0.0007928438859570691, 0.0006909677608253318, 0.0008205176609618055, 0.0008287060461909337, 0.000826662841192943, 0.0008284057243093559, 0.9885006638838219, 0.0008093724697894775, 1.0136520663437036]\n",
      "loss: 9.687614450012094e40\n",
      "pde_losses: [9.715117791340996e40, 2.2889180421258194e-6, 2.2559416785424573e-6, 2.3057908039070145e-6]\n",
      "bcs_losses: [0.0006328414906223783, 0.0006029595459199071, 0.0005900751507024555, 0.0006200923793525557, 0.0005397781707085521, 0.0006279571830508924, 0.0006323547830546109, 0.0006323744995797682, 0.0006351017257088874, 0.9883886993810191, 0.0006175688680059051, 1.0133883025790889]\n",
      "loss: 6.946958785453352e40\n",
      "pde_losses: [6.982354110977484e40, 2.2683735036033813e-6, 2.1996349505785167e-6, 2.2513019944259913e-6]\n",
      "bcs_losses: [0.0004496179659008164, 0.00044335386889800103, 0.00041742512968244623, 0.0004521533850227545, 0.00039653737300818844, 0.0004461917327198972, 0.00044843358335653466, 0.0004496282317753081, 0.0004481441573093298, 0.9891505260619354, 0.0004330843047820034, 1.01226103436197]\n",
      "loss: 4.955212540070363e40\n",
      "pde_losses: [4.935870572706219e40, 2.2247828599256978e-6, 2.257384008620663e-6, 2.2400903955635466e-6]\n",
      "bcs_losses: [0.0003075620366862679, 0.0003224754890826377, 0.00028994001606406266, 0.000324214566721967, 0.0002926376315293269, 0.00030930149289133007, 0.00030756958962336743, 0.0003079653889353138, 0.00030915364976026014, 0.9907032049001112, 0.000291594160333902, 1.010424371710397]\n",
      "loss: 3.6255576370344975e40\n",
      "pde_losses: [3.6312489787969175e40, 2.198148772003278e-6, 2.195074049787123e-6, 2.1995574212137933e-6]\n",
      "bcs_losses: [0.00021692421388293535, 0.0002452043702629153, 0.00020591730461103942, 0.0002403231970410569, 0.00022805688658671656, 0.00022090240857049193, 0.00021647191494572442, 0.00021653683892570728, 0.0002150392908431811, 0.9927773662220968, 0.00019728383576352694, 1.0081570542501799]\n",
      "loss: 2.853495286089562e40\n",
      "pde_losses: [2.8449823854868557e40, 2.1761833027252315e-6, 2.1504299292613777e-6, 2.1431143381586183e-6]\n",
      "bcs_losses: [0.00016143369549396792, 0.00019727109685655766, 0.00015731258013806302, 0.00019310290976692015, 0.00019228053045467153, 0.00016911250398743823, 0.00016173016295847303, 0.00016079574979522377, 0.00016070284548061773, 0.9950282180546652, 0.0001404658753358302, 1.0057859241630718]\n",
      "loss: 2.5347575686005853e40\n",
      "pde_losses: [2.5298778313855503e40, 2.1539777582970918e-6, 2.163040936711014e-6, 2.162419297418827e-6]\n",
      "bcs_losses: [0.0001377015741914232, 0.00017112326344918656, 0.00013549301350913244, 0.00017479262428135258, 0.00017797397319789537, 0.00015017344774310315, 0.00013988762539180437, 0.00013717807426754495, 0.00013816767555510051, 0.9973523702571414, 0.00011493241453041961, 1.0034025652405343]\n",
      "loss: 2.646685394154613e40\n",
      "pde_losses: [2.6765956897072927e40, 2.1210163813049206e-6, 2.102114275808749e-6, 2.142194271167257e-6]\n",
      "bcs_losses: [0.00014870124328917542, 0.00017633860168989518, 0.00014469856339720057, 0.0001904785947522539, 0.00019227148305652337, 0.0001638057846842439, 0.00014648068152828595, 0.0001475797027759465, 0.00014850962042671202, 0.9998581835378509, 0.00012089552275712748, 1.0008988182531309]\n",
      "loss: 3.218482728151197e40\n",
      "pde_losses: [3.2268196189499807e40, 2.072807645400626e-6, 2.1123310389621572e-6, 2.0637655511926586e-6]\n",
      "bcs_losses: [0.00018625559999371817, 0.000206989682212698, 0.0001794556335490616, 0.00022705459832870605, 0.0002233850337947399, 0.00020587873204438398, 0.00018617975083182805, 0.00018688626486173862, 0.0001857313934679111, 1.0027959204767516, 0.0001554410137878415, 0.9980178422142043]\n",
      "loss: 4.0092445234454e40\n",
      "pde_losses: [3.997056700546318e40, 2.0478293754833382e-6, 2.082387839520062e-6, 2.0633408159855437e-6]\n",
      "bcs_losses: [0.00023757538773957232, 0.00024741729595409147, 0.00022992374394195422, 0.0002779032866293226, 0.00026450750636828675, 0.0002625499490629758, 0.0002383985155706478, 0.00023812558391053673, 0.00023853313263238443, 1.006126765692705, 0.00020347622103027087, 0.9947678228655088]\n",
      "loss: 4.60015826650059e40\n",
      "pde_losses: [4.598968339475392e40, 2.0283888947093288e-6, 2.06749545467162e-6, 2.0414376612124704e-6]\n",
      "bcs_losses: [0.00028232729971517035, 0.0002793341991632886, 0.000273193680519359, 0.00031361914522396047, 0.0002925673143824068, 0.00030788503625931736, 0.00028177688085957156, 0.00028175408729357726, 0.00028078793156242535, 1.009406204209715, 0.0002431761206722511, 0.9915505221531161]\n",
      "loss: 4.763742296643736e40\n",
      "pde_losses: [4.753266218147591e40, 2.031540875868228e-6, 2.030853199703486e-6, 2.0782411886740487e-6]\n",
      "bcs_losses: [0.0002976671017536585, 0.00028558877322111835, 0.0002881875522359282, 0.0003211106178276548, 0.00029447762854360385, 0.00032523403756050086, 0.0002974506660597788, 0.00029744280713782704, 0.0002974560599055606, 1.0118833502506388, 0.00025589493934902576, 0.989081605754983]\n",
      "loss: 4.329594444202444e40\n",
      "pde_losses: [4.3296853152365667e40, 2.008901896375904e-6, 2.0298134216702003e-6, 2.0223297907233356e-6]\n",
      "bcs_losses: [0.0002758760864444423, 0.000258273170434598, 0.0002691432794553691, 0.00029049646856409486, 0.0002627150792526716, 0.0002989175422453335, 0.0002757083216391802, 0.00027653283808298746, 0.0002759174560252297, 1.0127521964732185, 0.00023250554320547882, 0.9881511059627975]\n",
      "loss: 3.3891950385709917e40\n",
      "pde_losses: [3.3882561355651607e40, 2.0077124958567204e-6, 1.956113175027837e-6, 1.977133799568644e-6]\n",
      "bcs_losses: [0.00022116520115569638, 0.0002010455856735911, 0.00021705438122991103, 0.00022792015698371544, 0.0002036577141014372, 0.0002402005586506555, 0.0002205582850866387, 0.00022090188009503506, 0.00021990666251236508, 1.0114957933690056, 0.00017644892034228378, 0.9892841086051544]\n",
      "loss: 2.1863861294825575e40\n",
      "pde_losses: [2.209799966248395e40, 2.00606293416057e-6, 1.9453942542246253e-6, 2.010110901345971e-6]\n",
      "bcs_losses: [0.0001482906085865471, 0.00013078730439204314, 0.00014733642372575856, 0.00014885831123543204, 0.00013281309705836435, 0.0001593212074602209, 0.00014926180973349985, 0.00014887089853603673, 0.0001488169352146017, 1.0082000224858698, 0.00010487505437001805, 0.992429418150872]\n",
      "loss: 1.1759388265094295e40\n",
      "pde_losses: [1.1738492187184388e40, 1.978859074556339e-6, 1.972373507793377e-6, 1.9965450107879857e-6]\n",
      "bcs_losses: [8.559477221355884e-5, 7.149239804581938e-5, 8.77432200949427e-5, 8.008872383220183e-5, 7.48295530224688e-5, 8.652663955956456e-5, 8.580220243180414e-5, 8.534921979605546e-5, 8.612559177022006e-5, 1.003606871925909, 4.3481184373558534e-5, 0.9968950009479418]\n",
      "loss: 6.031163384780336e39\n",
      "pde_losses: [6.145838665362729e39, 1.9578417595519306e-6, 1.9377384253407614e-6, 1.9883506281982425e-6]\n",
      "bcs_losses: [4.941080324959328e-5, 4.1287344606917695e-5, 5.5971118181671165e-5, 3.940688550788498e-5, 4.5602672788517214e-5, 4.253318149076227e-5, 4.959675706321062e-5, 5.009640335459731e-5, 4.981828414024514e-5, 0.9988598324656006, 1.2219291238734365e-5, 1.0015746365167868]\n",
      "loss: 5.760608704500523e39\n",
      "pde_losses: [5.81469483876023e39, 1.9317899025764422e-6, 1.9161803690733067e-6, 1.908634381308514e-6]\n",
      "bcs_losses: [4.5654029952558426e-5, 4.2463557958818345e-5, 5.452650138016919e-5, 3.220212808752979e-5, 4.7312023874640875e-5, 3.2436211848191115e-5, 4.581797779943304e-5, 4.5564503688915934e-5, 4.545080560169892e-5, 0.9950545825167403, 1.4713774847577581e-5, 1.0053776301231363]\n",
      "loss: 9.013598876590727e39\n",
      "pde_losses: [9.06167804450577e39, 1.942233358264035e-6, 1.9069918900074324e-6, 1.8925241086407905e-6]\n",
      "bcs_losses: [6.316930317635982e-5, 6.519372579202542e-5, 7.478001717675135e-5, 4.712586325946431e-5, 6.872222468973319e-5, 4.623014614440285e-5, 6.303148067236756e-5, 6.336032901013874e-5, 6.324376425711012e-5, 0.9927912151284058, 4.074096408029142e-5, 1.0076823610141088]\n",
      "loss: 1.3703389858853334e40\n",
      "pde_losses: [1.3579789010048215e40, 1.8864767782204214e-6, 1.9208367827257316e-6, 1.934371713609666e-6]\n",
      "bcs_losses: [8.9775930413378e-5, 9.435338235954975e-5, 0.00010275267433647878, 7.197816597717159e-5, 9.63213936897984e-5, 7.153165402385286e-5, 8.99864044525758e-5, 9.017192654035315e-5, 8.983558854665382e-5, 0.992056917997212, 7.530064627050829e-5, 1.0084725693194576]\n",
      "loss: 1.7577873928210164e40\n",
      "pde_losses: [1.7549270026397403e40, 1.891121598853741e-6, 1.8952781110734807e-6, 1.9191958398536576e-6]\n",
      "bcs_losses: [0.00011287687003796051, 0.00011791370796421211, 0.00012576701008097858, 9.365547845078844e-5, 0.00011881386982260725, 9.386064976576891e-5, 0.00011300538428886441, 0.00011295535521021468, 0.0001127918718284259, 0.9923861780451906, 0.00010445610844560438, 1.0081873137879014]\n",
      "loss: 1.9330672630472953e40\n",
      "pde_losses: [1.932159436640933e40, 1.8705470705140342e-6, 1.8626606024843334e-6, 1.8383600936046143e-6]\n",
      "bcs_losses: [0.0001227011534613358, 0.00012771170988472053, 0.00013450190001586, 0.00010470369383519296, 0.00012794831626968743, 0.00010553205965302502, 0.0001232346243074872, 0.00012302729613828889, 0.00012311987643365133, 0.993234815668196, 0.00011823080648749789, 1.007352569072728]\n",
      "loss: 1.81318344807381e40\n",
      "pde_losses: [1.8140624872535964e40, 1.8781371734931103e-6, 1.8373387047812456e-6, 1.8251806199319035e-6]\n",
      "bcs_losses: [0.00011706750499822703, 0.00012076997905921603, 0.00012523385460580906, 0.00010098737881297914, 0.00011998387227593866, 0.00010045601877799125, 0.00011663912977430611, 0.00011679236635963557, 0.00011645277101923293, 0.9941788003692299, 0.00011299945041119072, 1.0063863237715385]\n",
      "loss: 1.5035155831303627e40\n",
      "pde_losses: [1.4893849048848646e40, 1.8058654651973558e-6, 1.8039418749769655e-6, 1.8367021164984914e-6]\n",
      "bcs_losses: [9.664680341293593e-5, 9.948358719724372e-5, 0.00010493153277438559, 8.698900557321674e-5, 9.854794986975448e-5, 8.358406540629544e-5, 9.791980893396351e-5, 9.747618565603814e-5, 9.711730557758967e-5, 0.9950691191029672, 9.245145333616192e-5, 1.0054450090338496]\n",
      "loss: 1.090745253026782e40\n",
      "pde_losses: [1.0898916583734126e40, 1.7806755725778972e-6, 1.849196333322228e-6, 1.812891026805744e-6]\n",
      "bcs_losses: [7.341159669004327e-5, 7.360282495180562e-5, 7.899825061398057e-5, 6.733464055712422e-5, 7.265534925001738e-5, 6.193335942096602e-5, 7.275099575997093e-5, 7.30529238002027e-5, 7.250463397230205e-5, 0.9959616192734801, 6.492756576873473e-5, 1.0044887138822995]\n",
      "loss: 7.272563060525796e39\n",
      "pde_losses: [7.258602535705641e39, 1.801882217167867e-6, 1.8055669858242297e-6, 1.7757657875938744e-6]\n",
      "bcs_losses: [5.187182803537725e-5, 5.0970884830565786e-5, 5.545699432075604e-5, 5.123659361968951e-5, 4.951069474959169e-5, 4.354317186067594e-5, 5.149737399583796e-5, 5.197267838124264e-5, 5.19297503689842e-5, 0.9969901409302537, 3.9399429021067864e-5, 1.0034008150439757]\n",
      "loss: 4.963374108388987e39\n",
      "pde_losses: [4.9641943019107714e39, 1.779068224429742e-6, 1.7788154880257512e-6, 1.7642723275095357e-6]\n",
      "bcs_losses: [3.772474582696839e-5, 3.597642627684967e-5, 4.077245213466996e-5, 4.1039421532439784e-5, 3.490699508193723e-5, 3.341011938691477e-5, 3.82059299420548e-5, 3.84637950365599e-5, 3.8517736371767826e-5, 0.9981789082113399, 2.1219014377990465e-5, 1.0021674124960032]\n",
      "loss: 4.050059986816127e39\n",
      "pde_losses: [4.1102190658406935e39, 1.7818942755325062e-6, 1.8065415923469433e-6, 1.7701980074946326e-6]\n",
      "bcs_losses: [3.297016290506013e-5, 3.030368604575108e-5, 3.502838215785723e-5, 3.7464739133260963e-5, 2.903451724266532e-5, 3.178022308968313e-5, 3.2910204544858835e-5, 3.332719693315855e-5, 3.3120200052542336e-5, 0.9994481836553215, 1.1387151201865012e-5, 1.000870146660094]\n",
      "loss: 4.3551829087203114e39\n",
      "pde_losses: [4.4317763564251836e39, 1.7274722880811481e-6, 1.7588611336043135e-6, 1.751386240069052e-6]\n",
      "bcs_losses: [3.4540119207924224e-5, 3.077020102499238e-5, 3.508516255794475e-5, 3.895308960368798e-5, 3.0229385256939236e-5, 3.6748408120537936e-5, 3.463876332344072e-5, 3.480925811975731e-5, 3.47455525059004e-5, 1.0006960588148608, 8.902659381239268e-6, 0.9996090437881893]\n",
      "loss: 5.45750883003812e39\n",
      "pde_losses: [5.455113869202898e39, 1.7217377968969362e-6, 1.747957838338409e-6, 1.7523303539252217e-6]\n",
      "bcs_losses: [4.0402735897907536e-5, 3.656054186483496e-5, 3.954568297774523e-5, 4.396588430792236e-5, 3.629900606547516e-5, 4.5959008007400866e-5, 4.045879826604992e-5, 4.00112092651683e-5, 4.0211097244872296e-5, 1.0017584718920358, 1.2215395473066933e-5, 0.9985452470413536]\n",
      "loss: 6.753371967347615e39\n",
      "pde_losses: [6.707514752787416e39, 1.7276388032914802e-6, 1.7207713798320186e-6, 1.7193916042307195e-6]\n",
      "bcs_losses: [4.695658310247361e-5, 4.3734619644995076e-5, 4.5491907337790434e-5, 5.0514062631238166e-5, 4.4917091001863384e-5, 5.433229160595369e-5, 4.762431827201526e-5, 4.75043029390277e-5, 4.719818455900036e-5, 1.0025025357338422, 1.8714423382455743e-5, 0.9978066917708356]\n",
      "loss: 7.744168852125207e39\n",
      "pde_losses: [7.775396053186443e39, 1.7170451864659715e-6, 1.7322806240929838e-6, 1.69952677745833e-6]\n",
      "bcs_losses: [5.204264963548944e-5, 4.904045348452721e-5, 4.915830428525992e-5, 5.4716877255255474e-5, 5.2314466336622856e-5, 6.028424630026864e-5, 5.191541482089575e-5, 5.193228757315502e-5, 5.208594213850888e-5, 1.00286256920718, 2.4923981759586877e-5, 0.9974522581819946]\n",
      "loss: 7.968678234524305e39\n",
      "pde_losses: [7.922322687001801e39, 1.6993119648232463e-6, 1.7029912421432966e-6, 1.7041531186876185e-6]\n",
      "bcs_losses: [5.2876539033414895e-5, 4.935490271668537e-5, 4.9072809047446225e-5, 5.533082603521071e-5, 5.473179225680378e-5, 6.0273323380359075e-5, 5.2166732395923194e-5, 5.246686205355462e-5, 5.245541715396507e-5, 1.0027987331667665, 2.8115464191757638e-5, 0.9975164972091031]\n",
      "loss: 7.426895231414127e39\n",
      "pde_losses: [7.402441759863159e39, 1.706821792185106e-6, 1.6899714174567404e-6, 1.663340097176124e-6]\n",
      "bcs_losses: [4.864138308642439e-5, 4.6066207761829715e-5, 4.412779356606565e-5, 5.2335757089296975e-5, 5.2686052303459825e-5, 5.491256120559803e-5, 4.816860772627876e-5, 4.866640718644682e-5, 4.8750960923683485e-5, 1.0023627756264386, 2.7100468712832894e-5, 0.9979453996239123]\n",
      "loss: 6.219800126617897e39\n",
      "pde_losses: [6.123844074294472e39, 1.6603139265638304e-6, 1.6979677719948984e-6, 1.7029192987937897e-6]\n",
      "bcs_losses: [4.028721089457656e-5, 3.8524551169751426e-5, 3.589917245440037e-5, 4.501039885694406e-5, 4.565227050466731e-5, 4.5391968017022266e-5, 4.0205801758126245e-5, 4.0144655399322345e-5, 4.0740171087939314e-5, 1.0016290966439276, 2.1694260686393746e-5, 0.9986643207231116]\n",
      "loss: 4.5347630901817504e39\n",
      "pde_losses: [4.5709947041862514e39, 1.668413863739981e-6, 1.6879872949695538e-6, 1.649207307493681e-6]\n",
      "bcs_losses: [3.0614729273136944e-5, 2.878516001680691e-5, 2.6715528628765074e-5, 3.530650279996191e-5, 3.55884905573046e-5, 3.4145976578546145e-5, 3.1100324917251196e-5, 3.027512777950868e-5, 3.0961706870313304e-5, 1.000789997473427, 1.3695387013134847e-5, 0.9994842572982815]\n",
      "loss: 3.218246457955198e39\n",
      "pde_losses: [3.2142660397671493e39, 1.6694518134118576e-6, 1.648478761251872e-6, 1.6400807655281612e-6]\n",
      "bcs_losses: [2.321304336493159e-5, 2.1259198719240418e-5, 1.966821645425477e-5, 2.7447612559592443e-5, 2.672605102568616e-5, 2.5404716967600638e-5, 2.353165705199299e-5, 2.3042541497683072e-5, 2.349266397899708e-5, 1.0000532110359555, 6.849368536623436e-6, 1.000204553129395]\n",
      "loss: 2.6427179707894895e39\n",
      "pde_losses: [2.622702268720917e39, 1.6375511006534926e-6, 1.6264162662764319e-6, 1.6217753165790894e-6]\n",
      "bcs_losses: [2.0189003928019727e-5, 1.8737979752240994e-5, 1.824507592910757e-5, 2.3917281597340892e-5, 2.1494106818043452e-5, 2.144296986762577e-5, 2.0190995602836893e-5, 2.032691335299839e-5, 2.0269983491796214e-5, 0.9994727950859106, 4.284937777977169e-6, 1.0007773212742066]\n",
      "loss: 2.774549432209404e39\n",
      "pde_losses: [2.8342941095352316e39, 1.6675719064610784e-6, 1.6254015544019104e-6, 1.6182098385130675e-6]\n",
      "bcs_losses: [2.203828244908941e-5, 2.1425997818257025e-5, 2.2063099591241197e-5, 2.472159764443301e-5, 2.1636143322245193e-5, 2.2123738222230766e-5, 2.201173625089033e-5, 2.2161337640887363e-5, 2.2122477798209068e-5, 0.9990722091651472, 6.585294080150153e-6, 1.0011801969395093]\n",
      "loss: 3.490498958349023e39\n",
      "pde_losses: [3.4706525062596693e39, 1.5729664992641025e-6, 1.6143708191841315e-6, 1.5854111799058042e-6]\n",
      "bcs_losses: [2.61720192459792e-5, 2.576519558836703e-5, 2.8445410343020467e-5, 2.731212252330836e-5, 2.5358005744186726e-5, 2.4972253694590608e-5, 2.624452215112701e-5, 2.613717826845217e-5, 2.627715990874334e-5, 0.9987184641308093, 1.1510330930518863e-5, 1.0015418350892495]\n",
      "loss: 4.005704904726237e39\n",
      "pde_losses: [4.039632761116325e39, 1.6000445482997952e-6, 1.5836019876336407e-6, 1.6308747684141179e-6]\n",
      "bcs_losses: [2.940352352962217e-5, 2.9904943220429452e-5, 3.3939606903249886e-5, 2.9793464454914955e-5, 2.8711234687278756e-5, 2.735950990221608e-5, 2.9739047588044417e-5, 2.9782695444439775e-5, 2.9539892951233348e-5, 0.9983669457214577, 1.600721056174124e-5, 1.0019007673467448]\n",
      "loss: 4.197686176230382e39\n",
      "pde_losses: [4.221205214352798e39, 1.6002550500160275e-6, 1.59420213598219e-6, 1.5894154074678642e-6]\n",
      "bcs_losses: [3.0758783685221724e-5, 3.088000906679365e-5, 3.653136379829865e-5, 2.931925391512403e-5, 3.095170820086195e-5, 2.7025402783617914e-5, 3.0682450050536045e-5, 3.0641153083925256e-5, 3.087410705042801e-5, 0.9979896641046843, 1.8163184759983543e-5, 1.00228133675353]\n",
      "loss: 4.0465755432957394e39\n",
      "pde_losses: [4.036769626530278e39, 1.5688248891869462e-6, 1.5950914562709363e-6, 1.5872862744548918e-6]\n",
      "bcs_losses: [2.929538811563608e-5, 2.9357266213532867e-5, 3.6200273120628794e-5, 2.6657362141951645e-5, 3.135529504089895e-5, 2.490730386295526e-5, 2.9482745911062036e-5, 2.940360197638129e-5, 2.9615944088733504e-5, 0.9976890181770448, 1.785640714016742e-5, 1.0025805513325943]\n",
      "loss: 3.707053864546704e39\n",
      "pde_losses: [3.677387617695487e39, 1.5694457583939355e-6, 1.5765843792432522e-6, 1.5887426704856378e-6]\n",
      "bcs_losses: [2.687824119594345e-5, 2.6778870854458045e-5, 3.4068225115117085e-5, 2.3115462303255002e-5, 3.0011053469870602e-5, 2.219003712550247e-5, 2.6814531615847776e-5, 2.6652771747995677e-5, 2.6971484741662578e-5, 0.9976150617296721, 1.601490207656326e-5, 1.0026500338283675]\n",
      "loss: 3.2552985911636216e39\n",
      "pde_losses: [3.243188295709199e39, 1.5591867380893092e-6, 1.5447652369412473e-6, 1.5718903241671164e-6]\n",
      "bcs_losses: [2.3892764707051006e-5, 2.387113460907562e-5, 3.068538896280002e-5, 1.9217951228279327e-5, 2.7948517719694288e-5, 1.968219407592593e-5, 2.3915907759120683e-5, 2.4002395573195393e-5, 2.364720574200901e-5, 0.9978563483340803, 1.3567115278316004e-5, 1.0024028051484613]\n",
      "loss: 2.918140806442775e39\n",
      "pde_losses: [2.909384940178005e39, 1.5400779672452653e-6, 1.5549189067569793e-6, 1.5464337612751393e-6]\n",
      "bcs_losses: [2.1043030071497018e-5, 2.1256740562429022e-5, 2.7557530675033075e-5, 1.6125002969542596e-5, 2.6019202274768976e-5, 1.788239207562711e-5, 2.109054451471746e-5, 2.106854963252875e-5, 2.127865068664829e-5, 0.9983312425260393, 1.120049721933239e-5, 1.0019221148842026]\n",
      "loss: 2.650370148765163e39\n",
      "pde_losses: [2.648053519883621e39, 1.5235141696512107e-6, 1.5333750564137444e-6, 1.5629558393086183e-6]\n",
      "bcs_losses: [1.912796906330684e-5, 1.9347540030276576e-5, 2.459936207910119e-5, 1.440784087855798e-5, 2.388367463630917e-5, 1.7501849367636873e-5, 1.9244317775809207e-5, 1.9104290791882455e-5, 1.9143810186606656e-5, 0.9988851078858583, 9.029497631225694e-6, 1.0013631286191034]\n",
      "loss: 2.4899318009917673e39\n",
      "pde_losses: [2.5214845678606165e39, 1.5255149709749306e-6, 1.51187085850347e-6, 1.4891669690970621e-6]\n",
      "bcs_losses: [1.817952055728012e-5, 1.7866572397399025e-5, 2.2391775091736087e-5, 1.4389719518427123e-5, 2.2123986398449227e-5, 1.786834920328355e-5, 1.8282254925455567e-5, 1.809791629329393e-5, 1.8185383950659843e-5, 0.9993035227916993, 7.03710852517127e-6, 1.000940523377493]\n",
      "loss: 2.4078199473262303e39\n",
      "pde_losses: [2.4215266583398104e39, 1.5527584083998388e-6, 1.5048414378103582e-6, 1.5257357631152404e-6]\n",
      "bcs_losses: [1.7956798906176594e-5, 1.6871296957548417e-5, 2.070878971566408e-5, 1.565491937354871e-5, 2.1460697098881293e-5, 1.8423591908361934e-5, 1.7998716644494025e-5, 1.7944880667645637e-5, 1.7938307098915765e-5, 0.9994698821021837, 5.2248686609466796e-6, 1.0007712636762494]\n",
      "loss: 2.4099719420517575e39\n",
      "pde_losses: [2.4361372589464944e39, 1.4937783380183033e-6, 1.5196569897210344e-6, 1.5098463420959232e-6]\n",
      "bcs_losses: [1.8717218337596467e-5, 1.6653167538612586e-5, 1.99168373591394e-5, 1.8144785809041526e-5, 2.1077746592057445e-5, 1.994681350058314e-5, 1.8641050745386202e-5, 1.8752468734984762e-5, 1.8507645816088416e-5, 0.9994983390895704, 4.026833252193469e-6, 1.0007416779379983]\n",
      "loss: 2.5166964779248522e39\n",
      "pde_losses: [2.5370559978859857e39, 1.5042530081679069e-6, 1.504783037868179e-6, 1.5131636428959417e-6]\n",
      "bcs_losses: [1.9649738753082282e-5, 1.705290524599268e-5, 1.9228154969587292e-5, 2.1274523519934455e-5, 2.1506211525752514e-5, 2.1688436625500457e-5, 1.970127723032112e-5, 1.9826608226708713e-5, 1.962636272109046e-5, 0.9995868552076101, 3.7242643506928185e-6, 1.0006538092321984]\n",
      "loss: 2.6345986100823037e39\n",
      "pde_losses: [2.626658699676802e39, 1.4720979823235e-6, 1.4975725277377236e-6, 1.4584289524074183e-6]\n",
      "bcs_losses: [2.0126513227369684e-5, 1.7586759047814844e-5, 1.906189654647842e-5, 2.3598791492905803e-5, 2.1502414076997583e-5, 2.2716868449327006e-5, 2.0181746986151186e-5, 2.0445910500576432e-5, 2.0156675942078875e-5, 0.9998660468146168, 3.88162860242658e-6, 1.0003756930372536]\n",
      "loss: 2.5993016245511836e39\n",
      "pde_losses: [2.6441052480374436e39, 1.4693085278822566e-6, 1.4469328957212529e-6, 1.4530633291842707e-6]\n",
      "bcs_losses: [1.978681340740414e-5, 1.767922605607182e-5, 1.83496153597806e-5, 2.469212660789209e-5, 2.1040761356218232e-5, 2.31255954922331e-5, 1.983363092076675e-5, 1.9770975785797997e-5, 1.9691155895578143e-5, 1.0003235877361678, 4.058731585163252e-6, 0.9999186051419471]\n",
      "loss: 2.562293666629012e39\n",
      "pde_losses: [2.5204717072994264e39, 1.4670957238776396e-6, 1.45571334009171e-6, 1.4754178088337317e-6]\n",
      "bcs_losses: [1.849311535142308e-5, 1.7510626986828003e-5, 1.7672470701144494e-5, 2.403888491865339e-5, 2.018011452303711e-5, 2.2555997627546582e-5, 1.854242919305627e-5, 1.8536038541357423e-5, 1.854001910009822e-5, 1.0007707769692376, 4.0242396415679225e-6, 0.9994710830532363]\n",
      "loss: 2.39835047856352e39\n",
      "pde_losses: [2.380456909523242e39, 1.4658046893184043e-6, 1.4609388825411635e-6, 1.4419109881523543e-6]\n",
      "bcs_losses: [1.7076178882633692e-5, 1.6868789150333047e-5, 1.655021418453662e-5, 2.2672062195332545e-5, 1.9214216781213917e-5, 2.126582578130354e-5, 1.712968186645836e-5, 1.7095989771859966e-5, 1.7119445522714302e-5, 1.0010078885774485, 3.7555855477686183e-6, 0.999233285731402]\n",
      "loss: 2.2284309962427933e39\n",
      "pde_losses: [2.2275993021564938e39, 1.4374599062502174e-6, 1.4180524941819758e-6, 1.452350876241146e-6]\n",
      "bcs_losses: [1.5603791687929816e-5, 1.6113522768634082e-5, 1.5664228150608175e-5, 2.0693535666801802e-5, 1.88635648484196e-5, 1.946929778489568e-5, 1.5584524319911817e-5, 1.553323954955284e-5, 1.5642137391288315e-5, 1.0008730270320814, 3.4361869446997694e-6, 0.9993676467300439]\n",
      "loss: 2.1160876058533617e39\n",
      "pde_losses: [2.098225498281883e39, 1.4431247972275972e-6, 1.4121655065430568e-6, 1.4462648771167455e-6]\n",
      "bcs_losses: [1.4622714690459364e-5, 1.529204863165299e-5, 1.5277650302771806e-5, 1.880700126277507e-5, 1.8742675418925248e-5, 1.7565644111391616e-5, 1.458091542521573e-5, 1.4579578881343021e-5, 1.4633743517578001e-5, 1.0004082735405082, 3.278868238644494e-6, 0.9998324213839569]\n",
      "loss: 2.0578481177702483e39\n",
      "pde_losses: [2.0646748146437545e39, 1.4209453538624889e-6, 1.4050010590283513e-6, 1.3845003541687712e-6]\n",
      "bcs_losses: [1.4121964035219507e-5, 1.487828495822472e-5, 1.561220239677257e-5, 1.724370397245179e-5, 1.8928323668001996e-5, 1.5973955716684413e-5, 1.4274177140406646e-5, 1.4090830027017328e-5, 1.4137892679283256e-5, 0.999766962922972, 3.4405035205123977e-6, 1.0004745158067099]\n",
      "loss: 2.0324746774193328e39\n",
      "pde_losses: [2.0227647719921428e39, 1.4089918327857253e-6, 1.388702094926199e-6, 1.4033172517543203e-6]\n",
      "bcs_losses: [1.4329561605879874e-5, 1.4538072876397939e-5, 1.6313596041927346e-5, 1.5959301567538825e-5, 1.9209239396505534e-5, 1.4791848592897944e-5, 1.4303101448379725e-5, 1.4211783391183702e-5, 1.4284375966142215e-5, 0.999134082500702, 3.949425968583066e-6, 1.0011086724195621]\n",
      "loss: 2.015995551123253e39\n",
      "pde_losses: [2.0492351046080264e39, 1.378465977963965e-6, 1.3962184075884218e-6, 1.426607171268252e-6]\n",
      "bcs_losses: [1.4598172995238145e-5, 1.460711611224296e-5, 1.75235636024969e-5, 1.5155323185008154e-5, 1.9328784261689924e-5, 1.4295693826327832e-5, 1.4569838472135268e-5, 1.4666272415481645e-5, 1.4762900493811969e-5, 0.9986613580240464, 4.556910724743093e-6, 1.001582589253843]\n",
      "loss: 2.041831949538683e39\n",
      "pde_losses: [2.0238636372814138e39, 1.3812269699597498e-6, 1.4150660453966829e-6, 1.3671470727829321e-6]\n",
      "bcs_losses: [1.5016987880944455e-5, 1.4745392463176305e-5, 1.803708576700046e-5, 1.4582800584670284e-5, 1.9056747032164774e-5, 1.4190609316197225e-5, 1.4842537293331515e-5, 1.4767090140173465e-5, 1.4897980581747565e-5, 0.9984214902824821, 5.020438149015012e-6, 1.0018231767413253]\n",
      "loss: 2.03520329609272e39\n",
      "pde_losses: [2.0551028042605903e39, 1.4175772082922955e-6, 1.3811970255849604e-6, 1.3786146497066903e-6]\n",
      "bcs_losses: [1.5145287889621784e-5, 1.4931207959388194e-5, 1.854983857533824e-5, 1.4264077327511469e-5, 1.8742676247731676e-5, 1.4402575964408249e-5, 1.5191569288396591e-5, 1.5204762563490293e-5, 1.5288362211724735e-5, 0.9983726868926712, 5.2892235685695696e-6, 1.0018722240483886]\n",
      "loss: 2.0267667196776143e39\n",
      "pde_losses: [2.0285508956408044e39, 1.362275887892731e-6, 1.3665686848332226e-6, 1.3934779914429148e-6]\n",
      "bcs_losses: [1.5303134895154162e-5, 1.4975574199364884e-5, 1.8814470952806433e-5, 1.4436334435645307e-5, 1.8052873183846005e-5, 1.4701372447611975e-5, 1.5245180063238436e-5, 1.535053770263433e-5, 1.5350671288886315e-5, 0.9984684628543444, 5.523593093052842e-6, 1.001776590522685]\n",
      "loss: 1.9976096671769177e39\n",
      "pde_losses: [2.0117193646331794e39, 1.3690694856587353e-6, 1.3498913393837106e-6, 1.3122377043736926e-6]\n",
      "bcs_losses: [1.504509700117615e-5, 1.4682739992896203e-5, 1.871521393738262e-5, 1.4572001964152833e-5, 1.7551446561037567e-5, 1.4639732691752537e-5, 1.5042301494938132e-5, 1.5067713249315353e-5, 1.4964667837176112e-5, 0.9986662737337813, 5.6846406558479574e-6, 1.0015787409501287]\n",
      "loss: 1.957061563340053e39\n",
      "pde_losses: [1.936281553745111e39, 1.3739880560251026e-6, 1.3571099355064116e-6, 1.3659242322821223e-6]\n",
      "bcs_losses: [1.4592274471048678e-5, 1.4405963482584471e-5, 1.812550503329453e-5, 1.4971967759726378e-5, 1.7481265972035456e-5, 1.4730625615213883e-5, 1.4669792462561961e-5, 1.459912416294333e-5, 1.4533454503398479e-5, 0.9989314088535808, 5.716487279893586e-6, 1.0013131851705679]\n",
      "loss: 1.8901414081521624e39\n",
      "pde_losses: [1.897888992597891e39, 1.368416281788223e-6, 1.3528984587877492e-6, 1.3407860178590065e-6]\n",
      "bcs_losses: [1.3815554224207908e-5, 1.392702489003252e-5, 1.7420631573395774e-5, 1.5130652300740923e-5, 1.698499437303267e-5, 1.446297852252176e-5, 1.395357235399054e-5, 1.3902557526449371e-5, 1.4086576659931795e-5, 0.999256584502427, 5.566049774829365e-6, 1.0009869815702952]\n",
      "loss: 1.8396760526012682e39\n",
      "pde_losses: [1.8342420067282983e39, 1.347607812195616e-6, 1.34684503910735e-6, 1.3298607370726612e-6]\n",
      "bcs_losses: [1.3198571752650743e-5, 1.3521161905220924e-5, 1.6379909392739898e-5, 1.507969182117228e-5, 1.667180132494067e-5, 1.4420216507208968e-5, 1.3313637569014239e-5, 1.3372114328007314e-5, 1.3328322989954662e-5, 0.9995160153857061, 4.962159481656823e-6, 1.0007255902280265]\n",
      "loss: 1.7890416406073825e39\n",
      "pde_losses: [1.7784304541709057e39, 1.3077269688352638e-6, 1.3338822630866364e-6, 1.3183156886574101e-6]\n",
      "bcs_losses: [1.2841663570291779e-5, 1.3064337560354662e-5, 1.5485377967575232e-5, 1.5006645128834971e-5, 1.6390426002872413e-5, 1.4439032665481956e-5, 1.287183156034916e-5, 1.291773723970979e-5, 1.2902521023755078e-5, 0.9996310056245342, 3.903810069945748e-6, 1.0006078877003746]\n",
      "loss: 1.7319866080006787e39\n",
      "pde_losses: [1.76287869189039e39, 1.3220417582770135e-6, 1.2941666682505905e-6, 1.303557436788134e-6]\n",
      "bcs_losses: [1.2705378993822104e-5, 1.248469433280396e-5, 1.452749380633611e-5, 1.4895927453948295e-5, 1.6223123637169645e-5, 1.4573072961044681e-5, 1.2577903931421198e-5, 1.2655251629276347e-5, 1.2590545321270309e-5, 0.9996652078331782, 2.917016848915067e-6, 1.0005709509749618]\n",
      "loss: 1.7615417398702397e39\n",
      "pde_losses: [1.755709501009651e39, 1.314128831995671e-6, 1.3391436220878268e-6, 1.3401544518421472e-6]\n",
      "bcs_losses: [1.2739459213571904e-5, 1.2569504863262671e-5, 1.3922853591222837e-5, 1.4961932768636239e-5, 1.6208139640165328e-5, 1.5067127143350078e-5, 1.2858761552888262e-5, 1.2671840480444456e-5, 1.2657972853807656e-5, 0.9996741564030105, 2.2993825715429654e-6, 1.0005596994220833]\n",
      "loss: 1.7782697403033802e39\n",
      "pde_losses: [1.761899710784903e39, 1.2893602795872932e-6, 1.322717183143727e-6, 1.3341368270287127e-6]\n",
      "bcs_losses: [1.2622977606682097e-5, 1.2568267476946888e-5, 1.3646762580222655e-5, 1.5086159449545121e-5, 1.653569303141599e-5, 1.5050816804388977e-5, 1.2627293479600227e-5, 1.2773035181709567e-5, 1.2624443882007403e-5, 0.9997003916611792, 2.134459296457588e-6, 1.0005317694802172]\n",
      "loss: 1.7600684352181286e39\n",
      "pde_losses: [1.751627148643104e39, 1.3119192484775521e-6, 1.2999220851178735e-6, 1.2955018638197676e-6]\n",
      "bcs_losses: [1.2434436376012343e-5, 1.2468847786947683e-5, 1.3579123972291075e-5, 1.530607891080003e-5, 1.667966017500553e-5, 1.5099734477034745e-5, 1.2658630970018743e-5, 1.2697091962533231e-5, 1.2676786891331217e-5, 0.9996760773951092, 2.187652974223577e-6, 1.0005547152964147]\n",
      "loss: 1.7366195132716518e39\n",
      "pde_losses: [1.7650627608538895e39, 1.2798652281590227e-6, 1.2674216022661896e-6, 1.2857178420156684e-6]\n",
      "bcs_losses: [1.2507882610159025e-5, 1.2333334768689842e-5, 1.3284523177927047e-5, 1.5242492830263738e-5, 1.6586425763603173e-5, 1.4884871346026296e-5, 1.2592699372302237e-5, 1.2396510491143943e-5, 1.255141577428289e-5, 0.9996159157165568, 2.2587186984981455e-6, 1.0006135677334276]\n",
      "loss: 1.7120577083728925e39\n",
      "pde_losses: [1.7172522472597662e39, 1.2863110764487824e-6, 1.2864522245705739e-6, 1.2966411278765673e-6]\n",
      "bcs_losses: [1.2449690810729723e-5, 1.2133247381539658e-5, 1.3133017917413644e-5, 1.526099812368571e-5, 1.6171126324313618e-5, 1.4467114413245207e-5, 1.2282765777550121e-5, 1.236770752854454e-5, 1.2438145925218207e-5, 0.9995691422651436, 2.30415734456149e-6, 1.0006588914040035]\n",
      "loss: 1.6780846299696275e39\n",
      "pde_losses: [1.723280888071792e39, 1.2599984483933925e-6, 1.2601101445779094e-6, 1.2565019827893508e-6]\n",
      "bcs_losses: [1.2034708429754726e-5, 1.1962745361768319e-5, 1.2918901586887791e-5, 1.4906385306393238e-5, 1.593990113499261e-5, 1.415103917516947e-5, 1.2099420029607135e-5, 1.2038246579257012e-5, 1.1995731473832071e-5, 0.9995823464876601, 2.4918341294245054e-6, 1.000644302208141]\n",
      "loss: 1.6478210059114555e39\n",
      "pde_losses: [1.659796508723321e39, 1.2988978746050865e-6, 1.259370890162484e-6, 1.2738693367947972e-6]\n",
      "bcs_losses: [1.1798064288172916e-5, 1.196180193847532e-5, 1.3071327211888777e-5, 1.4694899562509814e-5, 1.5520806336309545e-5, 1.3776276161418608e-5, 1.1875158924943813e-5, 1.1857334676067362e-5, 1.1882724488716838e-5, 0.9996069534856759, 2.800865383759341e-6, 1.0006184132573948]\n",
      "loss: 1.6280775243954625e39\n",
      "pde_losses: [1.62900284155593e39, 1.2375614366120983e-6, 1.2500286438783386e-6, 1.2636497042647248e-6]\n",
      "bcs_losses: [1.16894523894992e-5, 1.1910943950211597e-5, 1.3159714275312207e-5, 1.4481327207003546e-5, 1.5055009922812728e-5, 1.3492535772877568e-5, 1.1598506721976976e-5, 1.1788499133716094e-5, 1.1615045543030762e-5, 0.9996264119602077, 3.183859392392411e-6, 1.0005976820736064]\n",
      "loss: 1.6059317551326865e39\n",
      "pde_losses: [1.5979063579306457e39, 1.2627983660726665e-6, 1.256165626820268e-6, 1.2551037466105074e-6]\n",
      "bcs_losses: [1.1564727960759875e-5, 1.1913454384223548e-5, 1.3488162296120689e-5, 1.4195601848726277e-5, 1.4915602906727105e-5, 1.32770424993592e-5, 1.1553703265372016e-5, 1.1623224506359284e-5, 1.1550720424709905e-5, 0.9996179356307892, 3.619056173908479e-6, 1.0006049696783157]\n",
      "loss: 1.6148031800234036e39\n",
      "pde_losses: [1.6385365970897002e39, 1.270775991623776e-6, 1.2507892987998362e-6, 1.2246299691730648e-6]\n",
      "bcs_losses: [1.1653054181845136e-5, 1.179095237809211e-5, 1.3645298355248233e-5, 1.3772241608207387e-5, 1.4922327124654144e-5, 1.2928404672965333e-5, 1.153541103894975e-5, 1.156046726488917e-5, 1.1414110711568025e-5, 0.9994983856947386, 3.88952659702057e-6, 1.0007232825805863]\n",
      "loss: 1.59561843997478e39\n",
      "pde_losses: [1.600894166135817e39, 1.2442471289627793e-6, 1.249755147423082e-6, 1.2271957943346458e-6]\n",
      "bcs_losses: [1.1577650550844586e-5, 1.1781999539766876e-5, 1.386677495613571e-5, 1.3389589585860788e-5, 1.500749340877554e-5, 1.2841793595293089e-5, 1.1579855880692435e-5, 1.1542513836834077e-5, 1.1438835731015545e-5, 0.9993052523240159, 3.950887173978105e-6, 1.0009149251760125]\n",
      "loss: 1.605170980247804e39\n",
      "pde_losses: [1.609011101377107e39, 1.2254825149370415e-6, 1.2350820408182873e-6, 1.225322191231473e-6]\n",
      "bcs_losses: [1.14599124490903e-5, 1.1589314535837883e-5, 1.3819650017606126e-5, 1.3173107779728204e-5, 1.5186261306981874e-5, 1.2671026970901682e-5, 1.1623087627645988e-5, 1.1613475904248791e-5, 1.1629038895379972e-5, 0.9991068714424174, 3.815583990862863e-6, 1.001111389236198]\n",
      "loss: 1.5903169356757424e39\n",
      "pde_losses: [1.6188831476517438e39, 1.2352318419931074e-6, 1.2278496178327463e-6, 1.2094336101666306e-6]\n",
      "bcs_losses: [1.1481581885578378e-5, 1.1480003300074303e-5, 1.3820159252310008e-5, 1.2953166389679954e-5, 1.515146989148891e-5, 1.2622496542396896e-5, 1.1601084565378029e-5, 1.1486066349703146e-5, 1.156769679862325e-5, 0.9990232711300855, 3.6956265036157675e-6, 1.0011929604390557]\n",
      "loss: 1.5701344140861938e39\n",
      "pde_losses: [1.5689524697615215e39, 1.2084684178503421e-6, 1.2169543159925654e-6, 1.2226195474870514e-6]\n",
      "bcs_losses: [1.1395566667647193e-5, 1.1423088794949352e-5, 1.3580881308308275e-5, 1.2669252415376065e-5, 1.5010568471247076e-5, 1.2524865128585673e-5, 1.1317282578752342e-5, 1.1399675170717238e-5, 1.125267210193112e-5, 0.9990746682275106, 3.6177388485077696e-6, 1.0011394947609678]\n",
      "loss: 1.5382359190732307e39\n",
      "pde_losses: [1.549360507690313e39, 1.212178747073645e-6, 1.1828019843489586e-6, 1.225137736064303e-6]\n",
      "bcs_losses: [1.1034157979163415e-5, 1.133386581145838e-5, 1.3229628796677834e-5, 1.25380989561584e-5, 1.4630700006090379e-5, 1.2425025678928009e-5, 1.1046500717641748e-5, 1.0987654487940537e-5, 1.1107178972615925e-5, 0.9992477803225498, 3.581271000459504e-6, 1.0009643230064214]\n",
      "loss: 1.511192843325301e39\n",
      "pde_losses: [1.513992414378795e39, 1.2100628848437326e-6, 1.1981193900704933e-6, 1.1739725182555225e-6]\n",
      "bcs_losses: [1.0845143842257936e-5, 1.1356983802485696e-5, 1.2924848201042589e-5, 1.2402988787316301e-5, 1.445198782317111e-5, 1.2516535438726841e-5, 1.0886809583038897e-5, 1.0906264388945446e-5, 1.0926775722394958e-5, 0.9993957951363146, 3.4381938504199055e-6, 1.0008142245668818]\n",
      "loss: 1.5074687499889913e39\n",
      "pde_losses: [1.504045369305924e39, 1.2170443420827416e-6, 1.2116024383412195e-6, 1.1880079159945119e-6]\n",
      "bcs_losses: [1.0746537771481251e-5, 1.0950834094212845e-5, 1.2578370935326492e-5, 1.2621368252980898e-5, 1.4500649820629757e-5, 1.2491931315176351e-5, 1.0623337389865042e-5, 1.0645629103192072e-5, 1.073059315216109e-5, 0.9994612893039208, 3.192496295338049e-6, 1.0007466958254327]\n",
      "loss: 1.4957949396457675e39\n",
      "pde_losses: [1.492602034697943e39, 1.2051196889857094e-6, 1.193922611352185e-6, 1.2054736718443627e-6]\n",
      "bcs_losses: [1.0539284868421837e-5, 1.0833179332628848e-5, 1.2192297779602191e-5, 1.2985488441532033e-5, 1.434556359417725e-5, 1.237949770797647e-5, 1.0551619914496368e-5, 1.0572897930051145e-5, 1.0708204222136333e-5, 0.9994765315739584, 2.962757222649483e-6, 1.0007296710497438]\n",
      "loss: 1.4932650870896302e39\n",
      "pde_losses: [1.488397781964899e39, 1.1856028184067376e-6, 1.1938762884900925e-6, 1.1889846566159217e-6]\n",
      "bcs_losses: [1.049359866346273e-5, 1.07022650186145e-5, 1.2110822843963589e-5, 1.3190751011791588e-5, 1.4166198992579575e-5, 1.2624597214309357e-5, 1.0592405838199086e-5, 1.0463608963719777e-5, 1.0723878367053248e-5, 0.9994964743566594, 2.798189330284405e-6, 1.0007080205229435]\n",
      "loss: 1.4890039160835604e39\n",
      "pde_losses: [1.4949422579428543e39, 1.1865061959181013e-6, 1.1806809976724425e-6, 1.150085490501574e-6]\n",
      "bcs_losses: [1.0478937340404066e-5, 1.0747708180729032e-5, 1.1840858593949998e-5, 1.3239266453397884e-5, 1.4069538605120279e-5, 1.2684385338479833e-5, 1.0520066378613209e-5, 1.0485286532199536e-5, 1.053235771065328e-5, 0.9995649845558512, 2.7558630967077326e-6, 1.000637886729097]\n",
      "loss: 1.4596475598567535e39\n",
      "pde_losses: [1.474840494368053e39, 1.1548424182678533e-6, 1.174808255496646e-6, 1.173725300946426e-6]\n",
      "bcs_losses: [1.040675584950258e-5, 1.0776054958684816e-5, 1.1864609572558905e-5, 1.3277577797764151e-5, 1.410392982326757e-5, 1.2636615337635123e-5, 1.0393207619422956e-5, 1.0340056912868193e-5, 1.0414778120391533e-5, 0.9996802112622806, 2.7760651298292232e-6, 1.0005211542344754]\n",
      "loss: 1.4833569550236745e39\n",
      "pde_losses: [1.482571640160964e39, 1.1587978243943823e-6, 1.1461253969298441e-6, 1.163622520401737e-6]\n",
      "bcs_losses: [1.0398600915270063e-5, 1.0690607176370648e-5, 1.1659320225363185e-5, 1.3169191845297832e-5, 1.3758736819823582e-5, 1.256448700404075e-5, 1.0452601035096746e-5, 1.0331588403775993e-5, 1.0393147732202567e-5, 0.9997338406878302, 2.7383947471716517e-6, 1.0004659301009178]\n",
      "loss: 1.4748258899979567e39\n",
      "pde_losses: [1.4462873044794682e39, 1.1786832051914153e-6, 1.152164318578538e-6, 1.143406414765944e-6]\n",
      "bcs_losses: [1.0263033083952468e-5, 1.0608412390815643e-5, 1.1517094506491061e-5, 1.2943969593289288e-5, 1.3630371852803628e-5, 1.2559850587854487e-5, 1.0418643267319746e-5, 1.0301269028606892e-5, 1.033994501395423e-5, 0.9996848998371455, 2.6244889417073848e-6, 1.0005133197194138]\n",
      "loss: 1.4703260678828812e39\n",
      "pde_losses: [1.4283742758416054e39, 1.1244276729401625e-6, 1.1548302184947577e-6, 1.166818914722139e-6]\n",
      "bcs_losses: [1.0243514175748887e-5, 1.039499521248899e-5, 1.1568411310415731e-5, 1.2691442349022677e-5, 1.374567249859257e-5, 1.2360403416982972e-5, 1.0286791243643288e-5, 1.0182458293350703e-5, 1.026034983877639e-5, 0.999573806350923, 2.5908912918299812e-6, 1.0006232588443327]\n",
      "loss: 1.430874658043302e39\n",
      "pde_losses: [1.4429184469542634e39, 1.1494623652570363e-6, 1.1386231778414977e-6, 1.1421704149469325e-6]\n",
      "bcs_losses: [1.010964056644307e-5, 1.0246214414906372e-5, 1.1425959674924614e-5, 1.2495092846060855e-5, 1.3728563936561194e-5, 1.195491302809168e-5, 1.0056446868014328e-5, 1.0105718981601502e-5, 1.0102825585353966e-5, 0.9994823598037226, 2.711320931869461e-6, 1.000713767930129]\n",
      "loss: 1.4242373555433427e39\n",
      "pde_losses: [1.4122737084579623e39, 1.1495009953057942e-6, 1.1331672513787634e-6, 1.1485054560653892e-6]\n",
      "bcs_losses: [9.890851618611395e-6, 1.0081791039195214e-5, 1.1439235402830689e-5, 1.233936405822939e-5, 1.3651887965187999e-5, 1.1776789969618844e-5, 9.939262614277503e-6, 9.948961249116106e-6, 1.006675376978806e-5, 0.9994292300454068, 2.9259978574613756e-6, 1.0007661018262808]\n",
      "loss: 1.3955471561732915e39\n",
      "pde_losses: [1.3959878617158904e39, 1.1340047117550872e-6, 1.126787871410955e-6, 1.1125359036189205e-6]\n",
      "bcs_losses: [9.87301859999765e-6, 1.0053572355650208e-5, 1.145095071741311e-5, 1.2039602007832312e-5, 1.362001436349374e-5, 1.1584719807636418e-5, 9.728246603363817e-6, 9.808529165264672e-6, 9.83795740697773e-6, 0.9994487372750385, 3.1010291969043496e-6, 1.0007455425432596]\n",
      "loss: 1.394720191893097e39\n",
      "pde_losses: [1.3989466893406497e39, 1.09662369811798e-6, 1.1311884707093979e-6, 1.1190825421857651e-6]\n",
      "bcs_losses: [9.816612191326477e-6, 1.0169602220708225e-5, 1.1688819044360873e-5, 1.1921387310820226e-5, 1.3383278903466937e-5, 1.1597170545749787e-5, 9.846433705761499e-6, 9.742453093494353e-6, 9.733653409240072e-6, 0.9994605822036583, 3.1619383906990316e-6, 1.0007325004547774]\n",
      "loss: 1.4040385373939396e39\n",
      "pde_losses: [1.3772816218757986e39, 1.116670244776718e-6, 1.120746793894451e-6, 1.1310464284153753e-6]\n",
      "bcs_losses: [9.793455476234089e-6, 1.0138557895439038e-5, 1.1466442183203022e-5, 1.1824297958450699e-5, 1.3116094414992888e-5, 1.1640783093651485e-5, 9.628288231247043e-6, 9.79227407041973e-6, 9.644471609443912e-6, 0.9994769056497844, 3.182475741997213e-6, 1.0007148846623388]\n",
      "loss: 1.367543334843477e39\n",
      "pde_losses: [1.3787017427754376e39, 1.1222834138607813e-6, 1.1129294201069358e-6, 1.1164684814569477e-6]\n",
      "bcs_losses: [9.776434245218986e-6, 1.0206537864791595e-5, 1.1382708353740431e-5, 1.1861336500208097e-5, 1.3080732120753484e-5, 1.1550127763297161e-5, 9.773034634476957e-6, 9.789121932571679e-6, 9.833094016649426e-6, 0.9994351209098136, 3.172203343401484e-6, 1.0007554041333049]\n",
      "loss: 1.3666657541281556e39\n",
      "pde_losses: [1.3662977735734074e39, 1.1335114196543658e-6, 1.1224849487683748e-6, 1.1065926451459997e-6]\n",
      "bcs_losses: [9.777198198783714e-6, 9.956795372689732e-6, 1.1404088142952302e-5, 1.195692214576343e-5, 1.2992293238907091e-5, 1.1402935043233261e-5, 9.738466955140293e-6, 9.757502318504884e-6, 9.712963416764746e-6, 0.9993934295544286, 3.1578406532194667e-6, 1.0007957826702665]\n",
      "loss: 1.357124480187397e39\n",
      "pde_losses: [1.369059177629673e39, 1.08818137284202e-6, 1.1064221460208493e-6, 1.098267570544481e-6]\n",
      "bcs_losses: [9.7409090260047e-6, 9.94798509453087e-6, 1.1310872541931518e-5, 1.1996214203558926e-5, 1.3108653485565239e-5, 1.1411630900561275e-5, 9.697864731313626e-6, 9.70815112997482e-6, 9.687647718790127e-6, 0.9993572275461282, 3.1213502665011183e-6, 1.0008305920152898]\n",
      "loss: 1.329749254992004e39\n",
      "pde_losses: [1.3720962034789206e39, 1.0876904413253171e-6, 1.0840538419002714e-6, 1.0950700098491248e-6]\n",
      "bcs_losses: [9.587647291104214e-6, 9.798879988923154e-6, 1.1084879148771392e-5, 1.1885742680272125e-5, 1.2965119291969137e-5, 1.1197455823510103e-5, 9.518688268404068e-6, 9.596773164950883e-6, 9.652511645422578e-6, 0.9993723642938173, 3.094892478807269e-6, 1.0008141159992665]\n",
      "loss: 1.3444979678715542e39\n",
      "pde_losses: [1.3360045332179603e39, 1.0795292405335022e-6, 1.1088110188280393e-6, 1.0827795652067507e-6]\n",
      "bcs_losses: [9.389626374000893e-6, 9.830677894944398e-6, 1.0935326552956692e-5, 1.1874377193106888e-5, 1.2921400263453862e-5, 1.1279176487084422e-5, 9.472145393641588e-6, 9.482749927348263e-6, 9.431810777552573e-6, 0.9994392436565, 3.0254667303603967e-6, 1.000745645313121]\n",
      "loss: 1.3193537685740724e39\n",
      "pde_losses: [1.3260024880929403e39, 1.091202848432744e-6, 1.085383187336467e-6, 1.0883270693770767e-6]\n",
      "bcs_losses: [9.319283980195623e-6, 9.682608158401757e-6, 1.0768625393683335e-5, 1.1694864953992628e-5, 1.2750931212307987e-5, 1.126104193041123e-5, 9.379387736533804e-6, 9.394215873953208e-6, 9.378441255870205e-6, 0.9995035130102566, 2.936621891073549e-6, 1.0006797206729052]\n",
      "loss: 1.3358735262287977e39\n",
      "pde_losses: [1.3183497093961355e39, 1.0678835404254276e-6, 1.095544691917431e-6, 1.0960708734519159e-6]\n",
      "bcs_losses: [9.285740273341553e-6, 9.638628506374828e-6, 1.048449081069846e-5, 1.1545007794048346e-5, 1.2615944181562785e-5, 1.1311933513759895e-5, 9.207120497059635e-6, 9.346221683572759e-6, 9.294033449192563e-6, 0.9995717570721656, 2.859250731775878e-6, 1.0006099898707326]\n",
      "loss: 1.3261752313572932e39\n",
      "pde_losses: [1.3401167224763476e39, 1.0685704535558009e-6, 1.1028441184367594e-6, 1.0780018639073368e-6]\n",
      "bcs_losses: [9.097108200956327e-6, 9.669353581533271e-6, 1.0481205080546539e-5, 1.1542230108629334e-5, 1.2487405081224663e-5, 1.1174710285253333e-5, 9.112817480888331e-6, 9.160442031096629e-6, 9.187996347671234e-6, 0.9996354780567243, 2.8346588183378934e-6, 1.0005448522609934]\n",
      "loss: 1.2962996636619061e39\n",
      "pde_losses: [1.3081777753018377e39, 1.0574027763093199e-6, 1.0800723169930803e-6, 1.0721299539649982e-6]\n",
      "bcs_losses: [9.110894366133222e-6, 9.3483902749206e-6, 1.0378519093864735e-5, 1.1469969552664714e-5, 1.2516367944917793e-5, 1.1255563614586983e-5, 9.098124212085387e-6, 9.132248459446993e-6, 9.193411141700085e-6, 0.9996263554716338, 2.761555066643062e-6, 1.0005526318863462]\n",
      "loss: 1.3042753981074037e39\n",
      "pde_losses: [1.2974138332696404e39, 1.0588831714416876e-6, 1.055390216369578e-6, 1.0893472380424301e-6]\n",
      "bcs_losses: [8.997577377546382e-6, 9.225728966014429e-6, 1.0217107250969103e-5, 1.1531081824805973e-5, 1.2556488076779364e-5, 1.1185453201550544e-5, 9.084571668018912e-6, 9.213431763835401e-6, 9.06915873747123e-6, 0.9995694464674543, 2.681779533897063e-6, 1.0006081534326792]\n",
      "loss: 1.3058178588194577e39\n",
      "pde_losses: [1.2982736550860642e39, 1.0489595403784022e-6, 1.061886525436904e-6, 1.05035054960497e-6]\n",
      "bcs_losses: [9.063047711667861e-6, 9.173487125668184e-6, 1.0225724893920307e-5, 1.1433101850904237e-5, 1.248165378878046e-5, 1.1206644512191386e-5, 9.088165106304715e-6, 9.122191811919297e-6, 9.151096255285256e-6, 0.9994909384246318, 2.589136852248635e-6, 1.000685377475719]\n",
      "loss: 1.2762531571524674e39\n",
      "pde_losses: [1.271577017479286e39, 1.0506463693374678e-6, 1.0615414734740633e-6, 1.0556878184786983e-6]\n",
      "bcs_losses: [8.966594261727946e-6, 9.16029015780637e-6, 1.0009989098152911e-5, 1.1485174944131273e-5, 1.2406375848042858e-5, 1.101209319895609e-5, 9.014063367625167e-6, 9.037368163495116e-6, 8.997537212926894e-6, 0.999495878993136, 2.6688738931982168e-6, 1.0006794093342783]\n",
      "loss: 1.2721860344161716e39\n",
      "pde_losses: [1.2870949528647622e39, 1.0575193253895e-6, 1.0494000488654235e-6, 1.083349369173729e-6]\n",
      "bcs_losses: [8.995808447013294e-6, 9.199279099475547e-6, 1.0201183417620037e-5, 1.1428396761909138e-5, 1.2129259061562003e-5, 1.1027400668536431e-5, 8.967550305137053e-6, 8.891471467715952e-6, 8.865945976838516e-6, 0.9995705606299993, 2.7898676425804733e-6, 1.0006037565592933]\n",
      "loss: 1.2771373487311232e39\n",
      "pde_losses: [1.289642846633988e39, 1.0250837874068855e-6, 1.0371033957987384e-6, 1.0322275375381517e-6]\n",
      "bcs_losses: [8.790893548098613e-6, 9.216778571178771e-6, 1.0068773970909195e-5, 1.1332176853730075e-5, 1.1913480597114145e-5, 1.0875746742500241e-5, 8.85942136939784e-6, 8.883070631476907e-6, 8.834721401387712e-6, 0.999643671437591, 2.917448128710175e-6, 1.000529741795545]\n",
      "loss: 1.2413539527731812e39\n",
      "pde_losses: [1.2590045437077975e39, 1.0317730323723074e-6, 1.0440089816435544e-6, 1.0394141084068326e-6]\n",
      "bcs_losses: [8.776179556764773e-6, 9.122771832169912e-6, 9.94854355256158e-6, 1.1201671089763153e-5, 1.1823826795632455e-5, 1.0840962684111035e-5, 8.694355525217825e-6, 8.739858093347357e-6, 8.704517382296445e-6, 0.999603194106965, 2.969800518933269e-6, 1.000569423060276]\n",
      "loss: 1.2354153389695685e39\n",
      "pde_losses: [1.2359427400888608e39, 1.0415646940265383e-6, 1.0232871352949522e-6, 1.0093362091489249e-6]\n",
      "bcs_losses: [8.645674305012099e-6, 9.195931239586799e-6, 1.0041647215502933e-5, 1.1097458071246027e-5, 1.1985086867874816e-5, 1.0850359364394241e-5, 8.702127647236653e-6, 8.694664760934135e-6, 8.765718131788896e-6, 0.999535760473503, 3.004719999091705e-6, 1.000636120773469]\n",
      "loss: 1.2303032796432619e39\n",
      "pde_losses: [1.241615656233206e39, 1.0324730890754723e-6, 1.0252755377294392e-6, 1.0304400470201511e-6]\n",
      "bcs_losses: [8.702161764741046e-6, 8.94662558988598e-6, 9.859691370374584e-6, 1.116005383852565e-5, 1.1814892868682204e-5, 1.0641725543524612e-5, 8.607145873612539e-6, 8.643758911052667e-6, 8.66040659309345e-6, 0.9995152981930904, 3.107855097981345e-6, 1.0006558501544864]\n",
      "loss: 1.2401290745095866e39\n",
      "pde_losses: [1.2412033846687085e39, 1.016503970183683e-6, 1.019893089042311e-6, 1.033516448634162e-6]\n",
      "bcs_losses: [8.492164393331575e-6, 8.80713941623682e-6, 9.890439430695203e-6, 1.0953293871679434e-5, 1.2050357474139741e-5, 1.0419217320616258e-5, 8.531259065939543e-6, 8.550035421220937e-6, 8.596963573384535e-6, 0.9994794811209889, 3.1349400210869103e-6, 1.000690863618487]\n",
      "loss: 1.2367648187275478e39\n",
      "pde_losses: [1.2202560176748207e39, 1.0061361286559954e-6, 1.0142525338333416e-6, 1.0236118813720082e-6]\n",
      "bcs_losses: [8.520145143804012e-6, 8.84373047141324e-6, 9.93187445515388e-6, 1.0935368652553958e-5, 1.1944355866166909e-5, 1.042851752865167e-5, 8.51358541057561e-6, 8.529013205722314e-6, 8.50306873974117e-6, 0.999429843604976, 3.00950209454688e-6, 1.0007394570922177]\n",
      "loss: 1.2329017827982998e39\n",
      "pde_losses: [1.216529911646574e39, 1.0130151743360888e-6, 1.0117812165587813e-6, 1.0078742048437722e-6]\n",
      "bcs_losses: [8.555779583763035e-6, 8.67969999524836e-6, 9.781509753742967e-6, 1.0835587436823584e-5, 1.1750606167635917e-5, 1.0458964242050848e-5, 8.535610734156289e-6, 8.493476937278296e-6, 8.462736019177944e-6, 0.9993692644698948, 2.7544551013708417e-6, 1.0007988127065517]\n",
      "loss: 1.2107476673518472e39\n",
      "pde_losses: [1.2234813371577377e39, 9.912174745967398e-7, 1.0099775173908339e-6, 9.980011047026359e-7]\n",
      "bcs_losses: [8.531524174769885e-6, 8.728536792291967e-6, 9.709577392194142e-6, 1.0836044550698941e-5, 1.164064352985679e-5, 1.0589811629766365e-5, 8.513280432428382e-6, 8.483684487431189e-6, 8.559418997765608e-6, 0.9993970882978429, 2.6525174242814353e-6, 1.0007698423091278]\n",
      "loss: 1.2127707298591713e39\n",
      "pde_losses: [1.1890237292706384e39, 1.0098357340067581e-6, 9.892524046372806e-7, 9.895535174832732e-7]\n",
      "bcs_losses: [8.36231485957217e-6, 8.726997196782923e-6, 9.409113766308173e-6, 1.0736705283180247e-5, 1.1575943697864604e-5, 1.0409849605163965e-5, 8.330494567193002e-6, 8.346136687161473e-6, 8.341089744815136e-6, 0.9995115012525362, 2.7620917709814234e-6, 1.000654510878312]\n",
      "loss: 1.2095447764142162e39\n",
      "pde_losses: [1.2112163802340792e39, 9.92391614749685e-7, 9.93615773873263e-7, 9.934075875257326e-7]\n",
      "bcs_losses: [8.253190966539384e-6, 8.707910921776784e-6, 9.565365144681846e-6, 1.0608815205266939e-5, 1.1282990735123587e-5, 1.0255965431153108e-5, 8.224460246276045e-6, 8.258897693276828e-6, 8.257361966738149e-6, 0.9996215820943564, 2.969325255192245e-6, 1.0005435544366685]\n",
      "loss: 1.1841234552433352e39\n",
      "pde_losses: [1.2054332521047747e39, 9.76980012706166e-7, 1.0026033410592598e-6, 9.649641758083107e-7]\n",
      "bcs_losses: [8.132986398482838e-6, 8.62274408199151e-6, 9.501582820302988e-6, 1.0820031990488275e-5, 1.1261747162129505e-5, 1.0120795189823485e-5, 8.091345706946218e-6, 8.09125547746278e-6, 8.115510545855263e-6, 0.9996405773543628, 3.0109042742893734e-6, 1.0005236005197329]\n",
      "loss: 1.184254755238893e39\n",
      "pde_losses: [1.1710250153852754e39, 9.687420972889147e-7, 1.0036653298666129e-6, 9.808830055451774e-7]\n",
      "bcs_losses: [8.13622232319947e-6, 8.500373840021944e-6, 9.372417833405922e-6, 1.0659318968953539e-5, 1.1291672500153774e-5, 1.0290293509128238e-5, 8.122376319064448e-6, 8.077322939674074e-6, 8.082024278544044e-6, 0.9995836558898128, 2.8467676846323674e-6, 1.0005792874409112]\n",
      "loss: 1.1878403699966156e39\n",
      "pde_losses: [1.1755234786779915e39, 9.964630578299301e-7, 1.001105411566622e-6, 9.737281217736737e-7]\n",
      "bcs_losses: [8.122437894852502e-6, 8.454494722404984e-6, 9.237672821385704e-6, 1.0607878221558578e-5, 1.1181477153039965e-5, 1.0173123366812905e-5, 8.080995216480414e-6, 8.17767054836151e-6, 8.141448696947445e-6, 0.9995558549245871, 2.7322765583325485e-6, 1.0006059083740975]\n",
      "loss: 1.1743938962804121e39\n",
      "pde_losses: [1.170417106218644e39, 9.822311157083792e-7, 9.72070188354353e-7, 9.829706479090003e-7]\n",
      "bcs_losses: [8.010407135280858e-6, 8.357446783210687e-6, 9.18768095504897e-6, 1.0595188157965465e-5, 1.1185584672997925e-5, 1.024477945122634e-5, 8.096802547334346e-6, 8.104076037166983e-6, 8.014793391388394e-6, 0.9995842589358, 2.7669649557790297e-6, 1.0005764673428021]\n",
      "loss: 1.1707359911832893e39\n",
      "pde_losses: [1.1646199093280863e39, 9.69255398418078e-7, 9.846249297744422e-7, 9.736188056424218e-7]\n",
      "bcs_losses: [8.030337945930206e-6, 8.482843041405493e-6, 9.246763072745456e-6, 1.0468344415014326e-5, 1.1112593418587613e-5, 9.985617876566216e-6, 7.988484669204207e-6, 8.007242547094805e-6, 7.922936837093829e-6, 0.9996392513160606, 2.925483863226818e-6, 1.0005206041082522]\n",
      "loss: 1.163856592715051e39\n",
      "pde_losses: [1.1523789873622655e39, 9.599120736331484e-7, 9.669582685539238e-7, 9.690594401528105e-7]\n",
      "bcs_losses: [7.842148111698887e-6, 8.282892031556639e-6, 9.122353541265072e-6, 1.0193261161719162e-5, 1.10395741331233e-5, 9.964592468278762e-6, 7.903849104463689e-6, 7.84116045590775e-6, 7.884989316914533e-6, 0.9996246588954569, 2.959544050822995e-6, 1.0005341918395687]\n",
      "loss: 1.1444290142611226e39\n",
      "pde_losses: [1.163958342060785e39, 9.536898123643702e-7, 9.728234733148783e-7, 9.734661809874327e-7]\n",
      "bcs_losses: [7.901181663083523e-6, 8.107669007480733e-6, 9.041075501770843e-6, 1.0206447759479215e-5, 1.1135720694718428e-5, 9.886254361797477e-6, 7.862447524389288e-6, 7.867219018510818e-6, 7.85808808363831e-6, 0.9995558027164672, 2.8222524408539387e-6, 1.0006018870098663]\n",
      "loss: 1.1324069970947897e39\n",
      "pde_losses: [1.1547154013049652e39, 9.596977295238577e-7, 9.504831671220253e-7, 9.600248949665019e-7]\n",
      "bcs_losses: [7.859281050028526e-6, 8.04481613926632e-6, 8.95520542367522e-6, 1.0237723807116511e-5, 1.1012995828192513e-5, 9.970504627771303e-6, 7.838557742078728e-6, 7.81046695447492e-6, 8.070166826066293e-6, 0.9994881814692007, 2.6793375009138317e-6, 1.000668297551402]\n",
      "loss: 1.1229815613109492e39\n",
      "pde_losses: [1.1465519376663567e39, 9.544093656110764e-7, 9.591026278254287e-7, 9.547496107414817e-7]\n",
      "bcs_losses: [7.917351778027107e-6, 8.16919279829329e-6, 8.845433192913748e-6, 1.0220635639497043e-5, 1.0801848744543587e-5, 9.990320068555887e-6, 7.844519106900111e-6, 7.859939000699196e-6, 7.809591854120784e-6, 0.9995129009110777, 2.657635055191068e-6, 1.0006422401306643]\n",
      "loss: 1.1442694125336813e39\n",
      "pde_losses: [1.1304985452465976e39, 9.420915793720468e-7, 9.517274522166568e-7, 9.507187750197817e-7]\n",
      "bcs_losses: [7.759535881955985e-6, 8.180273228400664e-6, 8.82052661639737e-6, 1.0160494543075563e-5, 1.0770164852589345e-5, 9.826535908329207e-6, 7.721798143556976e-6, 7.747815421735278e-6, 7.726661648104949e-6, 0.9995818028015083, 2.747933601649419e-6, 1.0005720966139275]\n",
      "loss: 1.125748267360118e39\n",
      "pde_losses: [1.10928828325302e39, 9.289251812462419e-7, 9.127801789987104e-7, 9.484531930968744e-7]\n",
      "bcs_losses: [7.664879410815853e-6, 8.189831144560139e-6, 8.782221451242426e-6, 1.0048264674899747e-5, 1.0670302304486734e-5, 9.716888750489794e-6, 7.612605629406249e-6, 7.580594999492733e-6, 7.473835435629602e-6, 0.9996298038409757, 2.886359224399569e-6, 1.0005229820044712]\n",
      "loss: 1.1242890671255243e39\n",
      "pde_losses: [1.1265953524715552e39, 9.245916529685392e-7, 9.374465040061961e-7, 9.455349472019457e-7]\n",
      "bcs_losses: [7.670630492728116e-6, 8.024525653231607e-6, 8.825853998695016e-6, 1.012048982166531e-5, 1.0669270465856118e-5, 9.569463379229418e-6, 7.6033091672480625e-6, 7.549318682360711e-6, 7.60239023121226e-6, 0.9996171438110819, 2.928056605839944e-6, 1.0005345074692862]\n",
      "loss: 1.1084974370417796e39\n",
      "pde_losses: [1.095342051296094e39, 9.265728253108269e-7, 9.426448344138511e-7, 9.272649728523695e-7]\n",
      "bcs_losses: [7.622517725083693e-6, 7.99233684786785e-6, 8.764558220868252e-6, 1.0045157084103752e-5, 1.0729668292697269e-5, 9.66374283335009e-6, 7.631582004646535e-6, 7.555072997996733e-6, 7.5558032054269895e-6, 0.9995409154432691, 2.778617173994877e-6, 1.0006095016311773]\n",
      "loss: 1.1261007279807694e39\n",
      "pde_losses: [1.1017358721298594e39, 9.339363627432488e-7, 8.981486189114258e-7, 9.291812205389033e-7]\n",
      "bcs_losses: [7.532951296795269e-6, 7.982708893826018e-6, 8.625223130632213e-6, 1.0058154661595049e-5, 1.0537497294264888e-5, 9.737417014112005e-6, 7.585072244076883e-6, 7.653908420769458e-6, 7.56936346089241e-6, 0.9995075317986057, 2.6958013735381784e-6, 1.0006416541574947]\n",
      "loss: 1.0856446249789727e39\n",
      "pde_losses: [1.0855541036561034e39, 9.202471986931676e-7, 9.195021714899533e-7, 9.246771013908177e-7]\n",
      "bcs_losses: [7.487362553036865e-6, 7.805156211052778e-6, 8.60357475086602e-6, 9.958115684887439e-6, 1.0473817560264413e-5, 9.626938096098824e-6, 7.421553272379084e-6, 7.486782160649029e-6, 7.454556320402659e-6, 0.999554004906248, 2.7637560762362426e-6, 1.0005940951336312]\n",
      "loss: 1.095097134924636e39\n",
      "pde_losses: [1.0789093108338343e39, 9.086134061105579e-7, 9.299398277023956e-7, 9.27536801576179e-7]\n",
      "bcs_losses: [7.4013393744710465e-6, 7.969940243673331e-6, 8.603229524348762e-6, 9.75418391573318e-6, 1.0337000229052433e-5, 9.451436337643383e-6, 7.410430034651582e-6, 7.366122275857971e-6, 7.276224859194198e-6, 0.9996535796760571, 2.9274038609305984e-6, 1.0004934824115919]\n",
      "loss: 1.0896687337120805e39\n",
      "pde_losses: [1.0646751287047616e39, 9.208951289255129e-7, 9.263563447780914e-7, 9.146396068234543e-7]\n",
      "bcs_losses: [7.262220152697229e-6, 7.822592126267686e-6, 8.503003972107417e-6, 9.704903010158535e-6, 1.0316251479290822e-5, 9.335986868957277e-6, 7.28392955953644e-6, 7.232574685035944e-6, 7.331562860289891e-6, 0.9996832786895793, 3.0196770756791383e-6, 1.0004625842711912]\n",
      "loss: 1.0876620887484841e39\n",
      "pde_losses: [1.081930374300091e39, 9.157046953968796e-7, 9.162783573623698e-7, 8.962720292258127e-7]\n",
      "bcs_losses: [7.247678051994807e-6, 7.767695919959877e-6, 8.346926398796323e-6, 9.67669352631573e-6, 1.0243449928788591e-5, 9.326655172650375e-6, 7.250496550055976e-6, 7.260870040607078e-6, 7.355346580647295e-6, 0.9995923974210694, 2.864608813354127e-6, 1.000552125784282]\n",
      "loss: 1.0782472002740688e39\n",
      "pde_losses: [1.076761400658201e39, 9.076562023995285e-7, 9.261623074677469e-7, 9.079605133325134e-7]\n",
      "bcs_losses: [7.349952123978829e-6, 7.712574953574086e-6, 8.308293760070918e-6, 9.601955134458106e-6, 1.0258644943431487e-5, 9.40427330385112e-6, 7.313316783636177e-6, 7.319003849395154e-6, 7.397880558015187e-6, 0.9995117024966594, 2.724355237666181e-6, 1.0006314997270196]\n",
      "loss: 1.0609049992126025e39\n",
      "pde_losses: [1.0638059670388314e39, 8.904412123307839e-7, 8.901118382069078e-7, 8.994100812886907e-7]\n",
      "bcs_losses: [7.292821433608046e-6, 7.610546928861638e-6, 8.162855966947823e-6, 9.707009957922338e-6, 1.0234854427617934e-5, 9.35335390415211e-6, 7.3836577086263025e-6, 7.286757382436496e-6, 7.2882450114258245e-6, 0.9995123030169906, 2.6894256694955853e-6, 1.0006296550862763]\n",
      "loss: 1.0606254638157436e39\n",
      "pde_losses: [1.0527026435431639e39, 8.910773389584228e-7, 9.05296190137656e-7, 9.060413928075723e-7]\n",
      "bcs_losses: [7.27497066459687e-6, 7.5982750435890165e-6, 8.212788674265627e-6, 9.642943663088182e-6, 1.0089864309389258e-5, 9.243305163220386e-6, 7.217198041576047e-6, 7.169559683943782e-6, 7.193306049683255e-6, 0.9995708885333702, 2.700966957904461e-6, 1.0005698017220723]\n",
      "loss: 1.0333163567418636e39\n",
      "pde_losses: [1.0489613812408793e39, 9.160759224282853e-7, 9.049644220890436e-7, 8.905018952675933e-7]\n",
      "bcs_losses: [7.155186001970209e-6, 7.518478999896549e-6, 8.157703003899135e-6, 9.652920530038671e-6, 9.919503687174288e-6, 9.252115036695805e-6, 7.114118336619184e-6, 7.186396364526876e-6, 7.125134710263422e-6, 0.9996406906183417, 2.7123429681398086e-6, 1.00049873447715]\n",
      "loss: 1.0561427147286927e39\n",
      "pde_losses: [1.0488641883991677e39, 8.823374227415912e-7, 8.928003414308154e-7, 8.941933008522679e-7]\n",
      "bcs_losses: [7.118259001529617e-6, 7.562348077873233e-6, 8.204718642474159e-6, 9.520434726422555e-6, 9.868243847446105e-6, 9.205963312397825e-6, 7.090867512056429e-6, 7.199214786378439e-6, 7.0859903990552875e-6, 0.9997044235774648, 2.7228709265894193e-6, 1.0004337369268874]\n",
      "loss: 1.0441741191191393e39\n",
      "pde_losses: [1.0525171650791288e39, 8.863565515260971e-7, 8.87755576611907e-7, 8.730416952762677e-7]\n",
      "bcs_losses: [7.027847693864372e-6, 7.599588593256851e-6, 8.143775752533035e-6, 9.608947666916474e-6, 9.773114691730034e-6, 9.124866388186779e-6, 7.033062681739086e-6, 7.105937225594209e-6, 7.113923279465187e-6, 0.9997006569720457, 2.6694476996817897e-6, 1.00043637812823]\n",
      "loss: 1.0292295359778006e39\n",
      "pde_losses: [1.0462753522896043e39, 8.801668342021121e-7, 8.846011042970874e-7, 8.703455032827467e-7]\n",
      "bcs_losses: [7.0315003277047724e-6, 7.4740601240830845e-6, 7.988820130342211e-6, 9.435873981815119e-6, 9.75975455706299e-6, 9.192444397604683e-6, 7.059585080835893e-6, 7.045263020158638e-6, 6.988526002262615e-6, 0.9996676897119279, 2.6913253224720393e-6, 1.0004683039592706]\n",
      "loss: 1.0253283079988462e39\n",
      "pde_losses: [1.0303051339354288e39, 8.910925336643264e-7, 8.810053554312509e-7, 8.754824070676929e-7]\n",
      "bcs_losses: [6.951236254204393e-6, 7.429593659786426e-6, 8.037151153470025e-6, 9.509855801597936e-6, 9.84547279796099e-6, 9.126243798519157e-6, 6.9021877193003475e-6, 6.9169673497627735e-6, 6.990340427572224e-6, 0.999641065770686, 2.7412608143827355e-6, 1.0004938628880309]\n",
      "loss: 1.0132216487291032e39\n",
      "pde_losses: [1.0387419566930456e39, 8.605393368982329e-7, 8.658479794416177e-7, 8.874360541383337e-7]\n",
      "bcs_losses: [6.827729637393565e-6, 7.363594366643548e-6, 8.091311958333586e-6, 9.400505447134688e-6, 9.984036112662338e-6, 8.914228698782009e-6, 6.908965483367378e-6, 6.886252570194859e-6, 6.932712636824195e-6, 0.999615372599292, 2.7455312140130737e-6, 1.0005184512004965]\n",
      "loss: 9.991009454891343e38\n",
      "pde_losses: [1.0102287046094609e39, 8.635661395241401e-7, 8.702176389581134e-7, 8.62729320830619e-7]\n",
      "bcs_losses: [6.8616143457088475e-6, 7.412587947715838e-6, 7.973844473515872e-6, 9.292585427069898e-6, 9.691053271877812e-6, 8.961472587761618e-6, 6.899932342805473e-6, 6.858176605653715e-6, 6.849151402912696e-6, 0.9996231579291359, 2.6967407261322113e-6, 1.0005094214955494]\n",
      "loss: 1.0158305852917018e39\n",
      "pde_losses: [1.020745342436007e39, 8.669730549414886e-7, 8.581327533773145e-7, 8.660380231246255e-7]\n",
      "bcs_losses: [6.853410666936541e-6, 7.3023242673121795e-6, 7.864560693580518e-6, 9.133199486222135e-6, 9.568587734862413e-6, 9.012804968607395e-6, 6.811591449573022e-6, 6.8799187547739976e-6, 6.9224388695596654e-6, 0.999624686806348, 2.6108287182224442e-6, 1.00050655155711]\n",
      "loss: 1.0078664427933466e39\n",
      "pde_losses: [9.975524807875923e38, 8.611744891241873e-7, 8.50388610822028e-7, 8.671095231013192e-7]\n",
      "bcs_losses: [6.832457557462678e-6, 7.198382400276982e-6, 7.768534147813075e-6, 9.10429925710639e-6, 9.609851598493662e-6, 9.063521143305306e-6, 6.875138570378037e-6, 6.8670149809259216e-6, 6.786334269108948e-6, 0.9996064242085708, 2.5824315265134725e-6, 1.000523754452634]\n",
      "loss: 1.0163071985137667e39\n",
      "pde_losses: [9.947852364514509e38, 8.677926803112568e-7, 8.682355511183982e-7, 8.48459091155705e-7]\n",
      "bcs_losses: [6.7246721468294635e-6, 7.235374982978516e-6, 7.682235650232838e-6, 9.164757392950681e-6, 9.508061935249434e-6, 8.78009234469995e-6, 6.779149793117289e-6, 6.804419773912395e-6, 6.761934044762932e-6, 0.9996171107220198, 2.6499368831757804e-6, 1.0005121104682364]\n",
      "loss: 9.792480614738828e38\n",
      "pde_losses: [9.988998023241377e38, 8.610103209483521e-7, 8.700783729034567e-7, 8.512638097516166e-7]\n",
      "bcs_losses: [6.620762365499606e-6, 7.1885750521422615e-6, 7.752163534178193e-6, 9.201860321109741e-6, 9.486942467714436e-6, 8.70631254825563e-6, 6.7313060381525366e-6, 6.692648631428168e-6, 6.626534236433403e-6, 0.999636697387805, 2.7843281813735333e-6, 1.0004918091191288]\n",
      "loss: 9.911158706163649e38\n",
      "pde_losses: [9.779485769960246e38, 8.380170171772519e-7, 8.611814557511792e-7, 8.553377929864979e-7]\n",
      "bcs_losses: [6.54670769342523e-6, 7.141970698777152e-6, 7.718515870601766e-6, 9.068941514849012e-6, 9.516260640633142e-6, 8.594281204737961e-6, 6.602958688364297e-6, 6.634521314698586e-6, 6.617612041972087e-6, 0.9996860378499883, 2.8692695675448696e-6, 1.0004416675657706]\n",
      "loss: 1.002596049497273e39\n",
      "pde_losses: [9.78858195733316e38, 8.507950230577358e-7, 8.521868808535377e-7, 8.398408249380325e-7]\n",
      "bcs_losses: [6.556716684539281e-6, 7.1070152478447636e-6, 7.572206412211638e-6, 9.075290385541944e-6, 9.317708660241172e-6, 8.799976089747296e-6, 6.640523977642922e-6, 6.697610470576112e-6, 6.612582249599114e-6, 0.9996990277970802, 2.76268091589044e-6, 1.0004276558920715]\n",
      "loss: 9.865724788095068e38\n",
      "pde_losses: [9.874516056756451e38, 8.467109207045535e-7, 8.433670925720906e-7, 8.318550569082292e-7]\n",
      "bcs_losses: [6.591897289914883e-6, 7.050145173412259e-6, 7.477014467069213e-6, 8.960548917118328e-6, 9.276040884746237e-6, 8.86405923479492e-6, 6.650676907232249e-6, 6.630506134686848e-6, 6.6474606112569956e-6, 0.9996701188781205, 2.6119724321296686e-6, 1.0004555748708202]\n",
      "loss: 9.738213496918583e38\n",
      "pde_losses: [9.701672280199453e38, 8.459176355767629e-7, 8.658720901521105e-7, 8.293136402824287e-7]\n",
      "bcs_losses: [6.612698525410447e-6, 7.01080739538437e-6, 7.500812848539554e-6, 8.921555062464343e-6, 9.216636450785643e-6, 8.724621329078992e-6, 6.630569159769413e-6, 6.606411584222388e-6, 6.644068098210485e-6, 0.999676537280975, 2.5982396839576724e-6, 1.000448293352596]\n",
      "loss: 9.769478246945441e38\n",
      "pde_losses: [9.662023474306682e38, 8.62411415745534e-7, 8.539086442326473e-7, 8.319495947315396e-7]\n",
      "bcs_losses: [6.50456654309415e-6, 6.9568561846966335e-6, 7.510492015023596e-6, 8.88257733313099e-6, 9.12722968674224e-6, 8.573941515718375e-6, 6.492555198332339e-6, 6.5250205743631794e-6, 6.490865650117432e-6, 0.9997187501397221, 2.7149954952180637e-6, 1.0004053556318986]\n",
      "loss: 9.640920253386942e38\n",
      "pde_losses: [9.683218370296981e38, 8.490590895125398e-7, 8.186910717637665e-7, 8.151277059139668e-7]\n",
      "bcs_losses: [6.471466265000868e-6, 6.914425105128736e-6, 7.437887760977172e-6, 8.795529675804644e-6, 9.117116731952003e-6, 8.533718479610467e-6, 6.443546858275819e-6, 6.444604540045716e-6, 6.405240457902383e-6, 0.9997083257451089, 2.791810718759792e-6, 1.000415106957207]\n",
      "loss: 9.556864730699251e38\n",
      "pde_losses: [9.675547496974669e38, 8.215436028012482e-7, 8.330493329585852e-7, 8.272679588217072e-7]\n",
      "bcs_losses: [6.397185288667091e-6, 6.836422976216947e-6, 7.477039778900407e-6, 8.823040533450403e-6, 9.164342147963772e-6, 8.50492700331276e-6, 6.431790963613186e-6, 6.373541941399966e-6, 6.301287689703555e-6, 0.9996532857194265, 2.7730679041301456e-6, 1.0004693147234254]\n",
      "loss: 9.47495013789904e38\n",
      "pde_losses: [9.425141604572397e38, 8.147406368228409e-7, 8.468685994270046e-7, 8.286411513630892e-7]\n",
      "bcs_losses: [6.338892369277389e-6, 6.745638790674402e-6, 7.382681370192014e-6, 8.702935601577578e-6, 9.069326048460231e-6, 8.513656607402626e-6, 6.4413100207193825e-6, 6.435520604883698e-6, 6.487198192647997e-6, 0.9996266175461719, 2.70586126052022e-6, 1.00049490655102]\n",
      "loss: 9.589298151967962e38\n",
      "pde_losses: [9.478520149005615e38, 8.041909253485516e-7, 8.258242976258148e-7, 8.112142711321873e-7]\n",
      "bcs_losses: [6.29973652075677e-6, 6.84838727263053e-6, 7.20592427150675e-6, 8.625159886393268e-6, 9.003116059007385e-6, 8.541549897812683e-6, 6.423898657637879e-6, 6.315137223752462e-6, 6.348987244756604e-6, 0.9996614843209979, 2.720676366734517e-6, 1.000459040544678]\n",
      "loss: 9.384975962742833e38\n",
      "pde_losses: [9.505165949192687e38, 8.281589302043547e-7, 8.204997994058873e-7, 8.302940563753351e-7]\n",
      "bcs_losses: [6.2890928256463685e-6, 6.739874173956613e-6, 7.187467837907877e-6, 8.64060896791271e-6, 8.863911748698912e-6, 8.560481466795844e-6, 6.233726170747445e-6, 6.3671402772880165e-6, 6.3518458542266995e-6, 0.9996554583054443, 2.7153852442333403e-6, 1.0004641589244265]\n",
      "loss: 9.458545688305219e38\n",
      "pde_losses: [9.43488168190081e38, 8.117255280618299e-7, 8.188255530904929e-7, 8.16512341502213e-7]\n",
      "bcs_losses: [6.347247993455531e-6, 6.74867788334778e-6, 7.190692042519655e-6, 8.553622417773227e-6, 8.844080780069076e-6, 8.427581045402943e-6, 6.265206501801468e-6, 6.3868004715943004e-6, 6.244498385459004e-6, 0.9996391844392786, 2.712080219991675e-6, 1.0004795814797123]\n",
      "loss: 9.255096219135751e38\n",
      "pde_losses: [9.390238497876638e38, 8.141380023474098e-7, 8.22297357326311e-7, 8.195338812387544e-7]\n",
      "bcs_losses: [6.3194097064122605e-6, 6.6628327727426334e-6, 7.1682060407950905e-6, 8.570104424418083e-6, 8.895481569596285e-6, 8.382679049265657e-6, 6.21697902057355e-6, 6.208672200955032e-6, 6.270534811924665e-6, 0.9996242222357381, 2.7057853165496847e-6, 1.000493651434724]\n",
      "loss: 9.374630949374367e38\n",
      "pde_losses: [9.29194840320427e38, 8.047118813240916e-7, 8.109470845991915e-7, 8.232974118168361e-7]\n",
      "bcs_losses: [6.133715647767699e-6, 6.645681513750839e-6, 7.112699937281212e-6, 8.571854377488836e-6, 8.871864108808911e-6, 8.285489370092061e-6, 6.227246547575007e-6, 6.241057615611987e-6, 6.138061555526256e-6, 0.9996759291094575, 2.7018714244531635e-6, 1.0004409666144674]\n",
      "loss: 9.182722942869941e38\n",
      "pde_losses: [9.113695614022158e38, 8.142998040409907e-7, 8.096568840078151e-7, 7.989670716590063e-7]\n",
      "bcs_losses: [6.067140646543846e-6, 6.6802152812444925e-6, 7.089208553783673e-6, 8.453675063805e-6, 8.780992264026191e-6, 8.282113172231765e-6, 6.197744945609082e-6, 6.162428783956514e-6, 6.184286876950238e-6, 0.9997099915575018, 2.6250500732283987e-6, 1.000405811837573]\n",
      "loss: 9.246949650838005e38\n",
      "pde_losses: [9.116637653995406e38, 8.001875637201425e-7, 8.018162238854056e-7, 8.041992508616435e-7]\n",
      "bcs_losses: [6.192623396304507e-6, 6.759870167335178e-6, 6.958661462015233e-6, 8.406459681473137e-6, 8.65105244689392e-6, 8.269257233033314e-6, 6.1434894043940506e-6, 6.150681090659544e-6, 6.187863187578583e-6, 0.9997310437482593, 2.575201021109916e-6, 1.0003838246781012]\n",
      "loss: 9.118749396788669e38\n",
      "pde_losses: [9.184093320431357e38, 7.998582464543843e-7, 7.97853681925805e-7, 8.173737449197724e-7]\n",
      "bcs_losses: [6.175255073535882e-6, 6.670764428831931e-6, 7.0653364420598935e-6, 8.450859129131511e-6, 8.58116736445731e-6, 8.189749031375328e-6, 6.105707435524257e-6, 6.178667853007771e-6, 6.072858694517019e-6, 0.9997313752184521, 2.606946887946162e-6, 1.0003827882173315]\n",
      "loss: 9.133017854120937e38\n",
      "pde_losses: [9.132222824258285e38, 7.878170278130455e-7, 7.837151819155548e-7, 7.904507520511106e-7]\n",
      "bcs_losses: [6.101062725185868e-6, 6.55522584242503e-6, 6.943148503377367e-6, 8.362844447724544e-6, 8.599820437958987e-6, 8.148352073229288e-6, 6.020227573030004e-6, 6.017440154029479e-6, 6.091381701161249e-6, 0.9997075468712217, 2.618989031219648e-6, 1.000405926836177]\n",
      "loss: 9.113625037814795e38\n",
      "pde_losses: [8.96646638806947e38, 7.849142473063726e-7, 7.965475467734593e-7, 7.758657130333306e-7]\n",
      "bcs_losses: [5.953453384758046e-6, 6.589080482847203e-6, 6.971042669623768e-6, 8.355430088631686e-6, 8.62628264270389e-6, 8.149698263410774e-6, 6.033933875263275e-6, 5.9421838547956804e-6, 5.989283603335753e-6, 0.9997058597952118, 2.6480481808233776e-6, 1.0004070009692612]\n",
      "loss: 8.998407633905535e38\n",
      "pde_losses: [9.030785912336045e38, 7.870469166489244e-7, 8.011564123983165e-7, 7.928704878672739e-7]\n",
      "bcs_losses: [5.955708009648516e-6, 6.524328490474492e-6, 6.87946344750524e-6, 8.305691598104336e-6, 8.4931137256787e-6, 8.052070253277856e-6, 5.892289698588612e-6, 5.917589213510323e-6, 5.956977976638314e-6, 0.9997359663411192, 2.704416717262683e-6, 1.0003763463945758]\n",
      "loss: 9.006589164157529e38\n",
      "pde_losses: [9.067081039025993e38, 7.726538080474156e-7, 7.710676059048313e-7, 7.893314471710024e-7]\n",
      "bcs_losses: [5.908065805477172e-6, 6.511970268981492e-6, 6.853484894498132e-6, 8.230401951969956e-6, 8.42772093985198e-6, 7.94550940256021e-6, 5.878567376664548e-6, 5.905282711334886e-6, 5.960625979881691e-6, 0.9997203765557243, 2.7179815954051468e-6, 1.0003912347194044]\n",
      "loss: 8.898966233561438e38\n",
      "pde_losses: [9.061569748182727e38, 7.768938093336073e-7, 7.852223492255873e-7, 7.961816721618517e-7]\n",
      "bcs_losses: [5.9223320090608665e-6, 6.473210229443215e-6, 6.710617384063015e-6, 8.225169890904352e-6, 8.380474359211134e-6, 8.081999138995725e-6, 5.883460782644153e-6, 5.92506155321245e-6, 5.949479250872809e-6, 0.9996786476363475, 2.632637735803724e-6, 1.0004321528349185]\n",
      "loss: 8.78302191519941e38\n",
      "pde_losses: [8.953605403709663e38, 7.697858094354818e-7, 7.649608198316533e-7, 7.768729358543687e-7]\n",
      "bcs_losses: [5.992536197600688e-6, 6.380244874215243e-6, 6.770825208662091e-6, 8.233313646469013e-6, 8.456085983648839e-6, 8.031818692377825e-6, 5.862838399348807e-6, 5.907633313134372e-6, 5.8814770001835986e-6, 0.9996468575995549, 2.5584463817026875e-6, 1.000463109829994]\n",
      "loss: 8.763716901873184e38\n",
      "pde_losses: [8.899004780387151e38, 7.691144749277695e-7, 7.53926216470438e-7, 7.655169296530564e-7]\n",
      "bcs_losses: [5.867169179928406e-6, 6.396824826286129e-6, 6.7194925303933464e-6, 8.053585141638728e-6, 8.233994009974263e-6, 7.90680799347855e-6, 5.821702252269508e-6, 5.8564578351010885e-6, 5.874139480703086e-6, 0.9997004016687436, 2.6182447304810872e-6, 1.0004088163216214]\n",
      "loss: 8.734162294432229e38\n",
      "pde_losses: [8.823535996531756e38, 7.903160849835719e-7, 7.743091005774113e-7, 7.392387638983203e-7]\n",
      "bcs_losses: [5.751120473238453e-6, 6.4350216448471e-6, 6.765058287920057e-6, 7.933124168998539e-6, 8.201264652932407e-6, 7.702612280469217e-6, 5.7872734627837834e-6, 5.8240304115419596e-6, 5.783979495304226e-6, 0.9997722090508242, 2.725710933913168e-6, 1.0003362461997458]\n",
      "loss: 8.529328021552481e38\n",
      "pde_losses: [8.910827163137258e38, 7.681244750372243e-7, 7.742102606108043e-7, 7.620846827191553e-7]\n",
      "bcs_losses: [5.71890073486729e-6, 6.314706881764014e-6, 6.627150027479775e-6, 7.977779691745373e-6, 8.162018519748442e-6, 7.720089730899559e-6, 5.799384519933061e-6, 5.7364576624265395e-6, 5.763418256982214e-6, 0.9997603772416059, 2.712082160418365e-6, 1.000347137410121]\n",
      "loss: 8.63595016415542e38\n",
      "pde_losses: [8.760798637156938e38, 7.537119642170313e-7, 7.491886389669858e-7, 7.494733247639228e-7]\n",
      "bcs_losses: [5.8081471459575866e-6, 6.275786724193922e-6, 6.62101492221754e-6, 7.995643249090566e-6, 8.100290293431766e-6, 7.788102846904543e-6, 5.80700398381894e-6, 5.744504113404039e-6, 5.815404699637655e-6, 0.99969869372452, 2.6322630243819825e-6, 1.0004077928329904]\n",
      "loss: 8.679655951108928e38\n",
      "pde_losses: [8.608608087934031e38, 7.514735044883246e-7, 7.652812212305563e-7, 7.48614289026247e-7]\n",
      "bcs_losses: [5.7524768616411694e-6, 6.244996105983765e-6, 6.509476854247486e-6, 8.023908387978833e-6, 8.11355049544149e-6, 7.779867696019846e-6, 5.815940544123351e-6, 5.711809247239903e-6, 5.7075190699928865e-6, 0.9996505666358132, 2.596046929635442e-6, 1.0004550646255868]\n",
      "loss: 8.624578466173581e38\n",
      "pde_losses: [8.631638392243647e38, 7.672009311534774e-7, 7.532915697975286e-7, 7.551136916493475e-7]\n",
      "bcs_losses: [5.680370804507056e-6, 6.1825104983565546e-6, 6.674372962864941e-6, 7.941883993851646e-6, 7.991092271001895e-6, 7.631085799650528e-6, 5.666104049382916e-6, 5.636810803169829e-6, 5.615953392277703e-6, 0.9997069955613049, 2.6673790479758946e-6, 1.0003978752295675]\n",
      "loss: 8.574488724071469e38\n",
      "pde_losses: [8.648851806945584e38, 7.575459378965984e-7, 7.509483190057802e-7, 7.462696834361425e-7]\n",
      "bcs_losses: [5.6578348883305756e-6, 6.198853319600722e-6, 6.683233185300032e-6, 7.921733023190504e-6, 7.947111712588236e-6, 7.5562697665308235e-6, 5.6196503239232634e-6, 5.627345761622403e-6, 5.528049275133155e-6, 0.999793915865555, 2.7437446168358014e-6, 1.000310232314399]\n",
      "loss: 8.463452961788858e38\n",
      "pde_losses: [8.580639331177444e38, 7.542532027052722e-7, 7.505076065512326e-7, 7.585549201746478e-7]\n",
      "bcs_losses: [5.614768757458392e-6, 6.116166373458156e-6, 6.569473892143395e-6, 7.838729348431685e-6, 7.922086792923949e-6, 7.58554961281946e-6, 5.539384536798598e-6, 5.584396668623497e-6, 5.485908842052242e-6, 0.9997976665651388, 2.6743956161646212e-6, 1.0003055484690953]\n",
      "loss: 8.427636935346473e38\n",
      "pde_losses: [8.478569833592196e38, 7.507123866526679e-7, 7.452071813680932e-7, 7.321708507344588e-7]\n",
      "bcs_losses: [5.6269781341498894e-6, 6.147034352324019e-6, 6.510225126382678e-6, 7.83118740777208e-6, 7.82619881268496e-6, 7.59115439107585e-6, 5.626728775759509e-6, 5.622588753820013e-6, 5.560723746684653e-6, 0.999743548772756, 2.514792244269343e-6, 1.0003585627340161]\n",
      "loss: 8.405357352914912e38\n",
      "pde_losses: [8.357591091942331e38, 7.268949825580958e-7, 7.426954944859998e-7, 7.418548318253455e-7]\n",
      "bcs_losses: [5.717156287784953e-6, 6.0545184081828576e-6, 6.4366337411274e-6, 7.78670812177447e-6, 7.818502500005977e-6, 7.640966216108592e-6, 5.55619586833638e-6, 5.549537229265156e-6, 5.652414697351099e-6, 0.9997242590252922, 2.464476885771003e-6, 1.0003769071102888]\n",
      "loss: 8.377018833196313e38\n",
      "pde_losses: [8.276501458610732e38, 7.234909878748651e-7, 7.304849683328325e-7, 7.534398009649883e-7]\n",
      "bcs_losses: [5.517827378939762e-6, 5.9912113225913075e-6, 6.477875900836786e-6, 7.836649422154365e-6, 7.798772405724722e-6, 7.572482235813395e-6, 5.529795052496743e-6, 5.539815457833695e-6, 5.5459450235163505e-6, 0.9997364556361943, 2.5196046633220183e-6, 1.0003639578962131]\n",
      "loss: 8.467870074912373e38\n",
      "pde_losses: [8.45555208415154e38, 7.312191960893993e-7, 7.312211448176442e-7, 7.464374192332493e-7]\n",
      "bcs_losses: [5.492851657727677e-6, 6.012054188813641e-6, 6.394021091401319e-6, 7.746594459763163e-6, 7.838869524926359e-6, 7.5545774571349225e-6, 5.4516435144289634e-6, 5.5136116084279335e-6, 5.454452196400947e-6, 0.9997834420102724, 2.6368589860350885e-6, 1.000316242449446]\n",
      "loss: 8.288721634082085e38\n",
      "pde_losses: [8.235596717946444e38, 7.327601312075956e-7, 7.470530793096367e-7, 7.362191427307492e-7]\n",
      "bcs_losses: [5.435604421280127e-6, 5.967368856617545e-6, 6.341684071852428e-6, 7.759705470820192e-6, 7.757057661176627e-6, 7.477277398294855e-6, 5.436168542645832e-6, 5.412317331462118e-6, 5.366359175162493e-6, 0.9998054340224982, 2.638282472571906e-6, 1.0002935359124394]\n",
      "loss: 8.30378531246016e38\n",
      "pde_losses: [8.261124441213169e38, 7.22980410003977e-7, 7.35808298031306e-7, 7.401189059400009e-7]\n",
      "bcs_losses: [5.416519914108394e-6, 6.02621035285495e-6, 6.3157541460833955e-6, 7.676794235577389e-6, 7.766777614234685e-6, 7.631216885968758e-6, 5.48867100364684e-6, 5.344918573722525e-6, 5.486468185890913e-6, 0.9997694234537141, 2.527127178396725e-6, 1.0003286250527537]\n",
      "loss: 8.20685818784843e38\n",
      "pde_losses: [8.182687748171328e38, 7.269973208702875e-7, 7.237239369306345e-7, 7.125074961063956e-7]\n",
      "bcs_losses: [5.407916907784298e-6, 5.96758861217307e-6, 6.3122216980540755e-6, 7.634945225882369e-6, 7.61453258143055e-6, 7.518920347429672e-6, 5.404291925251137e-6, 5.512688719199746e-6, 5.465043663115601e-6, 0.9997611152342811, 2.4914505457503685e-6, 1.0003362174965962]\n",
      "loss: 8.278380855063492e38\n",
      "pde_losses: [8.093756076663841e38, 7.244356332112803e-7, 7.304580827437551e-7, 7.370326223138565e-7]\n",
      "bcs_losses: [5.352650694841491e-6, 5.998826697357328e-6, 6.227907483001869e-6, 7.503548396125165e-6, 7.501518973771439e-6, 7.37444347710309e-6, 5.360432923354761e-6, 5.28960595397545e-6, 5.333971699635455e-6, 0.9998273951421922, 2.6283069752833506e-6, 1.0002693405170153]\n",
      "loss: 8.182483373973546e38\n",
      "pde_losses: [8.282564632416768e38, 7.065326008764088e-7, 7.280127615703821e-7, 7.265959853168817e-7]\n",
      "bcs_losses: [5.334748643318924e-6, 5.8657320253336844e-6, 6.266920172270119e-6, 7.472472790937693e-6, 7.5496482295874945e-6, 7.194995332376146e-6, 5.276982436719482e-6, 5.247407970397056e-6, 5.276584534180741e-6, 0.9998243729724792, 2.7662086759898343e-6, 1.0002718635908794]\n",
      "loss: 8.19058997015894e38\n",
      "pde_losses: [8.03429759122916e38, 7.220046437574458e-7, 7.231853183053334e-7, 7.186636657408506e-7]\n",
      "bcs_losses: [5.304456921823032e-6, 5.882709640304172e-6, 6.251505743988992e-6, 7.510566114728728e-6, 7.6005491365078435e-6, 7.282708583582726e-6, 5.3247107622148074e-6, 5.3228806383076514e-6, 5.275576713409856e-6, 0.9997079442872254, 2.639490450637702e-6, 1.0003875493266223]\n",
      "loss: 8.139436908997918e38\n",
      "pde_losses: [7.974812935317469e38, 7.310083362648964e-7, 7.16532184671059e-7, 7.367906517764416e-7]\n",
      "bcs_losses: [5.371240971040331e-6, 5.775040918659091e-6, 6.098072663886047e-6, 7.544446660768988e-6, 7.501209328519789e-6, 7.380481138334017e-6, 5.354410781373958e-6, 5.331299912878492e-6, 5.359713137376101e-6, 0.9996529395356563, 2.4718658289226037e-6, 1.0004417199882871]\n",
      "loss: 8.082629393432019e38\n",
      "pde_losses: [8.010228313950362e38, 7.165397111698093e-7, 7.15978426335519e-7, 7.198162495286812e-7]\n",
      "bcs_losses: [5.301315579934259e-6, 5.818124997777212e-6, 6.059083569704602e-6, 7.441334849245329e-6, 7.37147989682161e-6, 7.298457579564202e-6, 5.282812365620207e-6, 5.32105040424056e-6, 5.331090063756266e-6, 0.9997279709977207, 2.470346437245668e-6, 1.0003660407342956]\n",
      "loss: 8.039197827961004e38\n",
      "pde_losses: [7.99248634241539e38, 6.998821258486499e-7, 7.07593497167941e-7, 6.976129239322384e-7]\n",
      "bcs_losses: [5.222796149106633e-6, 5.882609819382298e-6, 6.103073290796569e-6, 7.358358476220542e-6, 7.290915937052854e-6, 7.1957371658862265e-6, 5.2889195691463466e-6, 5.18800593248331e-6, 5.257647815041798e-6, 0.9998588782056179, 2.636787621986594e-6, 1.0002346699333589]\n",
      "loss: 7.94657240531966e38\n",
      "pde_losses: [8.000683013032994e38, 7.205346296479355e-7, 7.088884704234326e-7, 7.164566354552586e-7]\n",
      "bcs_losses: [5.231453741177643e-6, 5.758237000496796e-6, 6.015063451513157e-6, 7.391527210902404e-6, 7.294877272448234e-6, 7.197586038238461e-6, 5.193292432331175e-6, 5.181990324244397e-6, 5.135656020405962e-6, 0.9998705310286319, 2.6513871259209352e-6, 1.000222509989955]\n",
      "loss: 8.09562411724613e38\n",
      "pde_losses: [7.917552784024776e38, 6.944302712936556e-7, 7.001097829209228e-7, 7.079692434158694e-7]\n",
      "bcs_losses: [5.1841282911492255e-6, 5.782347923805692e-6, 6.066465445220747e-6, 7.3955976625210195e-6, 7.207709339667044e-6, 7.203112524682692e-6, 5.192172098290314e-6, 5.168195845345057e-6, 5.229576006087366e-6, 0.9997633568850232, 2.482048107777375e-6, 1.0003290171850336]\n",
      "loss: 7.818617788626552e38\n",
      "pde_losses: [7.941622309111372e38, 7.014736911303081e-7, 7.073524308535112e-7, 6.922934416886763e-7]\n",
      "bcs_losses: [5.235522124191317e-6, 5.719129342744103e-6, 5.99400982357029e-6, 7.363543000068277e-6, 7.358607014211764e-6, 7.271016543934822e-6, 5.200791790842272e-6, 5.202557689355188e-6, 5.197915826537919e-6, 0.9997100768395237, 2.438804400337589e-6, 1.0003818078706044]\n",
      "loss: 7.909111322544196e38\n",
      "pde_losses: [7.861090211129286e38, 6.945246997867426e-7, 6.911148458558226e-7, 6.955034423632446e-7]\n",
      "bcs_losses: [5.156373116781923e-6, 5.733550524788371e-6, 5.966397961879222e-6, 7.302840323649254e-6, 7.268320213651331e-6, 7.062107628320953e-6, 5.122230501997783e-6, 5.101934918922508e-6, 5.0901908650348065e-6, 0.9997520732166423, 2.542782365518721e-6, 1.0003393374795178]\n",
      "loss: 7.73683057984995e38\n",
      "pde_losses: [7.763203490945474e38, 6.957521223228347e-7, 6.930051339137354e-7, 6.885592136335959e-7]\n",
      "bcs_losses: [5.075862619338167e-6, 5.6427613018234385e-6, 6.009248297598144e-6, 7.262568984301277e-6, 7.205862289414642e-6, 7.0995519741588655e-6, 5.0326131391104576e-6, 5.0633675659105414e-6, 5.039451076448075e-6, 0.9997925873416227, 2.5662827783860635e-6, 1.0002982565415]\n",
      "loss: 7.732273767380822e38\n",
      "pde_losses: [7.66074066668565e38, 6.907586610557651e-7, 6.898457698406483e-7, 7.127220580588579e-7]\n",
      "bcs_losses: [5.018387098046436e-6, 5.7049011237233e-6, 5.850899565861098e-6, 7.1654683695187604e-6, 7.055116146874087e-6, 7.024186827423286e-6, 4.986975971228473e-6, 5.063158746640233e-6, 5.043084242435877e-6, 0.9998152472719767, 2.5627337529834494e-6, 1.000274896237146]\n",
      "loss: 7.786277083520616e38\n",
      "pde_losses: [7.76612868232919e38, 7.035792335584326e-7, 6.754548888398611e-7, 6.753654383899492e-7]\n",
      "bcs_losses: [4.990933989317713e-6, 5.640016266813267e-6, 5.914859015842199e-6, 7.190391330817028e-6, 7.013266668221522e-6, 7.081920167663796e-6, 5.059982459812772e-6, 5.0587525911701615e-6, 5.117695549955472e-6, 0.9997678546389004, 2.469249540662617e-6, 1.0003214817907113]\n",
      "loss: 7.740752154702965e38\n",
      "pde_losses: [7.713324083326195e38, 6.932641173122703e-7, 6.833179078003628e-7, 6.742837230393968e-7]\n",
      "bcs_losses: [5.058713876140773e-6, 5.5933175177743205e-6, 5.878967939176368e-6, 7.197828705033217e-6, 7.0231034107473135e-6, 6.99767784859535e-6, 5.045642490946069e-6, 5.0415263094919326e-6, 5.059409701276033e-6, 0.999749624587916, 2.432650722841337e-6, 1.0003390636778762]\n",
      "loss: 7.661296060535149e38\n",
      "pde_losses: [7.634031812647809e38, 6.924771142141831e-7, 6.73055796328187e-7, 6.816259333691244e-7]\n",
      "bcs_losses: [5.004844930245334e-6, 5.550964738109572e-6, 5.8987919199495444e-6, 7.14689712118127e-6, 7.055980492213243e-6, 6.921948400424249e-6, 4.978294225003091e-6, 4.9883627199538204e-6, 4.926528966201527e-6, 0.9997903514641365, 2.499122600386657e-6, 1.0002978532470599]\n",
      "loss: 7.566457870005486e38\n",
      "pde_losses: [7.633651727627538e38, 6.757955685404797e-7, 6.678197332770908e-7, 6.736125610442805e-7]\n",
      "bcs_losses: [4.924882330303408e-6, 5.502824968731695e-6, 5.885685340198798e-6, 7.0606750733597625e-6, 6.896634907280977e-6, 6.865693160158023e-6, 4.91058166855424e-6, 4.976393551770873e-6, 4.951936828293567e-6, 0.9998492658529387, 2.573637232585246e-6, 1.0002384950867784]\n",
      "loss: 7.506415651098559e38\n",
      "pde_losses: [7.611101972572034e38, 6.707113924183115e-7, 6.681122049595449e-7, 6.714737070661957e-7]\n",
      "bcs_losses: [4.940443258573947e-6, 5.571347522650009e-6, 5.8317295003648e-6, 6.995062017207543e-6, 6.869721275350439e-6, 6.886818052881969e-6, 4.9302227403695805e-6, 4.89900818629686e-6, 4.97218137726116e-6, 0.999880340376146, 2.5893151211948816e-6, 1.0002068933611938]\n",
      "loss: 7.613905928188674e38\n",
      "pde_losses: [7.503205602626524e38, 6.582819266136912e-7, 6.755143974576931e-7, 6.907484805697439e-7]\n",
      "bcs_losses: [4.9232478653899e-6, 5.56422846809815e-6, 5.728422328101786e-6, 7.008267153788672e-6, 6.779557937531929e-6, 6.849619781074392e-6, 4.959154389042789e-6, 4.933119235621312e-6, 4.891934804549551e-6, 0.9998449135639262, 2.5480838390731465e-6, 1.0002416952634232]\n",
      "loss: 7.480179480144912e38\n",
      "pde_losses: [7.410078055501291e38, 6.885220423546498e-7, 6.677055916997678e-7, 6.741369500751977e-7]\n",
      "bcs_losses: [4.956810057586723e-6, 5.4911932278061316e-6, 5.6409215834787995e-6, 6.928619594746328e-6, 6.883122140989149e-6, 6.77567295791636e-6, 4.951579972827607e-6, 4.898080075879548e-6, 4.8728893492454115e-6, 0.9997850550364703, 2.5190767775009167e-6, 1.0003010311101037]\n",
      "loss: 7.475395083807401e38\n",
      "pde_losses: [7.458910863421306e38, 6.693802506504937e-7, 6.702012632837168e-7, 6.753934342562834e-7]\n",
      "bcs_losses: [4.9331403556001264e-6, 5.380506479530006e-6, 5.699874401837592e-6, 6.9672951102430405e-6, 6.846583131387326e-6, 6.790114074278262e-6, 4.832193486978423e-6, 4.873604281396509e-6, 4.861296796500815e-6, 0.9997643488641282, 2.551222824940101e-6, 1.0003212526152678]\n",
      "loss: 7.373600576413678e38\n",
      "pde_losses: [7.404504246460917e38, 6.70326086344546e-7, 6.550229776890547e-7, 6.813623637272931e-7]\n",
      "bcs_losses: [4.890711306771238e-6, 5.3850109469440265e-6, 5.654418086201931e-6, 6.99014955192356e-6, 6.820355684373709e-6, 6.7024888201858105e-6, 4.804710112204756e-6, 4.837843796327813e-6, 4.834789778275886e-6, 0.9997721898189408, 2.557094271905144e-6, 1.0003127998922237]\n",
      "loss: 7.324085822148973e38\n",
      "pde_losses: [7.312578989489387e38, 6.59139231609151e-7, 6.723419608350405e-7, 6.573865964784568e-7]\n",
      "bcs_losses: [4.804838901760801e-6, 5.3954571430397025e-6, 5.607617851106114e-6, 6.87637140769088e-6, 6.710029534517281e-6, 6.687861657494286e-6, 4.877575397882463e-6, 4.848226854855969e-6, 4.795192376971433e-6, 0.9998006202593694, 2.502871890995647e-6, 1.0002835665612413]\n",
      "loss: 7.4545365296542e38\n",
      "pde_losses: [7.416319444966364e38, 6.535780809737139e-7, 6.70767467175892e-7, 6.748835326488177e-7]\n",
      "bcs_losses: [4.798526350582677e-6, 5.382525182080601e-6, 5.596070025406795e-6, 6.862113016837216e-6, 6.684984335572748e-6, 6.715628990069989e-6, 4.80352064192117e-6, 4.831233635316084e-6, 4.799291104533217e-6, 0.9998450646816315, 2.4484920251127974e-6, 1.000238346978694]\n",
      "loss: 7.425196643253455e38\n",
      "pde_losses: [7.503963536857058e38, 6.566113497210001e-7, 6.677209485832935e-7, 6.61530147949166e-7]\n",
      "bcs_losses: [4.761025824712218e-6, 5.387796207738058e-6, 5.578643013570848e-6, 6.732250728072243e-6, 6.630452362218538e-6, 6.688701760490859e-6, 4.7907577220521235e-6, 4.806366006495062e-6, 4.7945517311699675e-6, 0.9998748194821134, 2.4495875188697775e-6, 1.0002079781494237]\n",
      "loss: 7.192832186093661e38\n",
      "pde_losses: [7.435541765203326e38, 6.571296240320391e-7, 6.513046986964658e-7, 6.51633506977232e-7]\n",
      "bcs_losses: [4.778503263269632e-6, 5.349270116303108e-6, 5.538951316401427e-6, 6.759049121350282e-6, 6.621970187554857e-6, 6.716580055219866e-6, 4.769592505817728e-6, 4.725300572796536e-6, 4.76940630175862e-6, 0.9998445613325103, 2.4430305015259297e-6, 1.0002377116311116]\n",
      "loss: 7.289572747576571e38\n",
      "pde_losses: [7.324769064425054e38, 6.544603018586572e-7, 6.477091827165799e-7, 6.523933274361766e-7]\n",
      "bcs_losses: [4.716430764594373e-6, 5.225592860205099e-6, 5.537345531563375e-6, 6.829905057165771e-6, 6.621357186949548e-6, 6.5657360573592135e-6, 4.672705833766477e-6, 4.713935032122113e-6, 4.7040162444209705e-6, 0.999841424072461, 2.50247173319497e-6, 1.00024037046296]\n",
      "loss: 7.188765070157213e38\n",
      "pde_losses: [7.179251050868633e38, 6.358440414317228e-7, 6.55919317235774e-7, 6.543441802074566e-7]\n",
      "bcs_losses: [4.645096091977936e-6, 5.293670331702301e-6, 5.50774186020375e-6, 6.808657066812967e-6, 6.554392031745691e-6, 6.458923280278955e-6, 4.69053582860686e-6, 4.671150587931912e-6, 4.698860637427216e-6, 0.9998618853153275, 2.5758433037159216e-6, 1.0002194527099937]\n",
      "loss: 7.188084640140393e38\n",
      "pde_losses: [7.198887063344039e38, 6.509307612148443e-7, 6.339052695396257e-7, 6.44457990084444e-7]\n",
      "bcs_losses: [4.673418506407342e-6, 5.245515288267277e-6, 5.4364147219502995e-6, 6.749731538574614e-6, 6.513467532132387e-6, 6.554171304761173e-6, 4.708382486105974e-6, 4.689683230024651e-6, 4.675684228289957e-6, 0.9998424820100855, 2.528914626106528e-6, 1.0002381703714178]\n",
      "loss: 7.17364627287815e38\n",
      "pde_losses: [7.144745425130577e38, 6.476909451448374e-7, 6.421365366158274e-7, 6.46921379875059e-7]\n",
      "bcs_losses: [4.6637381346859e-6, 5.246600001199755e-6, 5.446908118444218e-6, 6.696571606662141e-6, 6.452440988253839e-6, 6.5629648904225974e-6, 4.672525265027177e-6, 4.701276781334103e-6, 4.727501855674866e-6, 0.9998163490775468, 2.4662922058482154e-6, 1.000263462430793]\n",
      "loss: 6.996287589245995e38\n",
      "pde_losses: [7.118105857329319e38, 6.535340154805853e-7, 6.45792928712349e-7, 6.506071859105745e-7]\n",
      "bcs_losses: [4.631183575144976e-6, 5.22593850890593e-6, 5.493756247300281e-6, 6.594451666499511e-6, 6.410905817231176e-6, 6.534297371288237e-6, 4.6352952251835404e-6, 4.637770320025234e-6, 4.628435969377124e-6, 0.9998164140896242, 2.4911581041549287e-6, 1.0002625745876594]\n",
      "loss: 7.17096989950366e38\n",
      "pde_losses: [7.153517898137862e38, 6.418772859063271e-7, 6.372346226042096e-7, 6.296176029913748e-7]\n",
      "bcs_losses: [4.591480815062268e-6, 5.2017584058818e-6, 5.407957119114918e-6, 6.562713756701161e-6, 6.33879682539461e-6, 6.430444794202567e-6, 4.554536183665183e-6, 4.587735472112676e-6, 4.567119829037728e-6, 0.9998433094465258, 2.5270430897357265e-6, 1.0002348934847327]\n",
      "loss: 7.185386822752113e38\n",
      "pde_losses: [7.065933416197132e38, 6.489570506676147e-7, 6.201915440624367e-7, 6.198730188431237e-7]\n",
      "bcs_losses: [4.565459048020576e-6, 5.138999241947838e-6, 5.3566431067816e-6, 6.536625991133055e-6, 6.378550043984088e-6, 6.451489422975326e-6, 4.572866069912228e-6, 4.5477750973205965e-6, 4.504944954105572e-6, 0.9998117279798426, 2.477561846705538e-6, 1.0002656959166392]\n",
      "loss: 7.05766393024205e38\n",
      "pde_losses: [7.05554116939298e38, 6.310837325928818e-7, 6.292163529274518e-7, 6.30473078262914e-7]\n",
      "bcs_losses: [4.512467122915991e-6, 5.126181448088879e-6, 5.360714132174691e-6, 6.6292048560723474e-6, 6.3587398751258874e-6, 6.508360611298505e-6, 4.59164463084184e-6, 4.565450829070217e-6, 4.5794430172173286e-6, 0.9998043081424038, 2.4130569467306e-6, 1.000272353915545]\n",
      "loss: 7.067663706501095e38\n",
      "pde_losses: [7.065009980642766e38, 6.336662691482853e-7, 6.300612696644294e-7, 6.276813376671357e-7]\n",
      "bcs_losses: [4.508986979577376e-6, 5.165097203047217e-6, 5.308434142413006e-6, 6.50759679473503e-6, 6.283895547358763e-6, 6.44386278731658e-6, 4.57652828901943e-6, 4.521791729113818e-6, 4.560045679135795e-6, 0.9998976514980559, 2.4388248845527516e-6, 1.0001783188238456]\n",
      "loss: 7.041921968671007e38\n",
      "pde_losses: [6.915594318949022e38, 6.35219403319339e-7, 6.139339090197731e-7, 6.253913642089407e-7]\n",
      "bcs_losses: [4.55815273483559e-6, 5.179514840945001e-6, 5.3225630434878515e-6, 6.444320217881911e-6, 6.132510381066333e-6, 6.384660505466509e-6, 4.528682590545835e-6, 4.504847436206916e-6, 4.480497798071958e-6, 0.9999607013268108, 2.519499475696407e-6, 1.0001146315330685]\n",
      "loss: 6.897066039939719e38\n",
      "pde_losses: [7.014733773514599e38, 6.383489521648172e-7, 6.283510811872054e-7, 6.24112276574642e-7]\n",
      "bcs_losses: [4.508557543083124e-6, 5.119205463477325e-6, 5.321744197341877e-6, 6.517739817488191e-6, 6.155146676776232e-6, 6.319554179366276e-6, 4.441832552314605e-6, 4.540256477789471e-6, 4.508408996231436e-6, 0.9999335110757345, 2.560543797859256e-6, 1.0001412649601689]\n",
      "loss: 6.942476803734374e38\n",
      "pde_losses: [6.871701642643138e38, 6.310507150206613e-7, 6.362184773108959e-7, 6.311647041520189e-7]\n",
      "bcs_losses: [4.5436493472316825e-6, 5.05159454656468e-6, 5.34977160677976e-6, 6.443873356826456e-6, 6.168171499956649e-6, 6.3203020981012146e-6, 4.509596294560956e-6, 4.485739112585268e-6, 4.516030826840631e-6, 0.9998056668185008, 2.4826744521161698e-6, 1.000268534881137]\n",
      "loss: 6.864911187345898e38\n",
      "pde_losses: [6.843275446312711e38, 6.183399875298902e-7, 6.158958264921189e-7, 6.290469304372507e-7]\n",
      "bcs_losses: [4.548571916718666e-6, 5.023233954104739e-6, 5.265733159236114e-6, 6.558996310174058e-6, 6.09886910480144e-6, 6.380361309197156e-6, 4.5549429107042785e-6, 4.516246400338544e-6, 4.509189991058087e-6, 0.9997159119550243, 2.3936340953441088e-6, 1.00035784706624]\n",
      "loss: 6.856993988779388e38\n",
      "pde_losses: [6.89958224303731e38, 6.153196345058859e-7, 6.342965684847948e-7, 6.234189163263883e-7]\n",
      "bcs_losses: [4.479444682977618e-6, 5.024735917160733e-6, 5.204078523154097e-6, 6.410864396373052e-6, 6.1105097182802935e-6, 6.317701888206578e-6, 4.46307840056331e-6, 4.432441241448929e-6, 4.42720127944814e-6, 0.9998022282743888, 2.4501947739440287e-6, 1.0002710878993117]\n",
      "loss: 6.887781354272699e38\n",
      "pde_losses: [6.774161983592666e38, 6.173207813721358e-7, 6.303414516891685e-7, 6.182148085141781e-7]\n",
      "bcs_losses: [4.379002225596997e-6, 5.104491534105504e-6, 5.157097043463326e-6, 6.331328878529094e-6, 6.0271613013854845e-6, 6.1539613211828715e-6, 4.363913166340817e-6, 4.393020276574529e-6, 4.418168964621024e-6, 0.9999290993303237, 2.5438059550380943e-6, 1.000143776809596]\n",
      "loss: 6.7755694841515286e38\n",
      "pde_losses: [6.847285733838578e38, 6.130271989037309e-7, 6.052274764857723e-7, 6.154285399817507e-7]\n",
      "bcs_losses: [4.4161818102584366e-6, 5.024028144209022e-6, 5.140735690362665e-6, 6.224623134835554e-6, 5.933700571629109e-6, 6.157447597936427e-6, 4.354564115071709e-6, 4.3814569893450135e-6, 4.341651918779981e-6, 0.9999518447045608, 2.513206179191597e-6, 1.0001205759680363]\n",
      "loss: 6.71946459950491e38\n",
      "pde_losses: [6.770332625462986e38, 6.076621322207803e-7, 6.051681851320347e-7, 6.054729423821277e-7]\n",
      "bcs_losses: [4.402985692654529e-6, 5.047072640288729e-6, 5.124463269701675e-6, 6.297443178014739e-6, 6.0440414638562625e-6, 6.243052426342626e-6, 4.4111927537690725e-6, 4.404136715889328e-6, 4.38138281794062e-6, 0.999882603317876, 2.4060990116795517e-6, 1.0001893374220536]\n",
      "loss: 6.7228714044858385e38\n",
      "pde_losses: [6.774273321445463e38, 6.207666110865619e-7, 6.059068780996163e-7, 6.157612874536065e-7]\n",
      "bcs_losses: [4.386263639300332e-6, 4.847811944733001e-6, 5.1488699841560755e-6, 6.264639058815687e-6, 6.016264717329135e-6, 6.253414296960194e-6, 4.415315731120827e-6, 4.333423348478936e-6, 4.39332107370381e-6, 0.9998242094054641, 2.377821174601757e-6, 1.0002472962601137]\n",
      "loss: 6.735699980811282e38\n",
      "pde_losses: [6.731422763655237e38, 6.155927385638091e-7, 6.185969982851943e-7, 6.015607889211051e-7]\n",
      "bcs_losses: [4.278173851823305e-6, 4.925832313114908e-6, 5.117282974358003e-6, 6.1948392968238876e-6, 6.009758816654344e-6, 6.080255886713187e-6, 4.3487056460738925e-6, 4.328620094739184e-6, 4.302983525096033e-6, 0.9998564959658325, 2.446029134276565e-6, 1.0002145353202878]\n",
      "loss: 6.792639538237564e38\n",
      "pde_losses: [6.507860406634817e38, 5.958610862873279e-7, 6.000725698246893e-7, 6.016169451340794e-7]\n",
      "bcs_losses: [4.315060921143583e-6, 4.922800897745702e-6, 5.095988153861673e-6, 6.2610117762337915e-6, 5.884304720429133e-6, 6.074686937352894e-6, 4.332661691006844e-6, 4.2798155652237e-6, 4.308385388022582e-6, 0.9998922112432622, 2.4703372461682306e-6, 1.000178325843529]\n",
      "loss: 6.7077295744079286e38\n",
      "pde_losses: [6.577748152276665e38, 5.988296316253734e-7, 6.214037071635103e-7, 6.120727740793438e-7]\n",
      "bcs_losses: [4.301636804017097e-6, 4.882280047926414e-6, 5.05430965197874e-6, 6.199591121811097e-6, 5.883967622808474e-6, 6.106431343112577e-6, 4.303352588069584e-6, 4.325872566209714e-6, 4.319544674766766e-6, 0.9998853025945191, 2.4463983708359735e-6, 1.0001847823247936]\n",
      "loss: 6.588919842951631e38\n",
      "pde_losses: [6.5862791854042584e38, 6.022501238867898e-7, 6.039011745210335e-7, 6.056737127602992e-7]\n",
      "bcs_losses: [4.300491639866951e-6, 4.863183708776544e-6, 5.065679791409158e-6, 6.218678523022174e-6, 5.82988252221028e-6, 6.122845928261106e-6, 4.342426320428671e-6, 4.310466347006925e-6, 4.3384565778893825e-6, 0.9998342133447486, 2.3828154599654233e-6, 1.000235446879552]\n",
      "loss: 6.601041026323271e38\n",
      "pde_losses: [6.520506568430103e38, 6.002918894063115e-7, 5.904173087687019e-7, 5.94427251321747e-7]\n",
      "bcs_losses: [4.309057728396814e-6, 4.842952487898026e-6, 5.10574220784893e-6, 6.1826337693253275e-6, 5.855694904250134e-6, 6.0208429185931594e-6, 4.283950640257666e-6, 4.273837064216035e-6, 4.274852350653215e-6, 0.9998545870600232, 2.424269781268922e-6, 1.0002146759241937]\n",
      "loss: 6.5698889519424586e38\n",
      "pde_losses: [6.650358714675187e38, 5.906899106228152e-7, 5.950720437735699e-7, 6.015299727099889e-7]\n",
      "bcs_losses: [4.270361598357253e-6, 4.845395842066264e-6, 4.992062001452698e-6, 6.143788480115008e-6, 5.826917528125859e-6, 5.993508362327945e-6, 4.2175728622142715e-6, 4.2576551652927174e-6, 4.230270421814609e-6, 0.9998847105087071, 2.464338566939262e-6, 1.0001841418782929]\n",
      "loss: 6.450368999096582e38\n",
      "pde_losses: [6.5191534141337e38, 6.064436749298265e-7, 5.974719927457213e-7, 5.8872389302807e-7]\n",
      "bcs_losses: [4.2098502294745e-6, 4.783012384245955e-6, 5.007770966524506e-6, 6.064020618544198e-6, 5.796471243091734e-6, 5.922279659968e-6, 4.2323447951806925e-6, 4.2552936688692354e-6, 4.251915045966957e-6, 0.9998925425102836, 2.4644979284622657e-6, 1.000175938715227]\n",
      "loss: 6.459754923219691e38\n",
      "pde_losses: [6.496723822825934e38, 5.996472680190537e-7, 5.830755828225221e-7, 5.776472723591215e-7]\n",
      "bcs_losses: [4.270370158559971e-6, 4.799502945111376e-6, 4.918799263321717e-6, 6.0929925198890835e-6, 5.786108285428142e-6, 5.9713953871098166e-6, 4.254949001789952e-6, 4.23283031256733e-6, 4.209054583150448e-6, 0.9998968316562376, 2.4506762704364716e-6, 1.000171233545209]\n",
      "loss: 6.456329544369895e38\n",
      "pde_losses: [6.488152479726327e38, 5.943509459503609e-7, 5.952385702085007e-7, 5.8384918936318e-7]\n",
      "bcs_losses: [4.216822926002615e-6, 4.7374898826796934e-6, 4.938828552614638e-6, 6.055545692854292e-6, 5.731914049786922e-6, 5.918159317720557e-6, 4.177209852983566e-6, 4.206811665371581e-6, 4.228729530178581e-6, 0.9998954476600732, 2.4389845564288064e-6, 1.000172143545069]\n",
      "loss: 6.45049477756822e38\n",
      "pde_losses: [6.46365767247741e38, 5.81427658768736e-7, 5.85849599326718e-7, 5.962636851521369e-7]\n",
      "bcs_losses: [4.1852486570192175e-6, 4.763729606600312e-6, 4.921560563900219e-6, 6.026624100557627e-6, 5.68647426963419e-6, 5.894823869248942e-6, 4.171651184912192e-6, 4.212223505144613e-6, 4.168812808841128e-6, 0.999874927847068, 2.3925870801764347e-6, 1.0001921553689495]\n",
      "loss: 6.453691798288097e38\n",
      "pde_losses: [6.416592437670782e38, 5.835878575854447e-7, 5.717980005740853e-7, 5.928066123388733e-7]\n",
      "bcs_losses: [4.171388570570711e-6, 4.648316391166177e-6, 4.868092603594292e-6, 5.986800623936424e-6, 5.5647863108747845e-6, 5.924364334272683e-6, 4.182891589633472e-6, 4.1299709587570376e-6, 4.150573356612894e-6, 0.9998842638271492, 2.373510685850421e-6, 1.0001823853723864]\n",
      "loss: 6.459582221037557e38\n",
      "pde_losses: [6.413220169821897e38, 5.855527253636606e-7, 5.751519279920058e-7, 5.869444249890949e-7]\n",
      "bcs_losses: [4.118265168636291e-6, 4.647590831384917e-6, 4.885541404831442e-6, 5.9271459619465506e-6, 5.552596655377569e-6, 5.843939748367705e-6, 4.153157069832285e-6, 4.179616457943794e-6, 4.111501477046224e-6, 0.9999065340565636, 2.389166243399131e-6, 1.0001597870755878]\n",
      "loss: 6.3850605405556495e38\n",
      "pde_losses: [6.332947054056967e38, 5.719881929842143e-7, 5.829771267676131e-7, 5.80925087825429e-7]\n",
      "bcs_losses: [4.096529205004179e-6, 4.674131520281839e-6, 4.844085712893268e-6, 5.91806453854809e-6, 5.65210101881021e-6, 5.755149467872052e-6, 4.158693078691473e-6, 4.101316717979036e-6, 4.0882872068750205e-6, 0.9999148573066148, 2.3667910847272093e-6, 1.000151062938873]\n",
      "loss: 6.340590735786713e38\n",
      "pde_losses: [6.310718255902091e38, 5.780410295863351e-7, 5.840743681010904e-7, 5.692827573753885e-7]\n",
      "bcs_losses: [4.064494106712272e-6, 4.697650679262455e-6, 4.7683058920658944e-6, 5.904260466572711e-6, 5.599148314521933e-6, 5.757477881396065e-6, 4.114116513232038e-6, 4.064851313600015e-6, 4.088754332228321e-6, 0.9999261977365694, 2.3865694342379697e-6, 1.0001393850987306]\n",
      "loss: 6.294862071474901e38\n",
      "pde_losses: [6.354340764764111e38, 5.796439551256574e-7, 5.857686332927728e-7, 5.767928597225446e-7]\n",
      "bcs_losses: [4.0479952968208214e-6, 4.640098390376361e-6, 4.7728259238371154e-6, 5.897363061010759e-6, 5.478045568141946e-6, 5.648589369203115e-6, 4.0640868444936405e-6, 4.079053319576958e-6, 4.051259717993277e-6, 0.9999468718034595, 2.4327273963926543e-6, 1.000118308424402]\n",
      "loss: 6.2868665386474584e38\n",
      "pde_losses: [6.285653652399101e38, 5.704868654160808e-7, 5.832417781037501e-7, 5.810558937928791e-7]\n",
      "bcs_losses: [4.034813576994533e-6, 4.6685460004657905e-6, 4.768769234560692e-6, 5.906676709167762e-6, 5.483581096905854e-6, 5.686878855217038e-6, 4.0522679097951756e-6, 4.061141364646535e-6, 4.032138068281419e-6, 0.9999475825457939, 2.4767024852705804e-6, 1.0001170708484688]\n",
      "loss: 6.216461477352241e38\n",
      "pde_losses: [6.3056595419324246e38, 5.774928565420433e-7, 5.799973500543849e-7, 5.783339242280944e-7]\n",
      "bcs_losses: [4.027356335530553e-6, 4.571785870507799e-6, 4.824105509393984e-6, 5.870197954533021e-6, 5.457580174820921e-6, 5.7074470878108265e-6, 4.043186312186211e-6, 4.051187576833793e-6, 4.02196653817266e-6, 0.9999198196705915, 2.4481246700993542e-6, 1.0001441743926465]\n",
      "loss: 6.2442613518478485e38\n",
      "pde_losses: [6.267245696403094e38, 5.643047181123788e-7, 5.883141578207988e-7, 5.70680926149697e-7]\n",
      "bcs_losses: [4.056866752579967e-6, 4.619839881911126e-6, 4.747074555379706e-6, 5.946151422999305e-6, 5.521624449342197e-6, 5.661144197202483e-6, 4.100752224489587e-6, 4.059851944550415e-6, 4.04424292087523e-6, 0.9998638072459594, 2.386464500270518e-6, 1.000199468915581]\n",
      "loss: 6.1479524942780894e38\n",
      "pde_losses: [6.236089471514846e38, 5.616678809478403e-7, 5.632449742430312e-7, 5.521875055742382e-7]\n",
      "bcs_losses: [4.033688658812407e-6, 4.6120594564814905e-6, 4.7910045528626285e-6, 5.8393003057843795e-6, 5.464644505231994e-6, 5.702558978455357e-6, 4.032291340070202e-6, 4.065196419621983e-6, 4.029752862088359e-6, 0.9998584942551091, 2.3834395848286425e-6, 1.0002042349007763]\n",
      "loss: 6.198912200559158e38\n",
      "pde_losses: [6.230171174319701e38, 5.68108619329857e-7, 5.658732670904703e-7, 5.716099012159167e-7]\n",
      "bcs_losses: [4.025647719227418e-6, 4.582664189645923e-6, 4.78998621662602e-6, 5.814513386485188e-6, 5.335629556314293e-6, 5.603683241423965e-6, 4.006754287693808e-6, 4.015554740861628e-6, 4.030207833644172e-6, 0.9999105929636908, 2.419554056694789e-6, 1.000151611097328]\n",
      "loss: 6.0961458939899514e38\n",
      "pde_losses: [6.137959483933611e38, 5.651558575766403e-7, 5.680303103562033e-7, 5.694824872893558e-7]\n",
      "bcs_losses: [4.007267357292842e-6, 4.607530411721925e-6, 4.654857702376199e-6, 5.766067887386734e-6, 5.375412054095536e-6, 5.58753647084402e-6, 3.9991172551948955e-6, 4.000162853980774e-6, 3.9486379011626345e-6, 0.9999252405960046, 2.3885060070234158e-6, 1.000136418479538]\n",
      "loss: 6.090381913551451e38\n",
      "pde_losses: [6.1515698882789296e38, 5.685044334050441e-7, 5.613160882950824e-7, 5.587720895828416e-7]\n",
      "bcs_losses: [3.955526149572394e-6, 4.586301254253251e-6, 4.692530260423441e-6, 5.696563090350793e-6, 5.312460238186382e-6, 5.578421046023789e-6, 3.949810003157733e-6, 3.989901822318215e-6, 3.969936280829226e-6, 0.9999400283315685, 2.4015543145592587e-6, 1.0001211620808852]\n",
      "loss: 6.044294536336358e38\n",
      "pde_losses: [6.1169113029200735e38, 5.610718910298077e-7, 5.699014869747868e-7, 5.594850415312899e-7]\n",
      "bcs_losses: [3.936171179046097e-6, 4.461791660684703e-6, 4.669505180355726e-6, 5.682471487632346e-6, 5.361546624443651e-6, 5.602886645978266e-6, 3.957058102008676e-6, 3.914348401893257e-6, 3.891102682873748e-6, 0.9999468219408181, 2.400301764705147e-6, 1.0001139400957642]\n",
      "loss: 6.048853287419129e38\n",
      "pde_losses: [6.109591412540094e38, 5.553317335437538e-7, 5.645929441780584e-7, 5.564654139867602e-7]\n",
      "bcs_losses: [3.921104512799143e-6, 4.493171311847061e-6, 4.629988459510622e-6, 5.669578648212246e-6, 5.294953806432607e-6, 5.525845932278776e-6, 3.9178654179259e-6, 3.914514204950599e-6, 3.925698188659134e-6, 0.9999384224170955, 2.4028973567941646e-6, 1.0001218662865576]\n",
      "loss: 6.090673397491878e38\n",
      "pde_losses: [6.0639241681037735e38, 5.612163223478642e-7, 5.545317736045935e-7, 5.565705462192233e-7]\n",
      "bcs_losses: [3.926568857643922e-6, 4.501450677891546e-6, 4.527285943739065e-6, 5.598461014750853e-6, 5.2842537924667216e-6, 5.436873980462744e-6, 3.970688395758532e-6, 3.915836424758617e-6, 3.961933199114378e-6, 0.9999222415673301, 2.3683636409568604e-6, 1.0001375880849372]\n",
      "loss: 6.050659396111274e38\n",
      "pde_losses: [5.991959684992748e38, 5.384055947458679e-7, 5.508324647255267e-7, 5.548073231880114e-7]\n",
      "bcs_losses: [3.950835131716347e-6, 4.514145108084098e-6, 4.605862672343469e-6, 5.604079462692172e-6, 5.207642846909535e-6, 5.49048491678536e-6, 3.901729254081139e-6, 3.890776846739675e-6, 3.867849585293415e-6, 0.9999048976331849, 2.358620323171843e-6, 1.0001546696013361]\n",
      "loss: 5.916648959599108e38\n",
      "pde_losses: [5.971901609628438e38, 5.509331333501934e-7, 5.423998659656107e-7, 5.547960069743679e-7]\n",
      "bcs_losses: [3.887153787146023e-6, 4.466521371585247e-6, 4.5717224329450404e-6, 5.6492638887406834e-6, 5.213741998060673e-6, 5.5055409320837655e-6, 3.92435734907116e-6, 3.879994456409877e-6, 3.865473690412378e-6, 0.9998874756269442, 2.3561035847480305e-6, 1.0001719074850959]\n",
      "loss: 5.9869173617885676e38\n",
      "pde_losses: [6.016647768799403e38, 5.498770071941529e-7, 5.506770856508782e-7, 5.490167144445648e-7]\n",
      "bcs_losses: [3.883040618775451e-6, 4.4205250413486014e-6, 4.574761774539089e-6, 5.645621758606731e-6, 5.19888114014592e-6, 5.399008994763071e-6, 3.831435452994776e-6, 3.897668071802744e-6, 3.9014351289813215e-6, 0.999963902068776, 2.468666726193133e-6, 1.0000952787959507]\n",
      "loss: 5.9142257010036274e38\n",
      "pde_losses: [5.965442679341493e38, 5.401062455542001e-7, 5.495023835623432e-7, 5.488862815453176e-7]\n",
      "bcs_losses: [3.841974552183051e-6, 4.422346060842374e-6, 4.607793875094595e-6, 5.577265647096234e-6, 5.146158745253795e-6, 5.319078323076275e-6, 3.866997049673672e-6, 3.791729588610881e-6, 3.841052832865915e-6, 1.0000074779515402, 2.5007195619337324e-6, 1.0000514970202319]\n",
      "loss: 5.93068042141488e38\n",
      "pde_losses: [5.902878224721637e38, 5.441269544942831e-7, 5.395247789438962e-7, 5.521789205774806e-7]\n",
      "bcs_losses: [3.843582667930125e-6, 4.364214990742323e-6, 4.576125421968343e-6, 5.605697029743153e-6, 5.102754880950268e-6, 5.3889361612377185e-6, 3.826771774620142e-6, 3.85743167331842e-6, 3.865594736072236e-6, 0.9999610757196915, 2.3352597214453083e-6, 1.0000972995906565]\n",
      "loss: 5.9261081653910995e38\n",
      "pde_losses: [5.8908000444332036e38, 5.431768489984204e-7, 5.499893516290693e-7, 5.632830485275921e-7]\n",
      "bcs_losses: [3.8706269029994136e-6, 4.339442652202682e-6, 4.484030084879076e-6, 5.5650683306206435e-6, 5.1032057203588626e-6, 5.460486230263053e-6, 3.841912441285997e-6, 3.836230152606422e-6, 3.870267053667169e-6, 0.999934249676923, 2.2224122636362533e-6, 1.0001235182200827]\n",
      "loss: 5.813873026612596e38\n",
      "pde_losses: [5.864915949227939e38, 5.432628715052213e-7, 5.533223762985536e-7, 5.255038931125154e-7]\n",
      "bcs_losses: [3.780120737858917e-6, 4.369494200818868e-6, 4.476857993410814e-6, 5.458059481872861e-6, 5.041453463422556e-6, 5.342446461463254e-6, 3.807843518345181e-6, 3.819486029375844e-6, 3.81019528972408e-6, 0.9999742136372024, 2.247122717374128e-6, 1.0000829858807911]\n",
      "loss: 5.853304751780397e38\n",
      "pde_losses: [5.88297260259405e38, 5.33255443138652e-7, 5.392024641565456e-7, 5.490454355407182e-7]\n",
      "bcs_losses: [3.7423569332615908e-6, 4.335199291207594e-6, 4.525671053802803e-6, 5.421696888411298e-6, 5.053863668167713e-6, 5.24755191606379e-6, 3.7875289594821344e-6, 3.727150527800463e-6, 3.762899228799789e-6, 1.0000229912233631, 2.337844197309433e-6, 1.0000338203853738]\n",
      "loss: 5.901957841106076e38\n",
      "pde_losses: [5.8014774397557045e38, 5.336332139146184e-7, 5.354668307064611e-7, 5.370248225376814e-7]\n",
      "bcs_losses: [3.758152710936493e-6, 4.293619829360434e-6, 4.508287896730288e-6, 5.3673293321151215e-6, 5.021954062817772e-6, 5.3137964191003e-6, 3.79835497176434e-6, 3.81338188277873e-6, 3.751880184262149e-6, 0.9999733294116886, 2.3352161918875534e-6, 1.0000829846410162]\n",
      "loss: 5.797281502478574e38\n",
      "pde_losses: [5.765533794015937e38, 5.350902319351317e-7, 5.288931019090111e-7, 5.324446565932585e-7]\n",
      "bcs_losses: [3.81388054263777e-6, 4.2759689593300955e-6, 4.457525438657613e-6, 5.421285514072303e-6, 4.981548133618841e-6, 5.344645182757326e-6, 3.779812882991282e-6, 3.7672234406887145e-6, 3.813506559244936e-6, 0.9998724075798645, 2.3205337361903233e-6, 1.0001835106458605]\n",
      "loss: 5.695910900688378e38\n",
      "pde_losses: [5.814190873016791e38, 5.273568294308283e-7, 5.340503618554761e-7, 5.353216130515145e-7]\n",
      "bcs_losses: [3.7802121228642188e-6, 4.221966991955994e-6, 4.443227730312111e-6, 5.40878893590232e-6, 4.96991062509015e-6, 5.2589082665289194e-6, 3.7237711225648692e-6, 3.754847719167938e-6, 3.7447733196910125e-6, 0.9998709999313098, 2.416770724782392e-6, 1.0001846042703686]\n",
      "loss: 5.698373238945412e38\n",
      "pde_losses: [5.74523748411983e38, 5.402413846472489e-7, 5.376070212461169e-7, 5.299773683514651e-7]\n",
      "bcs_losses: [3.7020049022934144e-6, 4.28064897339602e-6, 4.457159845212793e-6, 5.378650845231977e-6, 4.8800192594070285e-6, 5.141456739987278e-6, 3.735891110724548e-6, 3.7082070291230306e-6, 3.6766011542085804e-6, 0.9999544591490226, 2.5408555464407803e-6, 1.0001008263869973]\n",
      "loss: 5.682909563752179e38\n",
      "pde_losses: [5.646263335531163e38, 5.276106244263754e-7, 5.255158332446288e-7, 5.408862760754565e-7]\n",
      "bcs_losses: [3.679574607334718e-6, 4.255933765425236e-6, 4.406375397924024e-6, 5.321346485937943e-6, 4.870180348214238e-6, 5.119022920725718e-6, 3.7315198664713633e-6, 3.697441594773544e-6, 3.6990258626809506e-6, 1.0000188570005117, 2.5158333835489593e-6, 1.0000359651363726]\n",
      "loss: 5.793240823371817e38\n",
      "pde_losses: [5.6679031044919595e38, 5.255719134766124e-7, 5.399356980291769e-7, 5.301843357212902e-7]\n",
      "bcs_losses: [3.732186126052096e-6, 4.290547350327773e-6, 4.423417928065699e-6, 5.347136162803416e-6, 4.865611738327388e-6, 5.217664747733876e-6, 3.71825819316583e-6, 3.7039795545528446e-6, 3.6992087376499342e-6, 0.999979242155381, 2.329522003175301e-6, 1.0000749142256755]\n",
      "loss: 5.6524350945460454e38\n",
      "pde_losses: [5.723886903063491e38, 5.268895730210223e-7, 5.261891283374709e-7, 5.227347119831347e-7]\n",
      "bcs_losses: [3.75001605926516e-6, 4.231662050129439e-6, 4.356647538908885e-6, 5.304797213503356e-6, 4.9120047015190065e-6, 5.298799185315866e-6, 3.73507159820554e-6, 3.701395173732345e-6, 3.713435253898081e-6, 0.9999294033618844, 2.2060311062379334e-6, 1.0001242243054038]\n",
      "loss: 5.668362128126339e38\n",
      "pde_losses: [5.6708801473430555e38, 5.22502203784821e-7, 5.243972300429938e-7, 5.101578217015921e-7]\n",
      "bcs_losses: [3.6542687587547634e-6, 4.2046858908743015e-6, 4.399738425066843e-6, 5.360919482429389e-6, 4.853455276171547e-6, 5.222432878993479e-6, 3.656716633882271e-6, 3.6849616007775457e-6, 3.6583701614672175e-6, 0.9999706690244047, 2.2411587181748507e-6, 1.0000826472150504]\n",
      "loss: 5.62049264036259e38\n",
      "pde_losses: [5.6913032149224805e38, 5.295058464577358e-7, 5.227463207604649e-7, 5.237528135889016e-7]\n",
      "bcs_losses: [3.6597190445281665e-6, 4.1979499984258225e-6, 4.403202657875558e-6, 5.275703829633692e-6, 4.79662823647659e-6, 5.104838961450423e-6, 3.6399425479195753e-6, 3.6370003331482247e-6, 3.6302591134284822e-6, 1.0000389597816621, 2.405174136766915e-6, 1.0000142773097118]\n",
      "loss: 5.686374483205076e38\n",
      "pde_losses: [5.6724375335449126e38, 5.116989484914341e-7, 5.21365585256746e-7, 5.263259249027929e-7]\n",
      "bcs_losses: [3.6294336003426344e-6, 4.252430109866872e-6, 4.384817830103885e-6, 5.318337524900227e-6, 4.719388732016293e-6, 5.049812958610692e-6, 3.6319541707306994e-6, 3.663282512373701e-6, 3.622746129914526e-6, 0.9999999322484168, 2.3864172166703227e-6, 1.0000530663016072]\n",
      "loss: 5.5657376474134715e38\n",
      "pde_losses: [5.6332666085445015e38, 5.259690964515063e-7, 5.163389310017863e-7, 5.156431896592146e-7]\n",
      "bcs_losses: [3.6796915950294588e-6, 4.165220885679293e-6, 4.283240940625051e-6, 5.295188423214105e-6, 4.769594516446697e-6, 5.123091672582854e-6, 3.6848094188109095e-6, 3.654616090720948e-6, 3.6837167716982583e-6, 0.9999206352942094, 2.2946789249592348e-6, 1.0001320544685124]\n",
      "loss: 5.6294396599159875e38\n",
      "pde_losses: [5.572340385483382e38, 5.17473780137845e-7, 5.240466247193867e-7, 5.223379524001283e-7]\n",
      "bcs_losses: [3.652874816699596e-6, 4.16509740745347e-6, 4.2124331317461095e-6, 5.253909709445188e-6, 4.720564136114738e-6, 5.096366299774123e-6, 3.6659165530425983e-6, 3.6546737041878544e-6, 3.690358774132295e-6, 0.9999119387645787, 2.312283326326596e-6, 1.0001406370731285]\n",
      "loss: 5.6331844502822536e38\n",
      "pde_losses: [5.561870154377315e38, 5.031168517317331e-7, 5.124888585780002e-7, 5.148470162346389e-7]\n",
      "bcs_losses: [3.57561838147413e-6, 4.114450269467895e-6, 4.28637407844401e-6, 5.246811385459602e-6, 4.677915979330421e-6, 4.975164269295171e-6, 3.5924292159578023e-6, 3.5760478807532408e-6, 3.627364342812305e-6, 0.9999668129995254, 2.4079376670282704e-6, 1.0000857187564327]\n",
      "loss: 5.589442090016517e38\n",
      "pde_losses: [5.532550498265791e38, 5.068505044476945e-7, 5.186039723220771e-7, 5.114191446719193e-7]\n",
      "bcs_losses: [3.5325791167000616e-6, 4.11211895292645e-6, 4.270484793114142e-6, 5.20826400080062e-6, 4.696012030910588e-6, 4.940708002129524e-6, 3.559076132506501e-6, 3.6050994815836647e-6, 3.565152836826724e-6, 1.000007935177863, 2.451110265871151e-6, 1.0000444930700811]\n",
      "loss: 5.559741523067552e38\n",
      "pde_losses: [5.52341324229247e38, 5.071019189061215e-7, 5.216124757409095e-7, 5.100059460188583e-7]\n",
      "bcs_losses: [3.5357777457828856e-6, 4.045686115821182e-6, 4.270292979013435e-6, 5.087284535893505e-6, 4.68859039817074e-6, 4.96857130111445e-6, 3.57533747102563e-6, 3.5732437206169324e-6, 3.6145266180579994e-6, 0.9999895679239345, 2.3239341522044057e-6, 1.0000624420416462]\n",
      "loss: 5.441330242879692e38\n",
      "pde_losses: [5.432675773215889e38, 5.065084694633112e-7, 5.107251679762804e-7, 5.065213494482056e-7]\n",
      "bcs_losses: [3.5750004289329373e-6, 4.0885038097876175e-6, 4.185352803112785e-6, 5.081575286661064e-6, 4.658187146393031e-6, 5.071268576528401e-6, 3.5763312353928576e-6, 3.5639960549032645e-6, 3.6330043181493484e-6, 0.9999659663111181, 2.1924504335610868e-6, 1.0000857068270712]\n",
      "loss: 5.407785836986965e38\n",
      "pde_losses: [5.453034951146622e38, 5.096489472233746e-7, 5.048690277471797e-7, 4.966563827384702e-7]\n",
      "bcs_losses: [3.5758940486033944e-6, 4.054560117007916e-6, 4.158029325556662e-6, 5.006992112377996e-6, 4.598997947594198e-6, 4.988508672031704e-6, 3.5921648002642217e-6, 3.5683943541272735e-6, 3.5706481274005796e-6, 1.0000073062493484, 2.2130351111241973e-6, 1.0000440760982514]\n",
      "loss: 5.453805875223254e38\n",
      "pde_losses: [5.549766586076864e38, 5.097395081536523e-7, 5.081909205715284e-7, 5.108525919050316e-7]\n",
      "bcs_losses: [3.5074097022805004e-6, 4.0396443738848845e-6, 4.2635271821189815e-6, 4.990854804538801e-6, 4.589900217301471e-6, 4.89692576464331e-6, 3.509031509522714e-6, 3.511024129218667e-6, 3.516657987269736e-6, 1.000063435138675, 2.360248318611374e-6, 0.9999877870027394]\n",
      "loss: 5.4177170639606464e38\n",
      "pde_losses: [5.422930495770586e38, 5.060902541483827e-7, 4.875665339702357e-7, 5.224542105238579e-7]\n",
      "bcs_losses: [3.5363533281209485e-6, 4.0432400614402615e-6, 4.1967314002967575e-6, 5.078995514885239e-6, 4.575210030344758e-6, 4.849512373120663e-6, 3.4613498310938854e-6, 3.4916703709366967e-6, 3.503898596057959e-6, 0.9999945839264477, 2.348168047059642e-6, 1.000056339488438]\n",
      "loss: 5.427264170077169e38\n",
      "pde_losses: [5.321837737872928e38, 5.013046602034333e-7, 5.008409162920793e-7, 5.05813318529671e-7]\n",
      "bcs_losses: [3.4859346107160786e-6, 3.988449714568802e-6, 4.197689810221633e-6, 5.131363233854221e-6, 4.595778753605202e-6, 4.950384460893824e-6, 3.5283276292686186e-6, 3.508580993649638e-6, 3.5284607289265185e-6, 0.9999024158369101, 2.278647944772317e-6, 1.0001481518566109]\n",
      "loss: 5.2834577639402535e38\n",
      "pde_losses: [5.3151429305988015e38, 5.006373251115488e-7, 4.874192521545118e-7, 4.974950648514992e-7]\n",
      "bcs_losses: [3.553069110540263e-6, 4.0361947660359695e-6, 4.112960081221041e-6, 5.16702427047894e-6, 4.568177281175636e-6, 4.94152516445123e-6, 3.567946794573883e-6, 3.5482080035890188e-6, 3.5200628688823038e-6, 0.9999033346157408, 2.298916301595543e-6, 1.0001467844613772]\n",
      "loss: 5.2605486609506296e38\n",
      "pde_losses: [5.382814643640074e38, 4.90597692841567e-7, 4.948545665923414e-7, 4.99339809358816e-7]\n",
      "bcs_losses: [3.4871861449535846e-6, 4.018933715493042e-6, 4.2001532416436715e-6, 5.026870351604523e-6, 4.5144791164249e-6, 4.7753690548558775e-6, 3.4504665862839775e-6, 3.539238376829889e-6, 3.4727509212185177e-6, 1.0000079515393423, 2.406843348806114e-6, 1.0000416826517693]\n",
      "loss: 5.324191956151065e38\n",
      "pde_losses: [5.36165992516129e38, 4.945628296616921e-7, 4.986002512867178e-7, 5.058892381486175e-7]\n",
      "bcs_losses: [3.48023559211848e-6, 4.065284405521325e-6, 4.121484256927557e-6, 4.997893477251513e-6, 4.42698917859781e-6, 4.724795134196149e-6, 3.494456606409274e-6, 3.4736553639469725e-6, 3.451213388477486e-6, 1.00006825648829, 2.3879598222476415e-6, 0.9999806375927933]\n",
      "loss: 5.380110815553287e38\n",
      "pde_losses: [5.294155861248849e38, 4.894550283113476e-7, 4.987679090038003e-7, 4.874786330625068e-7]\n",
      "bcs_losses: [3.4957360201746896e-6, 3.999418983507914e-6, 4.101034652921881e-6, 5.010089235707809e-6, 4.4506507897359544e-6, 4.759609030104084e-6, 3.4367720189924873e-6, 3.458512300500426e-6, 3.4715564735953747e-6, 1.0000377957308273, 2.2751350313154424e-6, 1.0000102935742952]\n",
      "loss: 5.353228237759072e38\n",
      "pde_losses: [5.2748503732042794e38, 4.909245165880203e-7, 4.896693730421199e-7, 4.904119199313372e-7]\n",
      "bcs_losses: [3.5005208758884455e-6, 3.9650331633323286e-6, 4.062502428483504e-6, 4.9529797784355375e-6, 4.511996288165959e-6, 4.887040907359002e-6, 3.483412961800814e-6, 3.5016018887128957e-6, 3.4728332599910307e-6, 0.999950610311882, 2.1635029267115944e-6, 1.0000967112632877]\n",
      "loss: 5.190036768466229e38\n",
      "pde_losses: [5.2571348383821006e38, 4.891289958485619e-7, 4.934331572604472e-7, 4.74455779602939e-7]\n",
      "bcs_losses: [3.472922696815166e-6, 3.8973204927639155e-6, 4.042704800205645e-6, 4.980772393891742e-6, 4.53695796768384e-6, 4.811273173298334e-6, 3.4367357129452926e-6, 3.4020690069596024e-6, 3.4511471310129366e-6, 0.9999489724297046, 2.17230866332419e-6, 1.000097804096465]\n",
      "loss: 5.166092001082509e38\n",
      "pde_losses: [5.208765163362072e38, 4.913802897711702e-7, 4.823707194034107e-7, 4.7509814572082684e-7]\n",
      "bcs_losses: [3.34821263999946e-6, 3.931708611406442e-6, 4.081608452653317e-6, 4.878371348907315e-6, 4.393049289717546e-6, 4.72189216809896e-6, 3.3859614738122285e-6, 3.4064530903453673e-6, 3.406342214960325e-6, 1.0000567364007593, 2.301800117687634e-6, 0.9999896765588401]\n",
      "loss: 5.173393395662575e38\n",
      "pde_losses: [5.2100572707978766e38, 4.887884205801629e-7, 4.7460604190220875e-7, 4.932038947585719e-7]\n",
      "bcs_losses: [3.406708071738158e-6, 3.975329047426836e-6, 4.0565725116698e-6, 4.847337227258484e-6, 4.326282202065923e-6, 4.68314609881122e-6, 3.3843159329174994e-6, 3.3468118697302183e-6, 3.3978859460269744e-6, 1.0001072053330513, 2.336445069177878e-6, 0.999938661288747]\n",
      "loss: 5.230986071473253e38\n",
      "pde_losses: [5.210780414612141e38, 4.752232735235946e-7, 4.854898613627519e-7, 4.850950305777198e-7]\n",
      "bcs_losses: [3.413615703083458e-6, 3.948419859256813e-6, 3.97254102122962e-6, 4.8846299411265915e-6, 4.3550793565787184e-6, 4.720995988771233e-6, 3.368580114005702e-6, 3.4209629943958208e-6, 3.452561591090723e-6, 1.0000373074814246, 2.2598119794266915e-6, 1.0000079592769084]\n",
      "loss: 5.19373198077473e38\n",
      "pde_losses: [5.193096654872776e38, 4.768422183927274e-7, 4.704708060513823e-7, 4.857385215862026e-7]\n",
      "bcs_losses: [3.4113184495862613e-6, 3.906733023856318e-6, 3.956048720114098e-6, 4.854643639695987e-6, 4.338365759115352e-6, 4.7871967237378535e-6, 3.4276930252220787e-6, 3.4034260777099016e-6, 3.3862460543662793e-6, 0.9999862876630065, 2.2730821714600483e-6, 1.0000586239722717]\n",
      "loss: 5.112447938322444e38\n",
      "pde_losses: [5.160773864730757e38, 4.817437650182924e-7, 4.686234045811483e-7, 4.789776533813911e-7]\n",
      "bcs_losses: [3.349934624968129e-6, 3.92737363666454e-6, 3.970683676296542e-6, 4.904365015997612e-6, 4.316159424006134e-6, 4.652467245091495e-6, 3.3601596578898455e-6, 3.3363218727127912e-6, 3.3176378780290056e-6, 1.0000162678542581, 2.3721754886822587e-6, 1.0000283973895208]\n",
      "loss: 5.179583438649803e38\n",
      "pde_losses: [5.218769192590948e38, 4.7521346385550714e-7, 4.6940249811623353e-7, 4.766935240680407e-7]\n",
      "bcs_losses: [3.3380550398333757e-6, 3.8605371305024425e-6, 3.995547629067146e-6, 4.890220558986492e-6, 4.336607239026632e-6, 4.609267996920906e-6, 3.3405087355614965e-6, 3.367506343740795e-6, 3.3329457557160515e-6, 1.0000121763625172, 2.3543719366583188e-6, 1.0000321846586928]\n",
      "loss: 5.079327391856627e38\n",
      "pde_losses: [5.178732219556187e38, 4.646564020946332e-7, 4.6428486623156827e-7, 4.774573538818275e-7]\n",
      "bcs_losses: [3.396546652348446e-6, 3.8513325706850625e-6, 3.977907705864023e-6, 4.869312685606313e-6, 4.263022911329168e-6, 4.6065814949913115e-6, 3.3622418934982773e-6, 3.358018300497485e-6, 3.409416861922767e-6, 0.9999746597398496, 2.2047774258769584e-6, 1.0000691786118456]\n",
      "loss: 5.075191658766785e38\n",
      "pde_losses: [5.082532730125075e38, 4.69774363919243e-7, 4.803210863209742e-7, 4.719054016222634e-7]\n",
      "bcs_losses: [3.3551687838979265e-6, 3.903493923970094e-6, 3.922007589395459e-6, 4.8221078065057885e-6, 4.231376985207949e-6, 4.6567383238390615e-6, 3.400510054073359e-6, 3.3447620472964664e-6, 3.388716972074563e-6, 1.0000071918397198, 2.176145380164492e-6, 1.000036261660127]\n",
      "loss: 5.1608131154173354e38\n",
      "pde_losses: [5.140338926192873e38, 4.682209212642936e-7, 4.7328231063849066e-7, 4.931880867846722e-7]\n",
      "bcs_losses: [3.36748525732152e-6, 3.882932055011055e-6, 3.994141686700102e-6, 4.7649649013043124e-6, 4.194017970644892e-6, 4.560692161004216e-6, 3.319734817836133e-6, 3.309267075275944e-6, 3.2934076069497267e-6, 1.0000605956668385, 2.266025807844669e-6, 0.9999825867660117]\n",
      "loss: 5.126493338357901e38\n",
      "pde_losses: [5.04078876095405e38, 4.774594353577472e-7, 4.644479247850271e-7, 4.6787306083227547e-7]\n",
      "bcs_losses: [3.301400246430008e-6, 3.782854659710479e-6, 4.000552150897546e-6, 4.771589466576089e-6, 4.23645004982751e-6, 4.536119891928491e-6, 3.281281635324908e-6, 3.292471449669911e-6, 3.3124458122591963e-6, 1.0000273845643939, 2.29608735112839e-6, 1.0000154702943898]\n",
      "loss: 5.080258355514417e38\n",
      "pde_losses: [4.99711751644346e38, 4.703357454846764e-7, 4.786231020349915e-7, 4.684803986090909e-7]\n",
      "bcs_losses: [3.2799334558307734e-6, 3.6950308508788772e-6, 3.919380994936802e-6, 4.7508406484983615e-6, 4.204640030367694e-6, 4.558965188581347e-6, 3.264210540047302e-6, 3.304633651388117e-6, 3.284158261984274e-6, 0.9999794520403029, 2.27127496929448e-6, 1.0000630267864041]\n",
      "loss: 5.050432011074105e38\n",
      "pde_losses: [5.006072692120805e38, 4.732802754067967e-7, 4.761126030870373e-7, 4.6633525372811663e-7]\n",
      "bcs_losses: [3.295720685150866e-6, 3.7521241408168743e-6, 3.8470904326174015e-6, 4.691142105798372e-6, 4.158955921956533e-6, 4.538484758578703e-6, 3.24703440025995e-6, 3.2715912831405363e-6, 3.280925845187909e-6, 1.0000272486744424, 2.3036412774467192e-6, 1.0000149182600018]\n",
      "loss: 4.936500021672419e38\n",
      "pde_losses: [5.020426077230282e38, 4.693419342126258e-7, 4.717758889410378e-7, 4.5934153577994677e-7]\n",
      "bcs_losses: [3.2751886922299174e-6, 3.8040601207130792e-6, 3.895022676471408e-6, 4.6504014382759006e-6, 4.060421136835623e-6, 4.447709201157211e-6, 3.239521785798281e-6, 3.267140559194023e-6, 3.249803605733095e-6, 1.0000718169355811, 2.347409246695433e-6, 0.9999700529078336]\n",
      "loss: 4.991634982831022e38\n",
      "pde_losses: [4.984177026726798e38, 4.729804754684093e-7, 4.5412269457446735e-7, 4.592099630562628e-7]\n",
      "bcs_losses: [3.270990155914183e-6, 3.805660938076622e-6, 3.94220419288211e-6, 4.711476695492852e-6, 4.053159201678338e-6, 4.511428937754264e-6, 3.2580126901722285e-6, 3.266564465042436e-6, 3.2847857532102714e-6, 1.0000628502867208, 2.3370301540451e-6, 0.9999786728121975]\n",
      "loss: 4.973723953041975e38\n",
      "pde_losses: [5.003905071788122e38, 4.5718113937555193e-7, 4.650298246847226e-7, 4.5051924385918527e-7]\n",
      "bcs_losses: [3.2675132128322994e-6, 3.760501154429093e-6, 3.845434680350989e-6, 4.6758873779177516e-6, 4.122102733245133e-6, 4.444709406142863e-6, 3.2433674040747838e-6, 3.2410297907635365e-6, 3.2487447915801027e-6, 1.0000045748316924, 2.2672487246788056e-6, 1.0000365211751037]\n",
      "loss: 4.903056492388841e38\n",
      "pde_losses: [4.9027623030530686e38, 4.6874610682547026e-7, 4.570202356127763e-7, 4.5894873723943857e-7]\n",
      "bcs_losses: [3.256464783485371e-6, 3.6983006473837747e-6, 3.872111283705979e-6, 4.699233281024388e-6, 4.104968502725837e-6, 4.491036076828724e-6, 3.246684671366867e-6, 3.2964424636900874e-6, 3.2425867805865297e-6, 0.9999585204701473, 2.2119284308201426e-6, 1.000082197767628]\n",
      "loss: 4.93538825160636e38\n",
      "pde_losses: [4.882444184256751e38, 4.527987313319445e-7, 4.572931462190141e-7, 4.542318782962544e-7]\n",
      "bcs_losses: [3.2306127868620102e-6, 3.693785580604916e-6, 3.859717448373952e-6, 4.699240780085013e-6, 4.113553438743614e-6, 4.399002246627243e-6, 3.2488478730206562e-6, 3.228627647964166e-6, 3.224624078450486e-6, 0.9999902475890515, 2.270632650009003e-6, 1.0000502892619798]\n",
      "loss: 4.8903420703292614e38\n",
      "pde_losses: [4.991684872443769e38, 4.536915501299659e-7, 4.547604912838211e-7, 4.5607393961558636e-7]\n",
      "bcs_losses: [3.211223595705067e-6, 3.6877744504988566e-6, 3.8551443279765774e-6, 4.615774484495156e-6, 3.959860923680905e-6, 4.358298424389169e-6, 3.216331560741884e-6, 3.1970604682928545e-6, 3.1906035363325093e-6, 1.0000980801146089, 2.3658537791575268e-6, 0.9999423677801014]\n",
      "loss: 4.9564333201541436e38\n",
      "pde_losses: [4.891367557254926e38, 4.6066529929874937e-7, 4.5281490054942525e-7, 4.4911324470241376e-7]\n",
      "bcs_losses: [3.1827167678142413e-6, 3.727671730152662e-6, 3.7670218531584367e-6, 4.633437051139109e-6, 4.019451641078354e-6, 4.381657444055143e-6, 3.2419983931817246e-6, 3.2062079142813835e-6, 3.1801215379927132e-6, 1.0001099010191326, 2.340807902378236e-6, 0.9999303589337808]\n",
      "loss: 4.899264020848424e38\n",
      "pde_losses: [4.908426814489674e38, 4.624364556220166e-7, 4.5400080099829557e-7, 4.532903664753954e-7]\n",
      "bcs_losses: [3.1912237233510852e-6, 3.6670301699708847e-6, 3.732697573172244e-6, 4.576302181631862e-6, 4.024448157201927e-6, 4.403607971725635e-6, 3.2079288868850454e-6, 3.15955501277455e-6, 3.2173182015454705e-6, 1.0000370296425996, 2.2142455043753836e-6, 1.0000028470089513]\n",
      "loss: 4.873635690542226e38\n",
      "pde_losses: [4.802555203866469e38, 4.5705567528943515e-7, 4.476589410274157e-7, 4.4236235918217723e-7]\n",
      "bcs_losses: [3.186811086432242e-6, 3.6629353725678823e-6, 3.7622004435200886e-6, 4.6063610226449266e-6, 4.002840695678281e-6, 4.391354063226653e-6, 3.18534275097679e-6, 3.1901501842896087e-6, 3.196916460723487e-6, 1.000021985054828, 2.1924141228939625e-6, 1.0000176146138111]\n",
      "loss: 4.947008901960993e38\n",
      "pde_losses: [4.910413271421395e38, 4.5130110953236907e-7, 4.590133898131439e-7, 4.5473311005570703e-7]\n",
      "bcs_losses: [3.1452166031665302e-6, 3.655028189103944e-6, 3.856885866728524e-6, 4.577879172728466e-6, 3.991525119946816e-6, 4.330842733696029e-6, 3.1545702415588573e-6, 3.1801813748257763e-6, 3.1808025852468365e-6, 1.000064060544546, 2.2671895888871527e-6, 0.9999755564359532]\n",
      "loss: 4.7960503199035564e38\n",
      "pde_losses: [4.850697899122819e38, 4.481077177914045e-7, 4.5007706006366516e-7, 4.48241081999537e-7]\n",
      "bcs_losses: [3.149939624786631e-6, 3.6160741000715383e-6, 3.7867610770706036e-6, 4.552333980433457e-6, 3.987951520539987e-6, 4.328161869315931e-6, 3.1474558655667915e-6, 3.137623286892651e-6, 3.161108584011543e-6, 1.000035124649442, 2.2148926870314046e-6, 1.0000043847626134]\n",
      "loss: 4.807059123201631e38\n",
      "pde_losses: [4.8037610409113436e38, 4.46977265646095e-7, 4.4851768591829914e-7, 4.3657512092269797e-7]\n",
      "bcs_losses: [3.1856696867521273e-6, 3.6353028617558052e-6, 3.702641087475164e-6, 4.593137122771994e-6, 3.972545632138237e-6, 4.305922521003419e-6, 3.1837881112744697e-6, 3.161697607597552e-6, 3.1871659135637827e-6, 1.0000438329836365, 2.2161751320954742e-6, 0.9999956609042773]\n",
      "loss: 4.783131752623151e38\n",
      "pde_losses: [4.798071125987412e38, 4.464845110256814e-7, 4.464100255548601e-7, 4.4502508683929146e-7]\n",
      "bcs_losses: [3.1645267614404664e-6, 3.5780667076283224e-6, 3.662364702303351e-6, 4.562513945208128e-6, 3.936836993856463e-6, 4.3567035359064124e-6, 3.1779405402736287e-6, 3.1791279580053907e-6, 3.1882811666015417e-6, 1.000070373505518, 2.259206241410671e-6, 0.9999691414007991]\n",
      "loss: 4.825707846394597e38\n",
      "pde_losses: [4.696950483986564e38, 4.389045385154048e-7, 4.5002753768069894e-7, 4.4158172849970183e-7]\n",
      "bcs_losses: [3.129536965295354e-6, 3.596091373336379e-6, 3.7751027568537032e-6, 4.532936755189082e-6, 3.88969716884916e-6, 4.28686436315972e-6, 3.1302246179557182e-6, 3.0919509762430322e-6, 3.1396299553816844e-6, 1.0001118499807675, 2.3350160821169416e-6, 0.9999277667783527]\n",
      "loss: 4.700081372808254e38\n",
      "pde_losses: [4.817216479602112e38, 4.367455042172825e-7, 4.4635246109599594e-7, 4.41275833136728e-7]\n",
      "bcs_losses: [3.093582075859445e-6, 3.536528220085966e-6, 3.7306472351614054e-6, 4.531487390706927e-6, 3.8800885182459635e-6, 4.2325250955780735e-6, 3.117841494246744e-6, 3.129536157726816e-6, 3.126429221302809e-6, 1.0000805292288144, 2.272739006010862e-6, 0.9999589646792904]\n",
      "loss: 4.731267659424536e38\n",
      "pde_losses: [4.714196043070813e38, 4.3505425425778907e-7, 4.382128326288002e-7, 4.3959688251712855e-7]\n",
      "bcs_losses: [3.084916935922584e-6, 3.525895588370074e-6, 3.6994632967019385e-6, 4.4657505987101256e-6, 3.902651253475729e-6, 4.2545122333960865e-6, 3.0900978243748163e-6, 3.067442384753009e-6, 3.101293160811527e-6, 1.0000148561450977, 2.1490447110614655e-6, 1.0000243338991206]\n",
      "loss: 4.652873651426106e38\n",
      "pde_losses: [4.7082949882829505e38, 4.408869452636575e-7, 4.3503745954504167e-7, 4.4793715006426313e-7]\n",
      "bcs_losses: [3.146174476806371e-6, 3.545806211668712e-6, 3.6810205359559763e-6, 4.478615952630608e-6, 3.888263656752724e-6, 4.266248726059878e-6, 3.0963370311604802e-6, 3.094905327149198e-6, 3.103860472396744e-6, 0.9999959354488, 2.11633435925866e-6, 1.000043028148301]\n",
      "loss: 4.673765795044895e38\n",
      "pde_losses: [4.7524235077939886e38, 4.363564992248127e-7, 4.319972293680666e-7, 4.386102047017439e-7]\n",
      "bcs_losses: [3.076696415754517e-6, 3.563122467419502e-6, 3.716206544100853e-6, 4.437695290526927e-6, 3.821404568320394e-6, 4.203910591993297e-6, 3.064068772218536e-6, 3.065154211215265e-6, 3.0865716619360724e-6, 1.0000305681356736, 2.199902369331246e-6, 1.0000082887378312]\n",
      "loss: 4.595574040191665e38\n",
      "pde_losses: [4.694144630887463e38, 4.4029228234736117e-7, 4.4042146930504844e-7, 4.4212099376661966e-7]\n",
      "bcs_losses: [3.0494720295846593e-6, 3.513945420994672e-6, 3.664522204924345e-6, 4.392745502391554e-6, 3.7909897817913374e-6, 4.128300879227493e-6, 3.033155497570419e-6, 3.0522037200753717e-6, 3.057647848642897e-6, 1.0000683902398237, 2.3006168469221876e-6, 0.9999703724206176]\n",
      "loss: 4.6593314693014334e38\n",
      "pde_losses: [4.608538980475819e38, 4.3244883463554713e-7, 4.3028738870360494e-7, 4.372892155839573e-7]\n",
      "bcs_losses: [3.053671171262729e-6, 3.4823591477199476e-6, 3.6505922197145156e-6, 4.434024188190089e-6, 3.7755365782754666e-6, 4.183183787750891e-6, 3.0443279501982063e-6, 3.0381580787470324e-6, 3.036385989289947e-6, 1.0000797282500415, 2.3177936514527654e-6, 0.9999588299998452]\n",
      "loss: 4.587586887732993e38\n",
      "pde_losses: [4.62987504268232e38, 4.379768782154774e-7, 4.3321914172082834e-7, 4.388660243834716e-7]\n",
      "bcs_losses: [3.00605120510141e-6, 3.477493667098816e-6, 3.661784353344154e-6, 4.4395847111280315e-6, 3.790387653299689e-6, 4.175870568211317e-6, 3.0434463742068703e-6, 3.027343496290639e-6, 3.029774716977857e-6, 1.0000721492785947, 2.2577040210445807e-6, 0.9999660567685229]\n",
      "loss: 4.590517101201428e38\n",
      "pde_losses: [4.601449149487461e38, 4.3792862664456036e-7, 4.26902421999642e-7, 4.3583378728469283e-7]\n",
      "bcs_losses: [3.0179197685057575e-6, 3.5386763164069754e-6, 3.6122638866954583e-6, 4.49726810764993e-6, 3.7364653001832497e-6, 4.1501999916539655e-6, 3.0244123199237992e-6, 3.0118355846114994e-6, 3.0228457711367346e-6, 1.000098653758204, 2.232741012199166e-6, 0.999939240267324]\n",
      "loss: 4.559992929890415e38\n",
      "pde_losses: [4.590476738805132e38, 4.3122442396172864e-7, 4.3186627642686184e-7, 4.2118541115805175e-7]\n",
      "bcs_losses: [3.032653807193549e-6, 3.4854881098033204e-6, 3.6643939961725807e-6, 4.384693073478836e-6, 3.7437078240199974e-6, 4.108826963553864e-6, 3.0290759250229264e-6, 3.0322500812260484e-6, 3.0048438980919617e-6, 1.00009410277152, 2.174670805623582e-6, 0.9999433884767164]\n",
      "loss: 4.658282949143268e38\n",
      "pde_losses: [4.530298628063298e38, 4.195103654830849e-7, 4.3347535360795056e-7, 4.352403863601684e-7]\n",
      "bcs_losses: [3.002099433433259e-6, 3.4661641731455214e-6, 3.6175171466966234e-6, 4.38751381359571e-6, 3.7055603599087978e-6, 4.122472140183372e-6, 3.035955799782806e-6, 3.0739097642544417e-6, 3.032362711039631e-6, 1.0000447502774588, 2.1121802088132533e-6, 0.9999924382174307]\n",
      "loss: 4.555710300645765e38\n",
      "pde_losses: [4.625168125628923e38, 4.1671532898352027e-7, 4.2733701524769767e-7, 4.294633170463057e-7]\n",
      "bcs_losses: [3.0386510767278785e-6, 3.449683119486786e-6, 3.6250871232533046e-6, 4.353787177046264e-6, 3.7428478533075054e-6, 4.17340260357736e-6, 3.037855179405287e-6, 3.029699746856731e-6, 3.0419287793668313e-6, 1.0000083077066857, 2.098525681338026e-6, 1.0000286115131036]\n",
      "loss: 4.566216062291484e38\n",
      "pde_losses: [4.560598785111115e38, 4.1797663209113746e-7, 4.2996426849573105e-7, 4.3108779823853246e-7]\n",
      "bcs_losses: [3.000976404177701e-6, 3.433152370576949e-6, 3.5363824720457826e-6, 4.292769656740776e-6, 3.6931499989194383e-6, 4.115089706034156e-6, 3.004109720495002e-6, 3.007704196427281e-6, 2.973749752239286e-6, 1.00004075413151, 2.1793289157718994e-6, 0.9999960250164]\n",
      "loss: 4.523407080818271e38\n",
      "pde_losses: [4.5185361508547446e38, 4.4079409678325227e-7, 4.2372779188811635e-7, 4.3253878204936027e-7]\n",
      "bcs_losses: [2.973080329373534e-6, 3.395848148812766e-6, 3.565175986159741e-6, 4.3247048978222705e-6, 3.7513132039822183e-6, 4.014602384679909e-6, 2.962304604764152e-6, 2.990136258939283e-6, 2.994270842398243e-6, 1.0000704221176728, 2.2638649065379964e-6, 0.9999661065156425]\n",
      "loss: 4.565803475216073e38\n",
      "pde_losses: [4.508621494104208e38, 4.226401065680202e-7, 4.196393702128039e-7, 4.2434483089748255e-7]\n",
      "bcs_losses: [2.934328033696227e-6, 3.3657709025762498e-6, 3.5185934285465954e-6, 4.263937971497882e-6, 3.6309887657807258e-6, 4.0445198573714344e-6, 2.956929691310373e-6, 2.9388917778215577e-6, 2.981528129260083e-6, 1.0000855792991978, 2.280965216587142e-6, 0.999950499428274]\n",
      "loss: 4.446974474599827e38\n",
      "pde_losses: [4.545872483018343e38, 4.2098934602885965e-7, 4.1489790469620625e-7, 4.1333318965362937e-7]\n",
      "bcs_losses: [2.9655548085626963e-6, 3.4001593819325477e-6, 3.5509534602539173e-6, 4.2925694760314385e-6, 3.668653054998995e-6, 4.061248337007141e-6, 2.9766757574501953e-6, 2.960341561482645e-6, 2.9452872828605556e-6, 1.0000970680941739, 2.239062228793709e-6, 0.999938477497001]\n",
      "loss: 4.463497924959963e38\n",
      "pde_losses: [4.548083834316335e38, 4.1465769323816547e-7, 4.214544161331408e-7, 4.237653045611598e-7]\n",
      "bcs_losses: [2.9316014836085055e-6, 3.4385474394918344e-6, 3.542689934989466e-6, 4.291917228389129e-6, 3.6177859010970428e-6, 3.9688581498391055e-6, 2.9412458915732313e-6, 2.9469037459147584e-6, 2.9725276949103552e-6, 1.0001483051189224, 2.2531509794054654e-6, 0.9998868442426886]\n",
      "loss: 4.448889955789393e38\n",
      "pde_losses: [4.446691426493512e38, 4.18883854663543e-7, 4.159137014753436e-7, 4.190307276620902e-7]\n",
      "bcs_losses: [2.9560524864913674e-6, 3.4034947876568062e-6, 3.5453379995550455e-6, 4.263003360281833e-6, 3.594484113050194e-6, 3.98255472055608e-6, 2.9625018313668495e-6, 2.927323049848345e-6, 2.915012153028414e-6, 1.0001224828534463, 2.2160792017164985e-6, 0.9999122702384863]\n",
      "loss: 4.481346069579254e38\n",
      "pde_losses: [4.463068541619947e38, 4.241567164506316e-7, 4.1324294640102114e-7, 4.161146134650207e-7]\n",
      "bcs_losses: [2.9213788060082375e-6, 3.319645324826474e-6, 3.5769565881628e-6, 4.255721281878696e-6, 3.617998444716823e-6, 3.9962432332508645e-6, 2.941316067566157e-6, 2.923792252336472e-6, 2.9415340234047572e-6, 1.0000712469541844, 2.1507218705730105e-6, 0.9999630777674975]\n",
      "loss: 4.489570784377257e38\n",
      "pde_losses: [4.477154998866879e38, 4.2020190084773305e-7, 4.178104319282175e-7, 4.1517195067794004e-7]\n",
      "bcs_losses: [2.949249468628662e-6, 3.3336024174590947e-6, 3.480509589963849e-6, 4.214508427604734e-6, 3.630815671833311e-6, 3.983218942371559e-6, 2.9447622987866835e-6, 2.968768735552889e-6, 2.959325287526902e-6, 1.000013950669267, 2.0862644316139575e-6, 1.0000199592271874]\n",
      "loss: 4.5003800501964486e38\n",
      "pde_losses: [4.424082880212195e38, 4.1637181943270307e-7, 4.069938717235726e-7, 4.1030065043496104e-7]\n",
      "bcs_losses: [2.9297491576055197e-6, 3.3212190873991295e-6, 3.486227647248292e-6, 4.191809272830689e-6, 3.55612774989864e-6, 3.887541410183899e-6, 2.928704309807943e-6, 2.915969641566219e-6, 2.9273005284611257e-6, 1.000059616159644, 2.1499294591352883e-6, 0.9999738834728472]\n",
      "loss: 4.388799207365623e38\n",
      "pde_losses: [4.387347154708302e38, 4.1230862951714656e-7, 4.186609023759366e-7, 4.181393590166045e-7]\n",
      "bcs_losses: [2.8929210215364486e-6, 3.3221966674512365e-6, 3.5078497488474155e-6, 4.160871356831456e-6, 3.51593527395467e-6, 3.8692627918549304e-6, 2.8844320670262676e-6, 2.898446786755261e-6, 2.9079343414052736e-6, 1.0001354461064782, 2.272246931211949e-6, 0.9998978167878472]\n",
      "loss: 4.340646802841152e38\n",
      "pde_losses: [4.3905533265072586e38, 4.1339461668107546e-7, 4.062866921405222e-7, 4.137301774739157e-7]\n",
      "bcs_losses: [2.885610111971755e-6, 3.3347688351497494e-6, 3.426643534888038e-6, 4.167345667700972e-6, 3.535211257512894e-6, 3.902373242779044e-6, 2.884635560985377e-6, 2.8855695832188846e-6, 2.895326078762773e-6, 1.0001177972973931, 2.2618934194553813e-6, 0.9999151290171191]\n",
      "loss: 4.33583123857207e38\n",
      "pde_losses: [4.36724004231074e38, 4.050738605288415e-7, 4.0683509724636156e-7, 3.952987791317677e-7]\n",
      "bcs_losses: [2.8933378084215817e-6, 3.3022612892824154e-6, 3.4390702193838536e-6, 4.166589274657377e-6, 3.556818850026357e-6, 3.882350738198551e-6, 2.915021827733069e-6, 2.909740436323483e-6, 2.911218710127334e-6, 1.0000683390492844, 2.2018659460578494e-6, 0.9999643057976257]\n",
      "loss: 4.3544323062302486e38\n",
      "pde_losses: [4.4092456186787945e38, 4.07986323620532e-7, 4.1008566155951627e-7, 4.0728771602444285e-7]\n",
      "bcs_losses: [2.8639347416129994e-6, 3.3215276657624162e-6, 3.471070318505128e-6, 4.199824758196896e-6, 3.540635585164892e-6, 3.898397470789985e-6, 2.8980100387984177e-6, 2.8939451441975884e-6, 2.889469465890551e-6, 1.0000801711604104, 2.1875301873459254e-6, 0.9999522826884786]\n",
      "loss: 4.384604091090983e38\n",
      "pde_losses: [4.40337984311501e38, 4.055778501448656e-7, 4.0331031540336043e-7, 4.111165931273311e-7]\n",
      "bcs_losses: [2.843724826023106e-6, 3.2985969054683065e-6, 3.449505496947733e-6, 4.164148353266965e-6, 3.4900980969494605e-6, 3.8153279658223125e-6, 2.842891523634306e-6, 2.8357730676220524e-6, 2.856982603042807e-6, 1.0001345966089312, 2.19880329214504e-6, 0.9998976942309117]\n",
      "loss: 4.3358157205171386e38\n",
      "pde_losses: [4.2323944796324685e38, 4.013675805997729e-7, 4.0379200265097055e-7, 4.029532114915001e-7]\n",
      "bcs_losses: [2.8597166311537037e-6, 3.3065394706652942e-6, 3.4503559808592184e-6, 4.082640150051368e-6, 3.496489484005357e-6, 3.7644199097874306e-6, 2.868036343387955e-6, 2.8456473231628727e-6, 2.8487845586388545e-6, 1.0001337170072873, 2.1581510466393163e-6, 0.9998984793577701]\n",
      "loss: 4.310976285783385e38\n",
      "pde_losses: [4.328487553643158e38, 3.95764146442372e-7, 4.033113974810448e-7, 4.163367132544475e-7]\n",
      "bcs_losses: [2.8282371086730386e-6, 3.240206477724316e-6, 3.402099653021819e-6, 4.082781671143052e-6, 3.5225465825238555e-6, 3.872299237573889e-6, 2.8324117497958463e-6, 2.8687706259260586e-6, 2.856136706979238e-6, 1.0000767319701862, 2.0975039043423788e-6, 0.999955316605082]\n",
      "loss: 4.309514045905502e38\n",
      "pde_losses: [4.366305501632994e38, 4.0298928879207713e-7, 3.9707926528683504e-7, 3.9770062932109746e-7]\n",
      "bcs_losses: [2.8440469430386975e-6, 3.232923666717692e-6, 3.3931110618988976e-6, 4.1007976569041574e-6, 3.4351261622896368e-6, 3.864547093941404e-6, 2.8262060053894876e-6, 2.8152918614268042e-6, 2.848932010839396e-6, 1.0000928694866098, 2.1727612237880594e-6, 0.9999392254763035]\n",
      "loss: 4.257255699262992e38\n",
      "pde_losses: [4.30171926145842e38, 4.032917761492681e-7, 4.029298481548668e-7, 3.967377240274249e-7]\n",
      "bcs_losses: [2.80379807762015e-6, 3.231054711726307e-6, 3.397651030288446e-6, 4.012673640046863e-6, 3.436779042214019e-6, 3.7286419541719825e-6, 2.819391320684693e-6, 2.807914749818636e-6, 2.7836269363970444e-6, 1.0001384818022094, 2.2663148603338618e-6, 0.9998935647514349]\n",
      "loss: 4.280042619059892e38\n",
      "pde_losses: [4.288021987740426e38, 4.0289241090542823e-7, 4.0538976259555404e-7, 4.025963087888085e-7]\n",
      "bcs_losses: [2.8126630719441975e-6, 3.2147452702560615e-6, 3.3761835563973644e-6, 3.9891752160256005e-6, 3.4117304962530896e-6, 3.7017938118625713e-6, 2.828927076856864e-6, 2.816917041414906e-6, 2.7992495827545165e-6, 1.0001010566814792, 2.2080242208680737e-6, 0.999930679391414]\n",
      "loss: 4.3105269585419355e38\n",
      "pde_losses: [4.2551629941307435e38, 4.0386395992043855e-7, 3.9185284271473587e-7, 3.9817278198583655e-7]\n",
      "bcs_losses: [2.8557495986965196e-6, 3.2786454962455927e-6, 3.3758728507545595e-6, 3.987040700790344e-6, 3.424823797002773e-6, 3.7556021539202303e-6, 2.836982561353523e-6, 2.853894635217485e-6, 2.83391937998935e-6, 1.0000600228022738, 2.1569223929669825e-6, 0.9999713716818273]\n",
      "loss: 4.240873597319523e38\n",
      "pde_losses: [4.2261235910901696e38, 3.948972480657562e-7, 3.9778776496861744e-7, 3.941670685245655e-7]\n",
      "bcs_losses: [2.8169767358565264e-6, 3.206257690887826e-6, 3.357906865895441e-6, 4.041092479648345e-6, 3.425751841173468e-6, 3.7274788681091583e-6, 2.822190528618348e-6, 2.8177091933137646e-6, 2.81618205802328e-6, 1.000060618733074, 2.156101954863738e-6, 0.9999704631787336]\n",
      "loss: 4.191493510593645e38\n",
      "pde_losses: [4.2152891362295936e38, 4.0068561122180996e-7, 3.958720494937785e-7, 4.009433480893036e-7]\n",
      "bcs_losses: [2.7727138694550316e-6, 3.2214466317707573e-6, 3.3720653181676253e-6, 4.05391842108404e-6, 3.3567430931677395e-6, 3.691401366784992e-6, 2.821547840434502e-6, 2.777608008492784e-6, 2.79872436869927e-6, 1.0000918628571984, 2.1760376589211945e-6, 0.9999389731111469]\n",
      "loss: 4.1471450019826334e38\n",
      "pde_losses: [4.3438746169247946e38, 3.8984321543102194e-7, 4.014368906517851e-7, 3.922570781114388e-7]\n",
      "bcs_losses: [2.7658844391623305e-6, 3.1953122964803874e-6, 3.332204590170011e-6, 4.008975927757384e-6, 3.343503177715677e-6, 3.711563231040447e-6, 2.768005266867553e-6, 2.7785385184019734e-6, 2.776914761755142e-6, 1.0001631719363806, 2.2240690415502723e-6, 0.999867519379897]\n",
      "loss: 4.281180490613282e38\n",
      "pde_losses: [4.184801697840202e38, 3.871129761948829e-7, 3.884898738681643e-7, 3.960464518845928e-7]\n",
      "bcs_losses: [2.759637056174042e-6, 3.201379207330879e-6, 3.3226479031647237e-6, 3.950863482273311e-6, 3.326609725973446e-6, 3.6483851115841406e-6, 2.7675871995279906e-6, 2.763782252330809e-6, 2.7991728425432723e-6, 1.0001860080800868, 2.231308078516666e-6, 0.9998444802410262]\n",
      "loss: 4.1861183842896235e38\n",
      "pde_losses: [4.211054767908218e38, 3.887800287455335e-7, 3.9244131650403246e-7, 3.802453286057723e-7]\n",
      "bcs_losses: [2.795511921370882e-6, 3.1895243024306777e-6, 3.2788153996976624e-6, 3.941226441600131e-6, 3.3572188727048556e-6, 3.6892458588006696e-6, 2.7783475985546543e-6, 2.78001530474549e-6, 2.767361775744115e-6, 1.0001188195959236, 2.1447959323888066e-6, 0.9999113163168334]\n",
      "loss: 4.1354076100196696e38\n",
      "pde_losses: [4.146827320248623e38, 3.979358583334801e-7, 3.8223687266633276e-7, 3.8367812604437837e-7]\n",
      "bcs_losses: [2.762135072263161e-6, 3.1738905539335075e-6, 3.282633136741213e-6, 3.950782365401931e-6, 3.364485205408631e-6, 3.6875419813292578e-6, 2.7787155562934963e-6, 2.7654190809874282e-6, 2.7702041592804345e-6, 1.0000868180468943, 2.118343055932357e-6, 0.999943093601672]\n",
      "loss: 4.099901534499453e38\n",
      "pde_losses: [4.104637114460239e38, 3.8326470598983505e-7, 3.877041265621779e-7, 3.8740356834002006e-7]\n",
      "bcs_losses: [2.73814247110416e-6, 3.15038476905727e-6, 3.325044077114704e-6, 3.916481869862571e-6, 3.3730666644244814e-6, 3.6275913115886474e-6, 2.7489105568226187e-6, 2.7069973789230873e-6, 2.7279146836668434e-6, 1.0000994563188326, 2.1427344288645765e-6, 0.999930270511715]\n",
      "loss: 4.108743810703759e38\n",
      "pde_losses: [4.111983671073754e38, 3.7418049003127824e-7, 3.9048635959343364e-7, 3.907203606860414e-7]\n",
      "bcs_losses: [2.7021742186554553e-6, 3.1794183230186767e-6, 3.349943070496953e-6, 3.928908801446341e-6, 3.3303711814827053e-6, 3.603437514004084e-6, 2.742707941133515e-6, 2.725178627711864e-6, 2.7334512372247282e-6, 1.0001007371225317, 2.1445487049617805e-6, 0.999928829446078]\n",
      "loss: 4.125136576600999e38\n",
      "pde_losses: [4.109840958430984e38, 3.8378945094559893e-7, 3.847645314592831e-7, 3.8435015323130924e-7]\n",
      "bcs_losses: [2.7397767900487504e-6, 3.124946008766011e-6, 3.265730916935563e-6, 3.9082746245316205e-6, 3.347016029925014e-6, 3.6288346984376214e-6, 2.7176442991025176e-6, 2.739119817437282e-6, 2.740894138402922e-6, 1.000065292895345, 2.0989519160181996e-6, 0.999963931753669]\n",
      "loss: 4.0641899828509435e38\n",
      "pde_losses: [4.159306542498935e38, 3.754133507829841e-7, 3.815269697965361e-7, 3.794574131941956e-7]\n",
      "bcs_losses: [2.6957824065004216e-6, 3.084109425920056e-6, 3.229453483861407e-6, 3.937168543736549e-6, 3.2939681432916037e-6, 3.6300019179469854e-6, 2.733033167667027e-6, 2.7118963471390254e-6, 2.7156122496612284e-6, 1.000094314736931, 2.1292025041609935e-6, 0.9999346914534148]\n",
      "loss: 4.080651576127969e38\n",
      "pde_losses: [4.137609578902723e38, 3.8302595475075595e-7, 3.841769754164024e-7, 3.912598141316687e-7]\n",
      "bcs_losses: [2.685435124626482e-6, 3.1170007647127924e-6, 3.261570027066472e-6, 3.890786831427177e-6, 3.283267679275598e-6, 3.5358461963489386e-6, 2.685682563878552e-6, 2.6773502182371434e-6, 2.6773317112096264e-6, 1.0001710168328903, 2.2279337324903243e-6, 0.9998578292983547]\n",
      "loss: 4.134362833000857e38\n",
      "pde_losses: [4.1368646755384655e38, 3.820125550027342e-7, 3.7733625283671214e-7, 3.8395113836932123e-7]\n",
      "bcs_losses: [2.6658286046925604e-6, 3.107305194105459e-6, 3.2345404930067296e-6, 3.926974792400716e-6, 3.225427824451305e-6, 3.5336316986144283e-6, 2.676057190071223e-6, 2.684270492775134e-6, 2.6801326019285704e-6, 1.000176990269395, 2.2265776026074106e-6, 0.9998515801012937]\n",
      "loss: 4.105546049291527e38\n",
      "pde_losses: [4.036060586253081e38, 3.7958578705958394e-7, 3.8047411121270247e-7, 3.876711636665996e-7]\n",
      "bcs_losses: [2.7025994322687396e-6, 3.1018612321993347e-6, 3.255891136707992e-6, 3.891370244522981e-6, 3.254708076372443e-6, 3.572848675861133e-6, 2.6731666031718322e-6, 2.6689847487451035e-6, 2.7188024497620036e-6, 1.0000977735607839, 2.130680759439082e-6, 0.9999304034612762]\n",
      "loss: 4.069943698610534e38\n",
      "pde_losses: [4.061351755403502e38, 3.8827802082678203e-7, 3.828884775214679e-7, 3.7769807223544477e-7]\n",
      "bcs_losses: [2.6984356272688906e-6, 3.1088008389324537e-6, 3.1889398899824886e-6, 3.952061349198767e-6, 3.2579270722411254e-6, 3.618466801888178e-6, 2.710926095166784e-6, 2.7038167421028893e-6, 2.710938391877354e-6, 1.0000705354428732, 2.1106735729550163e-6, 0.9999573682255294]\n",
      "loss: 4.043211546598496e38\n",
      "pde_losses: [4.052099545165243e38, 3.782263047874752e-7, 3.7042211493216584e-7, 3.8281112178516e-7]\n",
      "bcs_losses: [2.682755059151362e-6, 3.0911220504651465e-6, 3.2830847859465662e-6, 3.8176550594542845e-6, 3.23356014354214e-6, 3.5052640529256454e-6, 2.675984851198323e-6, 2.6603473828014e-6, 2.6783307837746207e-6, 1.0001508728600603, 2.2080447867427356e-6, 0.9998769256682174]\n",
      "loss: 3.982682704947123e38\n",
      "pde_losses: [3.9550074310138874e38, 3.75657778419168e-7, 3.7859300886885676e-7, 3.742367412924951e-7]\n",
      "bcs_losses: [2.642199291916826e-6, 3.100877086851803e-6, 3.215870868504381e-6, 3.821256776561741e-6, 3.1892297982738904e-6, 3.503544052064229e-6, 2.643608912632382e-6, 2.6461333680780446e-6, 2.6603435023884957e-6, 1.000157755206379, 2.21047379685178e-6, 0.9998698651784524]\n",
      "loss: 3.9893841211525755e38\n",
      "pde_losses: [3.980227557826135e38, 3.743943749388204e-7, 3.707097087014122e-7, 3.6704914635911515e-7]\n",
      "bcs_losses: [2.6414146531332996e-6, 3.0267958856290606e-6, 3.1811047683162786e-6, 3.81138272354503e-6, 3.1945344697847515e-6, 3.5059243876966357e-6, 2.646445865414346e-6, 2.6611381471113495e-6, 2.6493885165414428e-6, 1.0001273056626898, 2.142826974396107e-6, 0.999899955401836]\n",
      "loss: 3.958831090356009e38\n",
      "pde_losses: [3.9113726183387854e38, 3.7659768367294844e-7, 3.784585928666722e-7, 3.6669539609158183e-7]\n",
      "bcs_losses: [2.6237898092057125e-6, 2.9925409551283096e-6, 3.1864777648628573e-6, 3.7434938889296577e-6, 3.176924048096729e-6, 3.4843488002944056e-6, 2.6366171184575968e-6, 2.6387695698427894e-6, 2.6034680848661475e-6, 1.0001294204079314, 2.1174000197452183e-6, 0.9998975293371914]\n",
      "loss: 4.063320801579377e38\n",
      "pde_losses: [4.0207499601645866e38, 3.6426786357636923e-7, 3.727860465323662e-7, 3.802968923126347e-7]\n",
      "bcs_losses: [2.5973402363461743e-6, 3.0028818058424992e-6, 3.240163756226871e-6, 3.7716334291064454e-6, 3.176568045035839e-6, 3.4318432162761547e-6, 2.587913109788e-6, 2.608637552277324e-6, 2.5991261346473936e-6, 1.0001549589725698, 2.1434645874848017e-6, 0.9998716908736813]\n",
      "loss: 3.950825596566738e38\n",
      "pde_losses: [3.995903033034337e38, 3.7967611766100886e-7, 3.704860673941704e-7, 3.7126970150218025e-7]\n",
      "bcs_losses: [2.6200264849866014e-6, 2.9870428782467698e-6, 3.2316333063064184e-6, 3.790405586342552e-6, 3.1616088448034237e-6, 3.45805891174137e-6, 2.6132935594999282e-6, 2.637072502743978e-6, 2.627933044773284e-6, 1.0001417028269701, 2.0910766145073552e-6, 0.9998846641424045]\n",
      "loss: 3.98164433958655e38\n",
      "pde_losses: [3.944715580639636e38, 3.6709516472835154e-7, 3.697205801462834e-7, 3.713649630243176e-7]\n",
      "bcs_losses: [2.618593956901051e-6, 3.0365509755008087e-6, 3.2052301669274797e-6, 3.7734072146679645e-6, 3.193875175528712e-6, 3.520390849019084e-6, 2.6258827259792586e-6, 2.6098923799467937e-6, 2.645964047998932e-6, 1.0001190021029405, 2.0491210484239863e-6, 0.9999070991401476]\n",
      "loss: 3.9344124562291985e38\n",
      "pde_losses: [3.868913644294051e38, 3.703389556047641e-7, 3.6530445222082104e-7, 3.670376761299588e-7]\n",
      "bcs_losses: [2.642797518343205e-6, 2.9935741207598713e-6, 3.170376139024054e-6, 3.76578305032048e-6, 3.146744249962796e-6, 3.448966447565137e-6, 2.6373023611642767e-6, 2.630381048995396e-6, 2.621369361641244e-6, 1.0001443242254682, 2.1020615005095567e-6, 0.9998816954491785]\n",
      "loss: 3.8763599798361744e38\n",
      "pde_losses: [3.939218198246502e38, 3.719544992945139e-7, 3.7123214313381227e-7, 3.7640007969130105e-7]\n",
      "bcs_losses: [2.589035753465666e-6, 2.986196941900492e-6, 3.1900296506858635e-6, 3.7193529578338216e-6, 3.0811638372331334e-6, 3.3834754906768756e-6, 2.5970405634840414e-6, 2.6080404697401933e-6, 2.6056489182902975e-6, 1.0001602065653559, 2.1617352300117467e-6, 0.9998657045623407]\n",
      "loss: 3.909743252464275e38\n",
      "pde_losses: [3.865797133437027e38, 3.6614948030977837e-7, 3.659280383219598e-7, 3.67342208113229e-7]\n",
      "bcs_losses: [2.5934282485647092e-6, 2.926817334337191e-6, 3.147269553627605e-6, 3.7507035230733985e-6, 3.113958152196088e-6, 3.443011695063484e-6, 2.606748425712797e-6, 2.5807744319832672e-6, 2.603918103643186e-6, 1.0001299232036573, 2.124408095528135e-6, 0.9998959020393589]\n",
      "loss: 3.921621102747008e38\n",
      "pde_losses: [3.9495068938066654e38, 3.724474908383296e-7, 3.622233607619844e-7, 3.623474464309519e-7]\n",
      "bcs_losses: [2.581542428545485e-6, 2.9358187506688845e-6, 3.0551438673960016e-6, 3.715730244432674e-6, 3.1578513026795686e-6, 3.4136646960599994e-6, 2.573081747392087e-6, 2.591282134008098e-6, 2.571429459593586e-6, 1.0001284193954707, 2.1072499764650752e-6, 0.9998972144893259]\n",
      "loss: 3.860953851221282e38\n",
      "pde_losses: [3.851852007866614e38, 3.697625720570844e-7, 3.662396273167695e-7, 3.6127178773040443e-7]\n",
      "bcs_losses: [2.55593772948612e-6, 2.923562158183511e-6, 3.0746177476726245e-6, 3.6206089875615017e-6, 3.064928823377278e-6, 3.372369078625708e-6, 2.5817500202109095e-6, 2.5733359362438615e-6, 2.5799026476798816e-6, 1.0001584498971647, 2.0963930005482497e-6, 0.9998669379784856]\n",
      "loss: 3.8787218854224284e38\n",
      "pde_losses: [3.90397626724051e38, 3.610201414141304e-7, 3.688414247584404e-7, 3.673886704968122e-7]\n",
      "bcs_losses: [2.5730905657491574e-6, 2.915093478793921e-6, 3.104793183437834e-6, 3.638994829364108e-6, 3.098849247017291e-6, 3.3703183880555793e-6, 2.5675882356134555e-6, 2.574195216900871e-6, 2.5759503584463602e-6, 1.0001590891143533, 2.078543684392932e-6, 0.9998660171590549]\n",
      "loss: 3.846952300534554e38\n",
      "pde_losses: [3.9005463287676834e38, 3.591068639986311e-7, 3.598304885264156e-7, 3.628614887694154e-7]\n",
      "bcs_losses: [2.566745085507977e-6, 2.9377074023612267e-6, 3.1132068249571734e-6, 3.690170335726669e-6, 3.0876001785787296e-6, 3.3779780273390848e-6, 2.571049522511204e-6, 2.5442914783839043e-6, 2.5631370700934863e-6, 1.0001447791035862, 2.0915845123903036e-6, 0.9998801249381424]\n",
      "loss: 3.91939579498248e38\n",
      "pde_losses: [3.8571485223373095e38, 3.554306969667299e-7, 3.592027778271026e-7, 3.6766779189853243e-7]\n",
      "bcs_losses: [2.5576242286845493e-6, 2.9393705225332286e-6, 3.0647412715775096e-6, 3.7060315611528626e-6, 3.0720813420759527e-6, 3.3376977645705264e-6, 2.5480709146750755e-6, 2.552987517849498e-6, 2.5529726760456216e-6, 1.0001372942259652, 2.1229993205743924e-6, 0.9998875105234282]\n",
      "loss: 3.849119410213952e38\n",
      "pde_losses: [3.825490391425787e38, 3.577914650704649e-7, 3.5933723488021383e-7, 3.612988765858083e-7]\n",
      "bcs_losses: [2.5494766957807384e-6, 2.895814011680524e-6, 3.0581249377009695e-6, 3.671407833936108e-6, 3.027556718453288e-6, 3.3149907316403996e-6, 2.5608018162510025e-6, 2.5475041969984673e-6, 2.56645008741023e-6, 1.0001574304514085, 2.153797495192169e-6, 0.9998672803494436]\n",
      "loss: 3.8325595510901354e38\n",
      "pde_losses: [3.810175960220236e38, 3.617437551113329e-7, 3.58431908203667e-7, 3.5352464287379094e-7]\n",
      "bcs_losses: [2.5512476830758523e-6, 2.900849505422498e-6, 3.0105607099977876e-6, 3.648768874988349e-6, 3.025534141057998e-6, 3.331422511978507e-6, 2.5449438389110152e-6, 2.5285874418379166e-6, 2.5391343118286663e-6, 1.0001819350178422, 2.1717387837016817e-6, 0.9998426231620199]\n",
      "loss: 3.811378932321868e38\n",
      "pde_losses: [3.783893616824693e38, 3.623597877853094e-7, 3.539197654477042e-7, 3.5724541350941624e-7]\n",
      "bcs_losses: [2.531863600749071e-6, 2.8776487759105306e-6, 3.0641217381702433e-6, 3.628141904146421e-6, 2.99815130351036e-6, 3.316370347993108e-6, 2.526875033036157e-6, 2.5388121002083638e-6, 2.5305003517671042e-6, 1.0001797014961284, 2.161503945341431e-6, 0.9998446500685894]\n",
      "loss: 3.8392199451348686e38\n",
      "pde_losses: [3.740946670823746e38, 3.493472996531082e-7, 3.531563459279031e-7, 3.5738193487666657e-7]\n",
      "bcs_losses: [2.5007504859164495e-6, 2.8381801908624067e-6, 3.0392527492098624e-6, 3.566710752647063e-6, 3.0340770008527435e-6, 3.287635926385565e-6, 2.5152503111213723e-6, 2.507315567089336e-6, 2.518966508428095e-6, 1.0001257744031877, 2.086341638068046e-6, 0.9998983119073033]\n",
      "loss: 3.775778978476362e38\n",
      "pde_losses: [3.758083216640547e38, 3.583458041982458e-7, 3.470540141335182e-7, 3.5591740157341555e-7]\n",
      "bcs_losses: [2.502666033488788e-6, 2.817742014903935e-6, 3.032625335533628e-6, 3.602754652519449e-6, 3.062099359964803e-6, 3.325058179148877e-6, 2.4953495427967056e-6, 2.4819614473647346e-6, 2.5188819974339265e-6, 1.000073671058579, 2.0217195574006103e-6, 0.9999501587484507]\n",
      "loss: 3.7665883562864154e38\n",
      "pde_losses: [3.758659904864903e38, 3.519389590983425e-7, 3.5675745192884314e-7, 3.599868595098268e-7]\n",
      "bcs_losses: [2.497735633445659e-6, 2.8225250674166268e-6, 3.033060436672135e-6, 3.5671391402949506e-6, 3.0126518006889288e-6, 3.2764812440931567e-6, 2.49252687081695e-6, 2.51932080081841e-6, 2.490046499733084e-6, 1.0001292143867264, 2.0536417219779344e-6, 0.999894518391813]\n",
      "loss: 3.74954229047315e38\n",
      "pde_losses: [3.750554719268358e38, 3.510637070528779e-7, 3.535556159318507e-7, 3.570839332236172e-7]\n",
      "bcs_losses: [2.4735048489877344e-6, 2.813749254930524e-6, 3.031597592378234e-6, 3.545029250665402e-6, 2.948116190375397e-6, 3.256501869839563e-6, 2.45556970800589e-6, 2.4646874099257073e-6, 2.487434336043915e-6, 1.0001924281190062, 2.131000780629927e-6, 0.9998313080031597]\n",
      "loss: 3.7726103086926116e38\n",
      "pde_losses: [3.765444050954033e38, 3.460318750058591e-7, 3.5059482784028305e-7, 3.495890627906569e-7]\n",
      "bcs_losses: [2.4688935737087803e-6, 2.829918313507231e-6, 3.006442980581956e-6, 3.5670251240967676e-6, 2.9667087520684452e-6, 3.226301306996909e-6, 2.4899951117152656e-6, 2.489516993529924e-6, 2.4833026821290952e-6, 1.0001751158739287, 2.1221720427201057e-6, 0.9998486089728787]\n",
      "loss: 3.718703898422531e38\n",
      "pde_losses: [3.726053208723787e38, 3.461644249664654e-7, 3.500271723033445e-7, 3.5536090308640516e-7]\n",
      "bcs_losses: [2.476102665004617e-6, 2.8233574608853063e-6, 3.0119192059477494e-6, 3.647419711138969e-6, 2.9517394020563125e-6, 3.221913496258231e-6, 2.4644351391047587e-6, 2.4778226000532903e-6, 2.483285504203764e-6, 1.0001576180118343, 2.1314503345698138e-6, 0.9998660754331246]\n",
      "loss: 3.708170089398649e38\n",
      "pde_losses: [3.699726743786335e38, 3.5082873129300895e-7, 3.4901292622204307e-7, 3.485365649257076e-7]\n",
      "bcs_losses: [2.4955579568280643e-6, 2.850035557807822e-6, 3.0193495605989533e-6, 3.631919124274403e-6, 2.9180335341109064e-6, 3.2195542755515107e-6, 2.4710369613411187e-6, 2.4762733107195272e-6, 2.4877337963151082e-6, 1.0001775568443638, 2.165821409358614e-6, 0.999846041374498]\n",
      "loss: 3.7106417776745744e38\n",
      "pde_losses: [3.695154947836777e38, 3.49875431330271e-7, 3.535652473899476e-7, 3.4827955824488493e-7]\n",
      "bcs_losses: [2.4981387743862073e-6, 2.838925127256115e-6, 2.93465144586389e-6, 3.5645293023209197e-6, 2.9179194230717275e-6, 3.160807846813953e-6, 2.4712118161797982e-6, 2.4919240967294563e-6, 2.465094720699526e-6, 1.0001916710794785, 2.1400024132686916e-6, 0.9998317862180883]\n",
      "loss: 3.7289555467711295e38\n",
      "pde_losses: [3.686277503116261e38, 3.462075301239782e-7, 3.4105250603500786e-7, 3.524387510012831e-7]\n",
      "bcs_losses: [2.470056145802345e-6, 2.8379185153710304e-6, 2.956759541710061e-6, 3.5189736794918183e-6, 2.889530483505776e-6, 3.201310141678429e-6, 2.4717932705633592e-6, 2.485059678177269e-6, 2.462027152812141e-6, 1.0001769805235186, 2.081853377482276e-6, 0.9998463132470649]\n",
      "loss: 3.602879809997482e38\n",
      "pde_losses: [3.6634695290708145e38, 3.4433810094211463e-7, 3.4870032303692254e-7, 3.430321211736844e-7]\n",
      "bcs_losses: [2.43316489664911e-6, 2.7816609899028357e-6, 2.965803876490508e-6, 3.4923538694734347e-6, 2.922110369880753e-6, 3.18074943603937e-6, 2.4388122500544875e-6, 2.4623832677832818e-6, 2.4303283022605997e-6, 1.0001631564480695, 2.066369458582634e-6, 0.9998599604258833]\n",
      "loss: 3.613437277626221e38\n",
      "pde_losses: [3.6714625600978804e38, 3.3960579619605187e-7, 3.4514553292900147e-7, 3.455885703068692e-7]\n",
      "bcs_losses: [2.3991453885366385e-6, 2.7431980929144573e-6, 2.942401842075938e-6, 3.4371598824402562e-6, 2.898530803958988e-6, 3.1828201083170397e-6, 2.4074239569779606e-6, 2.3812914545418843e-6, 2.40503557539911e-6, 1.0001927522353107, 2.1160923830541736e-6, 0.9998303504807591]\n",
      "loss: 3.651947395282452e38\n",
      "pde_losses: [3.673700893352228e38, 3.486908778256297e-7, 3.3382605086842607e-7, 3.391738967269996e-7]\n",
      "bcs_losses: [2.438823642062783e-6, 2.793862284947893e-6, 2.9091028598314367e-6, 3.4494931592603585e-6, 2.8760238754150656e-6, 3.1482544451561834e-6, 2.4072719539802607e-6, 2.4002165972301917e-6, 2.4297806738514486e-6, 1.0001793054279347, 2.0741095849665982e-6, 0.9998436604409994]\n",
      "loss: 3.723866558493721e38\n",
      "pde_losses: [3.645776872715861e38, 3.432895687338974e-7, 3.380377167793413e-7, 3.409634021369956e-7]\n",
      "bcs_losses: [2.4591195830923345e-6, 2.764583734207337e-6, 2.8460170670149414e-6, 3.485312062198642e-6, 2.8867545028605215e-6, 3.2193280508941108e-6, 2.4554833116909288e-6, 2.4469489914766824e-6, 2.4868057099590276e-6, 1.0001453048598354, 2.0261289322260116e-6, 0.9998775957589757]\n",
      "loss: 3.63223151447511e38\n",
      "pde_losses: [3.6315853631450855e38, 3.442601752384168e-7, 3.419831622878106e-7, 3.440973516743543e-7]\n",
      "bcs_losses: [2.4037831491848822e-6, 2.7601815756895094e-6, 2.9444372524156786e-6, 3.4976813120710707e-6, 2.849782460417099e-6, 3.0785054719469882e-6, 2.4277122384563536e-6, 2.4109974495691492e-6, 2.408761100944842e-6, 1.0002101688291782, 2.1481341830133486e-6, 0.9998129482811443]\n",
      "loss: 3.656870446559381e38\n",
      "pde_losses: [3.6304773550433905e38, 3.3950563215161676e-7, 3.371891481605448e-7, 3.414228292764036e-7]\n",
      "bcs_losses: [2.384275038259306e-6, 2.7646107528540817e-6, 2.951630397030655e-6, 3.4949145550478503e-6, 2.83204410292991e-6, 3.046491788388352e-6, 2.3985571698963745e-6, 2.397536127866806e-6, 2.3693609022993257e-6, 1.0002467695685966, 2.222207128183366e-6, 0.9997765045564246]\n",
      "loss: 3.6280977921878705e38\n",
      "pde_losses: [3.638519785428122e38, 3.3535248009613145e-7, 3.3066744450516164e-7, 3.394985635271236e-7]\n",
      "bcs_losses: [2.415635130182547e-6, 2.7476551513631404e-6, 2.913436981706819e-6, 3.4926753465701736e-6, 2.884410699135437e-6, 3.1086382997089152e-6, 2.4122011854632287e-6, 2.416274685912931e-6, 2.409840954387962e-6, 1.0001548023439337, 2.0732907067990706e-6, 0.9998681685492062]\n",
      "loss: 3.6044254525484044e38\n",
      "pde_losses: [3.617247099073372e38, 3.370609749285141e-7, 3.336888172238553e-7, 3.3561513838274277e-7]\n",
      "bcs_losses: [2.4223233903737126e-6, 2.7271052978243187e-6, 2.867282971923121e-6, 3.495116713131862e-6, 2.882075588831909e-6, 3.1366820496052143e-6, 2.4250993833846833e-6, 2.4109481041322922e-6, 2.401078559857885e-6, 1.0001319691967132, 2.00523269045281e-6, 0.999890687760033]\n",
      "loss: 3.611878676854217e38\n",
      "pde_losses: [3.5440797291399344e38, 3.3219639116851393e-7, 3.406505941265895e-7, 3.3669278936606253e-7]\n",
      "bcs_losses: [2.3797144285082986e-6, 2.7254614300469413e-6, 2.9235333959073296e-6, 3.3726653412200594e-6, 2.8346009573208975e-6, 3.0838596338386217e-6, 2.3743407012390268e-6, 2.3771172380218294e-6, 2.35177005213198e-6, 1.0001898552235482, 2.071739940897384e-6, 0.9998325552401459]\n",
      "loss: 3.54118860179346e38\n",
      "pde_losses: [3.586628868209337e38, 3.3506690681721257e-7, 3.3006156705317837e-7, 3.298693972106097e-7]\n",
      "bcs_losses: [2.3507552008839057e-6, 2.701550328100293e-6, 2.9074950998588967e-6, 3.352219797713702e-6, 2.8086131003858923e-6, 3.0348827980422996e-6, 2.355561299693859e-6, 2.365131228368444e-6, 2.364126850119536e-6, 1.0002090979558669, 2.091700470077084e-6, 0.9998131230191787]\n",
      "loss: 3.594722418365405e38\n",
      "pde_losses: [3.553389124031001e38, 3.2497654201173214e-7, 3.382113822565821e-7, 3.3186261895033674e-7]\n",
      "bcs_losses: [2.382014656103115e-6, 2.6869776555666454e-6, 2.765463783682326e-6, 3.414205148174558e-6, 2.8081175422193144e-6, 3.0666182667197234e-6, 2.3876238566712054e-6, 2.411599007489857e-6, 2.3915626910178364e-6, 1.0001650657036016, 2.024725551325814e-6, 0.9998567506619148]\n",
      "loss: 3.578873678527772e38\n",
      "pde_losses: [3.518273363180897e38, 3.371097144284637e-7, 3.3099147559034054e-7, 3.3895935023657713e-7]\n",
      "bcs_losses: [2.378717809931836e-6, 2.6836985174976893e-6, 2.8290142507942426e-6, 3.410721475717484e-6, 2.797120713093505e-6, 3.087943758986946e-6, 2.3913625141474835e-6, 2.36069056221376e-6, 2.3875391553820426e-6, 1.0001741236240353, 2.0554892480354102e-6, 0.9998473143075195]\n",
      "loss: 3.562043232230439e38\n",
      "pde_losses: [3.556923176252474e38, 3.317451462446585e-7, 3.2740490654378376e-7, 3.2565262395311926e-7]\n",
      "bcs_losses: [2.3559256977826806e-6, 2.7113809449119804e-6, 2.910233074488617e-6, 3.4212530327245546e-6, 2.8024261910574266e-6, 2.9933165504526424e-6, 2.353117421941643e-6, 2.343488871136738e-6, 2.366911974692443e-6, 1.000232875562062, 2.1696483459896876e-6, 0.999788342229327]\n",
      "loss: 3.5319037271478786e38\n",
      "pde_losses: [3.521402471409769e38, 3.3728137725580377e-7, 3.3000553745683e-7, 3.32557151055262e-7]\n",
      "bcs_losses: [2.3429510278464724e-6, 2.6875930516458755e-6, 2.935726229871634e-6, 3.4219584915634293e-6, 2.7996622838169143e-6, 2.962115879700548e-6, 2.358621096397537e-6, 2.352147610615719e-6, 2.3350507523027253e-6, 1.0001894106916658, 2.119314408759674e-6, 0.9998314527538483]\n",
      "loss: 3.5076983578101284e38\n",
      "pde_losses: [3.500365655879124e38, 3.309733760513883e-7, 3.2873903488928047e-7, 3.2236631703262784e-7]\n",
      "bcs_losses: [2.3895130669761194e-6, 2.6721939705280975e-6, 2.83018280576383e-6, 3.476664426142119e-6, 2.8214240323300876e-6, 3.07937268884722e-6, 2.3605836531185022e-6, 2.365922257580537e-6, 2.3653657604120177e-6, 1.0001095398683346, 1.9815777279114612e-6, 0.9999107707188948]\n",
      "loss: 3.50628567527204e38\n",
      "pde_losses: [3.533790036016556e38, 3.270407724378181e-7, 3.232759918788877e-7, 3.271041621393206e-7]\n",
      "bcs_losses: [2.3515841494633995e-6, 2.6617989796739836e-6, 2.8348427793789344e-6, 3.3985399627548775e-6, 2.7633214584767457e-6, 2.9744435297330482e-6, 2.330562650580187e-6, 2.352795760912349e-6, 2.341579758031051e-6, 1.0001614394907765, 2.032151693664282e-6, 0.9998586845314744]\n",
      "loss: 3.4817856760371034e38\n",
      "pde_losses: [3.490992153977611e38, 3.3157606090340533e-7, 3.253038993191177e-7, 3.260738636398717e-7]\n",
      "bcs_losses: [2.289942185722483e-6, 2.629123558936322e-6, 2.875696345906244e-6, 3.2621526398366065e-6, 2.788215065124424e-6, 2.9277817214407055e-6, 2.2963131348068822e-6, 2.304314821875601e-6, 2.329002572327269e-6, 1.0002123796919684, 2.114909291130216e-6, 0.9998077209557747]\n",
      "loss: 3.466549691295289e38\n",
      "pde_losses: [3.477758938766269e38, 3.2559225966602453e-7, 3.2503810824672304e-7, 3.325733969694676e-7]\n",
      "bcs_losses: [2.3108206775539717e-6, 2.6095077746692486e-6, 2.784410952863416e-6, 3.3139115370697934e-6, 2.7490973453030824e-6, 2.9026817700175174e-6, 2.307646617560968e-6, 2.3079961486133876e-6, 2.3192679557938108e-6, 1.0001905686472117, 2.093458752317678e-6, 0.99982954463006]\n",
      "loss: 3.495782674596148e38\n",
      "pde_losses: [3.507597025477225e38, 3.2877386852907107e-7, 3.3122260768851513e-7, 3.2484372053262907e-7]\n",
      "bcs_losses: [2.3189235530156067e-6, 2.580055841742699e-6, 2.7792397663521028e-6, 3.3493621592349984e-6, 2.7322207984955652e-6, 2.92461680677053e-6, 2.3409321485793037e-6, 2.3256478852815095e-6, 2.342092412686973e-6, 1.0001796315198503, 2.084141549958652e-6, 0.9998405072510904]\n",
      "loss: 3.452682105464213e38\n",
      "pde_losses: [3.460239601035696e38, 3.1969407902193646e-7, 3.2428095015129887e-7, 3.2534905516822736e-7]\n",
      "bcs_losses: [2.3336844439730755e-6, 2.610009555121922e-6, 2.7593849377579375e-6, 3.3744814547734604e-6, 2.7539203663028346e-6, 2.95371302540129e-6, 2.3351983771792483e-6, 2.3505204290387603e-6, 2.3347917023458366e-6, 1.0001576628684057, 2.0564888606183954e-6, 0.9998624862602992]\n",
      "loss: 3.4315453035963375e38\n",
      "pde_losses: [3.47148761998311e38, 3.203215976900614e-7, 3.147039627242351e-7, 3.247521967091226e-7]\n",
      "bcs_losses: [2.313965305181255e-6, 2.631218015265776e-6, 2.808576914310546e-6, 3.3395141694495738e-6, 2.7147697423621023e-6, 2.860224786408786e-6, 2.3154950145318944e-6, 2.3214694770332095e-6, 2.3262910514710582e-6, 1.0002138043280508, 2.0958428242413453e-6, 0.9998062706278541]\n",
      "loss: 3.423600183504855e38\n",
      "pde_losses: [3.399052689362133e38, 3.205687959479018e-7, 3.239539792999891e-7, 3.1977723876314567e-7]\n",
      "bcs_losses: [2.311294613252493e-6, 2.649361368673093e-6, 2.831476113276623e-6, 3.3028264802925435e-6, 2.72741752809385e-6, 2.895839439817397e-6, 2.2985478382483524e-6, 2.2973743680224332e-6, 2.3099164512903156e-6, 1.0002288435829187, 2.0796462548126343e-6, 0.9997910780686782]\n",
      "loss: 3.441634566885421e38\n",
      "pde_losses: [3.466566876214044e38, 3.2245515096706395e-7, 3.2019611041823527e-7, 3.196447175110649e-7]\n",
      "bcs_losses: [2.2802862016407023e-6, 2.5608193197367183e-6, 2.7621036035759077e-6, 3.327712915990793e-6, 2.73730332957492e-6, 2.955700151432969e-6, 2.2684362136100633e-6, 2.289461627736058e-6, 2.2841599531381388e-6, 1.0001701452623657, 2.001758192357952e-6, 0.9998495067503994]\n",
      "loss: 3.403309116087888e38\n",
      "pde_losses: [3.3996224036109522e38, 3.250679774846125e-7, 3.1268818184604975e-7, 3.182446940757767e-7]\n",
      "bcs_losses: [2.257560620702059e-6, 2.558886416822486e-6, 2.767263530593961e-6, 3.2845404000931402e-6, 2.7278697986773846e-6, 2.9391576187524714e-6, 2.256249205144904e-6, 2.2565972215735003e-6, 2.266930274824418e-6, 1.0001786173264753, 2.0261649974548797e-6, 0.9998409196829028]\n",
      "loss: 3.3780915608223045e38\n",
      "pde_losses: [3.388927107961746e38, 3.1311796155461256e-7, 3.1949849382558216e-7, 3.138276787162918e-7]\n",
      "bcs_losses: [2.2390760966959214e-6, 2.565685159122454e-6, 2.782005021727603e-6, 3.2475854982315023e-6, 2.6933075699115793e-6, 2.855409558878678e-6, 2.2597568031555937e-6, 2.246820446721562e-6, 2.241915908808401e-6, 1.0002411706319858, 2.0700551279990206e-6, 0.9997783550638581]\n",
      "loss: 3.3749093556045935e38\n",
      "pde_losses: [3.351762590037842e38, 3.187341965571959e-7, 3.1603679208865806e-7, 3.1708362530229854e-7]\n",
      "bcs_losses: [2.25086451406492e-6, 2.5546198828796657e-6, 2.740673497997646e-6, 3.190529315990703e-6, 2.651000628452006e-6, 2.854758772228002e-6, 2.2616392997768656e-6, 2.251358736565663e-6, 2.25264523654558e-6, 1.0002503006986228, 2.035177243316328e-6, 0.9997691110737307]\n",
      "loss: 3.3973862991074404e38\n",
      "pde_losses: [3.3843305467484496e38, 3.157873168516866e-7, 3.1558372036043477e-7, 3.1849013890162667e-7]\n",
      "bcs_losses: [2.290683334950613e-6, 2.5581081511670295e-6, 2.7446906822712784e-6, 3.2294108532280507e-6, 2.642348700952591e-6, 2.8741487357931392e-6, 2.2892279340522695e-6, 2.300257336872079e-6, 2.303417466079556e-6, 1.0001795494461705, 1.974002046222636e-6, 0.9998397081645611]\n",
      "loss: 3.3550758999930596e38\n",
      "pde_losses: [3.3744008217589046e38, 3.173820956668117e-7, 3.110050272175526e-7, 3.1415636680829697e-7]\n",
      "bcs_losses: [2.24710764760076e-6, 2.5415622720432113e-6, 2.7544117427282763e-6, 3.2733703945649013e-6, 2.6782234495467435e-6, 2.8574948120530492e-6, 2.246461179050943e-6, 2.2501900522727463e-6, 2.2411469902066583e-6, 1.0001564797454847, 2.015127316210841e-6, 0.9998628111627441]\n",
      "loss: 3.3716684342882626e38\n",
      "pde_losses: [3.382824226797496e38, 3.107577717450276e-7, 3.09939389916922e-7, 3.181641481436335e-7]\n",
      "bcs_losses: [2.2338003693512574e-6, 2.5143528805930435e-6, 2.7815734023339254e-6, 3.270008466771624e-6, 2.676968228585596e-6, 2.8289537389054435e-6, 2.2466788299869774e-6, 2.2479707491742444e-6, 2.2257679269147734e-6, 1.0001812338865133, 2.0849608565814642e-6, 0.9998381330431656]\n",
      "loss: 3.3225873197591592e38\n",
      "pde_losses: [3.314293004331955e38, 3.101249102406921e-7, 3.119652188471946e-7, 3.1701889467196873e-7]\n",
      "bcs_losses: [2.2364242009043754e-6, 2.5579874481138583e-6, 2.679376149450957e-6, 3.2243842440368756e-6, 2.604668540619202e-6, 2.824961646843195e-6, 2.2246511283456905e-6, 2.2308729619164542e-6, 2.226693963783866e-6, 1.0002114856318047, 2.072087105530967e-6, 0.9998077903550969]\n",
      "loss: 3.3685266673810188e38\n",
      "pde_losses: [3.317691928424547e38, 3.054142976060157e-7, 3.0933551612777024e-7, 3.064385217855343e-7]\n",
      "bcs_losses: [2.2678107789837687e-6, 2.5349753837519146e-6, 2.65500775095641e-6, 3.233993264445125e-6, 2.60915412989666e-6, 2.830129519450839e-6, 2.243362410672144e-6, 2.2564658371721645e-6, 2.2545392294081243e-6, 1.0002256486142405, 2.0537640173393904e-6, 0.9997935342940407]\n",
      "loss: 3.3060275849973295e38\n",
      "pde_losses: [3.313461656320954e38, 3.1242510201429195e-7, 3.128786420785866e-7, 3.1244668397400065e-7]\n",
      "bcs_losses: [2.218365993333036e-6, 2.513189301239845e-6, 2.6790402438976293e-6, 3.188835676154084e-6, 2.6157433988964305e-6, 2.8267844022635443e-6, 2.2150409622048813e-6, 2.245890631449349e-6, 2.218031227388833e-6, 1.0002175029036355, 2.047989823776988e-6, 0.9998015622308069]\n",
      "loss: 3.357887246901802e38\n",
      "pde_losses: [3.2926855190814e38, 3.1618034432096884e-7, 3.0738157771388815e-7, 3.150789445549644e-7]\n",
      "bcs_losses: [2.1894908159587814e-6, 2.4999845310263784e-6, 2.706311425465096e-6, 3.217109810400465e-6, 2.6116942572016245e-6, 2.8122854055841813e-6, 2.189741435460277e-6, 2.1919300143197227e-6, 2.215390075814816e-6, 1.0002164456088949, 2.060377632552572e-6, 0.9998024054922288]\n",
      "loss: 3.2789814888723344e38\n",
      "pde_losses: [3.318382247637941e38, 3.068641581665263e-7, 3.0775474529939877e-7, 3.076319328703394e-7]\n",
      "bcs_losses: [2.202202772799047e-6, 2.460953784759736e-6, 2.738077166126101e-6, 3.2294299815216268e-6, 2.6333545529601664e-6, 2.8317470808873907e-6, 2.1948449865170205e-6, 2.1962222152314323e-6, 2.200072143981495e-6, 1.0001862324593287, 1.985841644436416e-6, 0.9998322837861633]\n",
      "loss: 3.304472270433539e38\n",
      "pde_losses: [3.297517739380757e38, 3.0745867583666583e-7, 3.0447177705381435e-7, 3.0856634743492114e-7]\n",
      "bcs_losses: [2.2373837579025325e-6, 2.504751367132274e-6, 2.669438471106117e-6, 3.1836970143807215e-6, 2.5981021280809533e-6, 2.850327691129816e-6, 2.222624496699121e-6, 2.233521186197523e-6, 2.233589336332942e-6, 1.0001829141547078, 1.9395289122511564e-6, 0.9998353103406485]\n",
      "loss: 3.2758072274426407e38\n",
      "pde_losses: [3.276748797421617e38, 3.0727777443606946e-7, 3.115627501984786e-7, 3.082681789096729e-7]\n",
      "bcs_losses: [2.207768919945292e-6, 2.4893586595320484e-6, 2.661155606794556e-6, 3.1684866152056665e-6, 2.5424267277890684e-6, 2.7970299972108086e-6, 2.193602484851261e-6, 2.2192430575695167e-6, 2.1930030420295604e-6, 1.0002693657877817, 2.0422278375380398e-6, 0.9997487668248366]\n",
      "loss: 3.2955814535255347e38\n",
      "pde_losses: [3.2909756289998354e38, 3.0827489518005667e-7, 3.086594762142252e-7, 3.049987515882191e-7]\n",
      "bcs_losses: [2.1784108988549228e-6, 2.4898566806289843e-6, 2.697154031166227e-6, 3.126733030706201e-6, 2.540150369850645e-6, 2.7144625724363297e-6, 2.1706602680461312e-6, 2.1767165808264355e-6, 2.177184604504888e-6, 1.000296578107728, 2.1134495721060466e-6, 0.9997213762052788]\n",
      "loss: 3.2478160104877827e38\n",
      "pde_losses: [3.2220015840376968e38, 3.076965578497974e-7, 3.0848161093811523e-7, 3.0148627866584654e-7]\n",
      "bcs_losses: [2.165283026878887e-6, 2.442314694947018e-6, 2.6327886342640723e-6, 3.1749973355484914e-6, 2.595269389665769e-6, 2.779225506557575e-6, 2.1854588113200555e-6, 2.1713402827853635e-6, 2.174082436456846e-6, 1.0001924099311197, 1.9983602657557062e-6, 0.9998250920891847]\n",
      "loss: 3.2899071734727932e38\n",
      "pde_losses: [3.201274665863783e38, 3.0789502663570554e-7, 3.0510525205361014e-7, 3.063377153511123e-7]\n",
      "bcs_losses: [2.198568075411438e-6, 2.4440615825273807e-6, 2.6612366733776026e-6, 3.1912415049706746e-6, 2.5957953374964436e-6, 2.799323466700966e-6, 2.179809297252676e-6, 2.1695071538981795e-6, 2.1719658082918873e-6, 1.0001544789009396, 1.951897849168189e-6, 0.9998627010157934]\n",
      "loss: 3.24024083264531e38\n",
      "pde_losses: [3.1822939228339858e38, 3.040692668482426e-7, 2.999169716257977e-7, 3.0404353889694107e-7]\n",
      "bcs_losses: [2.139361380370412e-6, 2.4719320004826233e-6, 2.6602447991113517e-6, 3.09447495670194e-6, 2.523512158737955e-6, 2.712430274668603e-6, 2.146751773003701e-6, 2.136475380012472e-6, 2.1307097285197457e-6, 1.0002467438162832, 2.0573954913568328e-6, 0.9997702523250862]\n",
      "loss: 3.2246070677884568e38\n",
      "pde_losses: [3.1812750394004645e38, 2.956833454775024e-7, 3.075651010122233e-7, 2.9750345049626636e-7]\n",
      "bcs_losses: [2.1431234392063744e-6, 2.4570926412359076e-6, 2.676886257644246e-6, 3.113484389258385e-6, 2.52303756979882e-6, 2.7119850692197614e-6, 2.1368282449277535e-6, 2.136760654595876e-6, 2.1128653866229463e-6, 1.0002598535404403, 2.0591534223394124e-6, 0.9997569215663692]\n",
      "loss: 3.224956108131188e38\n",
      "pde_losses: [3.2450112663547526e38, 3.0216471486973655e-7, 3.0569559992970174e-7, 2.9847174346668526e-7]\n",
      "bcs_losses: [2.1503007683847145e-6, 2.442462460460315e-6, 2.596281599892149e-6, 3.131600784963716e-6, 2.5560251266646744e-6, 2.7773835877261183e-6, 2.1654790383250767e-6, 2.1672735319071107e-6, 2.180427489831565e-6, 1.0001901047714614, 1.9513412701369545e-6, 0.9998264641850663]\n",
      "loss: 3.204359032018419e38\n",
      "pde_losses: [3.1936175434140584e38, 2.950725240693808e-7, 2.946623582513286e-7, 3.0062527359159356e-7]\n",
      "bcs_losses: [2.1405975775932507e-6, 2.4331778740345817e-6, 2.58742032229706e-6, 3.1176233191772874e-6, 2.531818709037552e-6, 2.7593720843386384e-6, 2.1334177986748326e-6, 2.155249003902495e-6, 2.148777508344198e-6, 1.000207561177758, 2.0080763029082617e-6, 0.9998090149707124]\n",
      "loss: 3.1777174161145315e38\n",
      "pde_losses: [3.1912737446559923e38, 2.9943989545884604e-7, 3.0378636037161286e-7, 2.98746689340548e-7]\n",
      "bcs_losses: [2.142738425272794e-6, 2.421602416876114e-6, 2.6131165134330732e-6, 3.139566570377825e-6, 2.5093556065571738e-6, 2.6908342860031016e-6, 2.133236410112757e-6, 2.139334190875486e-6, 2.119214563021545e-6, 1.0002348262262153, 2.0728248486914087e-6, 0.9997817437358021]\n",
      "loss: 3.120019381481205e38\n",
      "pde_losses: [3.1934618452346744e38, 3.0167696108198916e-7, 3.009048079702702e-7, 3.002339676705263e-7]\n",
      "bcs_losses: [2.13815953925196e-6, 2.4310025896290847e-6, 2.6087623769527535e-6, 3.10801192410422e-6, 2.529494756213958e-6, 2.7000963320325752e-6, 2.1291672241760198e-6, 2.149336767916938e-6, 2.1408334027226095e-6, 1.0001841386035257, 2.031559877191178e-6, 0.9998323411175962]\n",
      "loss: 3.1504826880545878e38\n",
      "pde_losses: [3.154338826928307e38, 2.9744881174591186e-7, 2.969602531895376e-7, 3.007023807725328e-7]\n",
      "bcs_losses: [2.148449103979816e-6, 2.378228552232995e-6, 2.5731430292593116e-6, 3.0802551230306333e-6, 2.495026893364352e-6, 2.688843665583471e-6, 2.1381810741290233e-6, 2.1355852447755406e-6, 2.120205585640974e-6, 1.0001782897069997, 2.0033157029204274e-6, 0.9998380955168912]\n",
      "loss: 3.1413863145716316e38\n",
      "pde_losses: [3.1442139337899825e38, 2.958124133221009e-7, 3.011155689079364e-7, 2.9573974459296335e-7]\n",
      "bcs_losses: [2.1097178890580835e-6, 2.4024508080057697e-6, 2.596254103343332e-6, 3.055931643333562e-6, 2.49400780939966e-6, 2.656006004786245e-6, 2.1445152895342527e-6, 2.1300534500375063e-6, 2.1254115046340374e-6, 1.0002207490562347, 2.006471437264434e-6, 0.9997955164681663]\n",
      "loss: 3.118489351140267e38\n",
      "pde_losses: [3.1708593813978763e38, 2.9553280898562783e-7, 2.9258249332502685e-7, 2.9986119498481924e-7]\n",
      "bcs_losses: [2.118786607853975e-6, 2.3868427091574676e-6, 2.59060129575105e-6, 3.0229634492931737e-6, 2.4693320823129697e-6, 2.69567043942784e-6, 2.1142991871576497e-6, 2.112166447354576e-6, 2.1100886076316107e-6, 1.0002360739381473, 1.9653735745752996e-6, 0.9997800123421587]\n",
      "loss: 3.1588960873907173e38\n",
      "pde_losses: [3.1819840525661217e38, 2.977929229747153e-7, 2.938597258878886e-7, 2.942939894968858e-7]\n",
      "bcs_losses: [2.106086105965759e-6, 2.363173693834934e-6, 2.557531772787932e-6, 3.0282571753935417e-6, 2.5089891193326612e-6, 2.6799230761507518e-6, 2.0976601068202804e-6, 2.083005612135e-6, 2.1216204278431898e-6, 1.000223653793894, 1.926606536171698e-6, 0.9997923097130508]\n",
      "loss: 3.1124130613625514e38\n",
      "pde_losses: [3.070854759823474e38, 2.9657710929777424e-7, 2.956787733435082e-7, 2.9770168393271376e-7]\n",
      "bcs_losses: [2.0909017187137894e-6, 2.346941585405925e-6, 2.5599922255648474e-6, 3.0501112561318114e-6, 2.4749948103638392e-6, 2.709227944826159e-6, 2.0917148100331537e-6, 2.0992117850386857e-6, 2.105232110784932e-6, 1.0002388864957898, 1.944495432570635e-6, 0.9997770325161881]\n",
      "loss: 3.132912171683624e38\n",
      "pde_losses: [3.136387101620622e38, 2.95913712107224e-7, 2.901158405179853e-7, 2.8757400697757613e-7]\n",
      "bcs_losses: [2.0624083812076757e-6, 2.3453661398711515e-6, 2.571632485262519e-6, 3.0405066488383122e-6, 2.462226170628555e-6, 2.628130531850824e-6, 2.0934525995334538e-6, 2.0940920983224755e-6, 2.0881602481282717e-6, 1.0002919046703398, 2.023077511046639e-6, 0.9997240184827254]\n",
      "loss: 3.1233778173873497e38\n",
      "pde_losses: [3.137905226448996e38, 2.9539008987462685e-7, 2.91451168857872e-7, 2.91864769570131e-7]\n",
      "bcs_losses: [2.0715491982326456e-6, 2.357703638257229e-6, 2.5624684342568573e-6, 3.0126370656390896e-6, 2.4284451002042777e-6, 2.631935457401633e-6, 2.0737017767026602e-6, 2.059238492283366e-6, 2.080330142621428e-6, 1.0002726199163656, 2.041329733688469e-6, 0.9997432246791197]\n",
      "loss: 3.1302938689701217e38\n",
      "pde_losses: [3.109100268990612e38, 2.929208647689067e-7, 2.9500845640127e-7, 2.846573145820108e-7]\n",
      "bcs_losses: [2.0977210435304117e-6, 2.3430256054652103e-6, 2.527571589019675e-6, 3.082789412416192e-6, 2.4516870107079546e-6, 2.658117904883655e-6, 2.1052973218187627e-6, 2.0949080106847165e-6, 2.088800291529661e-6, 1.000194478126386, 1.9760876369335337e-6, 0.9998210681889679]\n",
      "loss: 3.1234214606983785e38\n",
      "pde_losses: [3.055333717833308e38, 2.884586522268393e-7, 2.903218364453359e-7, 2.8644436230772946e-7]\n",
      "bcs_losses: [2.119730943588319e-6, 2.3407721373043056e-6, 2.4955412106725787e-6, 3.0489496363602505e-6, 2.463003700722504e-6, 2.6066939773405856e-6, 2.0964894634772325e-6, 2.093138360359088e-6, 2.085090161968325e-6, 1.0001862423540753, 1.9935113110104563e-6, 0.9998291905168678]\n",
      "loss: 3.093862488053105e38\n",
      "pde_losses: [3.1347930171100894e38, 2.8902112318197844e-7, 2.9177985463071734e-7, 2.873968219219541e-7]\n",
      "bcs_losses: [2.061059366608732e-6, 2.316414147836525e-6, 2.554750364538928e-6, 3.00498571581274e-6, 2.42810298522736e-6, 2.572010155694997e-6, 2.0442997726154546e-6, 2.0589407232672913e-6, 2.062192008211869e-6, 1.0002417452367736, 2.0569199085610335e-6, 0.9997736094660798]\n",
      "loss: 3.0891450221071227e38\n",
      "pde_losses: [3.115761214850197e38, 2.9373927161403037e-7, 2.902778514982191e-7, 2.885948134881181e-7]\n",
      "bcs_losses: [2.0617836233167894e-6, 2.331653837478503e-6, 2.532638045402121e-6, 2.968253935632129e-6, 2.383093222830041e-6, 2.576621137225786e-6, 2.0627520050328414e-6, 2.0788599904281087e-6, 2.0718193111464703e-6, 1.0002528110162214, 2.026415864502293e-6, 0.9997624610746916]\n",
      "loss: 3.072856355612437e38\n",
      "pde_losses: [3.1004447101579093e38, 2.8662819397400904e-7, 2.844705660115975e-7, 2.9263647117061506e-7]\n",
      "bcs_losses: [2.0908387267847697e-6, 2.2905441988861573e-6, 2.448916447798872e-6, 2.937725309821923e-6, 2.411304998951911e-6, 2.6436181477792375e-6, 2.077935273071539e-6, 2.0811824951330754e-6, 2.080742309986043e-6, 1.0002313860399052, 1.944439796802858e-6, 0.9997837819732694]\n",
      "loss: 3.06106967352867e38\n",
      "pde_losses: [3.051014733936076e38, 2.9019972122264445e-7, 2.829237609171586e-7, 2.857379301249394e-7]\n",
      "bcs_losses: [2.0594399079848136e-6, 2.2654929094543207e-6, 2.4697305569939353e-6, 2.9583835236008724e-6, 2.4350368225016984e-6, 2.600622862980641e-6, 2.033299250274228e-6, 2.0535888241196284e-6, 2.04139888887215e-6, 1.0002419719482525, 1.972875215892437e-6, 0.9997731238145938]\n",
      "loss: 3.076469534295424e38\n",
      "pde_losses: [3.0629513978292665e38, 2.890880977390636e-7, 2.803597820728797e-7, 2.840861921860903e-7]\n",
      "bcs_losses: [2.043036430183001e-6, 2.2533995032996814e-6, 2.493919133195163e-6, 2.9899156380755076e-6, 2.4139277223233975e-6, 2.555980017889143e-6, 2.034602829833665e-6, 2.0377593103011446e-6, 2.055394229630132e-6, 1.0002269960342185, 1.9941113458522186e-6, 0.9997879990323127]\n",
      "loss: 3.0676110037794997e38\n",
      "pde_losses: [3.03715505048648e38, 2.817588068597474e-7, 2.822418798315839e-7, 2.898386855423393e-7]\n",
      "bcs_losses: [2.0536978255710387e-6, 2.2634620168012947e-6, 2.468614520026835e-6, 2.978437918423964e-6, 2.394944291313775e-6, 2.576404147470583e-6, 2.03994848825079e-6, 2.041580182036428e-6, 2.051751110921251e-6, 1.0002159401165147, 1.970049834091806e-6, 0.9997989160258527]\n",
      "loss: 3.0512404415988607e38\n",
      "pde_losses: [2.997044230372898e38, 2.836747233496206e-7, 2.8083881511962097e-7, 2.841371502580608e-7]\n",
      "bcs_losses: [2.053669973303977e-6, 2.308893863207865e-6, 2.5026489564278957e-6, 2.9771032185409807e-6, 2.3798044317170885e-6, 2.5861160748171845e-6, 2.0263712379174836e-6, 2.0414600059856917e-6, 2.027277381772886e-6, 1.0002236044750439, 1.965476914767185e-6, 0.9997910652162657]\n",
      "loss: 3.010643859965078e38\n",
      "pde_losses: [3.0258089548356685e38, 2.7930038676741507e-7, 2.8235764996939463e-7, 2.8433499731343546e-7]\n",
      "bcs_losses: [2.0151206874617153e-6, 2.288313759489924e-6, 2.487789825584994e-6, 2.94005157285127e-6, 2.353853894917825e-6, 2.575962421298699e-6, 2.0251201018926273e-6, 2.0173755270964015e-6, 2.0299836349640266e-6, 1.0002345570809885, 1.9639455400544252e-6, 0.9997797396653894]\n",
      "loss: 3.0471374754242048e38\n",
      "pde_losses: [2.9938690274364263e38, 2.766893171872569e-7, 2.896909334770211e-7, 2.83800744862786e-7]\n",
      "bcs_losses: [2.024028713888738e-6, 2.251758402638424e-6, 2.487858789532166e-6, 2.928858314291321e-6, 2.382651379584563e-6, 2.53536780648946e-6, 2.014316325950876e-6, 2.0230047072061714e-6, 2.013199836719021e-6, 1.0002550480790342, 1.9716671779685936e-6, 0.9997588369528586]\n",
      "loss: 3.0055394739625302e38\n",
      "pde_losses: [2.972020425747967e38, 2.8083628768857166e-7, 2.830070550089854e-7, 2.7739941776043985e-7]\n",
      "bcs_losses: [2.0203135646711678e-6, 2.228808712862282e-6, 2.465139218144597e-6, 2.876444165559843e-6, 2.3419831154005166e-6, 2.5828180869752206e-6, 2.0266143797332205e-6, 2.019471301455392e-6, 2.0295687332014837e-6, 1.0002535875804512, 1.9429547943402366e-6, 0.9997599468604662]\n",
      "loss: 3.0209054257219236e38\n",
      "pde_losses: [2.9796219726219266e38, 2.795736045698918e-7, 2.7993146855653185e-7, 2.803123627829522e-7]\n",
      "bcs_losses: [2.0257603712736205e-6, 2.244985673353014e-6, 2.3969644489286512e-6, 2.870208338526898e-6, 2.36542198460703e-6, 2.530113878731897e-6, 2.0257025838990235e-6, 2.0286243726468056e-6, 2.0198938397704566e-6, 1.0002834552574758, 1.953509895765973e-6, 0.9997298014714053]\n",
      "loss: 2.9809876320986925e38\n",
      "pde_losses: [3.013600766113722e38, 2.8372927415949257e-7, 2.833110488316767e-7, 2.796932258834437e-7]\n",
      "bcs_losses: [2.040545825693021e-6, 2.240943556276216e-6, 2.440410664761335e-6, 2.8699305985324094e-6, 2.319069922398266e-6, 2.5375666749920523e-6, 2.0191180505210666e-6, 2.0077243689699067e-6, 2.013071089143346e-6, 1.00028033386138, 1.9317473807815903e-6, 0.9997326317925077]\n",
      "loss: 2.966627221255609e38\n",
      "pde_losses: [2.9634679216671862e38, 2.8046737685332326e-7, 2.7772557660295736e-7, 2.7481541947336047e-7]\n",
      "bcs_losses: [2.0037357629672272e-6, 2.229433868106067e-6, 2.4402303693259657e-6, 2.869698272588657e-6, 2.3354825642306943e-6, 2.5212023515081302e-6, 1.998687419448162e-6, 2.0126179706301355e-6, 2.0038607558045738e-6, 1.0002615423685128, 1.928407390122374e-6, 0.9997511923826619]\n",
      "loss: 2.9419865761628006e38\n",
      "pde_losses: [2.9745958498311645e38, 2.76341312742045e-7, 2.765642067425328e-7, 2.794818137926184e-7]\n",
      "bcs_losses: [1.98958382865505e-6, 2.2240080903893617e-6, 2.398082688434791e-6, 2.887446162901715e-6, 2.3091758456144836e-6, 2.5022419846454656e-6, 2.0092008247823092e-6, 1.9888764973771087e-6, 1.9911864234199904e-6, 1.0002590024239022, 1.9508624376476078e-6, 0.9997536070299156]\n",
      "loss: 2.9492950701899593e38\n",
      "pde_losses: [2.976483782879696e38, 2.774766035153104e-7, 2.758205849559396e-7, 2.7807344263951675e-7]\n",
      "bcs_losses: [1.9779009143372774e-6, 2.23284077130732e-6, 2.4447547028952377e-6, 2.878264269455522e-6, 2.313024107094627e-6, 2.4659434617621496e-6, 1.974497794403085e-6, 1.9783733137379597e-6, 1.9780740147972466e-6, 1.0002612051869753, 1.985423259310532e-6, 0.999751386796935]\n",
      "loss: 2.9009398026105143e38\n",
      "pde_losses: [2.9473767530568452e38, 2.7626123889380246e-7, 2.765268194148295e-7, 2.7728365806072664e-7]\n",
      "bcs_losses: [1.9557814833474697e-6, 2.1928868068695496e-6, 2.413810831290511e-6, 2.860649196112639e-6, 2.2936687315012e-6, 2.489314648647384e-6, 1.956797624820475e-6, 1.968791340245715e-6, 1.961655440880902e-6, 1.0002535966152495, 1.9833371186684525e-6, 0.9997589472836056]\n",
      "loss: 2.9509818166891564e38\n",
      "pde_losses: [2.9285380872780405e38, 2.764894773912221e-7, 2.76637795465582e-7, 2.7488216806910763e-7]\n",
      "bcs_losses: [1.960508094699728e-6, 2.2039346384105076e-6, 2.4000830763493733e-6, 2.8285508380915732e-6, 2.3038531330824415e-6, 2.46009551046976e-6, 1.9639309806334715e-6, 1.956672773362001e-6, 1.9514706649241923e-6, 1.000250367018431, 1.9748008734462705e-6, 0.9997621477921415]\n",
      "loss: 2.9161565574057812e38\n",
      "pde_losses: [2.909827339367683e38, 2.724177106324996e-7, 2.740701025551038e-7, 2.733828185822678e-7]\n",
      "bcs_losses: [1.9645143900270478e-6, 2.202644357888462e-6, 2.395144199146837e-6, 2.837028579526114e-6, 2.2877749094018806e-6, 2.4775745698536374e-6, 1.950025144898961e-6, 1.9536519742418305e-6, 1.976481824208623e-6, 1.0002223922614328, 1.92103507347729e-6, 0.9997900103983159]\n",
      "loss: 2.932418014279435e38\n",
      "pde_losses: [2.977599534703682e38, 2.704138945844721e-7, 2.772675222328443e-7, 2.7801311209016846e-7]\n",
      "bcs_losses: [1.974913146374169e-6, 2.2091559233254862e-6, 2.4088633108006486e-6, 2.8068455122383812e-6, 2.2675975016310974e-6, 2.443577331342229e-6, 1.955671413090879e-6, 1.9564093502732323e-6, 1.9675072959893795e-6, 1.0002468152277302, 1.929760903917986e-6, 0.999765615800316]\n",
      "loss: 2.8969952284649646e38\n",
      "pde_losses: [2.898049836136456e38, 2.6833642619986355e-7, 2.7821170213694255e-7, 2.703988864010472e-7]\n",
      "bcs_losses: [1.959157011868622e-6, 2.2072455186905546e-6, 2.388411346836449e-6, 2.8078727196731325e-6, 2.253008736615886e-6, 2.437424554377718e-6, 1.967575584076184e-6, 1.9734291744728076e-6, 1.957140046361883e-6, 1.0002605192011762, 1.94051370912236e-6, 0.9997519573217847]\n",
      "loss: 2.90618854364504e38\n",
      "pde_losses: [2.8936771094694215e38, 2.7407133855916647e-7, 2.7355778785118663e-7, 2.7188745211782933e-7]\n",
      "bcs_losses: [1.96358579728162e-6, 2.193132686646586e-6, 2.39422662506842e-6, 2.8342587947311855e-6, 2.2952170225415808e-6, 2.4346943586235186e-6, 1.942842453802735e-6, 1.9494918893985466e-6, 1.9328555165126325e-6, 1.000266155382446, 1.9585362661852444e-6, 0.9997462695847613]\n",
      "loss: 2.922732375778253e38\n",
      "pde_losses: [2.84869007761381e38, 2.70118002412042e-7, 2.7513137641403094e-7, 2.749766881290479e-7]\n",
      "bcs_losses: [1.9362384213968008e-6, 2.1818092402211633e-6, 2.370053593343305e-6, 2.814008821858445e-6, 2.2973780304078476e-6, 2.440638002223169e-6, 1.9442971066926756e-6, 1.949726310274645e-6, 1.941910926531901e-6, 1.0002389545390855, 1.913020613300321e-6, 0.9997733886928334]\n",
      "loss: 2.8308106723970107e38\n",
      "pde_losses: [2.8804731938740395e38, 2.6855928741046907e-7, 2.68603207348833e-7, 2.685976332361587e-7]\n",
      "bcs_losses: [1.945799908420277e-6, 2.1528883797166784e-6, 2.360709887469394e-6, 2.8165178488693053e-6, 2.293835108794849e-6, 2.433494910074659e-6, 1.929571891139536e-6, 1.912666883909789e-6, 1.9332795742234803e-6, 1.0002712123572626, 1.913157858507042e-6, 0.9997410281683301]\n",
      "loss: 2.8705467339553764e38\n",
      "pde_losses: [2.8727973093925312e38, 2.7340114881846277e-7, 2.678065094180866e-7, 2.760393537379193e-7]\n",
      "bcs_losses: [1.913011239211151e-6, 2.1407433820307292e-6, 2.379516004344803e-6, 2.7893330425732346e-6, 2.247429414534484e-6, 2.399424634752258e-6, 1.9332807334179617e-6, 1.903197139928744e-6, 1.918524070784669e-6, 1.000286720795966, 1.9175533639851836e-6, 0.9997253717383847]\n",
      "loss: 2.8654597198124216e38\n",
      "pde_losses: [2.85982293475981e38, 2.687839295590208e-7, 2.7629398251767037e-7, 2.6767654838977327e-7]\n",
      "bcs_losses: [1.9248324181653034e-6, 2.172565157920109e-6, 2.330520627122234e-6, 2.8173637950653532e-6, 2.229841144570612e-6, 2.438152036570643e-6, 1.938554059195303e-6, 1.922234702439174e-6, 1.919162991958099e-6, 1.0002629013271602, 1.874991639804152e-6, 0.9997490190130576]\n",
      "loss: 2.8742767462555805e38\n",
      "pde_losses: [2.869114718535655e38, 2.6812028569788614e-7, 2.626464627200084e-7, 2.7038553116986427e-7]\n",
      "bcs_losses: [1.915895242533359e-6, 2.17767031905657e-6, 2.343434168201051e-6, 2.7680743417514785e-6, 2.261559261326774e-6, 2.415228002560403e-6, 1.920114465488085e-6, 1.9327903439894964e-6, 1.9283272478753036e-6, 1.0002690079016618, 1.895137223707161e-6, 0.9997428981032508]\n",
      "loss: 2.8588479903661953e38\n",
      "pde_losses: [2.8675873365118028e38, 2.715881680380526e-7, 2.630089186316746e-7, 2.7028901456574357e-7]\n",
      "bcs_losses: [1.9179860848835668e-6, 2.1476296785681785e-6, 2.3556342144329462e-6, 2.725607652180154e-6, 2.2419852685851907e-6, 2.3485361755102307e-6, 1.8963177921206388e-6, 1.903091881105472e-6, 1.9086623869162107e-6, 1.0002908744978138, 1.9859999189673362e-6, 0.9997211247953462]\n",
      "loss: 2.823372688421643e38\n",
      "pde_losses: [2.8226495148209707e38, 2.6682788240808e-7, 2.658643471748284e-7, 2.650585169419726e-7]\n",
      "bcs_losses: [1.9129787284570887e-6, 2.0943120433983564e-6, 2.3376105378162703e-6, 2.7601623834451928e-6, 2.212367420407391e-6, 2.3712971287368753e-6, 1.8965558279572865e-6, 1.902017622906244e-6, 1.9140784402882218e-6, 1.0002186966728264, 1.9436690306283835e-6, 0.9997931269351399]\n",
      "loss: 2.8265756829596686e38\n",
      "pde_losses: [2.8782240418282124e38, 2.620842145956685e-7, 2.646592442429271e-7, 2.6398001005036505e-7]\n",
      "bcs_losses: [1.9342372089845673e-6, 2.105003253680476e-6, 2.308817616292973e-6, 2.736723702231207e-6, 2.2248605424139855e-6, 2.3654950980347735e-6, 1.944061188563097e-6, 1.945184423711758e-6, 1.9354777387672287e-6, 1.0002034579606822, 1.930130070965813e-6, 0.9998081323876147]\n",
      "loss: 2.8305150025453858e38\n",
      "pde_losses: [2.8154940173051735e38, 2.6679600131949906e-7, 2.6484278717564004e-7, 2.63526230274008e-7]\n",
      "bcs_losses: [1.8951383653557354e-6, 2.1348252056550573e-6, 2.353560337632632e-6, 2.7085311773829143e-6, 2.1895734843086835e-6, 2.2867216694284955e-6, 1.8954591073490687e-6, 1.9196994876943976e-6, 1.9022477682587385e-6, 1.0003020995217693, 2.038689631245603e-6, 0.9997094383545132]\n",
      "loss: 2.821569777757479e38\n",
      "pde_losses: [2.8315045754387264e38, 2.634091494741961e-7, 2.612901266232733e-7, 2.63931757646134e-7]\n",
      "bcs_losses: [1.8903529807153937e-6, 2.120571953113288e-6, 2.3576449676820786e-6, 2.7222898786657523e-6, 2.1889491349992965e-6, 2.312826787000975e-6, 1.896922024509131e-6, 1.8947501680227887e-6, 1.884746390711007e-6, 1.000274889492434, 1.9757584723633694e-6, 0.9997364071376108]\n",
      "loss: 2.803715618478024e38\n",
      "pde_losses: [2.791961594364986e38, 2.636920266984616e-7, 2.5872074780333636e-7, 2.699639264591199e-7]\n",
      "bcs_losses: [1.8876169281589937e-6, 2.0890077933065103e-6, 2.3084369680006434e-6, 2.75494824560489e-6, 2.207960864559423e-6, 2.3888278990497416e-6, 1.8933850689994963e-6, 1.9019546987908373e-6, 1.9066138039197559e-6, 1.0002110571174332, 1.8549431114928068e-6, 0.9997999105422807]\n",
      "loss: 2.8095671914015565e38\n",
      "pde_losses: [2.790900352351705e38, 2.610233703003514e-7, 2.5872213307000927e-7, 2.6132097282628487e-7]\n",
      "bcs_losses: [1.8938780729400603e-6, 2.115962207054353e-6, 2.2847255540881834e-6, 2.703722333021765e-6, 2.1886432582834732e-6, 2.3576372697421157e-6, 1.8839381282236223e-6, 1.8832472137672152e-6, 1.8823535003366408e-6, 1.0002435022797456, 1.8533306742514968e-6, 0.999767333623482]\n",
      "loss: 2.791715074839139e38\n",
      "pde_losses: [2.8082299104743167e38, 2.6092162824081714e-7, 2.5838841259956416e-7, 2.6050852064850867e-7]\n",
      "bcs_losses: [1.8724097031562234e-6, 2.0828125397797777e-6, 2.3184903415885015e-6, 2.6670747000006086e-6, 2.2019426775558088e-6, 2.3111326720828078e-6, 1.8614715055849016e-6, 1.8594087008280418e-6, 1.8565045582910093e-6, 1.000319874561041, 1.9504790194032762e-6, 0.9996910757483345]\n",
      "loss: 2.7660222038776e38\n",
      "pde_losses: [2.757532158827484e38, 2.514563678901931e-7, 2.613039373637492e-7, 2.620289882957642e-7]\n",
      "bcs_losses: [1.8617432646786177e-6, 2.0990175770135494e-6, 2.299519973017831e-6, 2.7197938905458054e-6, 2.1543245476521616e-6, 2.289041602717845e-6, 1.8613562336067151e-6, 1.8619273029495572e-6, 1.8527521772407004e-6, 1.000288209473144, 1.9322866316602812e-6, 0.9997227109587646]\n",
      "loss: 2.7538506049500193e38\n",
      "pde_losses: [2.790524012684862e38, 2.6298420072468966e-7, 2.55978883372633e-7, 2.636145168104471e-7]\n",
      "bcs_losses: [1.8942303592047655e-6, 2.078356656609493e-6, 2.245694962113224e-6, 2.712895077206005e-6, 2.1482848541996488e-6, 2.335623476493013e-6, 1.9026165619335453e-6, 1.9050128078498084e-6, 1.8947785441598043e-6, 1.000240699025469, 1.8959795498631392e-6, 0.9997700877891316]\n",
      "loss: 2.778841862340228e38\n",
      "pde_losses: [2.781778479712766e38, 2.5774193913467826e-7, 2.566520508770534e-7, 2.5463660105692005e-7]\n",
      "bcs_losses: [1.85558176485563e-6, 2.0501721723201866e-6, 2.3000117451395027e-6, 2.7142067272889074e-6, 2.18270522382112e-6, 2.3290480211615475e-6, 1.864279954953829e-6, 1.8799649293360696e-6, 1.8827472361972723e-6, 1.0002493103054144, 1.9050033367835116e-6, 0.9997614442915926]\n",
      "loss: 2.7594626165945876e38\n",
      "pde_losses: [2.7523237919401298e38, 2.5608740731214173e-7, 2.5892795493180945e-7, 2.5317440986308797e-7]\n",
      "bcs_losses: [1.8419549210354479e-6, 2.0398253615688905e-6, 2.3448429036300234e-6, 2.6884949641431406e-6, 2.1728313841385e-6, 2.2784140455344033e-6, 1.8547264818588825e-6, 1.8366075559044452e-6, 1.8368324664155103e-6, 1.0002811222954489, 1.9546590917466244e-6, 0.9997297225926094]\n",
      "loss: 2.7403469185388973e38\n",
      "pde_losses: [2.713972863401526e38, 2.553331289336998e-7, 2.595747026509947e-7, 2.5921912277496686e-7]\n",
      "bcs_losses: [1.8392046753005061e-6, 2.0571331317318146e-6, 2.2937059204598987e-6, 2.7282339625646853e-6, 2.172085759419256e-6, 2.3098171080509335e-6, 1.8526852581726572e-6, 1.8442856128387805e-6, 1.8537087910104307e-6, 1.0002627320930906, 1.896993035392967e-6, 0.9997480105968497]\n",
      "loss: 2.730068889139794e38\n",
      "pde_losses: [2.766222593655215e38, 2.564249400927487e-7, 2.5182230225115684e-7, 2.569475933820631e-7]\n",
      "bcs_losses: [1.8560910668268154e-6, 2.064130110950816e-6, 2.2348912597894433e-6, 2.681681462479601e-6, 2.1405252841511623e-6, 2.313774526757464e-6, 1.8599217640654e-6, 1.8744179557131236e-6, 1.8562388265959202e-6, 1.0002466615708276, 1.8720282173666253e-6, 0.9997640375233068]\n",
      "loss: 2.761345754746315e38\n",
      "pde_losses: [2.731371053542481e38, 2.6139998315923917e-7, 2.5234621660157025e-7, 2.563298870573955e-7]\n",
      "bcs_losses: [1.8258565988356087e-6, 2.053607645946211e-6, 2.2795470575610287e-6, 2.643070495850469e-6, 2.155691514240156e-6, 2.2517201837761054e-6, 1.8256377829268798e-6, 1.8211319333906352e-6, 1.8333395597056565e-6, 1.0002992405889128, 1.9415167501335203e-6, 0.9997114927681018]\n",
      "loss: 2.7218828345729647e38\n",
      "pde_losses: [2.6938557214373555e38, 2.579303133458462e-7, 2.545367286782756e-7, 2.534900945040545e-7]\n",
      "bcs_losses: [1.814650849054759e-6, 2.0097553537806535e-6, 2.2498084598912315e-6, 2.6559841552838525e-6, 2.1323877741347977e-6, 2.2574307475646957e-6, 1.8058538382655865e-6, 1.8194974997428475e-6, 1.816715567296022e-6, 1.0002706995154653, 1.9360249353107697e-6, 0.999740011120898]\n",
      "loss: 2.7253769357938536e38\n",
      "pde_losses: [2.723479109690149e38, 2.542780270607015e-7, 2.600218806511657e-7, 2.5694607055758376e-7]\n",
      "bcs_losses: [1.8088332097139762e-6, 2.0201214007146015e-6, 2.226152673522564e-6, 2.645327839860842e-6, 2.1447140082059747e-6, 2.287962926870643e-6, 1.8321619555888962e-6, 1.814262299620845e-6, 1.8274823025746213e-6, 1.0002413653904312, 1.8819782266481684e-6, 0.9997692380655879]\n",
      "loss: 2.7419973118653445e38\n",
      "pde_losses: [2.6922026859715825e38, 2.5623121306779706e-7, 2.5446358945525095e-7, 2.5080932810571125e-7]\n",
      "bcs_losses: [1.8181701610774778e-6, 2.0461668922677282e-6, 2.256335132233798e-6, 2.6455498411132036e-6, 2.112714068685059e-6, 2.2455461512648796e-6, 1.8279961463116392e-6, 1.8212521315532213e-6, 1.8132223172776494e-6, 1.0002582928236883, 1.9074852422873784e-6, 0.9997523666522818]\n",
      "loss: 2.6965236539798672e38\n",
      "pde_losses: [2.725873353223106e38, 2.465397992319994e-7, 2.542472136538496e-7, 2.485923387164265e-7]\n",
      "bcs_losses: [1.8362825943126084e-6, 2.0271154834443086e-6, 2.2453773437356263e-6, 2.632956459069873e-6, 2.1006211691465815e-6, 2.2235104616474954e-6, 1.8268421067075013e-6, 1.8446159770862806e-6, 1.8141161569169916e-6, 1.0002842721971326, 1.9098126658747915e-6, 0.9997264234277219]\n",
      "loss: 2.683636920066848e38\n",
      "pde_losses: [2.721598482338986e38, 2.532683720746796e-7, 2.538323301021643e-7, 2.565136805292899e-7]\n",
      "bcs_losses: [1.8546823372658311e-6, 2.0501210583698125e-6, 2.172403316871511e-6, 2.6565616721126816e-6, 2.1339809205083913e-6, 2.2717822786548516e-6, 1.851571998913077e-6, 1.8332630012947796e-6, 1.8469715161354214e-6, 1.000242888457345, 1.8414443388323388e-6, 0.9997678044313256]\n",
      "loss: 2.676086547701243e38\n",
      "pde_losses: [2.7011072241199012e38, 2.488174470812024e-7, 2.483695514934018e-7, 2.460164652829561e-7]\n",
      "bcs_losses: [1.8172069186083815e-6, 2.0146285407621627e-6, 2.207699630787371e-6, 2.6646739904575994e-6, 2.0863310123228416e-6, 2.248802263124824e-6, 1.8111906617638827e-6, 1.811221266751613e-6, 1.8080082188636664e-6, 1.000275353075094, 1.8856329436344442e-6, 0.9997354407014137]\n",
      "loss: 2.6919165283582847e38\n",
      "pde_losses: [2.7085367245530667e38, 2.5419891689067836e-7, 2.454554579847808e-7, 2.458960927028899e-7]\n",
      "bcs_losses: [1.7798521968038376e-6, 2.010445687718313e-6, 2.2079009185003705e-6, 2.6172422071696527e-6, 2.0588486664877858e-6, 2.162383654452158e-6, 1.7752562424973765e-6, 1.7902711244396439e-6, 1.7664374561166738e-6, 1.0003457479488627, 1.981396074127698e-6, 0.9996652003591582]\n",
      "loss: 2.677657484221154e38\n",
      "pde_losses: [2.6687343334394588e38, 2.508919125547454e-7, 2.549085400692742e-7, 2.500515505519261e-7]\n",
      "bcs_losses: [1.77883718023869e-6, 2.006338511321435e-6, 2.176476508548453e-6, 2.618414257254069e-6, 2.069527615205794e-6, 2.208389382680524e-6, 1.7982688614739488e-6, 1.7938827945023722e-6, 1.7977200845636362e-6, 1.0002949930689515, 1.911639604407632e-6, 0.9997157229840299]\n",
      "loss: 2.6641743668198998e38\n",
      "pde_losses: [2.6838156935182404e38, 2.4643791158827e-7, 2.4637855734192435e-7, 2.465910083162311e-7]\n",
      "bcs_losses: [1.8043951180328233e-6, 1.9751157829623e-6, 2.1383327104187153e-6, 2.6513958088284937e-6, 2.116026658219122e-6, 2.2475213895244553e-6, 1.7902716376228398e-6, 1.8125838893993698e-6, 1.7919227317487493e-6, 1.000231547947616, 1.8413628512834446e-6, 0.9997790415875034]\n",
      "loss: 2.6544413258246713e38\n",
      "pde_losses: [2.6810055191784196e38, 2.4877352388890215e-7, 2.4928390311108455e-7, 2.499944008412399e-7]\n",
      "bcs_losses: [1.7707006021094563e-6, 1.9555674919636773e-6, 2.2035612494791465e-6, 2.58983557775898e-6, 2.0911953718386484e-6, 2.169517273623816e-6, 1.7604592111322446e-6, 1.768944762406237e-6, 1.7825152256595316e-6, 1.0002754263777154, 1.897356702438428e-6, 0.9997351184760281]\n",
      "loss: 2.6391742915793184e38\n",
      "pde_losses: [2.646660537504918e38, 2.512264508999929e-7, 2.465876753386954e-7, 2.509272186583915e-7]\n",
      "bcs_losses: [1.7738204390801734e-6, 1.94538011457059e-6, 2.185176337211543e-6, 2.5922214841226313e-6, 2.0581198872838717e-6, 2.1696660343146503e-6, 1.7770281366288695e-6, 1.777935780506612e-6, 1.7609895762617334e-6, 1.000291666232787, 1.910659687985741e-6, 0.9997187461026196]\n",
      "loss: 2.6729859263942862e38\n",
      "pde_losses: [2.6456644294018123e38, 2.4614740868961345e-7, 2.4782611407018277e-7, 2.409729309358824e-7]\n",
      "bcs_losses: [1.7872179955863426e-6, 1.956294505391291e-6, 2.1669829240569495e-6, 2.5896515856308574e-6, 2.068275504774252e-6, 2.170791659871439e-6, 1.8092768585455005e-6, 1.798549832718666e-6, 1.8075948685096884e-6, 1.0002555692064292, 1.8538603613363503e-6, 0.9997545497218026]\n",
      "loss: 2.6319419187501937e38\n",
      "pde_losses: [2.6184547216582658e38, 2.4403664594896983e-7, 2.4671259823488813e-7, 2.4681207498935114e-7]\n",
      "bcs_losses: [1.8088408826432728e-6, 1.958571292219778e-6, 2.1663925114217116e-6, 2.6210147998509005e-6, 2.0347344884417776e-6, 2.162949817060621e-6, 1.7883667199757601e-6, 1.7887905399855313e-6, 1.808442112531605e-6, 1.0002679775717833, 1.8768643993693304e-6, 0.9997419007401145]\n",
      "loss: 2.631387035783691e38\n",
      "pde_losses: [2.6066977582999483e38, 2.4777197368073747e-7, 2.4321717499897985e-7, 2.4840865876025134e-7]\n",
      "bcs_losses: [1.78092100236742e-6, 1.94648994915117e-6, 2.2029898667764444e-6, 2.6099465964483297e-6, 2.030338053396811e-6, 2.1294197713266207e-6, 1.7634030452073279e-6, 1.7819043828146361e-6, 1.776821868179329e-6, 1.0002950386503027, 1.9414875516311584e-6, 0.9997145995142172]\n",
      "loss: 2.658014175868003e38\n",
      "pde_losses: [2.627196234933463e38, 2.495939903499112e-7, 2.48500514435315e-7, 2.468974939055605e-7]\n",
      "bcs_losses: [1.7626224633115312e-6, 1.930700795618321e-6, 2.188383210575124e-6, 2.6035475522332147e-6, 2.0571389896741214e-6, 2.1105882983588577e-6, 1.7775506218666029e-6, 1.7927121960880099e-6, 1.770548995628658e-6, 1.0002980582005585, 1.9301689900499357e-6, 0.9997112670371093]\n",
      "loss: 2.6135862509313853e38\n",
      "pde_losses: [2.6095452707160837e38, 2.3927446729856207e-7, 2.4372457457693985e-7, 2.4151883332341635e-7]\n",
      "bcs_losses: [1.7845467532238292e-6, 1.9240488947262713e-6, 2.1657650015975793e-6, 2.587652586829345e-6, 2.0589447327983336e-6, 2.175010216040502e-6, 1.7870190356180182e-6, 1.7779589478611716e-6, 1.788508456189131e-6, 1.0002626397771235, 1.8415579174686e-6, 0.9997462085346808]\n",
      "loss: 2.617915233543494e38\n",
      "pde_losses: [2.59550202614483e38, 2.4155748967521877e-7, 2.400139586637537e-7, 2.425471966093621e-7]\n",
      "bcs_losses: [1.7733776117682098e-6, 1.9320486681366364e-6, 2.1661204419068676e-6, 2.5318819039172778e-6, 2.061904677583071e-6, 2.163578789515317e-6, 1.7677043285230586e-6, 1.7722963846784594e-6, 1.7587948177288017e-6, 1.0002843273903834, 1.8363259731926678e-6, 0.9997241715160495]\n",
      "loss: 2.5880589051947796e38\n",
      "pde_losses: [2.5994117957208985e38, 2.456065899031868e-7, 2.3762145773702698e-7, 2.385831682163935e-7]\n",
      "bcs_losses: [1.74398438554898e-6, 1.9168972260431463e-6, 2.1660572877951654e-6, 2.519425230307996e-6, 2.0308449702191287e-6, 2.153560822952007e-6, 1.7197991565986248e-6, 1.7384941940211537e-6, 1.7225508696032852e-6, 1.0003336405225163, 1.8813881818258657e-6, 0.9996746383040733]\n",
      "loss: 2.5879869237445355e38\n",
      "pde_losses: [2.563406197046894e38, 2.433297375740469e-7, 2.425636188970625e-7, 2.4212541223199803e-7]\n",
      "bcs_losses: [1.7518637950232148e-6, 1.9156825903618176e-6, 2.123592677343614e-6, 2.5175051359494034e-6, 2.0278699182933267e-6, 2.108046703708124e-6, 1.7400506649177785e-6, 1.740042833375991e-6, 1.7367208864793251e-6, 1.0003225052034541, 1.8667457951556786e-6, 0.9996853872786053]\n",
      "loss: 2.5549327152035906e38\n",
      "pde_losses: [2.5538254844147305e38, 2.386844864591896e-7, 2.4071866466164817e-7, 2.4104445779781225e-7]\n",
      "bcs_losses: [1.7572784876406437e-6, 1.9282216258489087e-6, 2.1252312218660413e-6, 2.544853154391568e-6, 2.0360830136386234e-6, 2.155520543245563e-6, 1.7622046704678602e-6, 1.7459303905613577e-6, 1.7588385095944344e-6, 1.0002908306501839, 1.8510098887310492e-6, 0.9997168202685021]\n",
      "loss: 2.5534154689492653e38\n",
      "pde_losses: [2.571799686684359e38, 2.4591269983466066e-7, 2.3395726260247802e-7, 2.4390289783000423e-7]\n",
      "bcs_losses: [1.7392224004507619e-6, 1.9424999066312626e-6, 2.133384648154198e-6, 2.541495763639989e-6, 2.0068834201362188e-6, 2.1102179862790427e-6, 1.7429831419612397e-6, 1.7478773679769174e-6, 1.7272381877430447e-6, 1.0003087411748357, 1.896457244850887e-6, 0.9996988343092568]\n",
      "loss: 2.5844792496130226e38\n",
      "pde_losses: [2.5691065835877776e38, 2.3888700248651563e-7, 2.3792958189879757e-7, 2.416951251078653e-7]\n",
      "bcs_losses: [1.7267246236734954e-6, 1.9099169315667157e-6, 2.1305139086811786e-6, 2.5446470288131746e-6, 2.0009324377219935e-6, 2.118134931899043e-6, 1.7273884189900988e-6, 1.7355532736260469e-6, 1.7406650103987656e-6, 1.0002862338896858, 1.889870052821215e-6, 0.9997212641391311]\n",
      "loss: 2.5647792116933744e38\n",
      "pde_losses: [2.557453512968975e38, 2.418886499287017e-7, 2.371610571851937e-7, 2.467541822467283e-7]\n",
      "bcs_losses: [1.7454688776578163e-6, 1.9145054940635523e-6, 2.095043180344944e-6, 2.5316724947672215e-6, 2.003397862486704e-6, 2.129491043598741e-6, 1.7401531679550207e-6, 1.7413441986924954e-6, 1.7534888666942433e-6, 1.0002508160961163, 1.8411879222698823e-6, 0.9997566096044548]\n",
      "loss: 2.534494932161533e38\n",
      "pde_losses: [2.5565512484221752e38, 2.388455954345208e-7, 2.3558819986303661e-7, 2.3345879173645611e-7]\n",
      "bcs_losses: [1.7360254091593194e-6, 1.913026070710866e-6, 2.107831240422381e-6, 2.500980592622601e-6, 2.0206109713514215e-6, 2.121543515449419e-6, 1.7350081068207464e-6, 1.7327164885353422e-6, 1.7361947046308276e-6, 1.0002771773817647, 1.8408377329864735e-6, 0.9997302789316398]\n",
      "loss: 2.5244476072938534e38\n",
      "pde_losses: [2.532234513778248e38, 2.34180621610379e-7, 2.3669818706024187e-7, 2.3642799380470328e-7]\n",
      "bcs_losses: [1.7090863055506464e-6, 1.8791213563423808e-6, 2.1433194254576133e-6, 2.4454010124324135e-6, 1.9994289369641346e-6, 2.078769379940851e-6, 1.710728018069426e-6, 1.7153967612219647e-6, 1.7056413763756148e-6, 1.0003436785880488, 1.9016529580075748e-6, 0.9996639566688232]\n",
      "loss: 2.507093225984119e38\n",
      "pde_losses: [2.5338622369704644e38, 2.3405697446042546e-7, 2.397205001787989e-7, 2.3590952002753498e-7]\n",
      "bcs_losses: [1.7161779855739718e-6, 1.8964426403758347e-6, 2.0882560961099385e-6, 2.4797718045787837e-6, 1.987632852724941e-6, 2.112860059856873e-6, 1.7224157466540206e-6, 1.7186755292826162e-6, 1.718273601092009e-6, 1.0003019118555176, 1.8435129770268236e-6, 0.9997057431586798]\n",
      "loss: 2.4927227358195583e38\n",
      "pde_losses: [2.518555097724847e38, 2.3642147474244417e-7, 2.3616920530450231e-7, 2.332666866493579e-7]\n",
      "bcs_losses: [1.6970776410071351e-6, 1.8497416512308746e-6, 2.1142738634736278e-6, 2.494506043442979e-6, 1.9773845734901777e-6, 2.122013517193627e-6, 1.696663307067671e-6, 1.6994533466291635e-6, 1.723329479638055e-6, 1.0002676473504353, 1.8288866830254822e-6, 0.9997401219562427]\n",
      "loss: 2.4953882737767096e38\n",
      "pde_losses: [2.531492532258219e38, 2.3728300780804457e-7, 2.3637727029819252e-7, 2.3660260496009415e-7]\n",
      "bcs_losses: [1.7009614597011035e-6, 1.8651741320588918e-6, 2.143751427186243e-6, 2.4935702030741354e-6, 1.961842883345706e-6, 2.0924770778059464e-6, 1.6799657434505118e-6, 1.6731990250462947e-6, 1.6809691552235577e-6, 1.0002657052055304, 1.8471847159241494e-6, 0.9997422369249216]\n",
      "loss: 2.4979310631180592e38\n",
      "pde_losses: [2.490639287720941e38, 2.3640405246738493e-7, 2.3468918492796183e-7, 2.3457543813067717e-7]\n",
      "bcs_losses: [1.6916613156001997e-6, 1.8626999659980097e-6, 2.1085557632566783e-6, 2.4885637932062327e-6, 1.949394446269068e-6, 2.060684637599372e-6, 1.6996424452654482e-6, 1.6892940139564254e-6, 1.7059981841285746e-6, 1.0002874270046336, 1.8496788129928565e-6, 0.9997206258778849]\n",
      "loss: 2.484082587733721e38\n",
      "pde_losses: [2.470991162257398e38, 2.3259881860638652e-7, 2.3698992005426943e-7, 2.3383578873519723e-7]\n",
      "bcs_losses: [1.702240450409651e-6, 1.8788979909507331e-6, 2.0613890891147026e-6, 2.4685640957428312e-6, 1.9439369578034953e-6, 2.0546618427358885e-6, 1.702141288421481e-6, 1.7071544544725005e-6, 1.7140461920439615e-6, 1.000326476443548, 1.876920791829882e-6, 0.9996816372236357]\n",
      "loss: 2.48896354030267e38\n",
      "pde_losses: [2.504730818390104e38, 2.3052804717350935e-7, 2.3285493243383367e-7, 2.3335103633774952e-7]\n",
      "bcs_losses: [1.6929975191972224e-6, 1.8550642939092952e-6, 2.0667266153126946e-6, 2.4501536969645634e-6, 1.943662614309587e-6, 2.041650094467642e-6, 1.695200675265578e-6, 1.6989898029180332e-6, 1.6794831447622454e-6, 1.0003082055689991, 1.8754359406857136e-6, 0.99969997197599]\n",
      "loss: 2.483445756683529e38\n",
      "pde_losses: [2.5433828113172234e38, 2.355180834987212e-7, 2.3376210452097193e-7, 2.2918155955618251e-7]\n",
      "bcs_losses: [1.6896431282932388e-6, 1.8090695608689515e-6, 2.0768694733345434e-6, 2.445406434421207e-6, 1.9501189249124487e-6, 2.068555646583914e-6, 1.6680490803930312e-6, 1.6789501555140936e-6, 1.671463204147831e-6, 1.0002849952520318, 1.866657157793945e-6, 0.9997232243367324]\n",
      "loss: 2.487255703322321e38\n",
      "pde_losses: [2.4846357703722587e38, 2.3638682488443486e-7, 2.3453676149066793e-7, 2.30035334824926e-7]\n",
      "bcs_losses: [1.678542236055347e-6, 1.8337048997367603e-6, 2.072125287968643e-6, 2.425694629438496e-6, 1.9574845032136184e-6, 2.059895301065529e-6, 1.6892431247220797e-6, 1.6674831668962365e-6, 1.690039677791895e-6, 1.0002654255109342, 1.8266046661282008e-6, 0.9997428070442368]\n",
      "loss: 2.5142240762415317e38\n",
      "pde_losses: [2.4520083824864243e38, 2.3266212967055227e-7, 2.296130401986176e-7, 2.3089474885923985e-7]\n",
      "bcs_losses: [1.6953222647800424e-6, 1.8666989398838875e-6, 2.063977569409415e-6, 2.4079620325084756e-6, 1.9196170092707926e-6, 2.0455929780123304e-6, 1.6912568772138195e-6, 1.6962032541359817e-6, 1.6974539575019598e-6, 1.0002744632146972, 1.8057221289892993e-6, 0.999733730988347]\n",
      "loss: 2.4927004280647676e38\n",
      "pde_losses: [2.4544241440530228e38, 2.2902537973728233e-7, 2.324821049229625e-7, 2.3140663886446908e-7]\n",
      "bcs_losses: [1.6931821398093686e-6, 1.8650210829893268e-6, 2.036913142629167e-6, 2.4272870070073163e-6, 1.9235422603069235e-6, 2.0085864748497888e-6, 1.6885731812358718e-6, 1.6838689123980424e-6, 1.6931635357559326e-6, 1.000292401825977, 1.825422613652273e-6, 0.9997158294057048]\n",
      "loss: 2.4502200512399433e38\n",
      "pde_losses: [2.4598190550502018e38, 2.2455266506883796e-7, 2.272211294776497e-7, 2.2966145402218293e-7]\n",
      "bcs_losses: [1.662093136434454e-6, 1.7955627720744053e-6, 2.054959060659324e-6, 2.4401423975317886e-6, 1.9368932116802633e-6, 2.034998354869079e-6, 1.6623070626101705e-6, 1.6669032669852544e-6, 1.6564720520903678e-6, 1.0002978882689566, 1.8447354532306535e-6, 0.999710304028864]\n",
      "loss: 2.4558295374992083e38\n",
      "pde_losses: [2.4452699337098393e38, 2.23089817732306e-7, 2.255407893419779e-7, 2.2304678614926993e-7]\n",
      "bcs_losses: [1.6402652807898138e-6, 1.7904038855040827e-6, 2.0623278506286176e-6, 2.463192619260237e-6, 1.9595452578424045e-6, 2.0461171467411936e-6, 1.6457087322061575e-6, 1.6395810585913828e-6, 1.636976843105761e-6, 1.0002757431459877, 1.8248738177412566e-6, 0.9997323582563586]\n",
      "loss: 2.4682715875050953e38\n",
      "pde_losses: [2.460710122489305e38, 2.278681120035512e-7, 2.289580381521323e-7, 2.30098171169946e-7]\n",
      "bcs_losses: [1.6404049262816985e-6, 1.7990880462373694e-6, 2.0368000819746134e-6, 2.4010267998119076e-6, 1.908271454393962e-6, 1.989476371892155e-6, 1.6412448912397819e-6, 1.6344812705047419e-6, 1.6373964798137651e-6, 1.0003238384373716, 1.8664378894273973e-6, 0.999684195336948]\n",
      "loss: 2.4312869163922054e38\n",
      "pde_losses: [2.4606286727369345e38, 2.2809281610421562e-7, 2.2218543388192648e-7, 2.2845677736116974e-7]\n",
      "bcs_losses: [1.6557368839580133e-6, 1.8135696999449256e-6, 2.04319773300839e-6, 2.354614137909101e-6, 1.899853519377965e-6, 1.9617149174681085e-6, 1.6701701657121645e-6, 1.6733114936788848e-6, 1.6628312356396502e-6, 1.000331093826186, 1.8437346802470385e-6, 0.9996767482620568]\n",
      "loss: 2.4245510594393345e38\n",
      "pde_losses: [2.4142223828628573e38, 2.2442215124873876e-7, 2.2639532793133962e-7, 2.257064555874898e-7]\n",
      "bcs_losses: [1.6766867604108165e-6, 1.8368910654931352e-6, 2.0207945858702488e-6, 2.408090999964655e-6, 1.8862956218815764e-6, 1.985758291064025e-6, 1.6701569690422794e-6, 1.6736927528263682e-6, 1.656667889571584e-6, 1.0002752554478702, 1.784260131447714e-6, 0.9997323273412686]\n",
      "loss: 2.409390209909417e38\n",
      "pde_losses: [2.419446045061298e38, 2.2873071566309144e-7, 2.2724403110317684e-7, 2.2678183477107247e-7]\n",
      "bcs_losses: [1.6346806243707205e-6, 1.7725356578129393e-6, 2.0504548747527875e-6, 2.4352006512003673e-6, 1.9052577708354446e-6, 1.9987052513333508e-6, 1.6415311574401752e-6, 1.6357521450163206e-6, 1.6279109385844678e-6, 1.0002640938055232, 1.8190311165910076e-6, 0.9997433692288025]\n",
      "loss: 2.418001391480301e38\n",
      "pde_losses: [2.4526422631615575e38, 2.2471632600799986e-7, 2.2441158143585454e-7, 2.2606533026517718e-7]\n",
      "bcs_losses: [1.6375514550190034e-6, 1.7663866125632895e-6, 2.0501701789291552e-6, 2.435748385341254e-6, 1.8841541816799411e-6, 1.9880279175356245e-6, 1.6263374413623998e-6, 1.629300234803323e-6, 1.6246146728020694e-6, 1.000284144918232, 1.8395317968451708e-6, 0.9997231967362957]\n",
      "loss: 2.4272330969439248e38\n",
      "pde_losses: [2.398824862653833e38, 2.2465788282913704e-7, 2.254121297023764e-7, 2.2336258767467415e-7]\n",
      "bcs_losses: [1.6543172377605358e-6, 1.8210601757346506e-6, 2.0010536348342626e-6, 2.421069479390875e-6, 1.8636612955014233e-6, 1.9587665937055336e-6, 1.6525571382378566e-6, 1.6556822859119609e-6, 1.6558583947188093e-6, 1.0003269466372087, 1.8546252017898977e-6, 0.999680175185096]\n",
      "loss: 2.423955893501731e38\n",
      "pde_losses: [2.4160946935534365e38, 2.2785910073271102e-7, 2.247584845943587e-7, 2.2060492459050941e-7]\n",
      "bcs_losses: [1.634810165004013e-6, 1.7943495549442091e-6, 2.0209395890892217e-6, 2.412303450344531e-6, 1.8593580848976217e-6, 1.9458344612781153e-6, 1.6412970141710973e-6, 1.6368201965609272e-6, 1.6389966928846084e-6, 1.0003421936395707, 1.8723096477600107e-6, 0.9996646899915878]\n",
      "loss: 2.397216714377964e38\n",
      "pde_losses: [2.3930033346703947e38, 2.2100863834729862e-7, 2.239853111243787e-7, 2.1837895371275307e-7]\n",
      "bcs_losses: [1.6057317826212225e-6, 1.7662176015043117e-6, 2.0541137328978674e-6, 2.4100137232648898e-6, 1.8677404298130709e-6, 1.957558663587215e-6, 1.6004093328700328e-6, 1.61475749277405e-6, 1.611319751856002e-6, 1.0003222953210869, 1.8639036144731416e-6, 0.9996843143512036]\n",
      "loss: 2.376986822200436e38\n",
      "pde_losses: [2.4157546639839026e38, 2.2604097421684919e-7, 2.2734780209236352e-7, 2.2398575841980324e-7]\n",
      "bcs_losses: [1.6116486371388652e-6, 1.7394226512293748e-6, 2.0285788645643204e-6, 2.3968619616159643e-6, 1.904555721154615e-6, 1.9930251069477787e-6, 1.6034905678059298e-6, 1.5922919861572503e-6, 1.5934634997760468e-6, 1.0002717868247053, 1.7744054754432794e-6, 0.9997343381246246]\n",
      "loss: 2.3823246860095453e38\n",
      "pde_losses: [2.395811792498651e38, 2.1875927633664022e-7, 2.162141389827373e-7, 2.218009708529822e-7]\n",
      "bcs_losses: [1.6172756143935595e-6, 1.753968646846835e-6, 1.9843296561041416e-6, 2.340484440902412e-6, 1.8788178060481705e-6, 1.975104497588093e-6, 1.6238219726115367e-6, 1.6345657495176919e-6, 1.6329241359806698e-6, 1.0002886233575528, 1.7247120618428162e-6, 0.9997171525842244]\n",
      "loss: 2.3845837186964834e38\n",
      "pde_losses: [2.391133667461507e38, 2.2002163358148447e-7, 2.2257045746214264e-7, 2.2210868008329378e-7]\n",
      "bcs_losses: [1.6170426416292327e-6, 1.791415733415441e-6, 1.9999045635118364e-6, 2.3174418831184953e-6, 1.8547183971430028e-6, 1.9043375809937895e-6, 1.6324881927999995e-6, 1.630215158285651e-6, 1.6161654960406426e-6, 1.0003564328661856, 1.8015770093373296e-6, 0.9996492492286542]\n",
      "loss: 2.362319585519698e38\n",
      "pde_losses: [2.383014764872435e38, 2.2375063647497045e-7, 2.1896699867498515e-7, 2.2241179706949212e-7]\n",
      "bcs_losses: [1.615255451656752e-6, 1.7338777561368583e-6, 1.9808940900819495e-6, 2.351740277695505e-6, 1.8560970711985722e-6, 1.9322288059752277e-6, 1.607919935635452e-6, 1.599527929289407e-6, 1.6064732311737957e-6, 1.0003188120505104, 1.8356405549504258e-6, 0.9996868761079479]\n",
      "loss: 2.383883548776459e38\n",
      "pde_losses: [2.3821076066142718e38, 2.2110386182893836e-7, 2.1739587219080924e-7, 2.1761630214707683e-7]\n",
      "bcs_losses: [1.6184056333746645e-6, 1.7122489716774745e-6, 1.968817798686455e-6, 2.3897417963428863e-6, 1.9059663216881543e-6, 1.992339376331484e-6, 1.6190606147939085e-6, 1.6059883736539137e-6, 1.6224043244761523e-6, 1.0002193797406878, 1.8117423993623968e-6, 0.999786217496528]\n",
      "loss: 2.36146296143913e38\n",
      "pde_losses: [2.3586702169589643e38, 2.2017502393934204e-7, 2.1999880560195708e-7, 2.1848579415272442e-7]\n",
      "bcs_losses: [1.5911082017401887e-6, 1.721961428331259e-6, 1.995033058787249e-6, 2.3641859686620127e-6, 1.8604672838419165e-6, 1.9126624391459414e-6, 1.5756079919345082e-6, 1.5823991422971726e-6, 1.5822749474876677e-6, 1.0002825586189323, 1.8707896162223707e-6, 0.9997230785998876]\n",
      "loss: 2.396036299742182e38\n",
      "pde_losses: [2.35374705434187e38, 2.2129256722419457e-7, 2.1806358475447158e-7, 2.1649184143035844e-7]\n",
      "bcs_losses: [1.603715145026431e-6, 1.7564696962047023e-6, 2.0084469831940463e-6, 2.339309864899146e-6, 1.8220498751395697e-6, 1.8822901731186261e-6, 1.618922228488782e-6, 1.606423729435272e-6, 1.6025996664925585e-6, 1.0003428070476348, 1.867784166054505e-6, 0.9996627747475866]\n",
      "loss: 2.327302842791381e38\n",
      "pde_losses: [2.3453796423354065e38, 2.1684824498182458e-7, 2.2194347753252421e-7, 2.2253808519840497e-7]\n",
      "bcs_losses: [1.648981976300668e-6, 1.7792215968015422e-6, 1.9528269039579037e-6, 2.3432157132441644e-6, 1.8414094996916574e-6, 1.9316506757867814e-6, 1.6546737635409515e-6, 1.654407933211941e-6, 1.6436386985440732e-6, 1.0003142437699528, 1.7429140904879811e-6, 0.9996911632138182]\n",
      "loss: 2.3478960629534127e38\n",
      "pde_losses: [2.3235722383976595e38, 2.1795456967605267e-7, 2.1662654475499664e-7, 2.1945894824566423e-7]\n",
      "bcs_losses: [1.616048318301161e-6, 1.7527992541145464e-6, 1.958808255785871e-6, 2.305687657471895e-6, 1.8303933090628266e-6, 1.923170981932553e-6, 1.6268214835490691e-6, 1.6171758466909404e-6, 1.6129966427769858e-6, 1.000331671175235, 1.76460398963673e-6, 0.9996737219986583]\n",
      "loss: 2.34218372836556e38\n",
      "pde_losses: [2.3095974958149692e38, 2.195364557835052e-7, 2.1319982900347677e-7, 2.1542108018015626e-7]\n",
      "bcs_losses: [1.5705794250762635e-6, 1.6732226896793915e-6, 1.950138804413542e-6, 2.327215688245761e-6, 1.851725218493515e-6, 1.9498683233347408e-6, 1.5539176431990635e-6, 1.56907020553442e-6, 1.568179615752704e-6, 1.000283572318812, 1.771796430976197e-6, 0.9997218850590504]\n",
      "loss: 2.3124890486090523e38\n",
      "pde_losses: [2.3470275089068317e38, 2.149555580675648e-7, 2.122168883416543e-7, 2.2275948126693623e-7]\n",
      "bcs_losses: [1.571540326066548e-6, 1.6886223059301317e-6, 1.940956973256974e-6, 2.3261335718209007e-6, 1.8359439194355476e-6, 1.9104033308203094e-6, 1.5668696798293297e-6, 1.5602165433191524e-6, 1.5597986827025585e-6, 1.000293160223105, 1.813199985097405e-6, 0.9997124585579804]\n",
      "loss: 2.3423682597357784e38\n",
      "pde_losses: [2.3132470326419565e38, 2.1404395329870807e-7, 2.1307553218012647e-7, 2.187401612458149e-7]\n",
      "bcs_losses: [1.5628296824941035e-6, 1.7210899155101488e-6, 1.9409268500880932e-6, 2.2888038284382073e-6, 1.801833769005258e-6, 1.8848004182970644e-6, 1.5752495104962842e-6, 1.5659241596634555e-6, 1.5793493015000828e-6, 1.0003426757422424, 1.847550490375065e-6, 0.9996631722700442]\n",
      "loss: 2.3145452460124735e38\n",
      "pde_losses: [2.2842900761782067e38, 2.149256656089045e-7, 2.1628022962161788e-7, 2.1536885130349843e-7]\n",
      "bcs_losses: [1.598796225282187e-6, 1.7361666384704551e-6, 1.9530339749203292e-6, 2.2738013301112803e-6, 1.8119127201807697e-6, 1.8861804378199312e-6, 1.5892070636435755e-6, 1.5879751402508258e-6, 1.6033810847071804e-6, 1.0003047067786903, 1.795059658792772e-6, 0.9997011644115263]\n",
      "loss: 2.3162793097082108e38\n",
      "pde_losses: [2.3069848559225114e38, 2.1228412102446643e-7, 2.1267586324505663e-7, 2.1611100962400457e-7]\n",
      "bcs_losses: [1.5746159694527246e-6, 1.7072268434478488e-6, 1.9317201625774937e-6, 2.279899356563405e-6, 1.8104714574891933e-6, 1.8935750530738604e-6, 1.5802427954898591e-6, 1.582161850520229e-6, 1.5748379579142741e-6, 1.000272335709151, 1.770021573642448e-6, 0.9997335514931713]\n",
      "loss: 2.2927039010800144e38\n",
      "pde_losses: [2.3024532156477975e38, 2.1465994641305112e-7, 2.1249860405267012e-7, 2.118198798745574e-7]\n",
      "bcs_losses: [1.558615526635306e-6, 1.6760569926300928e-6, 1.9478177357346383e-6, 2.2937468491018025e-6, 1.7952653769632041e-6, 1.8791557187837831e-6, 1.5622959719019573e-6, 1.5625392873494182e-6, 1.5679866028449441e-6, 1.000283064308698, 1.7897115435194479e-6, 0.9997228438439485]\n",
      "loss: 2.2836167199846033e38\n",
      "pde_losses: [2.2907993020086407e38, 2.0855866170143388e-7, 2.121253261180462e-7, 2.1069846902647762e-7]\n",
      "bcs_losses: [1.566280680767011e-6, 1.6779676487560258e-6, 1.9018795631936246e-6, 2.2674968846128186e-6, 1.7846795306178029e-6, 1.8711896981585735e-6, 1.5766615116667332e-6, 1.5652049669951801e-6, 1.5651015771736747e-6, 1.0003167914787263, 1.8116680682009395e-6, 0.9996890518389382]\n",
      "loss: 2.248589310052808e38\n",
      "pde_losses: [2.257660328770881e38, 2.1369278703251924e-7, 2.1471450418038022e-7, 2.0812943938366355e-7]\n",
      "bcs_losses: [1.552895560385809e-6, 1.6914285378803668e-6, 1.8957625706965525e-6, 2.221029098733803e-6, 1.76067600805561e-6, 1.8499069195247764e-6, 1.555881096037007e-6, 1.5577215359033875e-6, 1.5469187069251944e-6, 1.0003593625664813, 1.839531989727393e-6, 0.9996464522617214]\n",
      "loss: 2.2765763319790797e38\n",
      "pde_losses: [2.2579323262678053e38, 2.089882691377628e-7, 2.1159360144240593e-7, 2.1259725703617028e-7]\n",
      "bcs_losses: [1.5535332093260654e-6, 1.6806581485411135e-6, 1.911712624160469e-6, 2.2516854097235862e-6, 1.7937983254428418e-6, 1.8601905757594658e-6, 1.5497193688497664e-6, 1.5592624810251438e-6, 1.5529497759747043e-6, 1.0002912441548888, 1.7709536715951199e-6, 0.9997144316004138]\n",
      "loss: 2.277012715701234e38\n",
      "pde_losses: [2.2499622191611743e38, 2.0957589054584783e-7, 2.1465722793201332e-7, 2.0677589733965327e-7]\n",
      "bcs_losses: [1.5282936605216236e-6, 1.6774617060852492e-6, 1.9363118621200174e-6, 2.2773401707023318e-6, 1.781218918909589e-6, 1.8593595253878231e-6, 1.5397954742922388e-6, 1.5467264731178512e-6, 1.5510084960262681e-6, 1.0002620051559032, 1.7454920723964331e-6, 0.9997436341674042]\n",
      "loss: 2.2609643902713743e38\n",
      "pde_losses: [2.272551970962667e38, 2.0868538446834925e-7, 2.085636738499593e-7, 2.088433445403098e-7]\n",
      "bcs_losses: [1.547943654716687e-6, 1.6803982440923753e-6, 1.9273087476273992e-6, 2.25098371305858e-6, 1.8004025509766424e-6, 1.8799600974173086e-6, 1.5223546056782784e-6, 1.5513156400305938e-6, 1.5353945549938874e-6, 1.0002692468186059, 1.7413416676062662e-6, 0.9997363779513473]\n",
      "loss: 2.2678177973154114e38\n",
      "pde_losses: [2.2570630871265246e38, 2.0987792830430233e-7, 2.086311897278894e-7, 2.040288400313427e-7]\n",
      "bcs_losses: [1.535474995316445e-6, 1.6828121340227924e-6, 1.8863274760232163e-6, 2.2522253226990567e-6, 1.7765166260001787e-6, 1.8412427203216148e-6, 1.5582344042912688e-6, 1.5286371341750987e-6, 1.5411321489712833e-6, 1.0003183924418955, 1.7774847268155462e-6, 0.9996872349362963]\n",
      "loss: 2.2376487292639485e38\n",
      "pde_losses: [2.2652391684778704e38, 2.1099044751304915e-7, 2.1145858361494958e-7, 2.083061893680577e-7]\n",
      "bcs_losses: [1.558115762504087e-6, 1.67592594130505e-6, 1.8788263061562581e-6, 2.2266485333315454e-6, 1.7413661853864245e-6, 1.7875951049117626e-6, 1.5553914941278175e-6, 1.5419480891476631e-6, 1.5474069770734882e-6, 1.0003727714063153, 1.820561758189843e-6, 0.9996328564098175]\n",
      "loss: 2.24158992472095e38\n",
      "pde_losses: [2.2621081169460146e38, 2.0225324475673946e-7, 2.0587240947172793e-7, 2.1241007203588744e-7]\n",
      "bcs_losses: [1.5274670250996766e-6, 1.6417166363318405e-6, 1.9163465626260093e-6, 2.2121101738885358e-6, 1.738149029320157e-6, 1.8233274880344858e-6, 1.5363630926707334e-6, 1.5154856879066175e-6, 1.5215216766144843e-6, 1.0003555106665214, 1.8205260131282785e-6, 0.9996501252147019]\n",
      "loss: 2.2223648988207303e38\n",
      "pde_losses: [2.2283783833028975e38, 2.1112096995532176e-7, 2.105535050841777e-7, 2.0414365580282214e-7]\n",
      "bcs_losses: [1.522598801098708e-6, 1.6285811534590026e-6, 1.8863330770746277e-6, 2.2057966618549097e-6, 1.7506138000104108e-6, 1.8463616908052555e-6, 1.5324509127144517e-6, 1.5281563394503688e-6, 1.5347578824999421e-6, 1.0002875264253306, 1.7488768299854165e-6, 0.9997180229911053]\n",
      "loss: 2.2375358507403378e38\n",
      "pde_losses: [2.206196599102698e38, 2.0705411683923452e-7, 2.1040468221428496e-7, 2.10441837055662e-7]\n",
      "bcs_losses: [1.5524987352150868e-6, 1.617820873600267e-6, 1.871605594769395e-6, 2.206292790724223e-6, 1.747931372305522e-6, 1.8458215837445672e-6, 1.5485943068835422e-6, 1.5458994367545918e-6, 1.5406142982331644e-6, 1.000256504804976, 1.7127774465969247e-6, 0.9997489354313176]\n",
      "loss: 2.2428947326591146e38\n",
      "pde_losses: [2.2199449839069422e38, 2.0493809852713903e-7, 2.0422173826673712e-7, 2.0673283356424486e-7]\n",
      "bcs_losses: [1.5285175557925085e-6, 1.637114056042543e-6, 1.8948044953922914e-6, 2.198335838297112e-6, 1.749299006600574e-6, 1.8065690764092243e-6, 1.5345549212588371e-6, 1.5311060602184528e-6, 1.5300404984273653e-6, 1.0003005364432673, 1.7629645189047984e-6, 0.9997048957804161]\n",
      "loss: 2.228845995984491e38\n",
      "pde_losses: [2.22314873594269e38, 2.0853000944919648e-7, 2.1006605683047744e-7, 2.046291251048963e-7]\n",
      "bcs_losses: [1.5306740459347044e-6, 1.6434996201257119e-6, 1.8664950544004207e-6, 2.198023046701137e-6, 1.7416828164328416e-6, 1.8029373150619e-6, 1.5260918776850165e-6, 1.5188938569582364e-6, 1.5306079182527e-6, 1.0003080713409074, 1.7788049455590712e-6, 0.9996973789306095]\n",
      "loss: 2.221581379207151e38\n",
      "pde_losses: [2.2136464533353204e38, 2.1096795224753789e-7, 1.9880111328035845e-7, 2.0549388436705977e-7]\n",
      "bcs_losses: [1.5289243372623968e-6, 1.6247665192748494e-6, 1.8674157906274994e-6, 2.2256821871530906e-6, 1.722587974939238e-6, 1.815568832107269e-6, 1.5232704042928592e-6, 1.512094049137117e-6, 1.5262940369537592e-6, 1.0003120032957729, 1.7825453245511414e-6, 0.9996935196207184]\n",
      "loss: 2.1837419783121874e38\n",
      "pde_losses: [2.2305726962289177e38, 2.0676345665668063e-7, 2.0650296197216703e-7, 2.0355801352794356e-7]\n",
      "bcs_losses: [1.4988434595316692e-6, 1.6020781540853642e-6, 1.892763766599768e-6, 2.214029512376165e-6, 1.7179790043177754e-6, 1.7790721878090431e-6, 1.5090985992862524e-6, 1.4952361472152428e-6, 1.5084836556679517e-6, 1.0003476250304177, 1.8146357992281251e-6, 0.9996580021090873]\n",
      "loss: 2.2243177881997222e38\n",
      "pde_losses: [2.234578264425192e38, 2.0361407788977468e-7, 2.0603337402698727e-7, 2.0528631760580436e-7]\n",
      "bcs_losses: [1.4882324215726766e-6, 1.5990243645696728e-6, 1.867204033959577e-6, 2.180390877819886e-6, 1.7360873970392453e-6, 1.7673504572668797e-6, 1.488035310294423e-6, 1.4966731065441298e-6, 1.503176805290394e-6, 1.0003396617083902, 1.787913176609941e-6, 0.9996658203232007]\n",
      "loss: 2.1724887528530632e38\n",
      "pde_losses: [2.199553693645556e38, 2.02097846357526e-7, 2.0408495099827864e-7, 2.0481696369516828e-7]\n",
      "bcs_losses: [1.5116463825695735e-6, 1.6055601776468365e-6, 1.8717511413277955e-6, 2.1836202367444952e-6, 1.7310872701098284e-6, 1.803056149354866e-6, 1.5114230356923836e-6, 1.513442438082475e-6, 1.5244687748376582e-6, 1.0002766194160655, 1.7103558129408677e-6, 0.9997286370690919]\n",
      "loss: 2.175861065304869e38\n",
      "pde_losses: [2.197962345906007e38, 2.0378211250837544e-7, 2.0731297176786205e-7, 2.0123246627372506e-7]\n",
      "bcs_losses: [1.4947030094965977e-6, 1.5934298876041684e-6, 1.8621395768872091e-6, 2.1860895484340814e-6, 1.7303384004209548e-6, 1.781548564200408e-6, 1.5088943982112389e-6, 1.4957281863582152e-6, 1.5081946468884555e-6, 1.0002800185193599, 1.735340443942531e-6, 0.9997251537501504]\n",
      "loss: 2.16182901972791e38\n",
      "pde_losses: [2.1648058480117784e38, 2.04330829737003e-7, 2.0270166281966476e-7, 2.0427619261120934e-7]\n",
      "bcs_losses: [1.492973261519556e-6, 1.5774129619268984e-6, 1.8893015811442088e-6, 2.1749692244302687e-6, 1.7248548337321958e-6, 1.7661049546447728e-6, 1.4839212547254262e-6, 1.4800689456112007e-6, 1.4783407719466841e-6, 1.0003031995530112, 1.7810695685863424e-6, 0.9997018484421065]\n",
      "loss: 2.1684836450086525e38\n",
      "pde_losses: [2.163256053836583e38, 2.0595742135856587e-7, 2.0200577080204904e-7, 2.028528776409901e-7]\n",
      "bcs_losses: [1.495596326114184e-6, 1.5891571153650337e-6, 1.839858424993321e-6, 2.2022186472619973e-6, 1.7101690038048186e-6, 1.775895267380999e-6, 1.503800284633946e-6, 1.505741454247359e-6, 1.4949863450729278e-6, 1.000309214229798, 1.7516595717861595e-6, 0.9996955587017464]\n",
      "loss: 2.1818427189983604e38\n",
      "pde_losses: [2.1800105946447662e38, 2.05166194144501e-7, 2.0420132882764414e-7, 2.0427593855457845e-7]\n",
      "bcs_losses: [1.5046682884374382e-6, 1.5979513541828606e-6, 1.8188816979094077e-6, 2.190045411225977e-6, 1.7068024726732232e-6, 1.7791714598780288e-6, 1.515455077779705e-6, 1.5170691841509697e-6, 1.503463208231989e-6, 1.0003338119805592, 1.7309342825258667e-6, 0.9996706862439894]\n",
      "loss: 2.138055054740329e38\n",
      "pde_losses: [2.1476947223058857e38, 2.0187323037939512e-7, 2.0207411537150305e-7, 2.0283641518603472e-7]\n",
      "bcs_losses: [1.4930901348330922e-6, 1.5943311106405912e-6, 1.875498875843906e-6, 2.150747392414772e-6, 1.6950470571227283e-6, 1.761541597306604e-6, 1.4827872150762219e-6, 1.4827857884895725e-6, 1.4884802780328234e-6, 1.0003804521916546, 1.7569686954791345e-6, 0.9996238208363672]\n",
      "loss: 2.144273113676177e38\n",
      "pde_losses: [2.1547383261672007e38, 1.9789676402033073e-7, 2.0289319594507323e-7, 2.032423911394986e-7]\n",
      "bcs_losses: [1.4636875858486362e-6, 1.5836251120310501e-6, 1.8521864943349405e-6, 2.1509550602084487e-6, 1.6839911038331131e-6, 1.7428126363376997e-6, 1.4557616585038835e-6, 1.458481506936725e-6, 1.4551647779559653e-6, 1.0003611220709816, 1.764391151538487e-6, 0.9996428479114778]\n",
      "loss: 2.1609327777034635e38\n",
      "pde_losses: [2.1706219970906347e38, 2.0074945571580738e-7, 1.9786102837971412e-7, 2.0056694931409564e-7]\n",
      "bcs_losses: [1.4708575573650397e-6, 1.5662855930372973e-6, 1.8233739699824304e-6, 2.164908922026239e-6, 1.7128556069017837e-6, 1.8052216358984304e-6, 1.4665001635472071e-6, 1.4695297210634798e-6, 1.4660824682411835e-6, 1.000264040507095, 1.6918765459384113e-6, 0.9997394916225023]\n",
      "loss: 2.1611952520902032e38\n",
      "pde_losses: [2.1762532738707937e38, 1.9699535559542971e-7, 2.03040085167473e-7, 1.9712638924743116e-7]\n",
      "bcs_losses: [1.466974725622439e-6, 1.564293740588838e-6, 1.8082317892991042e-6, 2.158324678474685e-6, 1.7113900892974763e-6, 1.7795532439567137e-6, 1.4764738887285878e-6, 1.4693374770748874e-6, 1.4659139744476983e-6, 1.0002554671913624, 1.704232908833636e-6, 0.9997477825314357]\n",
      "loss: 2.1540889270018163e38\n",
      "pde_losses: [2.1484350603950027e38, 1.9814039741845308e-7, 1.942127622929183e-7, 2.04045978289678e-7]\n",
      "bcs_losses: [1.4619301065567762e-6, 1.5943431088977495e-6, 1.8533453697402113e-6, 2.122895484325066e-6, 1.6775151272674565e-6, 1.6799236497996712e-6, 1.4619959503815569e-6, 1.4527537168528376e-6, 1.4718089749186422e-6, 1.0003376002630726, 1.787577535460501e-6, 0.9996655766493607]\n",
      "loss: 2.1487852269363035e38\n",
      "pde_losses: [2.114749045809757e38, 1.9753438501386034e-7, 1.9462872494217753e-7, 1.996157295278378e-7]\n",
      "bcs_losses: [1.47095735541441e-6, 1.5675151311411445e-6, 1.808260366805189e-6, 2.0999399017113258e-6, 1.6952690159009797e-6, 1.7268284763687097e-6, 1.4762190419820672e-6, 1.4746621994024756e-6, 1.4643595225858667e-6, 1.000310412419684, 1.7289141669658145e-6, 0.9996925177356564]\n",
      "loss: 2.1418779011778696e38\n",
      "pde_losses: [2.162429356397987e38, 1.984612007789098e-7, 1.9933079919252285e-7, 1.945525135532108e-7]\n",
      "bcs_losses: [1.4638961666396606e-6, 1.5637263346140254e-6, 1.7885751936354539e-6, 2.180935712388903e-6, 1.6746346968241454e-6, 1.7774318220249864e-6, 1.4714195614256543e-6, 1.4666085389471649e-6, 1.4765904263901067e-6, 1.0003009624887995, 1.7077732102497455e-6, 0.99970187640905]\n",
      "loss: 2.1568564289934368e38\n",
      "pde_losses: [2.1376757739549784e38, 2.010319045501222e-7, 1.9830739480569674e-7, 1.9815086722644164e-7]\n",
      "bcs_losses: [1.4398199170925448e-6, 1.56431119019773e-6, 1.831507600621334e-6, 2.1704190549379533e-6, 1.6668224284055237e-6, 1.7178044787651687e-6, 1.4462240407548402e-6, 1.4382623783243007e-6, 1.436338968165011e-6, 1.000365758492825, 1.772677436452217e-6, 0.9996371547030163]\n",
      "loss: 2.1473640662556408e38\n",
      "pde_losses: [2.110169842113991e38, 1.9375506303277937e-7, 1.961137495660988e-7, 1.9380336467617658e-7]\n",
      "bcs_losses: [1.4435356088739133e-6, 1.5724792038081933e-6, 1.8023309090196025e-6, 2.1097554318508627e-6, 1.6688329436343669e-6, 1.6854833906079768e-6, 1.4438678388032628e-6, 1.4382967969327977e-6, 1.4395251630748348e-6, 1.0003794832815867, 1.7725757092174194e-6, 0.9996234665473389]\n",
      "loss: 2.1376324223460962e38\n",
      "pde_losses: [2.1204798134958384e38, 1.941765606606335e-7, 1.9480917697845544e-7, 1.9818258489810172e-7]\n",
      "bcs_losses: [1.467278190878511e-6, 1.5536219482194976e-6, 1.7478523692321532e-6, 2.1444756018621723e-6, 1.6930944430679602e-6, 1.7581997979330766e-6, 1.472110153660569e-6, 1.4681536478310578e-6, 1.4734725689570752e-6, 1.000270086027308, 1.6818928954749573e-6, 0.9997329095224924]\n",
      "loss: 2.1385996783827755e38\n",
      "pde_losses: [2.1370529524050323e38, 1.9367143070244343e-7, 1.9692901397575456e-7, 1.9697922487200356e-7]\n",
      "bcs_losses: [1.4288753606063544e-6, 1.5271998052982437e-6, 1.777305484352116e-6, 2.1059542408857295e-6, 1.6993990964161954e-6, 1.7173326612646367e-6, 1.432594951628141e-6, 1.4374367119836059e-6, 1.4303098927955748e-6, 1.0002752874587102, 1.7154398708189944e-6, 0.9997280100157633]\n",
      "loss: 2.1080256286998983e38\n",
      "pde_losses: [2.082392148093222e38, 1.927096922821704e-7, 1.9527819549112193e-7, 1.9347550925843428e-7]\n",
      "bcs_losses: [1.4166215675983482e-6, 1.5266487385251777e-6, 1.8466118363378262e-6, 2.098367294550482e-6, 1.6564637033892592e-6, 1.6632637036235668e-6, 1.4107303297679534e-6, 1.4247155940286133e-6, 1.4146390209251934e-6, 1.0003371106438401, 1.7776395508779313e-6, 0.9996665010346311]\n",
      "loss: 2.1185766128409773e38\n",
      "pde_losses: [2.1091901964276935e38, 1.9091745516976822e-7, 1.9730671539935545e-7, 1.9457414051957685e-7]\n",
      "bcs_losses: [1.4439543754697743e-6, 1.5212828104276206e-6, 1.779579030006582e-6, 2.1034473533408014e-6, 1.6760857672990213e-6, 1.7190965189264508e-6, 1.4438115517850612e-6, 1.4282918042991342e-6, 1.443006140712618e-6, 1.0003101654486894, 1.6889211538156144e-6, 0.9996934801607045]\n",
      "loss: 2.1387253358327123e38\n",
      "pde_losses: [2.141266272355296e38, 1.9339356420532925e-7, 1.9184940128904937e-7, 1.9839869045838595e-7]\n",
      "bcs_losses: [1.4607719850400127e-6, 1.5438272731377946e-6, 1.7438533295333628e-6, 2.1136907508395328e-6, 1.6485936561662235e-6, 1.7156474795830662e-6, 1.4598894992366577e-6, 1.4597275543038491e-6, 1.4536570907660745e-6, 1.0003155630982548, 1.6820218383769654e-6, 0.9996882443455324]\n",
      "loss: 2.120237416812071e38\n",
      "pde_losses: [2.093019910348922e38, 1.9361033237156724e-7, 1.94416423146803e-7, 1.9227365462172386e-7]\n",
      "bcs_losses: [1.4134900665035605e-6, 1.5262855482232436e-6, 1.8256214639801081e-6, 2.0907100305731414e-6, 1.6390098182553067e-6, 1.644254176260294e-6, 1.424849136093306e-6, 1.4225949315514554e-6, 1.423980111343604e-6, 1.0003873493623994, 1.7992418069843921e-6, 0.999616811073358]\n",
      "loss: 2.086066632206263e38\n",
      "pde_losses: [2.0615069691555217e38, 1.8923053706462115e-7, 1.9243956925625382e-7, 1.9197513751933175e-7]\n",
      "bcs_losses: [1.419896773070276e-6, 1.5123374313284373e-6, 1.7644347707099114e-6, 2.0931048765270034e-6, 1.623178143708286e-6, 1.6830127532062815e-6, 1.4175148491384877e-6, 1.421907850074183e-6, 1.4288209925383762e-6, 1.000299568520206, 1.7186981309325464e-6, 0.9997047267175165]\n",
      "loss: 2.117175637054631e38\n",
      "pde_losses: [2.084960603826884e38, 1.9467586545104894e-7, 1.912660147831984e-7, 1.909788461263846e-7]\n",
      "bcs_losses: [1.4504305008839329e-6, 1.5062002934843006e-6, 1.7273769799392878e-6, 2.110445801383342e-6, 1.6895528183325261e-6, 1.7764120982676557e-6, 1.4462074592710305e-6, 1.4395551673604691e-6, 1.4462435000972678e-6, 1.0001984473447156, 1.6293825100582232e-6, 0.9998059428333095]\n",
      "loss: 2.0997495301011537e38\n",
      "pde_losses: [2.072944743231269e38, 1.8926135847190206e-7, 1.9359694095837188e-7, 1.9072903737524805e-7]\n",
      "bcs_losses: [1.415896385687715e-6, 1.515277351606693e-6, 1.750916333164677e-6, 2.0374833859326393e-6, 1.6195212058563002e-6, 1.66003880480817e-6, 1.4092412137901325e-6, 1.406898000298221e-6, 1.415791355050906e-6, 1.000338993899319, 1.734177109642005e-6, 0.9996656637633559]\n",
      "loss: 2.0595450647321286e38\n",
      "pde_losses: [2.0901561278606197e38, 1.876337741784261e-7, 1.906955562353001e-7, 1.9461977642672073e-7]\n",
      "bcs_losses: [1.4135229641756788e-6, 1.5322211386030855e-6, 1.7602550546357843e-6, 2.0225070490233156e-6, 1.6208814257793055e-6, 1.6270063734176753e-6, 1.4225442302443098e-6, 1.4256019564316229e-6, 1.420666970748178e-6, 1.0004103714732173, 1.7676700190055212e-6, 0.9995943731508066]\n",
      "loss: 2.073639612424112e38\n",
      "pde_losses: [2.068238627114107e38, 1.9055878716762705e-7, 1.8892539818396192e-7, 1.8845860055440232e-7]\n",
      "bcs_losses: [1.4166128619426084e-6, 1.507078303927896e-6, 1.7234405111400768e-6, 2.0769270467470975e-6, 1.6424114467281988e-6, 1.723142438732365e-6, 1.4250294088364752e-6, 1.4350235330256574e-6, 1.435711975426945e-6, 1.0002856905382969, 1.646956947570915e-6, 0.9997188469052226]\n",
      "loss: 2.1001686544062945e38\n",
      "pde_losses: [2.060534166057797e38, 1.9209490517156962e-7, 1.8976262906249322e-7, 1.9274582146709027e-7]\n",
      "bcs_losses: [1.4015682590250887e-6, 1.4892045336538513e-6, 1.7395114297278036e-6, 2.079086323691858e-6, 1.6245172533328205e-6, 1.7327323602772534e-6, 1.4004998672468447e-6, 1.4147861085227091e-6, 1.408598158564732e-6, 1.0002590595268637, 1.6596043469051606e-6, 0.9997454321585761]\n",
      "loss: 2.0600466892794557e38\n",
      "pde_losses: [2.0763332338524292e38, 1.8806779689700306e-7, 1.8976562810573857e-7, 1.8462451432842108e-7]\n",
      "bcs_losses: [1.397387949325454e-6, 1.4918009146285662e-6, 1.8106329639012559e-6, 2.039405979270721e-6, 1.6112541696764763e-6, 1.6037562602700455e-6, 1.3868653773456749e-6, 1.3947900149887544e-6, 1.3960156153083865e-6, 1.000382428843709, 1.8015233087096022e-6, 0.9996221874474994]\n",
      "loss: 2.052115188583963e38\n",
      "pde_losses: [2.0537985610015562e38, 1.9279005321920795e-7, 1.9017241852803496e-7, 1.8739993591929526e-7]\n",
      "bcs_losses: [1.4197481928567527e-6, 1.5095629326791575e-6, 1.743736130330444e-6, 2.02084101756595e-6, 1.5995480749063835e-6, 1.626275698702859e-6, 1.4314074920328912e-6, 1.4274417592721494e-6, 1.4275580941790817e-6, 1.0003435966907186, 1.7176011895500524e-6, 0.9996607188502967]\n",
      "loss: 2.04220236158477e38\n",
      "pde_losses: [2.035350494718577e38, 1.8881208696013006e-7, 1.866568067791393e-7, 1.8742649054479423e-7]\n",
      "bcs_losses: [1.450768183271039e-6, 1.5106333437222048e-6, 1.693561410252997e-6, 2.0483335070128483e-6, 1.6175993001665385e-6, 1.7243596225549457e-6, 1.4436851579130197e-6, 1.447489970159869e-6, 1.4444515134652035e-6, 1.000259617910321, 1.622032757479355e-6, 0.9997443011205466]\n",
      "loss: 2.0532210414495744e38\n",
      "pde_losses: [2.0454013481408186e38, 1.8806783316349397e-7, 1.8741812592072968e-7, 1.8884503908884447e-7]\n",
      "bcs_losses: [1.3765391316615683e-6, 1.4435203956462798e-6, 1.7689213412432187e-6, 2.015539663193205e-6, 1.5936440226799668e-6, 1.6406182069080403e-6, 1.3824950757203002e-6, 1.3664527893268079e-6, 1.375606644614869e-6, 1.0003250161662374, 1.7115212794559719e-6, 0.999678694490929]\n",
      "loss: 2.016555648223822e38\n",
      "pde_losses: [2.0512674357477753e38, 1.8522437947420448e-7, 1.8534097623670022e-7, 1.8804822133557947e-7]\n",
      "bcs_losses: [1.371882769086552e-6, 1.4630184138398647e-6, 1.7672678663401093e-6, 2.0231606809969163e-6, 1.5959945779220688e-6, 1.6199814193691607e-6, 1.3776276099129207e-6, 1.3733554201122936e-6, 1.378550981930545e-6, 1.000368663300634, 1.7425019661852994e-6, 0.9996347685601943]\n",
      "loss: 2.0388734525265184e38\n",
      "pde_losses: [2.047275329339369e38, 1.8389183175606474e-7, 1.8613519687900467e-7, 1.8992352866617586e-7]\n",
      "bcs_losses: [1.4236913039707556e-6, 1.4962881959091518e-6, 1.681243570201833e-6, 2.0197246115213068e-6, 1.611504158710567e-6, 1.6743813814671117e-6, 1.4193056155352978e-6, 1.4175733620309043e-6, 1.4266710443079605e-6, 1.0003134330750554, 1.6447400796642647e-6, 0.9996895653288986]\n",
      "loss: 2.0387612153605002e38\n",
      "pde_losses: [2.0200670559162165e38, 1.8776708336867697e-7, 1.8659885894270553e-7, 1.875432038089554e-7]\n",
      "bcs_losses: [1.389655856143226e-6, 1.484643702446804e-6, 1.7093183763589743e-6, 2.016419735240211e-6, 1.571514925224581e-6, 1.6253757788831514e-6, 1.393342067781046e-6, 1.4006466469339455e-6, 1.3962743698061227e-6, 1.0003276323893648, 1.6645737878597766e-6, 0.9996751423430169]\n",
      "loss: 2.013416957717762e38\n",
      "pde_losses: [2.0128633486777303e38, 1.874173537953574e-7, 1.920927080583539e-7, 1.8413067306547623e-7]\n",
      "bcs_losses: [1.3609835532531702e-6, 1.4570561808718026e-6, 1.7575031462651695e-6, 2.0079546700379125e-6, 1.578108828753848e-6, 1.5923874161809507e-6, 1.3758381129435746e-6, 1.357240971075825e-6, 1.3709436800665413e-6, 1.0003665032249525, 1.7381953174030454e-6, 0.999636195475123]\n",
      "loss: 2.0072515384515613e38\n",
      "pde_losses: [2.032679824496587e38, 1.854055085176414e-7, 1.8552397858898914e-7, 1.8708335153283487e-7]\n",
      "bcs_losses: [1.3728628685898875e-6, 1.437852964110776e-6, 1.7104621373749058e-6, 2.0244698378557095e-6, 1.5917487710388576e-6, 1.641270917915027e-6, 1.3664749959126276e-6, 1.3679392333071943e-6, 1.3671423032298558e-6, 1.000283127833261, 1.6436027337654259e-6, 0.9997192752919339]\n",
      "loss: 2.027930802891034e38\n",
      "pde_losses: [2.026585003252088e38, 1.828570953455065e-7, 1.837863336215014e-7, 1.8462646040019824e-7]\n",
      "bcs_losses: [1.3973246067429866e-6, 1.4738144672561216e-6, 1.677072510071484e-6, 2.0298368247549145e-6, 1.5940065976112766e-6, 1.6545634831719485e-6, 1.3944756871349137e-6, 1.3939482637799521e-6, 1.3950455056465665e-6, 1.000279863036341, 1.6203072787755183e-6, 0.9997223677011375]\n",
      "loss: 2.0059343171519663e38\n",
      "pde_losses: [1.991405764059662e38, 1.8242861125896404e-7, 1.810766372184992e-7, 1.840803201511187e-7]\n",
      "bcs_losses: [1.3550445492179779e-6, 1.4580735800209263e-6, 1.7369276757244605e-6, 1.999832702311758e-6, 1.5430900169370517e-6, 1.5809363145148806e-6, 1.3595073141915223e-6, 1.3570513979434463e-6, 1.3657107185516163e-6, 1.0003829214401772, 1.7368279997792151e-6, 0.9996193857302783]\n",
      "loss: 1.9980919083379654e38\n",
      "pde_losses: [1.987643889171621e38, 1.8292520316957263e-7, 1.8444802682313209e-7, 1.849744399057205e-7]\n",
      "bcs_losses: [1.3536330019176113e-6, 1.4487203409966671e-6, 1.7219478072081531e-6, 1.9896421167718773e-6, 1.5506518832888385e-6, 1.5730631544644233e-6, 1.3473619207184668e-6, 1.346863372251397e-6, 1.3493356474303924e-6, 1.0003685860916611, 1.7487046556668501e-6, 0.9996336925200726]\n",
      "loss: 2.0155228578675547e38\n",
      "pde_losses: [1.9868147630693662e38, 1.845353483132163e-7, 1.8075848456655285e-7, 1.833322179024203e-7]\n",
      "bcs_losses: [1.3728103369385858e-6, 1.4349283612550087e-6, 1.6761091622130893e-6, 2.0322750152888117e-6, 1.5932386280415918e-6, 1.6429122144930295e-6, 1.3788642032506225e-6, 1.381370070259162e-6, 1.3817336735711398e-6, 1.0002457394755464, 1.638900612684533e-6, 0.9997562742082111]\n",
      "loss: 1.9690801330100254e38\n",
      "pde_losses: [1.9780939547576467e38, 1.8524283390731476e-7, 1.8434473972055458e-7, 1.8405346429270354e-7]\n",
      "bcs_losses: [1.3593398237456835e-6, 1.4237812873985606e-6, 1.6948136978051492e-6, 1.9807486341647856e-6, 1.5554718673618456e-6, 1.5839127547531636e-6, 1.3650587238704917e-6, 1.356725152362523e-6, 1.3539284643502136e-6, 1.0003061236736512, 1.6830596818389472e-6, 0.9996959039448494]\n",
      "loss: 2.0075292983442594e38\n",
      "pde_losses: [1.985869886584385e38, 1.794275696303148e-7, 1.8420719019434925e-7, 1.841740216902037e-7]\n",
      "bcs_losses: [1.3648749020521955e-6, 1.461823533048528e-6, 1.7326733440259432e-6, 1.9545118989037484e-6, 1.5306704289809987e-6, 1.5239461737827735e-6, 1.3729161494751224e-6, 1.3631843159883442e-6, 1.3680582581822388e-6, 1.000394258110131, 1.7515316254940687e-6, 0.9996077539961774]\n",
      "loss: 1.948516768835233e38\n",
      "pde_losses: [1.975985676892708e38, 1.7876759339175254e-7, 1.8132328869526656e-7, 1.8083783674281024e-7]\n",
      "bcs_losses: [1.388014740608399e-6, 1.426369918563766e-6, 1.656689004994227e-6, 1.9730851520480362e-6, 1.5626504800514393e-6, 1.61062649244355e-6, 1.3818284101482477e-6, 1.3922216301411423e-6, 1.3882453936383233e-6, 1.000288019329701, 1.6294646174905707e-6, 0.9997137418508814]\n",
      "loss: 1.982117475105646e38\n",
      "pde_losses: [1.9592183762458427e38, 1.7733474753755715e-7, 1.7954586736456272e-7, 1.8338240577309807e-7]\n",
      "bcs_losses: [1.351755335058553e-6, 1.4021788201534738e-6, 1.6754078217028482e-6, 1.9811678034845807e-6, 1.5616575822686194e-6, 1.5794512722814357e-6, 1.3385395345433374e-6, 1.3519346861555307e-6, 1.3530435070560943e-6, 1.0003097417508284, 1.669139922836274e-6, 0.9996920243438396]\n",
      "loss: 1.9602852257905517e38\n",
      "pde_losses: [1.9392737903003414e38, 1.797389508078574e-7, 1.8079757996301e-7, 1.800225018973727e-7]\n",
      "bcs_losses: [1.3230879853000341e-6, 1.4175232664859385e-6, 1.717075306996912e-6, 1.9479443740623626e-6, 1.5353279981894187e-6, 1.5237818014902314e-6, 1.3331553941633795e-6, 1.339908095833978e-6, 1.3234487351812758e-6, 1.0003904131685528, 1.7600421403126905e-6, 0.9996114311633117]\n",
      "loss: 1.9727554966957443e38\n",
      "pde_losses: [1.941745757790541e38, 1.8174698724834532e-7, 1.771562056147737e-7, 1.8273589597747247e-7]\n",
      "bcs_losses: [1.3769049587812959e-6, 1.4362194322694273e-6, 1.6400726587008875e-6, 1.9652436528433676e-6, 1.5457658376778063e-6, 1.60098334444928e-6, 1.3758013336092861e-6, 1.3703683111687044e-6, 1.367944742346422e-6, 1.0003108576481958, 1.6414813238295339e-6, 0.9996908265705813]\n",
      "loss: 1.9563723787198545e38\n",
      "pde_losses: [1.925334468251661e38, 1.818436701905369e-7, 1.821906070195437e-7, 1.7979299097874429e-7]\n",
      "bcs_losses: [1.354099971309883e-6, 1.41212007043878e-6, 1.6766178368586967e-6, 1.9760937011229887e-6, 1.5786879899142894e-6, 1.6225232401509639e-6, 1.3511064598791091e-6, 1.3496821953105446e-6, 1.3582790591916164e-6, 1.0002836951067753, 1.5954429316165354e-6, 0.9997179707275258]\n",
      "loss: 1.962048453400705e38\n",
      "pde_losses: [1.9615609489937285e38, 1.783516917630851e-7, 1.787414432877449e-7, 1.7740247490593452e-7]\n",
      "bcs_losses: [1.3214179177983417e-6, 1.4142470586032477e-6, 1.730200900798106e-6, 1.96830930833512e-6, 1.5410509511503255e-6, 1.5537819280262673e-6, 1.3146484819723537e-6, 1.3131110418405425e-6, 1.314324513838462e-6, 1.0003741470033112, 1.6874655292010485e-6, 0.9996276399178022]\n",
      "loss: 1.9384305482608093e38\n",
      "pde_losses: [1.8984447381137713e38, 1.7591734014694528e-7, 1.7797466203176656e-7, 1.8323280142291392e-7]\n",
      "bcs_losses: [1.3357022189350092e-6, 1.4108256905409118e-6, 1.6609700229518973e-6, 1.957396590813193e-6, 1.5384053034392059e-6, 1.5696878816690738e-6, 1.3275299937063245e-6, 1.3306401668407994e-6, 1.3355552527670996e-6, 1.000357854984811, 1.6502470197954477e-6, 0.9996439083052133]\n",
      "loss: 1.9409062898505197e38\n",
      "pde_losses: [1.957252611491375e38, 1.768688630828031e-7, 1.807815819518176e-7, 1.7619625138717186e-7]\n",
      "bcs_losses: [1.3502408143243982e-6, 1.399999884407155e-6, 1.6258743798563415e-6, 1.941479389539015e-6, 1.5300955734296995e-6, 1.5784780424153214e-6, 1.3602449148510225e-6, 1.3578958970367638e-6, 1.3494446091652016e-6, 1.0003343734523082, 1.6448449236231028e-6, 0.999667432731367]\n",
      "loss: 1.94579423927324e38\n",
      "pde_losses: [1.932521328222336e38, 1.7760503397974869e-7, 1.7877973295987605e-7, 1.7778324991337948e-7]\n",
      "bcs_losses: [1.3199833876880585e-6, 1.3636780011105817e-6, 1.6650153448316078e-6, 1.922932461325237e-6, 1.4989582858637972e-6, 1.5141476097376787e-6, 1.3148208794634847e-6, 1.3165366387682362e-6, 1.3240401385798869e-6, 1.0003621602592796, 1.7319763514353957e-6, 0.99963976346315]\n",
      "loss: 1.9225640649829766e38\n",
      "pde_losses: [1.9115021173780687e38, 1.7987654009477485e-7, 1.7612278781653554e-7, 1.7656981081440217e-7]\n",
      "bcs_losses: [1.3324802695232587e-6, 1.3755361689313018e-6, 1.658596475010398e-6, 1.929262217423172e-6, 1.5170205806947978e-6, 1.5221772934998563e-6, 1.3273747287326007e-6, 1.3203669061443671e-6, 1.3313404810341596e-6, 1.000292841038437, 1.6737695445221694e-6, 0.9997090512160002]\n",
      "loss: 1.93086642170282e38\n",
      "pde_losses: [1.9131948697272136e38, 1.7303386232307212e-7, 1.7599330978636015e-7, 1.8181719099945117e-7]\n",
      "bcs_losses: [1.3654745236010301e-6, 1.3824114157834139e-6, 1.6003527227674057e-6, 1.9500403838806902e-6, 1.5449050264117673e-6, 1.5624357446137585e-6, 1.3621447112903605e-6, 1.3613853077051922e-6, 1.3658487483418019e-6, 1.0002410895555385, 1.6076912858740486e-6, 0.9997607702244299]\n",
      "loss: 1.90236896416107e38\n",
      "pde_losses: [1.904369215448369e38, 1.777566520862154e-7, 1.7623221480964226e-7, 1.758228107295836e-7]\n",
      "bcs_losses: [1.3352654693623985e-6, 1.3981864255163953e-6, 1.6606301384618874e-6, 1.908146054462645e-6, 1.5144564794598445e-6, 1.502846080446766e-6, 1.3241306309111373e-6, 1.3361217346401052e-6, 1.331108682144199e-6, 1.0003617106157305, 1.7036662614179686e-6, 0.9996403224474694]\n",
      "loss: 1.9197751406106283e38\n",
      "pde_losses: [1.9334521839559077e38, 1.8073921376543018e-7, 1.7157284172918017e-7, 1.770261733085896e-7]\n",
      "bcs_losses: [1.3255578476527695e-6, 1.376678595812214e-6, 1.6619267155713432e-6, 1.9197072765926365e-6, 1.5006927861512693e-6, 1.493246832729239e-6, 1.3209931935550193e-6, 1.3257249549917197e-6, 1.32132860555575e-6, 1.0003864483431226, 1.698924332382418e-6, 0.9996156153408637]\n",
      "loss: 1.900298290635145e38\n",
      "pde_losses: [1.924762749321359e38, 1.7438535398603788e-7, 1.784087172047705e-7, 1.7591716853955046e-7]\n",
      "bcs_losses: [1.348029960955695e-6, 1.3692800334454953e-6, 1.5902564996170793e-6, 1.941469757762977e-6, 1.5364058381050908e-6, 1.5770582786221628e-6, 1.3353784847988453e-6, 1.3331671844647532e-6, 1.3280974980654361e-6, 1.0003174365955116, 1.6115532836130448e-6, 0.9996845297922391]\n",
      "loss: 1.901764642101772e38\n",
      "pde_losses: [1.9031752283477543e38, 1.7375411062552728e-7, 1.7357461109004e-7, 1.7119054167377722e-7]\n",
      "bcs_losses: [1.3087671335339448e-6, 1.3697290693618576e-6, 1.6168836433214522e-6, 1.9035101883836273e-6, 1.5238644587964955e-6, 1.5315360516834337e-6, 1.2991883224244435e-6, 1.2975719475594626e-6, 1.3043860454631634e-6, 1.0003635647526505, 1.6458548696469577e-6, 0.9996384274706782]\n",
      "loss: 1.906694785799611e38\n",
      "pde_losses: [1.9132439949115075e38, 1.7402878694064128e-7, 1.7105943454185313e-7, 1.711426734847883e-7]\n",
      "bcs_losses: [1.2935934400266863e-6, 1.3627139089110247e-6, 1.635141648533805e-6, 1.8656040407653112e-6, 1.5067649194114243e-6, 1.5111947781668447e-6, 1.2831100524459244e-6, 1.2929484884600101e-6, 1.2886880429444448e-6, 1.0003548630628059, 1.6565848179631836e-6, 0.9996471759161313]\n",
      "loss: 1.8926491159833394e38\n",
      "pde_losses: [1.89060576839796e38, 1.7466295949727218e-7, 1.7374387128556205e-7, 1.7559208852932786e-7]\n",
      "bcs_losses: [1.3127496438549708e-6, 1.3430101603637457e-6, 1.617305403260995e-6, 1.8961641654413947e-6, 1.538339868500803e-6, 1.567697171430559e-6, 1.321386641355788e-6, 1.3086329579875676e-6, 1.3212577328293509e-6, 1.0002731844299424, 1.5637630884800166e-6, 0.999728755720737]\n",
      "loss: 1.870012367464596e38\n",
      "pde_losses: [1.9102797319104627e38, 1.72674695657525e-7, 1.7498186627191916e-7, 1.74966934749503e-7]\n",
      "bcs_losses: [1.3211192009311968e-6, 1.356024550468331e-6, 1.608186188773477e-6, 1.89217582114951e-6, 1.510801212769563e-6, 1.5255953012751257e-6, 1.3259079021893224e-6, 1.3194257405201932e-6, 1.3151002769714122e-6, 1.0002843596292497, 1.5899294069886954e-6, 0.9997176918881516]\n",
      "loss: 1.8672202565227393e38\n",
      "pde_losses: [1.8720972494265406e38, 1.7418860383772497e-7, 1.746773364671414e-7, 1.7380280639389144e-7]\n",
      "bcs_losses: [1.2947613428604148e-6, 1.351589780490944e-6, 1.6398268186114706e-6, 1.8558377765377227e-6, 1.4803140470838104e-6, 1.4716963671159718e-6, 1.303206544314125e-6, 1.3146836093102275e-6, 1.303506500913255e-6, 1.0003909425499415, 1.6858124464910814e-6, 0.999611252516303]\n",
      "loss: 1.8323672670001515e38\n",
      "pde_losses: [1.8772995520487366e38, 1.7101921320885107e-7, 1.6748250496271464e-7, 1.716612905943956e-7]\n",
      "bcs_losses: [1.3122039998956485e-6, 1.352902868476849e-6, 1.5909447724209706e-6, 1.873022547711033e-6, 1.4713118883117053e-6, 1.5033968513937928e-6, 1.3269321457352091e-6, 1.3219132528567378e-6, 1.3145058363241066e-6, 1.0003705918655714, 1.6523767731290342e-6, 0.9996314626229961]\n",
      "loss: 1.8602770151246833e38\n",
      "pde_losses: [1.8546612588893952e38, 1.7353529912868648e-7, 1.7306760832261093e-7, 1.7263989860423105e-7]\n",
      "bcs_losses: [1.31273322150714e-6, 1.357904634543878e-6, 1.5893372944604765e-6, 1.8587789759412683e-6, 1.4658967366233725e-6, 1.5015159432626838e-6, 1.3170293325019146e-6, 1.3096656920769013e-6, 1.3077177236108512e-6, 1.000351904340572, 1.6400364755554302e-6, 0.999649909966758]\n",
      "loss: 1.8687182468162908e38\n",
      "pde_losses: [1.8768491536543713e38, 1.7050228611859523e-7, 1.7322088656481136e-7, 1.6902115415836866e-7]\n",
      "bcs_losses: [1.2784438862532257e-6, 1.3474154124061028e-6, 1.5945862361698307e-6, 1.8554851129663833e-6, 1.4777894723637977e-6, 1.4815867218369464e-6, 1.2830832607946527e-6, 1.283330254071633e-6, 1.291287274913653e-6, 1.000333336152354, 1.6530413597574333e-6, 0.9996683470792462]\n",
      "loss: 1.8754616403605263e38\n",
      "pde_losses: [1.8810674581167016e38, 1.7049311211445035e-7, 1.7176847336306133e-7, 1.7048411050958586e-7]\n",
      "bcs_losses: [1.2694795098197538e-6, 1.3338202270274007e-6, 1.6058549744933337e-6, 1.8934465745975442e-6, 1.503254717721339e-6, 1.5296065791312892e-6, 1.280976782726786e-6, 1.2754187952483121e-6, 1.287973327154374e-6, 1.000262665587194, 1.6099916669664348e-6, 0.9997387793213892]\n",
      "loss: 1.852927612083815e38\n",
      "pde_losses: [1.8439500114567368e38, 1.6614504193145092e-7, 1.687702059367689e-7, 1.75486071313643e-7]\n",
      "bcs_losses: [1.2811177739020491e-6, 1.3341673860975985e-6, 1.5840923467571672e-6, 1.8859844941545912e-6, 1.4974679307384414e-6, 1.5261536018700191e-6, 1.275333588044442e-6, 1.2833206375501916e-6, 1.2803477453678858e-6, 1.0002746864476029, 1.595693337272511e-6, 0.9997267090345229]\n",
      "loss: 1.8685023731940875e38\n",
      "pde_losses: [1.8529656456837585e38, 1.7042691279313666e-7, 1.743335328997708e-7, 1.7289205035348504e-7]\n",
      "bcs_losses: [1.2946532327235915e-6, 1.336172195245667e-6, 1.6086518556911657e-6, 1.8532392831867218e-6, 1.4726002769825974e-6, 1.4726512146806682e-6, 1.2784258779104366e-6, 1.2901008082716165e-6, 1.2878049210750638e-6, 1.0003581830839599, 1.6286946075948062e-6, 0.9996432499095956]\n",
      "loss: 1.8509638723708393e38\n",
      "pde_losses: [1.836502760160845e38, 1.6958451565218258e-7, 1.7077765745457473e-7, 1.6875611729633705e-7]\n",
      "bcs_losses: [1.297009649023737e-6, 1.3398096647693788e-6, 1.5948930358475151e-6, 1.8544276302978427e-6, 1.469140644167642e-6, 1.4711372523617625e-6, 1.282657410460566e-6, 1.2838224025293097e-6, 1.28025425240376e-6, 1.0003769342039164, 1.6325053624280672e-6, 0.9996244525753861]\n",
      "loss: 1.847839788479339e38\n",
      "pde_losses: [1.840703800278696e38, 1.6877253291677083e-7, 1.6929336702054882e-7, 1.7132034365103903e-7]\n",
      "bcs_losses: [1.2787813119675232e-6, 1.3041012205777215e-6, 1.6006078906532776e-6, 1.8579149468675195e-6, 1.4597785101838974e-6, 1.5027892635081621e-6, 1.2760955461476407e-6, 1.2780863574895173e-6, 1.2814327027922485e-6, 1.0003285032054925, 1.593291953368084e-6, 0.9996727291505321]\n",
      "loss: 1.830637215131968e38\n",
      "pde_losses: [1.8481001950432003e38, 1.6634044268835568e-7, 1.683587080472306e-7, 1.7174420167020555e-7]\n",
      "bcs_losses: [1.2818125653597217e-6, 1.3212188966022153e-6, 1.5673408801660535e-6, 1.8392133237424306e-6, 1.4631842756650907e-6, 1.4805686561099306e-6, 1.2845971073004281e-6, 1.283969228863188e-6, 1.2811611067154888e-6, 1.0003194518811207, 1.5842214794121833e-6, 0.9996816687710368]\n",
      "loss: 1.8286325473833435e38\n",
      "pde_losses: [1.8402749122076953e38, 1.6870878924036713e-7, 1.675049509509151e-7, 1.7262804969998347e-7]\n",
      "bcs_losses: [1.2733882136082102e-6, 1.3236024538269026e-6, 1.5932088790950722e-6, 1.8118897386759852e-6, 1.4530778961774746e-6, 1.4353088072849363e-6, 1.274103963456236e-6, 1.266992948426481e-6, 1.2717903585732876e-6, 1.0003523194569137, 1.641058093670774e-6, 0.9996486836375261]\n",
      "loss: 1.8395315703838953e38\n",
      "pde_losses: [1.820479778203447e38, 1.6366200575882827e-7, 1.6824221357986108e-7, 1.6822379414202165e-7]\n",
      "bcs_losses: [1.2688865012249574e-6, 1.3093897458252012e-6, 1.5801554046258702e-6, 1.847209800318411e-6, 1.464752006674869e-6, 1.457876770857789e-6, 1.271149812284797e-6, 1.2682450506924002e-6, 1.2660741643403198e-6, 1.0003048503924026, 1.6231315235897682e-6, 0.9996959328580592]\n",
      "loss: 1.8498127026159613e38\n",
      "pde_losses: [1.8335251336861784e38, 1.6571071856501637e-7, 1.6540274917252818e-7, 1.685372524561038e-7]\n",
      "bcs_losses: [1.256276608496535e-6, 1.2967964994734272e-6, 1.563505385855603e-6, 1.8874005037848575e-6, 1.4727382690219844e-6, 1.5023824070818522e-6, 1.2592080212599014e-6, 1.2554515245674841e-6, 1.2712179342143227e-6, 1.0002690225179172, 1.59960650145825e-6, 0.9997316288650048]\n",
      "loss: 1.8137084066115097e38\n",
      "pde_losses: [1.843112087300115e38, 1.6894716033926863e-7, 1.65748396456385e-7, 1.6717174423996116e-7]\n",
      "bcs_losses: [1.2525504270590417e-6, 1.312587341472504e-6, 1.6027237077744988e-6, 1.8549728186696097e-6, 1.416892792381537e-6, 1.4278519485763194e-6, 1.2491707062343199e-6, 1.2511371211780752e-6, 1.246777487384064e-6, 1.0003817075530583, 1.6724018884329062e-6, 0.9996188455570711]\n",
      "loss: 1.816116394218849e38\n",
      "pde_losses: [1.8181415044553946e38, 1.6738643523649541e-7, 1.6487398416059548e-7, 1.6503432002631132e-7]\n",
      "bcs_losses: [1.2775842502306332e-6, 1.3390482471224674e-6, 1.5571223133795671e-6, 1.8258272544004678e-6, 1.4259381497105384e-6, 1.4215367416827791e-6, 1.2749846600665602e-6, 1.2759245688867259e-6, 1.2763562320029068e-6, 1.000409498695122, 1.6509167881994556e-6, 0.9995908286010904]\n",
      "loss: 1.8095954537864147e38\n",
      "pde_losses: [1.7995535308067818e38, 1.6956490946965585e-7, 1.6462553549474405e-7, 1.6810752578886138e-7]\n",
      "bcs_losses: [1.2718351744663574e-6, 1.2907220398531538e-6, 1.5284695787891997e-6, 1.8333421702972257e-6, 1.42729585468935e-6, 1.4590318786353566e-6, 1.2700178060997302e-6, 1.2710993514040837e-6, 1.2812125621702307e-6, 1.0002981398090314, 1.5727343989690275e-6, 0.999701990383025]\n",
      "loss: 1.7907856029362648e38\n",
      "pde_losses: [1.805051440355303e38, 1.671369605610146e-7, 1.6307592852092908e-7, 1.6577096781619364e-7]\n",
      "bcs_losses: [1.2255205979871678e-6, 1.2480558054712693e-6, 1.5873510260111381e-6, 1.8133956538961957e-6, 1.4501848522991365e-6, 1.4644822816565125e-6, 1.2301537243609512e-6, 1.2301911713499321e-6, 1.2221015481393647e-6, 1.0002663511821388, 1.6017320205782884e-6, 0.9997337715408421]\n",
      "loss: 1.8087345063926503e38\n",
      "pde_losses: [1.814454107671392e38, 1.634595661728995e-7, 1.6799569598510916e-7, 1.6653379115127078e-7]\n",
      "bcs_losses: [1.2317745614297025e-6, 1.2561402128270175e-6, 1.5716123629033082e-6, 1.7872783809431601e-6, 1.4358263574190722e-6, 1.4283072637442622e-6, 1.2414645226032543e-6, 1.2429247197915324e-6, 1.232691355609799e-6, 1.0002956654111033, 1.6100462812286132e-6, 0.999704473100197]\n",
      "loss: 1.7846052054907933e38\n",
      "pde_losses: [1.804855520868005e38, 1.6594393666368372e-7, 1.6364818677079847e-7, 1.6400343350359677e-7]\n",
      "bcs_losses: [1.270797957574187e-6, 1.3079077983068476e-6, 1.5327947045073687e-6, 1.7993482483480812e-6, 1.4110389309930878e-6, 1.43044231850757e-6, 1.2745269062358504e-6, 1.2790958581751268e-6, 1.2807556614704608e-6, 1.0003235104028878, 1.5872752506591477e-6, 0.9996766585658252]\n",
      "loss: 1.7859829390146147e38\n",
      "pde_losses: [1.7951547590100504e38, 1.6711456417261457e-7, 1.6245033716276864e-7, 1.6436486034778773e-7]\n",
      "bcs_losses: [1.265225244280048e-6, 1.3133480813219058e-6, 1.548504163879939e-6, 1.8144420278357497e-6, 1.4127116264418442e-6, 1.41561473429939e-6, 1.2520024015592325e-6, 1.2691763715675671e-6, 1.2623773678349307e-6, 1.0003652377026677, 1.6201811719068171e-6, 0.9996351490538707]\n",
      "loss: 1.8242960597307277e38\n",
      "pde_losses: [1.7981146134614308e38, 1.6367436339446537e-7, 1.645934529851755e-7, 1.6448957476677652e-7]\n",
      "bcs_losses: [1.228399780151349e-6, 1.2765101517266624e-6, 1.5767715717186996e-6, 1.8238506814199756e-6, 1.4123910153044634e-6, 1.4245593415524386e-6, 1.220555650695123e-6, 1.226066359302293e-6, 1.2285987825974198e-6, 1.000379475252593, 1.6510171166371977e-6, 0.9996210987391132]\n",
      "loss: 1.791824822361807e38\n",
      "pde_losses: [1.79926412343212e38, 1.6354868298322098e-7, 1.6356934586386533e-7, 1.6286403893428817e-7]\n",
      "bcs_losses: [1.2487566410647482e-6, 1.2615611834997764e-6, 1.5269136334707533e-6, 1.8160985186832653e-6, 1.4161292753398117e-6, 1.4670817677808e-6, 1.2507810212133172e-6, 1.2445114123780871e-6, 1.2426226134176937e-6, 1.0003294709277413, 1.565860837009694e-6, 0.9996711186228318]\n",
      "loss: 1.769871997743927e38\n",
      "pde_losses: [1.783558289844983e38, 1.653412254177492e-7, 1.6605544384135778e-7, 1.6610690330716484e-7]\n",
      "bcs_losses: [1.2489607918575844e-6, 1.2745940123461855e-6, 1.5080133224656725e-6, 1.7668877792071595e-6, 1.4236846907463633e-6, 1.4346335202780951e-6, 1.2513795193452328e-6, 1.257273544802156e-6, 1.2523912406077797e-6, 1.0003571393229675, 1.56467444855678e-6, 0.9996436064081713]\n",
      "loss: 1.7881915072344835e38\n",
      "pde_losses: [1.7752602594874876e38, 1.6027885741069074e-7, 1.6457736454134074e-7, 1.6503472798111565e-7]\n",
      "bcs_losses: [1.2455033105358033e-6, 1.2932582547032082e-6, 1.5264293969715477e-6, 1.7329069981725823e-6, 1.4113863228549903e-6, 1.3941487209838712e-6, 1.2360980331952643e-6, 1.2465453236432392e-6, 1.2417491676735065e-6, 1.0003878376684538, 1.6091527574784184e-6, 0.9996130334833889]\n",
      "loss: 1.762021095317623e38\n",
      "pde_losses: [1.785447013734657e38, 1.6227640461977427e-7, 1.5967949340408667e-7, 1.6030146862989018e-7]\n",
      "bcs_losses: [1.237433170147969e-6, 1.2601363203157424e-6, 1.5015291107949765e-6, 1.7763128382923465e-6, 1.4318724189449918e-6, 1.4467856541988915e-6, 1.2337789569370379e-6, 1.2391113264733554e-6, 1.2341859076379117e-6, 1.0002686777736916, 1.527276357351599e-6, 0.9997321879210996]\n",
      "loss: 1.7642793196213764e38\n",
      "pde_losses: [1.772357895090353e38, 1.6095425160265344e-7, 1.6289229180439204e-7, 1.6136953088270215e-7]\n",
      "bcs_losses: [1.2225237458627867e-6, 1.2287934475341208e-6, 1.5373308450026398e-6, 1.7704954612154062e-6, 1.4167599645881612e-6, 1.4560022293833587e-6, 1.2173281277686636e-6, 1.2221196076802824e-6, 1.2213840655725318e-6, 1.000252415474289, 1.5361078505094675e-6, 0.9997486270502103]\n",
      "loss: 1.7808758369973763e38\n",
      "pde_losses: [1.7549872606813488e38, 1.6035763651335982e-7, 1.6261109063836477e-7, 1.6291847688125732e-7]\n",
      "bcs_losses: [1.214711458347316e-6, 1.255483095998041e-6, 1.5636509097832824e-6, 1.77050197115641e-6, 1.3952354593668142e-6, 1.3854767583017342e-6, 1.2156991068894341e-6, 1.2162876458837854e-6, 1.2213799989801632e-6, 1.0003738868050418, 1.6358464321233879e-6, 0.9996273601420999]\n",
      "loss: 1.7687874525935395e38\n",
      "pde_losses: [1.747720098463491e38, 1.6326543578740544e-7, 1.6100455202873725e-7, 1.6331770965265912e-7]\n",
      "bcs_losses: [1.2550129348974439e-6, 1.2703742619671865e-6, 1.5021319126136386e-6, 1.7709242148307422e-6, 1.3861079268593688e-6, 1.4225436629635651e-6, 1.2537452417072628e-6, 1.2535957553855642e-6, 1.257532200115878e-6, 1.0003500019973703, 1.5756279353405534e-6, 0.9996511782433263]\n",
      "loss: 1.754744831922841e38\n",
      "pde_losses: [1.7555035915522803e38, 1.6307279702228e-7, 1.6094872752340433e-7, 1.6137285262339827e-7]\n",
      "bcs_losses: [1.2312085537990504e-6, 1.2518450672474786e-6, 1.4992416286246917e-6, 1.759064770020583e-6, 1.381959308517947e-6, 1.401533750273447e-6, 1.2265562837358715e-6, 1.2243380210053478e-6, 1.2380594114803603e-6, 1.000351820237999, 1.592017402412571e-6, 0.9996493128624184]\n",
      "loss: 1.763717036287254e38\n",
      "pde_losses: [1.775781855752042e38, 1.6137013864126211e-7, 1.6385477372085752e-7, 1.5602581918854909e-7]\n",
      "bcs_losses: [1.192479831849245e-6, 1.2349345716209818e-6, 1.5550332358281931e-6, 1.766373311359698e-6, 1.3763636222283222e-6, 1.3751441645970709e-6, 1.195211577731118e-6, 1.197212032262796e-6, 1.2002641593528687e-6, 1.0003488738579223, 1.6300119496600946e-6, 0.9996522204770614]\n",
      "loss: 1.7273919923059848e38\n",
      "pde_losses: [1.7445227093822045e38, 1.5927768985345914e-7, 1.6091408787456094e-7, 1.5966474444491154e-7]\n",
      "bcs_losses: [1.2195329751669589e-6, 1.234770754540153e-6, 1.522547633854687e-6, 1.7677450815098732e-6, 1.378879556462917e-6, 1.4052776429151163e-6, 1.2194503767243855e-6, 1.219508142274545e-6, 1.211936269549832e-6, 1.0002847475932506, 1.5585193606330675e-6, 0.9997161645345685]\n",
      "loss: 1.762082149354459e38\n",
      "pde_losses: [1.7424047362808453e38, 1.5757667915356467e-7, 1.634151968545789e-7, 1.5944138974470148e-7]\n",
      "bcs_losses: [1.2532953296018525e-6, 1.2752066111329683e-6, 1.4609689944193353e-6, 1.7496122506563484e-6, 1.390687414232834e-6, 1.388220294737048e-6, 1.2507820880124838e-6, 1.251593880156078e-6, 1.2531648963555288e-6, 1.0003112050604623, 1.5619037897065213e-6, 0.9996897619034385]\n",
      "loss: 1.7319318796930104e38\n",
      "pde_losses: [1.7298710827642833e38, 1.580745168950176e-7, 1.6160782218034297e-7, 1.5918678346644904e-7]\n",
      "bcs_losses: [1.226170201257399e-6, 1.2598070346555585e-6, 1.5226542868386285e-6, 1.7208136050679918e-6, 1.36073593906502e-6, 1.3267422967345576e-6, 1.2278266234229397e-6, 1.2253027794495131e-6, 1.23104205181578e-6, 1.000408973438564, 1.6541586678561579e-6, 0.9995921155320172]\n",
      "loss: 1.73800755235185e38\n",
      "pde_losses: [1.731816367417238e38, 1.5928542682419098e-7, 1.5821273231539594e-7, 1.5733108728108983e-7]\n",
      "bcs_losses: [1.2209725574759136e-6, 1.2224219839777013e-6, 1.4848098900159484e-6, 1.7606944872660674e-6, 1.3924458051973786e-6, 1.3987749677680577e-6, 1.2143989512442596e-6, 1.2105596896003946e-6, 1.2175842626282044e-6, 1.0003043507005325, 1.5440534813346327e-6, 0.9996965670576868]\n",
      "loss: 1.732210317955529e38\n",
      "pde_losses: [1.7289267884393933e38, 1.5432234605954335e-7, 1.580114111101697e-7, 1.5694959873215237e-7]\n",
      "bcs_losses: [1.2231959849852563e-6, 1.2069332829874162e-6, 1.4831332530761695e-6, 1.7612453065487914e-6, 1.3885259096814448e-6, 1.422407163915007e-6, 1.2141502087587636e-6, 1.2251182350655954e-6, 1.2160316967953733e-6, 1.0003094543989115, 1.5256884459648378e-6, 0.9996913310250795]\n",
      "loss: 1.732263136546246e38\n",
      "pde_losses: [1.7584018219087813e38, 1.5723844531377737e-7, 1.5768965596136228e-7, 1.5825591031608911e-7]\n",
      "bcs_losses: [1.1964854897901673e-6, 1.239333355604942e-6, 1.51241720760305e-6, 1.724832426797612e-6, 1.371515223629824e-6, 1.337772608735435e-6, 1.2021372565514802e-6, 1.199363934104558e-6, 1.2022463723860863e-6, 1.0004180921238324, 1.6051107857697752e-6, 0.9995826347131102]\n",
      "loss: 1.721097338344955e38\n",
      "pde_losses: [1.713235300922934e38, 1.5684325239022285e-7, 1.5695866688838462e-7, 1.5886861329322189e-7]\n",
      "bcs_losses: [1.2036059032613428e-6, 1.2267599054540558e-6, 1.5068664402401378e-6, 1.7242847407925144e-6, 1.3811369266664888e-6, 1.371814325821142e-6, 1.206417548177894e-6, 1.2080723624285312e-6, 1.2081742128764042e-6, 1.0003352853062504, 1.5294065124489673e-6, 0.9996650553642095]\n",
      "loss: 1.712952113576322e38\n",
      "pde_losses: [1.7112786896205727e38, 1.5936559950432866e-7, 1.5830579264535485e-7, 1.5438452862426032e-7]\n",
      "bcs_losses: [1.1802469164348964e-6, 1.1936295010866911e-6, 1.4867160117161776e-6, 1.7331304512801814e-6, 1.3974853766498412e-6, 1.404475913344749e-6, 1.1856727667421284e-6, 1.1869407421021827e-6, 1.186012047553104e-6, 1.000279225797277, 1.5275659278909497e-6, 0.999720897322466]\n",
      "loss: 1.733501510372416e38\n",
      "pde_losses: [1.6897158440259444e38, 1.561921141197206e-7, 1.5714775529807003e-7, 1.5894132586376572e-7]\n",
      "bcs_losses: [1.1694609202623427e-6, 1.189872998388406e-6, 1.5130948984895006e-6, 1.7298395658055916e-6, 1.379485075205839e-6, 1.3586325449636951e-6, 1.1666589877874533e-6, 1.1703469244551506e-6, 1.1767324636352542e-6, 1.0003147257012568, 1.5826296879099026e-6, 0.9996853468364563]\n",
      "loss: 1.6960993919959059e38\n",
      "pde_losses: [1.711769586783724e38, 1.531247857293927e-7, 1.5330473043644297e-7, 1.5948117497779103e-7]\n",
      "bcs_losses: [1.2016105013673585e-6, 1.222905941782409e-6, 1.4734324380957464e-6, 1.7053452100436793e-6, 1.3506015511302873e-6, 1.3526347631419585e-6, 1.1914492927947738e-6, 1.198573805047146e-6, 1.1996037466565595e-6, 1.0003428843449935, 1.5695448705036694e-6, 0.9996570648979184]\n",
      "loss: 1.694334277384771e38\n",
      "pde_losses: [1.7228833226278512e38, 1.5391505966142237e-7, 1.5361868412742333e-7, 1.54408814186945e-7]\n",
      "bcs_losses: [1.2245833954818166e-6, 1.2319267940449743e-6, 1.4480528476377075e-6, 1.7249155227873866e-6, 1.35170047363301e-6, 1.3494945437236331e-6, 1.220102613654106e-6, 1.2229807510352465e-6, 1.2155095784056494e-6, 1.0003362031671437, 1.5443962187196687e-6, 0.9996636391669871]\n",
      "loss: 1.7215054418880466e38\n",
      "pde_losses: [1.6852333596052854e38, 1.5702149334596505e-7, 1.5517294158779757e-7, 1.5262461021841787e-7]\n",
      "bcs_losses: [1.1897859732234107e-6, 1.2172371322373128e-6, 1.500445722516908e-6, 1.704082115414964e-6, 1.347480843275048e-6, 1.3181265371432015e-6, 1.2001750428664032e-6, 1.1964982415488178e-6, 1.2059509864301846e-6, 1.0003802223297606, 1.598855068444805e-6, 0.9996196462327223]\n",
      "loss: 1.6875061812921181e38\n",
      "pde_losses: [1.6970854820299673e38, 1.5674083472476276e-7, 1.5148158829592448e-7, 1.531818979066951e-7]\n",
      "bcs_losses: [1.2011900737385108e-6, 1.2044900862644089e-6, 1.4663122845612774e-6, 1.7108730206696549e-6, 1.3615376710608381e-6, 1.355975711052289e-6, 1.2025507965970803e-6, 1.1984873327809272e-6, 1.2076336142549174e-6, 1.0003220673234448, 1.5427724601714025e-6, 0.9996777900054852]\n",
      "loss: 1.703407877447931e38\n",
      "pde_losses: [1.6832702238757648e38, 1.5501509373761679e-7, 1.558640123012966e-7, 1.5369354436233898e-7]\n",
      "bcs_losses: [1.1961488575773812e-6, 1.2020551337893954e-6, 1.4369464252251294e-6, 1.7103437956208401e-6, 1.3531105314092507e-6, 1.3592907569191565e-6, 1.1957127465280883e-6, 1.1995548670516438e-6, 1.1932474963798852e-6, 1.0003187900876123, 1.5455818668844525e-6, 0.9996811411450478]\n",
      "loss: 1.6852319241164941e38\n",
      "pde_losses: [1.6903183425734449e38, 1.5379774936312766e-7, 1.538735514791169e-7, 1.5424938899281732e-7]\n",
      "bcs_losses: [1.1568686582421349e-6, 1.1914389944234779e-6, 1.5076601584440175e-6, 1.6857479904429347e-6, 1.3478187139102312e-6, 1.30473576786199e-6, 1.1587056538141487e-6, 1.1527998770711843e-6, 1.158166672932357e-6, 1.000389177539792, 1.6248310994096225e-6, 0.9996109161674076]\n",
      "loss: 1.690522784153148e38\n",
      "pde_losses: [1.6908310573236582e38, 1.5305874921887563e-7, 1.5544002708293968e-7, 1.5235057563437996e-7]\n",
      "bcs_losses: [1.1774753212157682e-6, 1.1865967928379477e-6, 1.4587779391589148e-6, 1.6854866443808726e-6, 1.3480654503830934e-6, 1.3485805376498571e-6, 1.1663881027357025e-6, 1.1711154752601831e-6, 1.1753666382886135e-6, 1.000320649846868, 1.510007064445852e-6, 0.9996792463322638]\n",
      "loss: 1.6624822499768e38\n",
      "pde_losses: [1.697104545594635e38, 1.4922237207819145e-7, 1.534660486264968e-7, 1.5545197890239852e-7]\n",
      "bcs_losses: [1.1749500880450778e-6, 1.1767122338049753e-6, 1.4626913787954735e-6, 1.6919746812540396e-6, 1.3654657412102514e-6, 1.4015377069929418e-6, 1.1733223291791554e-6, 1.1661180787779535e-6, 1.1773465168308679e-6, 1.0002626531061, 1.4408061104481577e-6, 0.9997371601169414]\n",
      "loss: 1.7157285705245647e38\n",
      "pde_losses: [1.6687581294393063e38, 1.5154448715961618e-7, 1.5372377847940013e-7, 1.5542154079209815e-7]\n",
      "bcs_losses: [1.1639394788974245e-6, 1.1828396936718104e-6, 1.506278508174274e-6, 1.6625336365210883e-6, 1.3411376590978817e-6, 1.3069332224004994e-6, 1.1519250929359186e-6, 1.1545723169556875e-6, 1.1606500439283495e-6, 1.0003953857920025, 1.5659592163943061e-6, 0.9996045768963977]\n",
      "loss: 1.6715283666621677e38\n",
      "pde_losses: [1.6822901368951405e38, 1.5538944429106126e-7, 1.5138223699907817e-7, 1.5300475242944482e-7]\n",
      "bcs_losses: [1.1810382918324573e-6, 1.200865788339224e-6, 1.4280220463661665e-6, 1.6898590786736213e-6, 1.3147301303288768e-6, 1.315002504813036e-6, 1.1899296989883485e-6, 1.1927058826769606e-6, 1.1807574226469702e-6, 1.0003645322204202, 1.5363938919442645e-6, 0.999635428115148]\n",
      "loss: 1.6708177312516861e38\n",
      "pde_losses: [1.6760218928383013e38, 1.536861612426661e-7, 1.5340440837493388e-7, 1.4985589788251618e-7]\n",
      "bcs_losses: [1.196256450895876e-6, 1.2067883977353855e-6, 1.4174274969538349e-6, 1.6955580783890347e-6, 1.314904693352751e-6, 1.3178239003457658e-6, 1.1994398171686763e-6, 1.2006691943437125e-6, 1.2057221565030508e-6, 1.0003308141561744, 1.5722685516083066e-6, 0.9996693000481338]\n",
      "loss: 1.690406877754939e38\n",
      "pde_losses: [1.6510482002029382e38, 1.5026788007588147e-7, 1.52920728618973e-7, 1.551800752214245e-7]\n",
      "bcs_losses: [1.1493861192061243e-6, 1.1704811940193244e-6, 1.4938424664727808e-6, 1.7154574884436126e-6, 1.317465327328676e-6, 1.2915791484667611e-6, 1.150992514363296e-6, 1.1455157693841883e-6, 1.1446954608479853e-6, 1.0003464575202001, 1.6459759220572684e-6, 0.9996539048562099]\n",
      "loss: 1.6439766049745184e38\n",
      "pde_losses: [1.652652387833355e38, 1.5270500672159386e-7, 1.5385853578363775e-7, 1.5171514718191841e-7]\n",
      "bcs_losses: [1.1710823250200643e-6, 1.1678076522300926e-6, 1.4301756502154691e-6, 1.6875603899477256e-6, 1.3232620419137537e-6, 1.320439489925406e-6, 1.1595554929517019e-6, 1.1595932208719737e-6, 1.1611389043191047e-6, 1.0002957434783672, 1.5433040830290604e-6, 0.9997045781657736]\n",
      "loss: 1.6164560925040875e38\n",
      "pde_losses: [1.6563945982771628e38, 1.5139141481160701e-7, 1.5588232163825986e-7, 1.510540673206725e-7]\n",
      "bcs_losses: [1.1853937140889804e-6, 1.1919825410530017e-6, 1.4166097134470239e-6, 1.6518757732485257e-6, 1.330266350226611e-6, 1.340549620743516e-6, 1.1813414369970204e-6, 1.178078562854161e-6, 1.1802442349931731e-6, 1.0003064881410628, 1.4819403729820213e-6, 0.9996936946766987]\n",
      "loss: 1.6533367062231382e38\n",
      "pde_losses: [1.6373689173710714e38, 1.5090581419065603e-7, 1.5206041726670797e-7, 1.5253192649358172e-7]\n",
      "bcs_losses: [1.1440514887551163e-6, 1.1695084736378625e-6, 1.4541055924511367e-6, 1.6437365192976207e-6, 1.3134509872106867e-6, 1.3035899578244216e-6, 1.1479633068117442e-6, 1.1493741957560456e-6, 1.1455094990732261e-6, 1.0003873796406069, 1.5203315197594122e-6, 0.9996126845044111]\n",
      "loss: 1.6233694798806767e38\n",
      "pde_losses: [1.6354149698362168e38, 1.5234807242283684e-7, 1.4942801211634543e-7, 1.5085431244959135e-7]\n",
      "bcs_losses: [1.1352438223732896e-6, 1.1386903145829003e-6, 1.4617890566153316e-6, 1.678636747413369e-6, 1.3073626587661754e-6, 1.3381916267206633e-6, 1.1409866506854904e-6, 1.1345419301226518e-6, 1.1345596670683628e-6, 1.0003373150733565, 1.4907143875321251e-6, 0.999662543280284]\n",
      "loss: 1.6349178882246559e38\n",
      "pde_losses: [1.6434166973634822e38, 1.5066064407509398e-7, 1.5206705101240274e-7, 1.4988012244921337e-7]\n",
      "bcs_losses: [1.1532227630136318e-6, 1.1470057935663954e-6, 1.441436723477441e-6, 1.6698355013741633e-6, 1.3058759764139018e-6, 1.330014909174596e-6, 1.1458856047764713e-6, 1.1411836141507573e-6, 1.1485584368375025e-6, 1.0003189495255063, 1.4901482557234421e-6, 0.9996807940953396]\n",
      "loss: 1.6197163497250403e38\n",
      "pde_losses: [1.6471524278319178e38, 1.4827922037824858e-7, 1.5110812810818037e-7, 1.4732455154515238e-7]\n",
      "bcs_losses: [1.1593345275195576e-6, 1.1774834094653932e-6, 1.4496915747919453e-6, 1.6488620291885565e-6, 1.2800862393769775e-6, 1.259032057919624e-6, 1.1556198417914543e-6, 1.1541851287071433e-6, 1.1536959220269618e-6, 1.0003731495333648, 1.5613795595016295e-6, 0.9996265911376424]\n",
      "loss: 1.6611805860860978e38\n",
      "pde_losses: [1.6441754854495801e38, 1.5011918339277542e-7, 1.4745208851009403e-7, 1.4803838116028365e-7]\n",
      "bcs_losses: [1.169814011435646e-6, 1.1634824559760654e-6, 1.4043394991312025e-6, 1.6660687619856485e-6, 1.2950144453241535e-6, 1.2804385962575998e-6, 1.1628493007369407e-6, 1.1560139892889215e-6, 1.1660391194795744e-6, 1.0003138202198951, 1.5382531937360207e-6, 0.9996857874391992]\n",
      "loss: 1.6427628249988175e38\n",
      "pde_losses: [1.630628983554791e38, 1.485639023147678e-7, 1.485235044890058e-7, 1.4974689100764347e-7]\n",
      "bcs_losses: [1.154830950606004e-6, 1.1413058655033855e-6, 1.4079352469097679e-6, 1.6368977404563655e-6, 1.303041423600263e-6, 1.2938613694062749e-6, 1.1514826034934759e-6, 1.1416925524837669e-6, 1.1443579495073842e-6, 1.000283336677961, 1.5145512967704546e-6, 0.9997161576771368]\n",
      "loss: 1.6171584765642641e38\n",
      "pde_losses: [1.6311538670083399e38, 1.4747910550142882e-7, 1.4992625596647284e-7, 1.4771048002748184e-7]\n",
      "bcs_losses: [1.1320348228527543e-6, 1.1298633596188121e-6, 1.43469114009619e-6, 1.6291570850418297e-6, 1.3116156707522361e-6, 1.3025472584012458e-6, 1.1296521240846177e-6, 1.1452402108130712e-6, 1.138774276574622e-6, 1.000313101981567, 1.497716466738012e-6, 0.9996862706847397]\n",
      "loss: 1.6353955294256553e38\n",
      "pde_losses: [1.607733984783536e38, 1.491112791931516e-7, 1.4779374851883327e-7, 1.459074651248847e-7]\n",
      "bcs_losses: [1.1322799439440076e-6, 1.1474248425129173e-6, 1.4325822650183717e-6, 1.6276133547865966e-6, 1.2909125844289414e-6, 1.2942945724163322e-6, 1.1409538279770945e-6, 1.1479467262449921e-6, 1.138248460254665e-6, 1.0003613829936675, 1.4962841395605284e-6, 0.9996379531265118]\n",
      "loss: 1.6067003237383553e38\n",
      "pde_losses: [1.6141308382506165e38, 1.4845920613457866e-7, 1.448598292607729e-7, 1.485552002732839e-7]\n",
      "bcs_losses: [1.1589472585605492e-6, 1.165276090341082e-6, 1.3975449157531416e-6, 1.6297401606891202e-6, 1.2941692097621677e-6, 1.306368771494728e-6, 1.148812997703114e-6, 1.158836167111335e-6, 1.1482117519449108e-6, 1.0003546114339261, 1.4721115699196974e-6, 0.9996447045059538]\n",
      "loss: 1.6280868779485027e38\n",
      "pde_losses: [1.6137395361959266e38, 1.4965569218337043e-7, 1.485539322953152e-7, 1.4867142589209714e-7]\n",
      "bcs_losses: [1.1314894214491013e-6, 1.1468158429284225e-6, 1.4287763913565172e-6, 1.6308479605198131e-6, 1.2902010690522697e-6, 1.2733070677151006e-6, 1.1360385340157235e-6, 1.1425429958569228e-6, 1.1253057524545456e-6, 1.0003746297914842, 1.5299155078718927e-6, 0.9996248375541146]\n",
      "loss: 1.6050967035455127e38\n",
      "pde_losses: [1.6031710236442912e38, 1.4238593693075982e-7, 1.4816538296001302e-7, 1.4929414742424706e-7]\n",
      "bcs_losses: [1.1269883668157684e-6, 1.13351358118206e-6, 1.4449715777910397e-6, 1.6565376462256791e-6, 1.286079166504928e-6, 1.2790746867821706e-6, 1.1314860589506972e-6, 1.1108414160901854e-6, 1.1264054485583584e-6, 1.0003211220121626, 1.5316819595671724e-6, 0.9996785019154915]\n",
      "loss: 1.623679775360856e38\n",
      "pde_losses: [1.595185834189517e38, 1.4490721416311668e-7, 1.433415783470037e-7, 1.4700456277957745e-7]\n",
      "bcs_losses: [1.1403131430692795e-6, 1.1208170611203501e-6, 1.396321822312598e-6, 1.632075394602575e-6, 1.2907381491249992e-6, 1.291962644062685e-6, 1.1467986365223744e-6, 1.1543496801438485e-6, 1.144294418791853e-6, 1.000278682762184, 1.4938738342781148e-6, 0.999720934204227]\n",
      "loss: 1.5997437169396823e38\n",
      "pde_losses: [1.6085956589090601e38, 1.4639400697352493e-7, 1.4402112784828264e-7, 1.4797571851964887e-7]\n",
      "bcs_losses: [1.1453522518167852e-6, 1.121238245367432e-6, 1.408056121421976e-6, 1.5966868621059017e-6, 1.2739468131094236e-6, 1.2476181791344922e-6, 1.1470657562283223e-6, 1.135357401675121e-6, 1.1275179367549675e-6, 1.000339984032808, 1.5135184837188837e-6, 0.9996597462632977]\n",
      "loss: 1.5775675198524355e38\n",
      "pde_losses: [1.5931331088119822e38, 1.465340615618909e-7, 1.4849884130650964e-7, 1.422083116164367e-7]\n",
      "bcs_losses: [1.1282021111684679e-6, 1.108763640020403e-6, 1.402505357490361e-6, 1.5928952176817505e-6, 1.2705502149474885e-6, 1.249073987733634e-6, 1.1302541291652108e-6, 1.1214749646024331e-6, 1.12632886389152e-6, 1.0003469097636448, 1.5025130106610018e-6, 0.9996529517990332]\n",
      "loss: 1.5879542448871842e38\n",
      "pde_losses: [1.5964481647702871e38, 1.4350515784368648e-7, 1.4260658532236012e-7, 1.429798953101065e-7]\n",
      "bcs_losses: [1.1268614489788038e-6, 1.1089001999861497e-6, 1.3857510492855193e-6, 1.604094701036971e-6, 1.2656101414381837e-6, 1.2799054483638029e-6, 1.1263471682319425e-6, 1.1336426313448017e-6, 1.1265715116186301e-6, 1.0003293627238175, 1.4760906494752228e-6, 0.9996705394745933]\n",
      "loss: 1.5652936102101411e38\n",
      "pde_losses: [1.5818439308525475e38, 1.4596092727200858e-7, 1.452349615253493e-7, 1.4464172632056175e-7]\n",
      "bcs_losses: [1.1172304705610239e-6, 1.1223360207249417e-6, 1.3954069510178857e-6, 1.6008133777059167e-6, 1.2547382685213932e-6, 1.256679852263116e-6, 1.124679366458498e-6, 1.1208280111268809e-6, 1.1120707429506656e-6, 1.000353819582351, 1.5029642399764658e-6, 0.9996462603802101]\n",
      "loss: 1.5858587244458284e38\n",
      "pde_losses: [1.5842490583953125e38, 1.424892228789379e-7, 1.437229824701542e-7, 1.427715162072806e-7]\n",
      "bcs_losses: [1.1242639360674886e-6, 1.1210345322899504e-6, 1.3778534447366091e-6, 1.607182556736058e-6, 1.2629584433699077e-6, 1.2610257650434448e-6, 1.1242593548343826e-6, 1.1177748389866122e-6, 1.1233203987570717e-6, 1.000324046461605, 1.5010917311522488e-6, 0.999676147560533]\n",
      "loss: 1.5930355088748123e38\n",
      "pde_losses: [1.5714015002626441e38, 1.4556247711363595e-7, 1.434408894333119e-7, 1.4525556419911883e-7]\n",
      "bcs_losses: [1.1120660223006197e-6, 1.109305270239505e-6, 1.3781691989761947e-6, 1.6311589787463735e-6, 1.2611612793320879e-6, 1.249484947402308e-6, 1.116497648985279e-6, 1.1182321752844765e-6, 1.1214668397420875e-6, 1.0003162187493264, 1.5189676840283261e-6, 0.9996840422993658]\n",
      "loss: 1.5878988895707842e38\n",
      "pde_losses: [1.5645867945358363e38, 1.4410942574739875e-7, 1.4470063280204553e-7, 1.450409653877211e-7]\n",
      "bcs_losses: [1.1107561219894687e-6, 1.1237912493684806e-6, 1.3786722581664712e-6, 1.592941275999285e-6, 1.2360265041509683e-6, 1.2306927528762023e-6, 1.123345142058303e-6, 1.130876114290027e-6, 1.114903805405244e-6, 1.0003657060379227, 1.5469139176977378e-6, 0.9996345682282101]\n",
      "loss: 1.5679982399267532e38\n",
      "pde_losses: [1.5693244450792977e38, 1.4687415683616631e-7, 1.422363080181808e-7, 1.4761341162289873e-7]\n",
      "bcs_losses: [1.1069217638300374e-6, 1.1028397589643016e-6, 1.3878825022235232e-6, 1.572299898657159e-6, 1.2467456543539849e-6, 1.2568576119282954e-6, 1.1022207085888674e-6, 1.103365711938635e-6, 1.1110524299237927e-6, 1.0003346058106386, 1.4882574666624878e-6, 0.999665591565553]\n",
      "loss: 1.5607373623562269e38\n",
      "pde_losses: [1.5742324273029998e38, 1.4494672433392925e-7, 1.3967963710198973e-7, 1.4369695419252118e-7]\n",
      "bcs_losses: [1.1099843363565656e-6, 1.0801963216314147e-6, 1.4027058839545523e-6, 1.591129010542268e-6, 1.2728661927155574e-6, 1.2773620672970036e-6, 1.1021400116522937e-6, 1.1064047712353305e-6, 1.1048134515935219e-6, 1.0003002079027008, 1.427630448199625e-6, 0.9996999238545652]\n",
      "loss: 1.5716811886340212e38\n",
      "pde_losses: [1.5692669649268688e38, 1.4003315428935707e-7, 1.4276685406312616e-7, 1.4449937097596774e-7]\n",
      "bcs_losses: [1.1036223633174512e-6, 1.095517138269335e-6, 1.3938254434683213e-6, 1.567553064913669e-6, 1.2645746014424674e-6, 1.2532760300908202e-6, 1.1123733985025637e-6, 1.1040938368804738e-6, 1.1083898135141433e-6, 1.0003345393025898, 1.4428826176475276e-6, 0.9996655927087816]\n",
      "loss: 1.5735914768143496e38\n",
      "pde_losses: [1.5633696021962922e38, 1.4106863852059875e-7, 1.4347189620229642e-7, 1.4554286851105518e-7]\n",
      "bcs_losses: [1.1244140936811328e-6, 1.1045574947347758e-6, 1.383489605802172e-6, 1.5655529329694184e-6, 1.2309371667692026e-6, 1.2265144842067974e-6, 1.1201445423322551e-6, 1.1234984936387876e-6, 1.1207100634375166e-6, 1.0003595601343518, 1.468495053089438e-6, 0.999640464867905]\n",
      "loss: 1.5603462346699096e38\n",
      "pde_losses: [1.5526933728586235e38, 1.4257679993193077e-7, 1.4298408002857508e-7, 1.4076670284104258e-7]\n",
      "bcs_losses: [1.1140254030167772e-6, 1.1000849778431759e-6, 1.3711849826960631e-6, 1.5954600697539342e-6, 1.2562732249402267e-6, 1.2440456503046823e-6, 1.1096385314591717e-6, 1.1164015614741081e-6, 1.1101121084190603e-6, 1.0003150733514494, 1.481839904654199e-6, 0.9996847833111587]\n",
      "loss: 1.5686934379545123e38\n",
      "pde_losses: [1.5468112983199002e38, 1.4111585992531896e-7, 1.4198303858294185e-7, 1.429617080233663e-7]\n",
      "bcs_losses: [1.0884018443851573e-6, 1.0773816283399233e-6, 1.3846778207210178e-6, 1.6043035167987564e-6, 1.2420276535640093e-6, 1.2282243783379482e-6, 1.0907482258564269e-6, 1.0939725802932162e-6, 1.0855179962682563e-6, 1.0003149719203444, 1.5312796996312384e-6, 0.9996847780153921]\n",
      "loss: 1.5344197604954042e38\n",
      "pde_losses: [1.5513692381383498e38, 1.3923462458408893e-7, 1.433776339178556e-7, 1.4077962465129796e-7]\n",
      "bcs_losses: [1.0883460286221731e-6, 1.0772933687865242e-6, 1.3647420679473691e-6, 1.5709401872769817e-6, 1.2414103436996662e-6, 1.2261048703874973e-6, 1.089571538132044e-6, 1.0879974318353739e-6, 1.0868617042732193e-6, 1.0003250479700219, 1.5044284638746928e-6, 0.999674543078466]\n",
      "loss: 1.5358730415045836e38\n",
      "pde_losses: [1.5609988704292197e38, 1.426012458752738e-7, 1.3875170551370292e-7, 1.4204785179903238e-7]\n",
      "bcs_losses: [1.1089674866019938e-6, 1.0982595902741222e-6, 1.3263957134312875e-6, 1.566830006155149e-6, 1.2380579406173317e-6, 1.2279056254314086e-6, 1.1172800669789348e-6, 1.1178231783041013e-6, 1.1123007955336879e-6, 1.0003319928366108, 1.4653364926842142e-6, 0.9996673748370778]\n",
      "loss: 1.5438859181002498e38\n",
      "pde_losses: [1.556074809543806e38, 1.3911321719904126e-7, 1.4096077794973794e-7, 1.398572099922016e-7]\n",
      "bcs_losses: [1.1095356045292458e-6, 1.1027656758346832e-6, 1.3676074458740953e-6, 1.5618839819416777e-6, 1.23589252102822e-6, 1.2030839063174172e-6, 1.1064251798530535e-6, 1.1029529778895386e-6, 1.094603015975529e-6, 1.0003728143479453, 1.4852771643927693e-6, 0.9996264362696469]\n",
      "loss: 1.565929080814972e38\n",
      "pde_losses: [1.562302305418116e38, 1.3851879529200706e-7, 1.4059890952879615e-7, 1.395025414387176e-7]\n",
      "bcs_losses: [1.0786894276203926e-6, 1.0658907036607317e-6, 1.377173822145739e-6, 1.5641899546638548e-6, 1.238282290155394e-6, 1.2291839455357042e-6, 1.0874225375528026e-6, 1.0842672232036807e-6, 1.0976694136658488e-6, 1.0003229135968557, 1.461094339286864e-6, 0.9996763144642682]\n",
      "loss: 1.5405054506343658e38\n",
      "pde_losses: [1.5399359911791156e38, 1.4174818386452723e-7, 1.3876116003111473e-7, 1.3833517046834488e-7]\n",
      "bcs_losses: [1.0902239672209396e-6, 1.0669015813394684e-6, 1.355495187702023e-6, 1.5407503855885859e-6, 1.2466726283603216e-6, 1.237640550804538e-6, 1.0988436465228204e-6, 1.097510363434011e-6, 1.0914492643391713e-6, 1.000298682706521, 1.4451207625170737e-6, 0.9997006236318529]\n",
      "loss: 1.5366175773510005e38\n",
      "pde_losses: [1.5329860014039387e38, 1.366731499360788e-7, 1.4008604829103837e-7, 1.3737578176638837e-7]\n",
      "bcs_losses: [1.0902939853978663e-6, 1.0824670586204192e-6, 1.3631288230879963e-6, 1.5279929386937577e-6, 1.217445557792313e-6, 1.1874179046828e-6, 1.0880915316446214e-6, 1.093659481035353e-6, 1.0895474813861141e-6, 1.0003808148833724, 1.5036250705100733e-6, 0.9996186557013196]\n",
      "loss: 1.522442202537745e38\n",
      "pde_losses: [1.5272197667733317e38, 1.3647210804904906e-7, 1.3996239263923362e-7, 1.3847197510472584e-7]\n",
      "bcs_losses: [1.1014965293995814e-6, 1.094013412431661e-6, 1.3492373045954514e-6, 1.5427835177769974e-6, 1.2181110444462077e-6, 1.205159758640547e-6, 1.0945531076698835e-6, 1.0987369896035205e-6, 1.0939568449332477e-6, 1.0003669156261434, 1.4825367498563808e-6, 0.9996325741834475]\n",
      "loss: 1.5121664468321501e38\n",
      "pde_losses: [1.507650912353031e38, 1.3699686850545975e-7, 1.394478857399196e-7, 1.399460201620713e-7]\n",
      "bcs_losses: [1.0709899623878608e-6, 1.0709394296306888e-6, 1.3412283713443512e-6, 1.552095733629093e-6, 1.2415827117110153e-6, 1.2375411961161877e-6, 1.0781651829632425e-6, 1.0809199514724076e-6, 1.0831490667246182e-6, 1.0003063458164705, 1.4428686826238481e-6, 0.9996931981678943]\n",
      "loss: 1.5329495961530003e38\n",
      "pde_losses: [1.5328202820226187e38, 1.3730431089034956e-7, 1.3985735952556842e-7, 1.4057519534780099e-7]\n",
      "bcs_losses: [1.0754701331447754e-6, 1.0622489940357071e-6, 1.3720483288397768e-6, 1.5449522928575942e-6, 1.2334702910342481e-6, 1.2115589592838952e-6, 1.0731685631467126e-6, 1.067450947428853e-6, 1.0685246075661444e-6, 1.0003287394758185, 1.4615530262046397e-6, 0.9996708396656555]\n",
      "loss: 1.5275791350214266e38\n",
      "pde_losses: [1.521212672998948e38, 1.3504353957075197e-7, 1.375247782485933e-7, 1.3559736969200989e-7]\n",
      "bcs_losses: [1.087838642902835e-6, 1.0724338425688877e-6, 1.332238011336286e-6, 1.5161461753980319e-6, 1.2199621302034012e-6, 1.1779427006190067e-6, 1.0863972248688826e-6, 1.0738509606836521e-6, 1.0837909271919033e-6, 1.0003382097683642, 1.4633098649181761e-6, 0.9996613489093245]\n",
      "loss: 1.5164363114288088e38\n",
      "pde_losses: [1.5224836645003296e38, 1.3787726625057466e-7, 1.3996189776581444e-7, 1.3746234187028544e-7]\n",
      "bcs_losses: [1.0997164856658007e-6, 1.0743982977521076e-6, 1.3124561167477249e-6, 1.5099218918878416e-6, 1.2154749118011886e-6, 1.1968190419634706e-6, 1.0987629913772122e-6, 1.0959863625594594e-6, 1.0981461166042277e-6, 1.0003181238718608, 1.4405614685125238e-6, 0.9996814129394869]\n",
      "loss: 1.5087889909946848e38\n",
      "pde_losses: [1.5125135018373567e38, 1.3852383360974006e-7, 1.3531402721450737e-7, 1.3773269809531627e-7]\n",
      "bcs_losses: [1.0748565116497962e-6, 1.0553777454412452e-6, 1.3320976077997122e-6, 1.4854192811644681e-6, 1.2125069219921998e-6, 1.1808959199272416e-6, 1.0882949450802854e-6, 1.0802770944459279e-6, 1.0764176871396159e-6, 1.0003630573305315, 1.4803416263858619e-6, 0.9996365567772646]\n",
      "loss: 1.5092020789862896e38\n",
      "pde_losses: [1.5102064251918646e38, 1.3696644211890955e-7, 1.3754389676455224e-7, 1.3819512348372828e-7]\n",
      "bcs_losses: [1.0733722555603729e-6, 1.0384027613720237e-6, 1.3161621879491889e-6, 1.5156993951210958e-6, 1.2094186893708515e-6, 1.190122623720343e-6, 1.0803295063467335e-6, 1.0688101826175384e-6, 1.070890507916982e-6, 1.0003359113291042, 1.4547888200295815e-6, 0.9996637247296665]\n",
      "loss: 1.4937486338631818e38\n",
      "pde_losses: [1.5256668844267864e38, 1.388611416930519e-7, 1.3770331802226825e-7, 1.371529396660966e-7]\n",
      "bcs_losses: [1.0787655688635562e-6, 1.0387417688736622e-6, 1.3186067354596354e-6, 1.5394656209238436e-6, 1.2191629374496706e-6, 1.2159949898444171e-6, 1.071193777430215e-6, 1.0725240416628841e-6, 1.0775834128399946e-6, 1.0002976736586007, 1.4249956223335621e-6, 0.9997020374323403]\n",
      "loss: 1.5066258830695613e38\n",
      "pde_losses: [1.5146681923788316e38, 1.339938191564684e-7, 1.3764883212366066e-7, 1.3612159500206056e-7]\n",
      "bcs_losses: [1.060406589115938e-6, 1.0426696352504309e-6, 1.3563451972226117e-6, 1.5209320180599555e-6, 1.2065807548963352e-6, 1.1844150886494493e-6, 1.0558259801917474e-6, 1.0547631340637512e-6, 1.0609093846886742e-6, 1.000346286363764, 1.4706054820891296e-6, 0.9996536205399446]\n",
      "loss: 1.4829676429938107e38\n",
      "pde_losses: [1.5137886346239819e38, 1.3832245184064273e-7, 1.3800527700416835e-7, 1.3690634272195262e-7]\n",
      "bcs_losses: [1.0889846337530027e-6, 1.0667018123640655e-6, 1.3041753668607392e-6, 1.5214994588869207e-6, 1.18524442169242e-6, 1.1837598289972546e-6, 1.0947383220638817e-6, 1.0907368595649119e-6, 1.0907769958609472e-6, 1.0003422715658972, 1.4401537545423128e-6, 0.9996577054673477]\n",
      "loss: 1.507403363471391e38\n",
      "pde_losses: [1.4927417215023866e38, 1.3825776712400152e-7, 1.3269358437287543e-7, 1.3616630882632697e-7]\n",
      "bcs_losses: [1.0743737990925055e-6, 1.049714730858077e-6, 1.3022800325958993e-6, 1.514552174698686e-6, 1.1828648407064489e-6, 1.1900333914402036e-6, 1.073599434346993e-6, 1.0754536861469012e-6, 1.0760453560065689e-6, 1.0003379956867915, 1.450210278819829e-6, 0.9996620109403649]\n",
      "loss: 1.4888956495893203e38\n",
      "pde_losses: [1.4872179645517013e38, 1.3600548243497371e-7, 1.3679673637036103e-7, 1.342600011758581e-7]\n",
      "bcs_losses: [1.0476394698976108e-6, 1.0120804108987146e-6, 1.3505160573329934e-6, 1.4996687954949775e-6, 1.1808311083030088e-6, 1.1710762519575615e-6, 1.0454342174950233e-6, 1.0437941194901413e-6, 1.0415117491786467e-6, 1.0003477613155256, 1.4842239452058399e-6, 0.9996521850245268]\n",
      "loss: 1.4898840161169067e38\n",
      "pde_losses: [1.4737843132411853e38, 1.3519174760185224e-7, 1.3203044791602246e-7, 1.3482122712908305e-7]\n",
      "bcs_losses: [1.0589415800622302e-6, 1.017643405280185e-6, 1.3233383680463358e-6, 1.5124789019674132e-6, 1.1883425557095002e-6, 1.1952783945487441e-6, 1.0574761973860964e-6, 1.0618714933775016e-6, 1.0555450356211677e-6, 1.0002924538593052, 1.4275228280431276e-6, 0.9997072331269935]\n",
      "loss: 1.4724757264294785e38\n",
      "pde_losses: [1.4849211681903086e38, 1.3449563648355083e-7, 1.345743411994525e-7, 1.355075576597568e-7]\n",
      "bcs_losses: [1.0882883395495333e-6, 1.0385142626113316e-6, 1.2940432863274804e-6, 1.4987545715960092e-6, 1.183881396781995e-6, 1.18771551537458e-6, 1.0860941155727938e-6, 1.088384383967571e-6, 1.080294669725722e-6, 1.0003135088105055, 1.40679437214583e-6, 0.9996859968369964]\n",
      "loss: 1.4873130191222348e38\n",
      "pde_losses: [1.4845502326594262e38, 1.3433742252600565e-7, 1.3411311369976872e-7, 1.339348358481853e-7]\n",
      "bcs_losses: [1.0563685252649636e-6, 1.0383728783588677e-6, 1.3269064750372456e-6, 1.5040115735850754e-6, 1.1764997774945267e-6, 1.1565690701211919e-6, 1.061385817569207e-6, 1.0599470969105625e-6, 1.0591240819730996e-6, 1.000357801011949, 1.450254716712716e-6, 0.9996416946592188]\n",
      "loss: 1.4957231604579321e38\n",
      "pde_losses: [1.486455195705031e38, 1.342755415996432e-7, 1.3422002195997803e-7, 1.348662866379364e-7]\n",
      "bcs_losses: [1.0297921771129406e-6, 1.0023708876511205e-6, 1.3395477290382163e-6, 1.5143425498737769e-6, 1.1842778841921698e-6, 1.1923969643123597e-6, 1.0313965771249837e-6, 1.0317057508429548e-6, 1.0397480271584293e-6, 1.0003091343842603, 1.4249987987634139e-6, 0.9996901992733085]\n",
      "loss: 1.4789481967654477e38\n",
      "pde_losses: [1.4808468645939909e38, 1.3483745936243383e-7, 1.3289164773655774e-7, 1.3398940510524655e-7]\n",
      "bcs_losses: [1.048938303485521e-6, 1.0201038716322734e-6, 1.3138654059503672e-6, 1.5189788313208986e-6, 1.1709096174655752e-6, 1.1925356117040776e-6, 1.0480001568388433e-6, 1.0498643479015055e-6, 1.0463243128387891e-6, 1.0003106560879815, 1.405987239625895e-6, 0.9996884429605994]\n",
      "loss: 1.4733224816330662e38\n",
      "pde_losses: [1.4738903950586527e38, 1.344278112419491e-7, 1.343813946472192e-7, 1.3450503297977138e-7]\n",
      "bcs_losses: [1.0570138282940365e-6, 1.0542469146153533e-6, 1.3023855038263175e-6, 1.490741940100831e-6, 1.1512903491537946e-6, 1.1452427493984297e-6, 1.0589526059778774e-6, 1.0471906555023748e-6, 1.0501002826047477e-6, 1.0004104244993004, 1.4726480051059309e-6, 0.9995886313700577]\n",
      "loss: 1.481087072913735e38\n",
      "pde_losses: [1.4616390941149648e38, 1.3210663923995313e-7, 1.318230810664569e-7, 1.3607239502282794e-7]\n",
      "bcs_losses: [1.043572017074418e-6, 1.0275201948489982e-6, 1.2888439069065625e-6, 1.5074787520540606e-6, 1.1688334112329276e-6, 1.1576043518861836e-6, 1.0298781764461904e-6, 1.0375465903864736e-6, 1.0453373149898594e-6, 1.0003445354148148, 1.441516683846785e-6, 0.9996544347480825]\n",
      "loss: 1.458212032848051e38\n",
      "pde_losses: [1.4580883234183958e38, 1.3659958731965637e-7, 1.3442480090923392e-7, 1.3373904060233626e-7]\n",
      "bcs_losses: [1.0427319100263248e-6, 9.99389730311335e-7, 1.291903550039949e-6, 1.507778219475565e-6, 1.179704807241265e-6, 1.188014413789145e-6, 1.0364317156034473e-6, 1.0324504886443005e-6, 1.0411366798167427e-6, 1.0002731333241377, 1.4097124860250891e-6, 0.9997257608061261]\n",
      "loss: 1.4731871742443749e38\n",
      "pde_losses: [1.4423987158059357e38, 1.3481755800259117e-7, 1.3378822982123877e-7, 1.3273290391584174e-7]\n",
      "bcs_losses: [1.0288032196107266e-6, 1.0090386361993936e-6, 1.29134392787948e-6, 1.4775531864315907e-6, 1.1679006025026447e-6, 1.147380635172933e-6, 1.0300653946146924e-6, 1.0398159993099295e-6, 1.0445136472708388e-6, 1.0003334500541103, 1.4394858878357997e-6, 0.9996654357643511]\n",
      "loss: 1.4408626390409996e38\n",
      "pde_losses: [1.4510188902739831e38, 1.3137209437153416e-7, 1.3186539868239567e-7, 1.299772207456663e-7]\n",
      "bcs_losses: [1.0567310721616592e-6, 1.0358521155992194e-6, 1.2655794126322574e-6, 1.4518671126576708e-6, 1.1492855614441087e-6, 1.1402602092053846e-6, 1.05940661721562e-6, 1.0568286663605436e-6, 1.0579788531354456e-6, 1.0003667929302895, 1.4326835590081578e-6, 0.9996320607364337]\n",
      "loss: 1.4552800038308534e38\n",
      "pde_losses: [1.476033505541351e38, 1.3165578553618272e-7, 1.3293720229167525e-7, 1.31316977987122e-7]\n",
      "bcs_losses: [1.025493273770484e-6, 1.0140694741339032e-6, 1.307922810517528e-6, 1.457712853920168e-6, 1.156294930183926e-6, 1.1254872361785147e-6, 1.0288985345999943e-6, 1.0289025162769656e-6, 1.0239456660168182e-6, 1.000356006232773, 1.4411858754858886e-6, 0.9996428843442382]\n",
      "loss: 1.4542095953683933e38\n",
      "pde_losses: [1.448359195291405e38, 1.3223814922271692e-7, 1.3348740485975477e-7, 1.3176640854792726e-7]\n",
      "bcs_losses: [1.0159256697327783e-6, 9.93768078892911e-7, 1.2983336989386537e-6, 1.503373680948108e-6, 1.1721695339046768e-6, 1.1697459072846168e-6, 1.0122676811687127e-6, 1.0212508016704958e-6, 1.0191372283259201e-6, 1.0002954510307007, 1.4144203189744184e-6, 0.9997034055537913]\n",
      "loss: 1.4447966450041815e38\n",
      "pde_losses: [1.4335579708647363e38, 1.3183852246842508e-7, 1.3076169403650176e-7, 1.2911856271924062e-7]\n",
      "bcs_losses: [1.02376434937048e-6, 1.0073721105970292e-6, 1.2894862352647696e-6, 1.4926415287471697e-6, 1.1667429262053037e-6, 1.1572813166088002e-6, 1.0203486912602239e-6, 1.0205599675929387e-6, 1.0275227708979675e-6, 1.0003073768560662, 1.406868911917004e-6, 0.9996914507947963]\n",
      "loss: 1.4319632477608923e38\n",
      "pde_losses: [1.4222809631684894e38, 1.3097347334971932e-7, 1.3097403997210488e-7, 1.341455902320645e-7]\n",
      "bcs_losses: [1.0345511043335678e-6, 1.0207548344295453e-6, 1.2907580952371499e-6, 1.4444829412328387e-6, 1.151647923845171e-6, 1.1125206767232437e-6, 1.0271523091192739e-6, 1.030838913705556e-6, 1.0296129507878298e-6, 1.0003868964356086, 1.4557148406405934e-6, 0.9996120870314418]\n",
      "loss: 1.4544786642041551e38\n",
      "pde_losses: [1.4562954806655514e38, 1.3283199940165964e-7, 1.3172345253055586e-7, 1.3096515980092847e-7]\n",
      "bcs_losses: [1.0354569994527396e-6, 1.0025703487955252e-6, 1.2795155252032948e-6, 1.4570233012440246e-6, 1.1572854048573294e-6, 1.1401432517856512e-6, 1.040757122962469e-6, 1.0358384022088746e-6, 1.0327049864416345e-6, 1.0003261315349516, 1.40483478788265e-6, 0.9996728781157822]\n",
      "loss: 1.4322628510511377e38\n",
      "pde_losses: [1.433525791948638e38, 1.317448719631883e-7, 1.3208309803164511e-7, 1.3077291986121172e-7]\n",
      "bcs_losses: [1.0273540067002552e-6, 9.882279435738876e-7, 1.2713607814001927e-6, 1.4559531131657637e-6, 1.159503523594037e-6, 1.1493957718949415e-6, 1.025026220815506e-6, 1.0262240610192064e-6, 1.0232249942602873e-6, 1.00028993868596, 1.3862945843817112e-6, 0.9997091694809448]\n",
      "loss: 1.4398312120598235e38\n",
      "pde_losses: [1.4216047013728784e38, 1.3142440716720078e-7, 1.299180825716214e-7, 1.3137103699544875e-7]\n",
      "bcs_losses: [1.0261977288009355e-6, 9.883978922946966e-7, 1.287785964819579e-6, 1.4487390609814164e-6, 1.151467960698341e-6, 1.1210499877092058e-6, 1.0213708042590532e-6, 1.0278695909685938e-6, 1.0295306811536269e-6, 1.000338460540136, 1.422567403725326e-6, 0.9996607830633252]\n",
      "loss: 1.4198811554287866e38\n",
      "pde_losses: [1.4307326175786946e38, 1.30572930025186e-7, 1.3062379475007463e-7, 1.2986643664256687e-7]\n",
      "bcs_losses: [1.0387266076101254e-6, 1.0070798914213367e-6, 1.2637062392882264e-6, 1.4487508349185193e-6, 1.1413944128916892e-6, 1.1225446431605141e-6, 1.0444520723901232e-6, 1.0280770680484437e-6, 1.0359099823626526e-6, 1.0003414177196195, 1.4222936622241834e-6, 0.9996579776758768]\n",
      "loss: 1.4328512066726483e38\n",
      "pde_losses: [1.415534969867499e38, 1.301055683995212e-7, 1.3162200398013112e-7, 1.2735581485613332e-7]\n",
      "bcs_losses: [1.0246625826556475e-6, 1.0012923094188472e-6, 1.2772512049756653e-6, 1.4673928321338532e-6, 1.1515504614354729e-6, 1.1187714139888101e-6, 1.0236730061184929e-6, 1.0340522994002996e-6, 1.0289471261290405e-6, 1.000358330950324, 1.433186343744177e-6, 0.999641188504768]\n",
      "loss: 1.4026358132613498e38\n",
      "pde_losses: [1.4177328758866462e38, 1.2721188499942105e-7, 1.2973226083546894e-7, 1.280534120364458e-7]\n",
      "bcs_losses: [1.0084116571450008e-6, 9.788658572324176e-7, 1.2858324425218513e-6, 1.4393748525863378e-6, 1.158596537822309e-6, 1.128031254887139e-6, 1.0016290869199952e-6, 1.0107484682375355e-6, 9.97046580841124e-7, 1.0003399680237843, 1.432335399607644e-6, 0.9996596670582225]\n",
      "loss: 1.4301250468765513e38\n",
      "pde_losses: [1.428627209381507e38, 1.3013866621602784e-7, 1.291803167393179e-7, 1.2732945068919755e-7]\n",
      "bcs_losses: [1.014658713161512e-6, 9.712883765755996e-7, 1.2653000746943324e-6, 1.4233243634958143e-6, 1.1605325991283693e-6, 1.140788196825196e-6, 1.0268047127540213e-6, 1.0155558935019228e-6, 1.0136938967300867e-6, 1.0003050327051959, 1.3745142101811992e-6, 0.9996945651710425]\n",
      "loss: 1.3947789867435233e38\n",
      "pde_losses: [1.431680441699729e38, 1.250467736687831e-7, 1.3012957133575226e-7, 1.2879349345997743e-7]\n",
      "bcs_losses: [1.014841875154772e-6, 9.68695814847404e-7, 1.2772256452911585e-6, 1.4160110959350674e-6, 1.1444067966816156e-6, 1.1226521449080302e-6, 1.0161115428590067e-6, 1.0218909190677246e-6, 1.026541561702996e-6, 1.0003149068693915, 1.3703922183465254e-6, 0.9996847516044685]\n",
      "loss: 1.3952073728673072e38\n",
      "pde_losses: [1.423952039279699e38, 1.2523709055139336e-7, 1.2875775578328957e-7, 1.258357526835889e-7]\n",
      "bcs_losses: [1.010147501359087e-6, 9.648868930971802e-7, 1.2790821419577131e-6, 1.4150240843225774e-6, 1.1405542358869196e-6, 1.1118481518927545e-6, 1.023098670569182e-6, 1.0213058186353378e-6, 1.022690607404691e-6, 1.0003216611524932, 1.380497794998517e-6, 0.9996779954991579]\n",
      "loss: 1.3983849963444339e38\n",
      "pde_losses: [1.4129225387877711e38, 1.2763436182915812e-7, 1.2799109349948643e-7, 1.2777732073443335e-7]\n",
      "bcs_losses: [1.022131405850425e-6, 9.667803743773277e-7, 1.24495158484973e-6, 1.4126380571436535e-6, 1.1299486412442658e-6, 1.1272082982866538e-6, 1.0182867026621232e-6, 1.0247936570294806e-6, 1.0224719672575848e-6, 1.0003062738398547, 1.3872312045417861e-6, 0.9996934206912463]\n",
      "loss: 1.4161685375382594e38\n",
      "pde_losses: [1.4090651529091314e38, 1.2764943432557661e-7, 1.2704501024566882e-7, 1.2750952205877312e-7]\n",
      "bcs_losses: [1.0039032996042784e-6, 9.703471639981995e-7, 1.2499824923936741e-6, 1.4412714663522282e-6, 1.1243393938282077e-6, 1.0926487442996402e-6, 1.00611110343808e-6, 1.0061004166075067e-6, 1.0042223442727779e-6, 1.0003421816825175, 1.4415766733798327e-6, 0.9996576392827597]\n",
      "loss: 1.3921550113517631e38\n",
      "pde_losses: [1.4065539412933517e38, 1.2752256530223979e-7, 1.2543983759521747e-7, 1.2675864324238415e-7]\n",
      "bcs_losses: [9.900798319030128e-7, 9.60206232124392e-7, 1.2764392394009165e-6, 1.425412935672205e-6, 1.1207765500408467e-6, 1.1054613102496853e-6, 9.9567603495548e-7, 9.933671045441075e-7, 9.928689635953354e-7, 1.000338921157291, 1.4393449167488743e-6, 0.9996610147705856]\n",
      "loss: 1.3991296140709646e38\n",
      "pde_losses: [1.4013855375261337e38, 1.26022775208974e-7, 1.2728645681720958e-7, 1.2726030913400183e-7]\n",
      "bcs_losses: [1.024829370957768e-6, 9.769447647664666e-7, 1.2565882589053045e-6, 1.4252755422043422e-6, 1.133247448142233e-6, 1.130984820909727e-6, 1.0188180021612706e-6, 1.0212686389364195e-6, 1.0240792109486632e-6, 1.000281223340838, 1.3553417817212318e-6, 0.9997187107537178]\n",
      "loss: 1.4059221216953239e38\n",
      "pde_losses: [1.3926727553005811e38, 1.257231372664477e-7, 1.2855438448657796e-7, 1.2952653201315888e-7]\n",
      "bcs_losses: [1.0166687509740803e-6, 9.854353000677604e-7, 1.2579917552875583e-6, 1.3945683246332554e-6, 1.1182200548221078e-6, 1.0879801457143612e-6, 1.0238834733777565e-6, 1.02060384398774e-6, 1.023828779360522e-6, 1.0003572601580162, 1.3808058361271112e-6, 0.9996427545871045]\n",
      "loss: 1.4058726154842776e38\n",
      "pde_losses: [1.418338335742121e38, 1.2799874279834816e-7, 1.2628871824618627e-7, 1.262830072450735e-7]\n",
      "bcs_losses: [1.0125120830285852e-6, 9.74214437516971e-7, 1.255012538350992e-6, 1.3658981116367394e-6, 1.1230634467925866e-6, 1.0811198816673943e-6, 1.015702288104148e-6, 1.0127861958968663e-6, 1.0195732306806215e-6, 1.000392656329496, 1.406051096702372e-6, 0.999607484607633]\n",
      "loss: 1.3973859939027398e38\n",
      "pde_losses: [1.4042895018583323e38, 1.2684520855497393e-7, 1.2601478180367622e-7, 1.2546193275480038e-7]\n",
      "bcs_losses: [1.0347496557779947e-6, 9.52884232841844e-7, 1.2142383928555457e-6, 1.4075375341919428e-6, 1.150587695861182e-6, 1.1479032643844115e-6, 1.0424375925545668e-6, 1.0385336739316496e-6, 1.0330982802936161e-6, 1.00026453814317, 1.332173250544927e-6, 0.9997355133016628]\n",
      "loss: 1.417244851573186e38\n",
      "pde_losses: [1.3877665783716672e38, 1.2863455647325487e-7, 1.2657557903166338e-7, 1.2709136301345578e-7]\n",
      "bcs_losses: [9.953899551719887e-7, 9.361154201790289e-7, 1.2594289481912557e-6, 1.3696717213332084e-6, 1.1155715847641277e-6, 1.0828924682803914e-6, 1.000131532619289e-6, 9.924876097032716e-7, 9.99711914345441e-7, 1.000349235808778, 1.412296530614626e-6, 0.9996508422771606]\n",
      "loss: 1.4027046062353285e38\n",
      "pde_losses: [1.4022648008059911e38, 1.2304768191324545e-7, 1.2432875361522394e-7, 1.2652952916960283e-7]\n",
      "bcs_losses: [1.0109834164562347e-6, 9.640478054584929e-7, 1.2697875472210594e-6, 1.3975073040788693e-6, 1.1079189823289125e-6, 1.0643708351387174e-6, 1.0023851131349118e-6, 9.993617469647219e-7, 1.0030282710011013e-6, 1.0003619441661749, 1.416989416085181e-6, 0.9996380650369667]\n",
      "loss: 1.380867414763062e38\n",
      "pde_losses: [1.4043459216961608e38, 1.2591612914145775e-7, 1.249086774556559e-7, 1.2536772594436063e-7]\n",
      "bcs_losses: [1.0163421347998327e-6, 9.666863690407304e-7, 1.2304875048678703e-6, 1.4184465861999509e-6, 1.1331302858602946e-6, 1.1356724047314674e-6, 1.0158371256846751e-6, 1.008154687039619e-6, 1.0241120199125994e-6, 1.0002753880482156, 1.3331369590772843e-6, 0.9997243441862997]\n",
      "loss: 1.400659692293743e38\n",
      "pde_losses: [1.3973477702828183e38, 1.2532437014025228e-7, 1.244801121823014e-7, 1.2354845246884509e-7]\n",
      "bcs_losses: [9.767093900085062e-7, 9.51632438261916e-7, 1.2598794840336074e-6, 1.37195816153469e-6, 1.1163995291708414e-6, 1.0743381258759002e-6, 9.673589787925993e-7, 9.748965583524053e-7, 9.796964534024693e-7, 1.0003545248611043, 1.3914941010222797e-6, 0.9996450879436642]\n",
      "loss: 1.3766774650698518e38\n",
      "pde_losses: [1.373622694796411e38, 1.2536913009021466e-7, 1.2595586399108734e-7, 1.2625791638378875e-7]\n",
      "bcs_losses: [9.774153918081005e-7, 9.429526438851208e-7, 1.2559819448450512e-6, 1.377860766006535e-6, 1.122094493442508e-6, 1.0932624072430081e-6, 9.825235823016963e-7, 9.79212371571253e-7, 9.746800570044494e-7, 1.0003219621084363, 1.3630988607634499e-6, 0.9996774414384696]\n",
      "loss: 1.3869278153981007e38\n",
      "pde_losses: [1.3736798494693527e38, 1.2475941081731386e-7, 1.2579312303031331e-7, 1.2468997766990931e-7]\n",
      "bcs_losses: [1.0192774549849787e-6, 9.703347306121967e-7, 1.2094370717582852e-6, 1.3864447724607787e-6, 1.1076690965955206e-6, 1.09848847578698e-6, 1.016005714094558e-6, 1.0152626443706555e-6, 1.0150268561839802e-6, 1.000318019401004, 1.3600749773360195e-6, 0.9996812308133978]\n",
      "loss: 1.3687666222743638e38\n",
      "pde_losses: [1.3730273833504477e38, 1.2543534793107656e-7, 1.2511429852632172e-7, 1.256421070178221e-7]\n",
      "bcs_losses: [9.973759794447647e-7, 9.578831888533365e-7, 1.242190260990932e-6, 1.3944464308278799e-6, 1.0949503398845227e-6, 1.0517219175394721e-6, 9.94697988848874e-7, 9.866738780276562e-7, 9.949491527940184e-7, 1.0003758302692096, 1.4289180612548692e-6, 0.9996233290785235]\n",
      "loss: 1.3598224839469779e38\n",
      "pde_losses: [1.3489342392869948e38, 1.2356858866580694e-7, 1.262226131767125e-7, 1.2420902223965413e-7]\n",
      "bcs_losses: [9.929358863406714e-7, 9.440953237162613e-7, 1.2293208287055308e-6, 1.4169799361572286e-6, 1.1057581087458648e-6, 1.067779581618267e-6, 9.946280933285485e-7, 9.904917678005327e-7, 9.890762057563123e-7, 1.0003248786779633, 1.41355697891446e-6, 0.9996740960153467]\n",
      "loss: 1.3877698470604407e38\n",
      "pde_losses: [1.3800855244445412e38, 1.2463767078645178e-7, 1.2329590047667264e-7, 1.2282865123449382e-7]\n",
      "bcs_losses: [9.93201353482483e-7, 9.470085656213085e-7, 1.2166880016633845e-6, 1.415920770692419e-6, 1.1219232410784388e-6, 1.0938030660913488e-6, 9.947343250585112e-7, 1.0052670799088927e-6, 9.96812216436849e-7, 1.0002787826943198, 1.3760287747161871e-6, 0.9997200139254483]\n",
      "loss: 1.3516311044969364e38\n",
      "pde_losses: [1.3517381991137894e38, 1.2577245057371912e-7, 1.2256323706817244e-7, 1.2468677579751158e-7]\n",
      "bcs_losses: [9.762753845206656e-7, 9.348755469019516e-7, 1.238762929426058e-6, 1.384421008869139e-6, 1.094526649855659e-6, 1.0552379398615352e-6, 9.786365665722655e-7, 9.796346743218671e-7, 9.79230222256426e-7, 1.0003656755728465, 1.412950933967363e-6, 0.9996330995101369]\n",
      "loss: 1.3617264841415626e38\n",
      "pde_losses: [1.3621971847570022e38, 1.2329090482632475e-7, 1.227634658585757e-7, 1.2069906991013995e-7]\n",
      "bcs_losses: [9.70896723947208e-7, 9.269385729294787e-7, 1.2171996149103424e-6, 1.3509839350155356e-6, 1.1001983954807067e-6, 1.072543947357391e-6, 9.648229610438518e-7, 9.756715730502277e-7, 9.70292844137362e-7, 1.000351144111017, 1.3604666559145455e-6, 0.9996475449907131]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Решение\n",
    "res = solve(prob, opt; maxiters = 800, callback, log_frequency = 50)\n",
    "phi = discretization.phi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
