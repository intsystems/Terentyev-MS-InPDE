{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f32abb7",
   "metadata": {},
   "source": [
    "# Обратная задача ЭЭГ\n",
    "\n",
    "Обратная задача ЭЭГ заключается в восстановлении распределения источников (тока и заряда) внутри области (например, головы) на основе измерений электрического потенциала на границе.\n",
    "\n",
    "В данном ноутбуке мы используем нейросеть для моделирования распределения заряда и тока, а также обновляем функцию потерь и пайплайн для решения этой задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee54cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "using NeuralPDE, Lux, ModelingToolkit, Optimization, OptimizationOptimJL, LineSearches,\n",
    "      OptimizationOptimisers, LuxCUDA, Random, ComponentArrays\n",
    "using ModelingToolkit: Interval, infimum, supremum\n",
    "using Distributions, Plots, CUDA\n",
    "\n",
    "using Random\n",
    "using TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1339f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::CPUDevice) (generic function with 4 methods)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const gpud = gpu_device()\n",
    "const cpud = cpu_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c97391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dalembert_operator (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Определение прямой задачи\n",
    "@parameters x, y, z, t\n",
    "@variables φ(..), Ax(..),Ay(..),Az(..), ρ(..), jx(..), jy(..), jz(..)\n",
    "A = [Ax, Ay, Az]\n",
    "j = [jx, jy, jz]\n",
    "Dxx = Differential(x)^2\n",
    "Dyy = Differential(y)^2\n",
    "Dzz = Differential(z)^2\n",
    "\n",
    "# Определение физических постоянных\n",
    "const c = 2.99792458e10 # Скорость света в вакууме (см/с)\n",
    "const ε₀ = 1.0 # Диэлектрическая постоянная вакуума в СГС (размерность отсутствует)\n",
    "const ε = 1.0  # Диэлектрическая проницаемость (отн.)\n",
    "const μ₀ = 1.0 # Магнитная постоянная вакуума в СГС (размерность отсутствует)\n",
    "const μ = 1.0  # Магнитная проницаемость (отн.)\n",
    "\n",
    "\n",
    "# Определение оператора Лапласа как функции\n",
    "function laplacian(F, params)\n",
    "    return sum((Differential(param)^2)(F) for param in params)\n",
    "end\n",
    "\n",
    "# Определение оператора Даламбера как функции\n",
    "function dalembert_operator(F, params, ε, μ, c)\n",
    "    Δ = laplacian(F, params)\n",
    "    return Δ  - (ε * μ / c^2) * (Differential(t)^2)(F)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2eb18d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\varphi\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\varphi\\left( x, y, z, t \\right)\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "Differential(y)(Differential(y)(φ(x, y, z, t))) + Differential(x)(Differential(x)(φ(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(φ(x, y, z, t))) + Differential(z)(Differential(z)(φ(x, y, z, t)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dalembert_operator(φ(x,y,z,t), [x, y, z], ε, μ, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "988ba867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{align}\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\varphi\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\varphi\\left( x, y, z, t \\right) &=  - 12.566 \\rho\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ax}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Ax}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ax}\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Ax}\\left( x, y, z, t \\right) &=  - 4.1917 \\cdot 10^{-10} \\mathtt{jx}\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Ay}\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ay}\\left( x, y, z, t \\right) &=  - 4.1917 \\cdot 10^{-10} \\mathtt{jy}\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Az}\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Az}\\left( x, y, z, t \\right) &=  - 4.1917 \\cdot 10^{-10} \\mathtt{jz}\\left( x, y, z, t \\right) \\\\\n",
       "3.3356 \\cdot 10^{-11} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ax}\\left( x, y, z, t \\right) &= 0\n",
       "\\end{align}\n",
       " $$"
      ],
      "text/plain": [
       "5-element Vector{Equation}:\n",
       " Differential(y)(Differential(y)(φ(x, y, z, t))) + Differential(x)(Differential(x)(φ(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(φ(x, y, z, t))) + Differential(z)(Differential(z)(φ(x, y, z, t))) ~ -12.566370614359172ρ(x, y, z, t)\n",
       " Differential(x)(Differential(x)(Ax(x, y, z, t))) + Differential(z)(Differential(z)(Ax(x, y, z, t))) + Differential(y)(Differential(y)(Ax(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Ax(x, y, z, t))) ~ -4.191690043903363e-10jx(x, y, z, t)\n",
       " Differential(y)(Differential(y)(Ay(x, y, z, t))) + Differential(z)(Differential(z)(Ay(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Ay(x, y, z, t))) + Differential(x)(Differential(x)(Ay(x, y, z, t))) ~ -4.191690043903363e-10jy(x, y, z, t)\n",
       " Differential(z)(Differential(z)(Az(x, y, z, t))) + Differential(y)(Differential(y)(Az(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Az(x, y, z, t))) + Differential(x)(Differential(x)(Az(x, y, z, t))) ~ -4.191690043903363e-10jz(x, y, z, t)\n",
       " 3.33564095198152e-11Differential(t)(φ(x, y, z, t)) + Differential(y)(Ay(x, y, z, t)) + Differential(z)(Az(x, y, z, t)) + Differential(x)(Ax(x, y, z, t)) ~ 0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Уравнение\n",
    "eqs = [\n",
    "\n",
    "    [dalembert_operator(φ(x, y, z, t), [x, y, z], ε, μ, c) ~ -4 * pi * ρ(x, y, z, t) / ε];\n",
    "    [dalembert_operator(A[i](x, y, z, t), [x, y, z], ε, μ, c) ~ -μ * 4 * pi / c* j[i](x, y, z, t) for i in 1:3];\n",
    "    (Differential(x)(Ax(x, y, z, t)) + Differential(y)(Ay(x, y, z, t)) + Differential(z)(Az(x, y, z, t)) + (ε * μ / c) * Differential(t)(φ(x, y, z, t))) ~ 0.0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "694a6dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{align}\n",
       "\\varphi\\left( -10, y, z, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( 10, y, z, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( x, -10, z, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( x, 10, z, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( x, y, -10, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( x, y, 10, t \\right) &= 0 \\\\\n",
       "\\mathtt{Ax}\\left( -10, y, z, t \\right) &= 0 \\\\\n",
       "\\mathtt{Ay}\\left( -10, y, z, t \\right) &= 0 \\\\\n",
       "\\mathtt{Az}\\left( -10, y, z, t \\right) &= 0\n",
       "\\end{align}\n",
       " $$"
      ],
      "text/plain": [
       "9-element Vector{Equation}:\n",
       " φ(-10.0, y, z, t) ~ 0.0\n",
       " φ(10.0, y, z, t) ~ 0.0\n",
       " φ(x, -10.0, z, t) ~ 0.0\n",
       " φ(x, 10.0, z, t) ~ 0.0\n",
       " φ(x, y, -10.0, t) ~ 0.0\n",
       " φ(x, y, 10.0, t) ~ 0.0\n",
       " Ax(-10.0, y, z, t) ~ 0.0\n",
       " Ay(-10.0, y, z, t) ~ 0.0\n",
       " Az(-10.0, y, z, t) ~ 0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Границы области\n",
    "const x_min, x_max = -10.0, 10.0\n",
    "const y_min, y_max = -10.0, 10.0\n",
    "const z_min, z_max = -10.0, 10.0\n",
    "const t_min, t_max = 0.0, 1.0\n",
    "# Область\n",
    "domains = [x ∈ Interval(x_min, x_max),\n",
    "           y ∈ Interval(y_min, y_max),\n",
    "           z ∈ Interval(z_min, z_max), \n",
    "           t ∈ Interval(t_min, t_max)]\n",
    "# Начальные условия\n",
    "\n",
    "function analytic_sol_func(t, x, y, z)\n",
    "    r = sqrt((x)^2 + (y)^2 + (z)^2)\n",
    "    (t + 1)^2 / r\n",
    "end\n",
    "\n",
    "# Генерация случайных точек в пределах домена\n",
    "num_points = 100\n",
    "measured_points = []\n",
    "for _ in 1:num_points\n",
    "    x_p = rand(x_min/2:x_max/2)\n",
    "    y_p = rand(y_min/2:y_max/2)\n",
    "    z_p = rand(z_min/2:z_max/2)\n",
    "    t_p = rand(t_min/2:t_max/2)\n",
    "    # Добавление случайной точки в массив measured_points\n",
    "    phi_p = analytic_sol_func(t_p, x_p, y_p, z_p)\n",
    "    push!(measured_points, [x_p, y_p, z_p, t_p, phi_p])\n",
    "end\n",
    "measured_points = measured_points |> gpud\n",
    "bcs = [\n",
    "    [φ(x_min, y, z, t) ~ 0.0, φ(x_max, y, z, t) ~ 0.0,\n",
    "    φ(x, y_min, z, t) ~ 0.0, φ(x, y_max, z, t) ~ 0.0,\n",
    "    φ(x, y, z_min, t) ~ 0.0, φ(x, y, z_max, t) ~ 0.0];\n",
    "    [A[i](x_min, y, z, t)  ~ 0.0 for i in 1:3]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94dcb1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Vector{CuArray{Float32, 1, CUDA.DeviceMemory}}:\n",
       " Float32[3.0, 3.0, -1.0, 0.0, 0.22941573]\n",
       " Float32[2.0, 3.0, -3.0, 0.0, 0.21320072]\n",
       " Float32[2.0, 4.0, 5.0, 0.0, 0.1490712]\n",
       " Float32[-3.0, 0.0, -5.0, 0.0, 0.17149858]\n",
       " Float32[0.0, 3.0, 5.0, 0.0, 0.17149858]\n",
       " Float32[-4.0, -1.0, -1.0, 0.0, 0.23570226]\n",
       " Float32[3.0, -2.0, 2.0, 0.0, 0.24253562]\n",
       " Float32[4.0, -5.0, 4.0, 0.0, 0.13245323]\n",
       " Float32[4.0, -1.0, 0.0, 0.0, 0.24253562]\n",
       " Float32[-2.0, -2.0, 2.0, 0.0, 0.28867513]\n",
       " Float32[-2.0, 4.0, -3.0, 0.0, 0.18569534]\n",
       " Float32[-4.0, 3.0, -5.0, 0.0, 0.14142136]\n",
       " Float32[2.0, 0.0, -2.0, 0.0, 0.35355338]\n",
       " ⋮\n",
       " Float32[-1.0, 3.0, 1.0, 0.0, 0.30151135]\n",
       " Float32[1.0, -3.0, 5.0, 0.0, 0.16903085]\n",
       " Float32[-5.0, 3.0, 0.0, 0.0, 0.17149858]\n",
       " Float32[-2.0, -5.0, 1.0, 0.0, 0.18257418]\n",
       " Float32[-2.0, 0.0, 3.0, 0.0, 0.2773501]\n",
       " Float32[2.0, -2.0, -4.0, 0.0, 0.20412415]\n",
       " Float32[4.0, 2.0, 0.0, 0.0, 0.2236068]\n",
       " Float32[0.0, 5.0, -5.0, 0.0, 0.14142136]\n",
       " Float32[4.0, -1.0, 2.0, 0.0, 0.2182179]\n",
       " Float32[-2.0, -4.0, 1.0, 0.0, 0.2182179]\n",
       " Float32[4.0, 5.0, 0.0, 0.0, 0.15617377]\n",
       " Float32[-3.0, -2.0, -4.0, 0.0, 0.18569534]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measured_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f3a7fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "additional_loss_weightened (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function additional_loss_weightened(lambda)\n",
    "    \n",
    "    function additional_loss(phi_pred_fun, θ, p_)\n",
    "        CUDA.allowscalar() do\n",
    "            # phi is first output of phi_pred_fun\n",
    "            result = sum(abs2(phi_pred_fun([x, y, z, t]|>cpud, θ|>cpud)[1] - phi|>cpud) for (x, y, z, t, phi) in measured_points) / length(measured_points)|>cpud\n",
    "            result = result * lambda\n",
    "            return result\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return additional_loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8d660e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhysicsInformedNN{Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}, ComponentVector{Float32, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Axis{(layer_1 = ViewAxis(1:160, Axis(weight = ViewAxis(1:128, ShapedAxis((32, 4))), bias = ViewAxis(129:160, Shaped1DAxis((32,))))), layer_2 = ViewAxis(161:1216, Axis(weight = ViewAxis(1:1024, ShapedAxis((32, 32))), bias = ViewAxis(1025:1056, Shaped1DAxis((32,))))), layer_3 = ViewAxis(1217:2272, Axis(weight = ViewAxis(1:1024, ShapedAxis((32, 32))), bias = ViewAxis(1025:1056, Shaped1DAxis((32,))))), layer_4 = ViewAxis(2273:2536, Axis(weight = ViewAxis(1:256, ShapedAxis((8, 32))), bias = ViewAxis(257:264, Shaped1DAxis((8,))))))}}}, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, typeof(NeuralPDE.numeric_derivative), Bool, var\"#additional_loss#9\"{Int64}, Nothing, Nothing, Base.RefValue{Int64}, Base.Pairs{Symbol, Union{}, Tuple{}, @NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0), (layer_1 = (weight = Float32[0.69994116 -0.63226193 -0.3018212 -0.64831465; 0.18077125 0.09091234 0.053698044 -0.19166526; … ; 0.7750067 -0.66308856 0.3553004 -0.7092977; 0.7773942 -0.576916 0.25883827 0.39448273], bias = Float32[-0.07686895, -0.43142104, 0.26869768, -0.025500774, 0.13360089, 0.3540216, 0.25741345, 0.46908528, -0.42326617, 0.250952  …  0.058882356, -0.4812764, -0.010896802, 0.41112483, 0.44522828, 0.3044933, -0.21727884, 0.21671909, 0.22979301, 0.30580503]), layer_2 = (weight = Float32[0.08157742 0.16457507 … -0.024190756 -0.22894347; 0.09951087 0.08414985 … 0.2951659 0.27771863; … ; -0.04239485 0.048925802 … -0.017146282 -0.24618654; 0.106469095 0.23134577 … -0.04598589 0.14455271], bias = Float32[0.00368492, -0.008523526, -0.07762135, -0.13192563, -0.16620627, -0.05994226, 0.097244434, -0.10875598, -0.0035047422, 0.1598501  …  -0.16315202, 0.020648563, -0.10884169, 0.06564138, 0.11590457, 0.15769005, -0.054944843, -0.17498332, -0.06446021, 0.11780472]), layer_3 = (weight = Float32[-0.0875735 0.06297745 … -0.092396274 -0.19073494; -0.098234676 -0.11379454 … -0.014695217 -0.09297247; … ; -0.020103566 -0.29910743 … 0.29025596 -0.1311653; -0.22228312 0.15919465 … -0.19697039 0.06439946], bias = Float32[0.03065216, 0.033415496, 0.09960186, 0.15590063, 0.084808454, -0.04728004, 0.07808842, -0.09333436, 0.04569123, 0.0374256  …  0.123191215, -0.005717768, 0.112000465, -0.12711808, 0.025665238, -0.0618218, -0.04071685, 0.13963512, -0.17397486, -0.033385783]), layer_4 = (weight = Float32[-0.15585005 0.045899786 … 0.18697801 0.26784617; -0.29181027 -0.043503765 … -0.10684887 -0.03519131; … ; 0.12847596 0.10345304 … -0.16461635 0.22063269; -0.22998391 -0.21223895 … -0.115582034 -0.056428242], bias = Float32[-0.06490634, -0.013736543, -0.02565641, -0.031889487, 0.063018896, -0.12696584, -0.14836323, 0.041077226])), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), NeuralPDE.numeric_derivative, false, var\"#additional_loss#9\"{Int64}(10), nothing, nothing, LogOptions(50), Base.RefValue{Int64}(1), true, false, Base.Pairs{Symbol, Union{}, Tuple{}, @NamedTuple{}}())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Нейросеть\n",
    "# Определение новой нейросети для моделирования распределения заряда и тока\n",
    "input_ = 4  # x, y, z\n",
    "n = 32      # число нейронов в скрытых слоях\n",
    "lambda = 10 # вес дополнительной потерь\n",
    "# Функция для разделения выхода сети на переменные\n",
    "\"\"\"\n",
    "function split_outputs(out)\n",
    "    φ_pred = out[1]\n",
    "    A_pred = out[2:4]\n",
    "    ρ_pred = out[5]\n",
    "    j_pred = out[6:8]\n",
    "    return φ_pred, A_pred, ρ_pred, j_pred\n",
    "end\n",
    "\n",
    "chain = [Chain(\n",
    "    Dense(input_, n, σ),\n",
    "    Dense(n, n, σ),\n",
    "    Dense(n, 1)\n",
    ") for _ in 1:8] \n",
    "\n",
    "# Определение системы\n",
    "ps = [Lux.setup(Random.default_rng(), chain[i])[1] |> ComponentArray |> gpud .|> Float64 for i in 1:8]\n",
    "\"\"\"\n",
    "chain = Chain(\n",
    "    Dense(input_, n, σ),\n",
    "    Dense(n, n, σ),\n",
    "    Dense(n, n, σ),\n",
    "    Dense(n, 8)\n",
    ")\n",
    "\n",
    "# Определение системы\n",
    "ps = Lux.setup(Random.default_rng(), chain)[1] |> ComponentArray |> gpud .|> Float32\n",
    "\n",
    "strategy = QuasiRandomTraining(4096)\n",
    "discretization = PhysicsInformedNN(chain, strategy; init_params = ps, additional_loss = additional_loss_weightened(lambda), \n",
    "log_options = LogOptions(; log_frequency = 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9525824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0265117f0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_loss_weightened(lambda)(discretization.phi, ps, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e01addc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{c}\n",
       "\\varphi\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{Ax}\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{Ay}\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{Az}\\left( x, y, z, t \\right) \\\\\n",
       "\\rho\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{jx}\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{jy}\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{jz}\\left( x, y, z, t \\right) \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "8-element Vector{Num}:\n",
       "  φ(x, y, z, t)\n",
       " Ax(x, y, z, t)\n",
       " Ay(x, y, z, t)\n",
       " Az(x, y, z, t)\n",
       "  ρ(x, y, z, t)\n",
       " jx(x, y, z, t)\n",
       " jy(x, y, z, t)\n",
       " jz(x, y, z, t)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allvars = [φ(x, y, z, t); [A_(x, y, z, t) for A_ in A]; ρ(x, y, z, t); [j_(x, y, z, t) for j_ in j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3610692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{align}\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\varphi\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\varphi\\left( x, y, z, t \\right) &=  - 12.566 \\rho\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ax}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Ax}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ax}\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Ax}\\left( x, y, z, t \\right) &=  - 4.1917 \\cdot 10^{-10} \\mathtt{jx}\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Ay}\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ay}\\left( x, y, z, t \\right) &=  - 4.1917 \\cdot 10^{-10} \\mathtt{jy}\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Az}\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Az}\\left( x, y, z, t \\right) &=  - 4.1917 \\cdot 10^{-10} \\mathtt{jz}\\left( x, y, z, t \\right) \\\\\n",
       "3.3356 \\cdot 10^{-11} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ax}\\left( x, y, z, t \\right) &= 0\n",
       "\\end{align}\n",
       " $$"
      ],
      "text/plain": [
       "PDESystem\n",
       "Equations: Equation[Differential(y)(Differential(y)(φ(x, y, z, t))) + Differential(x)(Differential(x)(φ(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(φ(x, y, z, t))) + Differential(z)(Differential(z)(φ(x, y, z, t))) ~ -12.566370614359172ρ(x, y, z, t), Differential(x)(Differential(x)(Ax(x, y, z, t))) + Differential(z)(Differential(z)(Ax(x, y, z, t))) + Differential(y)(Differential(y)(Ax(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Ax(x, y, z, t))) ~ -4.191690043903363e-10jx(x, y, z, t), Differential(y)(Differential(y)(Ay(x, y, z, t))) + Differential(z)(Differential(z)(Ay(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Ay(x, y, z, t))) + Differential(x)(Differential(x)(Ay(x, y, z, t))) ~ -4.191690043903363e-10jy(x, y, z, t), Differential(z)(Differential(z)(Az(x, y, z, t))) + Differential(y)(Differential(y)(Az(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Az(x, y, z, t))) + Differential(x)(Differential(x)(Az(x, y, z, t))) ~ -4.191690043903363e-10jz(x, y, z, t), 3.33564095198152e-11Differential(t)(φ(x, y, z, t)) + Differential(y)(Ay(x, y, z, t)) + Differential(z)(Az(x, y, z, t)) + Differential(x)(Ax(x, y, z, t)) ~ 0.0]\n",
       "Boundary Conditions: Equation[φ(-10.0, y, z, t) ~ 0.0, φ(10.0, y, z, t) ~ 0.0, φ(x, -10.0, z, t) ~ 0.0, φ(x, 10.0, z, t) ~ 0.0, φ(x, y, -10.0, t) ~ 0.0, φ(x, y, 10.0, t) ~ 0.0, Ax(-10.0, y, z, t) ~ 0.0, Ay(-10.0, y, z, t) ~ 0.0, Az(-10.0, y, z, t) ~ 0.0]\n",
       "Domain: Symbolics.VarDomainPairing[Symbolics.VarDomainPairing(x, -10.0 .. 10.0), Symbolics.VarDomainPairing(y, -10.0 .. 10.0), Symbolics.VarDomainPairing(z, -10.0 .. 10.0), Symbolics.VarDomainPairing(t, 0.0 .. 1.0)]\n",
       "Dependent Variables: Num[φ(x, y, z, t), Ax(x, y, z, t), Ay(x, y, z, t), Az(x, y, z, t), ρ(x, y, z, t), jx(x, y, z, t), jy(x, y, z, t), jz(x, y, z, t)]\n",
       "Independent Variables: Num[x, y, z, t]\n",
       "Parameters: SciMLBase.NullParameters()\n",
       "Default Parameter ValuesDict{Any, Any}()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@named pde_system = PDESystem(eqs, bcs, domains, [x, y, z, t], allvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5817f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralPDE.PINNRepresentation(Equation[Differential(y)(Differential(y)(φ(x, y, z, t))) + Differential(x)(Differential(x)(φ(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(φ(x, y, z, t))) + Differential(z)(Differential(z)(φ(x, y, z, t))) ~ -12.566370614359172ρ(x, y, z, t), Differential(x)(Differential(x)(Ax(x, y, z, t))) + Differential(z)(Differential(z)(Ax(x, y, z, t))) + Differential(y)(Differential(y)(Ax(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Ax(x, y, z, t))) ~ -4.191690043903363e-10jx(x, y, z, t), Differential(y)(Differential(y)(Ay(x, y, z, t))) + Differential(z)(Differential(z)(Ay(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Ay(x, y, z, t))) + Differential(x)(Differential(x)(Ay(x, y, z, t))) ~ -4.191690043903363e-10jy(x, y, z, t), Differential(z)(Differential(z)(Az(x, y, z, t))) + Differential(y)(Differential(y)(Az(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Az(x, y, z, t))) + Differential(x)(Differential(x)(Az(x, y, z, t))) ~ -4.191690043903363e-10jz(x, y, z, t), 3.33564095198152e-11Differential(t)(φ(x, y, z, t)) + Differential(y)(Ay(x, y, z, t)) + Differential(z)(Az(x, y, z, t)) + Differential(x)(Ax(x, y, z, t)) ~ 0.0], Equation[φ(-10.0, y, z, t) ~ 0.0, φ(10.0, y, z, t) ~ 0.0, φ(x, -10.0, z, t) ~ 0.0, φ(x, 10.0, z, t) ~ 0.0, φ(x, y, -10.0, t) ~ 0.0, φ(x, y, 10.0, t) ~ 0.0, Ax(-10.0, y, z, t) ~ 0.0, Ay(-10.0, y, z, t) ~ 0.0, Az(-10.0, y, z, t) ~ 0.0], Symbolics.VarDomainPairing[Symbolics.VarDomainPairing(x, -10.0 .. 10.0), Symbolics.VarDomainPairing(y, -10.0 .. 10.0), Symbolics.VarDomainPairing(z, -10.0 .. 10.0), Symbolics.VarDomainPairing(t, 0.0 .. 1.0)], SciMLBase.NullParameters(), Dict{Any, Any}(), nothing, false, var\"#additional_loss#9\"{Int64}(10), NonAdaptiveLoss{Float32}(Float32[1.0, 1.0, 1.0, 1.0, 1.0], Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], Float32[1.0]), [:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz], [:x, :y, :z, :t], Dict(:y => 2, :z => 3, :t => 4, :x => 1), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:φ => [:x, :y, :z, :t], :ρ => [:x, :y, :z, :t], :Az => [:x, :y, :z, :t], :jx => [:x, :y, :z, :t], :Ax => [:x, :y, :z, :t], :jz => [:x, :y, :z, :t], :jy => [:x, :y, :z, :t], :Ay => [:x, :y, :z, :t]), nothing, false, Base.RefValue{Int64}(1), (layer_1 = (weight = Float32[0.69994116 -0.63226193 -0.3018212 -0.64831465; 0.18077125 0.09091234 0.053698044 -0.19166526; … ; 0.7750067 -0.66308856 0.3553004 -0.7092977; 0.7773942 -0.576916 0.25883827 0.39448273], bias = Float32[-0.07686895, -0.43142104, 0.26869768, -0.025500774, 0.13360089, 0.3540216, 0.25741345, 0.46908528, -0.42326617, 0.250952  …  0.058882356, -0.4812764, -0.010896802, 0.41112483, 0.44522828, 0.3044933, -0.21727884, 0.21671909, 0.22979301, 0.30580503]), layer_2 = (weight = Float32[0.08157742 0.16457507 … -0.024190756 -0.22894347; 0.09951087 0.08414985 … 0.2951659 0.27771863; … ; -0.04239485 0.048925802 … -0.017146282 -0.24618654; 0.106469095 0.23134577 … -0.04598589 0.14455271], bias = Float32[0.00368492, -0.008523526, -0.07762135, -0.13192563, -0.16620627, -0.05994226, 0.097244434, -0.10875598, -0.0035047422, 0.1598501  …  -0.16315202, 0.020648563, -0.10884169, 0.06564138, 0.11590457, 0.15769005, -0.054944843, -0.17498332, -0.06446021, 0.11780472]), layer_3 = (weight = Float32[-0.0875735 0.06297745 … -0.092396274 -0.19073494; -0.098234676 -0.11379454 … -0.014695217 -0.09297247; … ; -0.020103566 -0.29910743 … 0.29025596 -0.1311653; -0.22228312 0.15919465 … -0.19697039 0.06439946], bias = Float32[0.03065216, 0.033415496, 0.09960186, 0.15590063, 0.084808454, -0.04728004, 0.07808842, -0.09333436, 0.04569123, 0.0374256  …  0.123191215, -0.005717768, 0.112000465, -0.12711808, 0.025665238, -0.0618218, -0.04071685, 0.13963512, -0.17397486, -0.033385783]), layer_4 = (weight = Float32[-0.15585005 0.045899786 … 0.18697801 0.26784617; -0.29181027 -0.043503765 … -0.10684887 -0.03519131; … ; 0.12847596 0.10345304 … -0.16461635 0.22063269; -0.22998391 -0.21223895 … -0.115582034 -0.056428242], bias = Float32[-0.06490634, -0.013736543, -0.02565641, -0.031889487, 0.063018896, -0.12696584, -0.14836323, 0.041077226])), (layer_1 = (weight = Float32[0.69994116 -0.63226193 -0.3018212 -0.64831465; 0.18077125 0.09091234 0.053698044 -0.19166526; … ; 0.7750067 -0.66308856 0.3553004 -0.7092977; 0.7773942 -0.576916 0.25883827 0.39448273], bias = Float32[-0.07686895, -0.43142104, 0.26869768, -0.025500774, 0.13360089, 0.3540216, 0.25741345, 0.46908528, -0.42326617, 0.250952  …  0.058882356, -0.4812764, -0.010896802, 0.41112483, 0.44522828, 0.3044933, -0.21727884, 0.21671909, 0.22979301, 0.30580503]), layer_2 = (weight = Float32[0.08157742 0.16457507 … -0.024190756 -0.22894347; 0.09951087 0.08414985 … 0.2951659 0.27771863; … ; -0.04239485 0.048925802 … -0.017146282 -0.24618654; 0.106469095 0.23134577 … -0.04598589 0.14455271], bias = Float32[0.00368492, -0.008523526, -0.07762135, -0.13192563, -0.16620627, -0.05994226, 0.097244434, -0.10875598, -0.0035047422, 0.1598501  …  -0.16315202, 0.020648563, -0.10884169, 0.06564138, 0.11590457, 0.15769005, -0.054944843, -0.17498332, -0.06446021, 0.11780472]), layer_3 = (weight = Float32[-0.0875735 0.06297745 … -0.092396274 -0.19073494; -0.098234676 -0.11379454 … -0.014695217 -0.09297247; … ; -0.020103566 -0.29910743 … 0.29025596 -0.1311653; -0.22228312 0.15919465 … -0.19697039 0.06439946], bias = Float32[0.03065216, 0.033415496, 0.09960186, 0.15590063, 0.084808454, -0.04728004, 0.07808842, -0.09333436, 0.04569123, 0.0374256  …  0.123191215, -0.005717768, 0.112000465, -0.12711808, 0.025665238, -0.0618218, -0.04071685, 0.13963512, -0.17397486, -0.033385783]), layer_4 = (weight = Float32[-0.15585005 0.045899786 … 0.18697801 0.26784617; -0.29181027 -0.043503765 … -0.10684887 -0.03519131; … ; 0.12847596 0.10345304 … -0.16461635 0.22063269; -0.22998391 -0.21223895 … -0.115582034 -0.056428242], bias = Float32[-0.06490634, -0.013736543, -0.02565641, -0.031889487, 0.063018896, -0.12696584, -0.14836323, 0.041077226])), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), NeuralPDE.numeric_derivative, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0), Vector{Any}[[:x, :y, :z, :t], [:x, :y, :z, :t], [:x, :y, :z, :t], [:x, :y, :z, :t], [:x, :y, :z, :t]], Vector{Any}[[:y, :z, :t], [:y, :z, :t], [:x, :z, :t], [:x, :z, :t], [:x, :y, :t], [:x, :y, :t], [:y, :z, :t], [:y, :z, :t], [:y, :z, :t]], [[:t, :x, :y, :z], [:t, :x, :y, :z], [:t, :x, :y, :z], [:t, :x, :y, :z], [:t, :x, :y, :z]], [[:t, :y, :z], [:t, :y, :z], [:t, :x, :z], [:t, :x, :z], [:t, :x, :y], [:t, :x, :y], [:t, :y, :z], [:t, :y, :z], [:t, :y, :z]], NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), Expr[:((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord5 = vcat(x, y, z, t)\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  (+).((+).((+).(derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord1, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")) .- (*).(-12.566370614359172, u(cord5, var\"##θ#230\", phi))\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord6 = vcat(x, y, z, t)\n",
       "                      cord2 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  (+).((+).((+).(derivative(phi, u, cord2, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))) .- (*).(-4.191690043903363e-10, u(cord6, var\"##θ#230\", phi))\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord7 = vcat(x, y, z, t)\n",
       "                      cord3 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  (+).((+).((+).(derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord3, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord7, var\"##θ#230\", phi))\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord4 = vcat(x, y, z, t)\n",
       "                      cord8 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  (+).((+).((+).(derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord4, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord8, var\"##θ#230\", phi))\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord4 = vcat(x, y, z, t)\n",
       "                      cord2 = vcat(x, y, z, t)\n",
       "                      cord3 = vcat(x, y, z, t)\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  (+).((+).((+).((*).(3.33564095198152e-11, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.0049215658]], 1, var\"##θ#230\")), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0049215658, 0.0, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0049215658, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0049215658, 0.0, 0.0, 0.0]], 1, var\"##θ#230\")) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end)], Expr[:((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord2 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord2, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord3 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord3, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord4 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord4, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end)], NeuralPDE.PINNLossFunctions(NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function[NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[10.0, -9.999756, -9.999756, 0.00024414062], Float32[10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -10.0, -9.999756, 0.00024414062], Float32[9.999756, -10.0, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, 10.0, -9.999756, 0.00024414062], Float32[9.999756, 10.0, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -10.0, 0.00024414062], Float32[9.999756, 9.999756, -10.0, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, 10.0, 0.00024414062], Float32[9.999756, 9.999756, 10.0, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord2, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord3, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord4, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()))], NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function[NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord5 = vcat(x, y, z, t)\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord1, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")) .- (*).(-12.566370614359172, u(cord5, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord6 = vcat(x, y, z, t)\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord2, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))) .- (*).(-4.191690043903363e-10, u(cord6, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord7 = vcat(x, y, z, t)\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord3, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord7, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "                cord8 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord4, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord8, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).((*).(3.33564095198152e-11, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.0049215658]], 1, var\"##θ#230\")), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0049215658, 0.0, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0049215658, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0049215658, 0.0, 0.0, 0.0]], 1, var\"##θ#230\")) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()))], NeuralPDE.var\"#full_loss_function#283\"{Returns{Nothing}, Vector{NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function}, Vector{NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function}, NeuralPDE.PINNRepresentation, Int64, Bool, Base.RefValue{Int64}, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, var\"#additional_loss#9\"{Int64}, Bool}(Returns{Nothing}(nothing), NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function[NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[10.0, -9.999756, -9.999756, 0.00024414062], Float32[10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -10.0, -9.999756, 0.00024414062], Float32[9.999756, -10.0, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, 10.0, -9.999756, 0.00024414062], Float32[9.999756, 10.0, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -10.0, 0.00024414062], Float32[9.999756, 9.999756, -10.0, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, 10.0, 0.00024414062], Float32[9.999756, 9.999756, 10.0, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord2, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord3, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord4, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()))], NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function[NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord5 = vcat(x, y, z, t)\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord1, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")) .- (*).(-12.566370614359172, u(cord5, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord6 = vcat(x, y, z, t)\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord2, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))) .- (*).(-4.191690043903363e-10, u(cord6, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord7 = vcat(x, y, z, t)\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord3, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord7, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "                cord8 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord4, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord8, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).((*).(3.33564095198152e-11, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.0049215658]], 1, var\"##θ#230\")), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0049215658, 0.0, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0049215658, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0049215658, 0.0, 0.0, 0.0]], 1, var\"##θ#230\")) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()))], NeuralPDE.PINNRepresentation(#= circular reference @-3 =#), Core.Box(NonAdaptiveLoss{Float32}(Float32[1.0, 1.0, 1.0, 1.0, 1.0], Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], Float32[1.0])), 50, true, Base.RefValue{Int64}(1), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), var\"#additional_loss#9\"{Int64}(10), false), var\"#additional_loss#9\"{Int64}(10), NeuralPDE.var\"#197#198\"{_loss_function, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing} where _loss_function[NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord5 = vcat(x, y, z, t)\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord1, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")) .- (*).(-12.566370614359172, u(cord5, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord6 = vcat(x, y, z, t)\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord2, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))) .- (*).(-4.191690043903363e-10, u(cord6, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord7 = vcat(x, y, z, t)\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord3, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord7, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "                cord8 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord4, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord8, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).((*).(3.33564095198152e-11, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.0049215658]], 1, var\"##θ#230\")), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0049215658, 0.0, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0049215658, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0049215658, 0.0, 0.0, 0.0]], 1, var\"##θ#230\")) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing)], NeuralPDE.var\"#197#198\"{_loss_function, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing} where _loss_function[NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord2, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord3, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord4, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing)]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = discretize(pde_system, discretization)\n",
    "sym_prob = symbolic_discretize(pde_system, discretization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21235add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_callback (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#phi = discretization.phi\n",
    "pde_inner_loss_functions = sym_prob.loss_functions.pde_loss_functions\n",
    "bcs_inner_loss_functions = sym_prob.loss_functions.bc_loss_functions\n",
    "add_functon = sym_prob.loss_functions.additional_loss_function\n",
    "\n",
    "\n",
    "\n",
    "# Создаем логгер для TensorBoard\n",
    "logger = TBLogger(\"../../logs/inverse_npde_exp\")\n",
    "\n",
    "function create_callback()\n",
    "    iter = 0  # Локальный счетчик итераций\n",
    "\n",
    "    return function (p, l)\n",
    "        \n",
    "        iter += 1  # Увеличиваем номер итерации\n",
    "        \n",
    "        # Логируем общую потерю\n",
    "        log_value(logger, \"Loss/Total\", l; step=iter)\n",
    "        \n",
    "        # Логируем потери по PDE\n",
    "        pde_losses = map(l_ -> l_(p.u), pde_inner_loss_functions)\n",
    "        for (i, pde_loss) in enumerate(pde_losses)\n",
    "            log_value(logger, \"Loss/PDE_$i\", pde_loss; step=iter)\n",
    "        end\n",
    "        \n",
    "        # Логируем потери по граничным условиям\n",
    "        bcs_losses = map(l_ -> l_(p.u), bcs_inner_loss_functions)\n",
    "        for (i, bc_loss) in enumerate(bcs_losses)\n",
    "            log_value(logger, \"Loss/BC_$i\", bc_loss; step=iter)\n",
    "        end\n",
    "        \n",
    "        # Выводим информацию в консоль\n",
    "        println(\"Iteration: $iter, Total Loss: $l\")\n",
    "        println(\"PDE Losses: \", pde_losses)\n",
    "        println(\"BC Losses: \", bcs_losses)\n",
    "        \n",
    "        return false\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a7efe4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#22 (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = create_callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f8d8b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam(0.001, (0.9, 0.999), 1.0e-8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оптимизация\n",
    "opt = OptimizationOptimisers.Adam(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f985ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2, Total Loss: 32.620009136009585\n",
      "PDE Losses: [26.08448274869011, 5.112024676015553e-6, 5.196069098985501e-6, 5.1098342774461885e-6, 3.2560078804921945e-5]\n",
      "BC Losses: [0.16840384601949607, 0.16209392460857575, 0.1538349991126832, 0.17756767392898776, 0.15247310921255391, 0.17889902632147903, 0.16846200083314958, 0.16843226472519712, 0.16845072231507316]\n",
      "[26.08448274869011, 5.112024676015553e-6, 5.196069098985501e-6, 5.1098342774461885e-6, 3.2560078804921945e-5]\n",
      "BC Losses: [0.16840384601949607, 0.16209392460857575, 0.1538349991126832, 0.17756767392898776, 0.15247310921255391, 0.17889902632147903, 0.16846200083314958, 0.16843226472519712, 0.16845072231507316]\n",
      "Iteration: 3, Total Loss: 29.43963123314975\n",
      "PDE Losses: [23.55060941452313, 5.213018030316391e-6, 5.113438606671548e-6, 5.088027216532092e-6, 3.215359027682133e-5]\n",
      "BC Losses: [0.1524209109470089, 0.14599582726957355, 0.13811862023069682, 0.16102730200749105, 0.1373201236199592, 0.16192458734113563, 0.152387941132107, 0.1523562001769022, 0.15237944873738116]\n",
      "Iteration: 3, Total Loss: 29.43963123314975\n",
      "PDE Losses: [23.55060941452313, 5.213018030316391e-6, 5.113438606671548e-6, 5.088027216532092e-6, 3.215359027682133e-5]\n",
      "BC Losses: [0.1524209109470089, 0.14599582726957355, 0.13811862023069682, 0.16102730200749105, 0.1373201236199592, 0.16192458734113563, 0.152387941132107, 0.1523562001769022, 0.15237944873738116]\n",
      "Iteration: 4, Total Loss: 26.472258526874445\n",
      "PDE Losses: [21.19328179576555, 5.238815312651155e-6, 5.022366627014676e-6, 5.247357158355353e-6, 3.2017705925395655e-5]\n",
      "BC Losses: [0.1374823543030924, 0.1310361050006132, 0.12373694785902492, 0.14570369158024543, 0.12321863351911652, 0.1461867257399337, 0.13751397288614428, 0.13747026066476348, 0.13751816682516155]\n",
      "Iteration: 4, Total Loss: 26.472258526874445\n",
      "PDE Losses: [21.19328179576555, 5.238815312651155e-6, 5.022366627014676e-6, 5.247357158355353e-6, 3.2017705925395655e-5]\n",
      "BC Losses: [0.1374823543030924, 0.1310361050006132, 0.12373694785902492, 0.14570369158024543, 0.12321863351911652, 0.1461867257399337, 0.13751397288614428, 0.13747026066476348, 0.13751816682516155]\n",
      "Iteration: 5, Total Loss: 23.75010261464153\n",
      "PDE Losses: [19.030497656347812, 5.148571153996207e-6, 5.1952088353357366e-6, 5.089728795413693e-6, 3.1636569010450553e-5]\n",
      "BC Losses: [0.12376713254362719, 0.1172815409112877, 0.11051732936946135, 0.1314607246620572, 0.11037016999369284, 0.13165216775570776, 0.1237547701457851, 0.12375244789036961, 0.1237722833464436]\n",
      "Iteration: 5, Total Loss: 23.75010261464153\n",
      "PDE Losses: [19.030497656347812, 5.148571153996207e-6, 5.1952088353357366e-6, 5.089728795413693e-6, 3.1636569010450553e-5]\n",
      "BC Losses: [0.12376713254362719, 0.1172815409112877, 0.11051732936946135, 0.1314607246620572, 0.11037016999369284, 0.13165216775570776, 0.1237547701457851, 0.12375244789036961, 0.1237722833464436]\n",
      "Iteration: 6, Total Loss: 21.22237027563097\n",
      "PDE Losses: [17.03980386787724, 5.1321527426294095e-6, 5.106876970687275e-6, 5.108888428223019e-6, 3.114802918388866e-5]\n",
      "BC Losses: [0.11112899173321578, 0.10458089727960172, 0.09837937458961507, 0.11822096598002063, 0.09844243672968128, 0.11821633238765969, 0.11108115112672035, 0.11113025911161031, 0.11111571583262352]\n",
      "Iteration: 6, Total Loss: 21.22237027563097\n",
      "PDE Losses: [17.03980386787724, 5.1321527426294095e-6, 5.106876970687275e-6, 5.108888428223019e-6, 3.114802918388866e-5]\n",
      "BC Losses: [0.11112899173321578, 0.10458089727960172, 0.09837937458961507, 0.11822096598002063, 0.09844243672968128, 0.11821633238765969, 0.11108115112672035, 0.11113025911161031, 0.11111571583262352]\n",
      "Iteration: 7, Total Loss: 18.900061246883148\n",
      "PDE Losses: [15.180978375614469, 4.973980822255632e-6, 5.115681672844028e-6, 5.081876912059302e-6, 3.1090680215351644e-5]\n",
      "BC Losses: [0.09938573694408082, 0.09284685156912884, 0.0872383104314589, 0.10584335528160577, 0.08752993057776015, 0.1056864008852274, 0.09939874655995704, 0.09935349091730689, 0.0993922697654747]\n",
      "Iteration: 7, Total Loss: 18.900061246883148\n",
      "PDE Losses: [15.180978375614469, 4.973980822255632e-6, 5.115681672844028e-6, 5.081876912059302e-6, 3.1090680215351644e-5]\n",
      "BC Losses: [0.09938573694408082, 0.09284685156912884, 0.0872383104314589, 0.10584335528160577, 0.08752993057776015, 0.1056864008852274, 0.09939874655995704, 0.09935349091730689, 0.0993922697654747]\n",
      "Iteration: 8, Total Loss: 16.730125115707235\n",
      "PDE Losses: [13.460855184866963, 5.056003799619086e-6, 5.014674381781277e-6, 5.050242476982795e-6, 3.0875065876926254e-5]\n",
      "BC Losses: [0.08852443284233413, 0.08193102412112574, 0.07700022587735583, 0.09431974139594018, 0.07738038273397992, 0.09398743176840971, 0.0885327612694537, 0.08851220093418706, 0.08854351548217221]\n",
      "Iteration: 8, Total Loss: 16.730125115707235\n",
      "PDE Losses: [13.460855184866963, 5.056003799619086e-6, 5.014674381781277e-6, 5.050242476982795e-6, 3.0875065876926254e-5]\n",
      "BC Losses: [0.08852443284233413, 0.08193102412112574, 0.07700022587735583, 0.09431974139594018, 0.07738038273397992, 0.09398743176840971, 0.0885327612694537, 0.08851220093418706, 0.08854351548217221]\n",
      "Iteration: 9, Total Loss: 14.728774501591687\n",
      "PDE Losses: [11.872407961115051, 5.048129868958615e-6, 4.966704282979675e-6, 4.953390276978338e-6, 3.077085489713433e-5]\n",
      "BC Losses: [0.07847768522468096, 0.07186315601371021, 0.06763095858171261, 0.08359491238855288, 0.0680950253990697, 0.0831861452516152, 0.07849698681226568, 0.07847070169457215, 0.07842560865792529]\n",
      "Iteration: 9, Total Loss: 14.728774501591687\n",
      "PDE Losses: [11.872407961115051, 5.048129868958615e-6, 4.966704282979675e-6, 4.953390276978338e-6, 3.077085489713433e-5]\n",
      "BC Losses: [0.07847768522468096, 0.07186315601371021, 0.06763095858171261, 0.08359491238855288, 0.0680950253990697, 0.0831861452516152, 0.07849698681226568, 0.07847070169457215, 0.07842560865792529]\n",
      "Iteration: 10, Total Loss: 12.900746568604788\n",
      "PDE Losses: [10.418206401864891, 4.9384141864592685e-6, 5.0330681161682725e-6, 5.086439091751185e-6, 2.9923324886796564e-5]\n",
      "BC Losses: [0.0692453420608677, 0.06264093310221276, 0.05908324574481273, 0.07365635569623383, 0.05954641570612369, 0.07325664535634815, 0.06922851551602291, 0.06924950657641067, 0.06925184128955779]\n",
      "Iteration: 10, Total Loss: 12.900746568604788\n",
      "PDE Losses: [10.418206401864891, 4.9384141864592685e-6, 5.0330681161682725e-6, 5.086439091751185e-6, 2.9923324886796564e-5]\n",
      "BC Losses: [0.0692453420608677, 0.06264093310221276, 0.05908324574481273, 0.07365635569623383, 0.05954641570612369, 0.07325664535634815, 0.06922851551602291, 0.06924950657641067, 0.06925184128955779]\n",
      "Iteration: 11, Total Loss: 11.252484282407952\n",
      "PDE Losses: [9.096188114200633, 4.870554906324686e-6, 4.964381619988868e-6, 5.03457684980436e-6, 2.9656493353023407e-5]\n",
      "BC Losses: [0.06081989979059928, 0.05430432293950063, 0.05133032036546445, 0.06456380386700492, 0.05180455332417086, 0.06414860359796236, 0.060853841373041846, 0.060825986273747926, 0.060808065855770914]\n",
      "Iteration: 11, Total Loss: 11.252484282407952\n",
      "PDE Losses: [9.096188114200633, 4.870554906324686e-6, 4.964381619988868e-6, 5.03457684980436e-6, 2.9656493353023407e-5]\n",
      "BC Losses: [0.06081989979059928, 0.05430432293950063, 0.05133032036546445, 0.06456380386700492, 0.05180455332417086, 0.06414860359796236, 0.060853841373041846, 0.060825986273747926, 0.060808065855770914]\n",
      "Iteration: 12, Total Loss: 9.750502045274848\n",
      "PDE Losses: [7.894228381629563, 4.951813538069829e-6, 4.942404153527808e-6, 4.880766580869571e-6, 2.94454437488961e-5]\n",
      "BC Losses: [0.05317806898666201, 0.046728200147400874, 0.04442931487883661, 0.056277659494276905, 0.04481650603049218, 0.05591288057801237, 0.053152098865831984, 0.05318130878955129, 0.05318903956478616]\n",
      "Iteration: 12, Total Loss: 9.750502045274848\n",
      "PDE Losses: [7.894228381629563, 4.951813538069829e-6, 4.942404153527808e-6, 4.880766580869571e-6, 2.94454437488961e-5]\n",
      "BC Losses: [0.05317806898666201, 0.046728200147400874, 0.04442931487883661, 0.056277659494276905, 0.04481650603049218, 0.05591288057801237, 0.053152098865831984, 0.05318130878955129, 0.05318903956478616]\n",
      "Iteration: 13, Total Loss: 8.401021937418527\n",
      "PDE Losses: [6.813099497290361, 4.877964504244298e-6, 4.818038963963417e-6, 4.917180275881949e-6, 2.954256267233285e-5]\n",
      "BC Losses: [0.04632459142527711, 0.03995593738911566, 0.03823244169864274, 0.04878888432505436, 0.03857728914907049, 0.04843500956849235, 0.04632634014008395, 0.0462849339481745, 0.04630017432159478]\n",
      "Iteration: 13, Total Loss: 8.401021937418527\n",
      "PDE Losses: [6.813099497290361, 4.877964504244298e-6, 4.818038963963417e-6, 4.917180275881949e-6, 2.954256267233285e-5]\n",
      "BC Losses: [0.04632459142527711, 0.03995593738911566, 0.03823244169864274, 0.04878888432505436, 0.03857728914907049, 0.04843500956849235, 0.04632634014008395, 0.0462849339481745, 0.04630017432159478]\n",
      "Iteration: 14, Total Loss: 7.209495114803256\n",
      "PDE Losses: [5.841630824784156, 4.775076080385682e-6, 4.840346594942372e-6, 4.8425756136834315e-6, 2.792870018322451e-5]\n",
      "BC Losses: [0.040098925900921345, 0.03392690150765419, 0.032726212833537084, 0.04204709473110918, 0.032986633539157276, 0.041776371844168006, 0.04012347816187846, 0.04010857718638657, 0.04011426740096381]\n",
      "Iteration: 14, Total Loss: 7.209495114803256\n",
      "PDE Losses: [5.841630824784156, 4.775076080385682e-6, 4.840346594942372e-6, 4.8425756136834315e-6, 2.792870018322451e-5]\n",
      "BC Losses: [0.040098925900921345, 0.03392690150765419, 0.032726212833537084, 0.04204709473110918, 0.032986633539157276, 0.041776371844168006, 0.04012347816187846, 0.04010857718638657, 0.04011426740096381]\n",
      "Iteration: 15, Total Loss: 6.147835721528569\n",
      "PDE Losses: [4.993007061508987, 4.868371408506179e-6, 4.797594133204756e-6, 4.7383645341669135e-6, 2.824688761186223e-5]\n",
      "BC Losses: [0.0345914025696141, 0.028638734503260984, 0.027874755065886263, 0.03601861687842308, 0.028027975967312487, 0.03588380521240108, 0.03458431431536539, 0.03458073816680768, 0.034574548506432747]\n",
      "Iteration: 15, Total Loss: 6.147835721528569\n",
      "PDE Losses: [4.993007061508987, 4.868371408506179e-6, 4.797594133204756e-6, 4.7383645341669135e-6, 2.824688761186223e-5]\n",
      "BC Losses: [0.0345914025696141, 0.028638734503260984, 0.027874755065886263, 0.03601861687842308, 0.028027975967312487, 0.03588380521240108, 0.03458431431536539, 0.03458073816680768, 0.034574548506432747]\n",
      "Iteration: 16, Total Loss: 5.198891806430444\n",
      "PDE Losses: [4.232665120892219, 4.810044527529242e-6, 4.76931242782088e-6, 4.819314560375397e-6, 2.7645796378644657e-5]\n",
      "BC Losses: [0.029652300465087628, 0.023935643006464592, 0.023607840020270443, 0.03062996914615819, 0.023660202067807643, 0.030563959422608027, 0.029659602236933688, 0.02964610380599298, 0.02966346514315863]\n",
      "Iteration: 16, Total Loss: 5.198891806430444\n",
      "PDE Losses: [4.232665120892219, 4.810044527529242e-6, 4.76931242782088e-6, 4.819314560375397e-6, 2.7645796378644657e-5]\n",
      "BC Losses: [0.029652300465087628, 0.023935643006464592, 0.023607840020270443, 0.03062996914615819, 0.023660202067807643, 0.030563959422608027, 0.029659602236933688, 0.02964610380599298, 0.02966346514315863]\n",
      "Iteration: 17, Total Loss: 4.378068449464981\n",
      "PDE Losses: [3.5688888234505063, 4.87145592027509e-6, 4.698382421604518e-6, 4.845087992370231e-6, 2.7592709188395302e-5]\n",
      "BC Losses: [0.02527586823946699, 0.019868675413760202, 0.01990111465637534, 0.02587276914128319, 0.019840992560744272, 0.025903771595933905, 0.025271464661150975, 0.025291029253567493, 0.025299687858976162]\n",
      "Iteration: 17, Total Loss: 4.378068449464981\n",
      "PDE Losses: [3.5688888234505063, 4.87145592027509e-6, 4.698382421604518e-6, 4.845087992370231e-6, 2.7592709188395302e-5]\n",
      "BC Losses: [0.02527586823946699, 0.019868675413760202, 0.01990111465637534, 0.02587276914128319, 0.019840992560744272, 0.025903771595933905, 0.025271464661150975, 0.025291029253567493, 0.025299687858976162]\n",
      "Iteration: 18, Total Loss: 3.6625549002504303\n",
      "PDE Losses: [2.987740373186266, 4.682785771242937e-6, 4.732421974655537e-6, 4.708641471636244e-6, 2.6930830787361555e-5]\n",
      "BC Losses: [0.021459746726421855, 0.01638477566642521, 0.016681952705154726, 0.021686842277969402, 0.01653016420239914, 0.021784319709084718, 0.02145448561232026, 0.021459650329930427, 0.02146089339972558]\n",
      "Iteration: 18, Total Loss: 3.6625549002504303\n",
      "PDE Losses: [2.987740373186266, 4.682785771242937e-6, 4.732421974655537e-6, 4.708641471636244e-6, 2.6930830787361555e-5]\n",
      "BC Losses: [0.021459746726421855, 0.01638477566642521, 0.016681952705154726, 0.021686842277969402, 0.01653016420239914, 0.021784319709084718, 0.02145448561232026, 0.021459650329930427, 0.02146089339972558]\n",
      "Iteration: 19, Total Loss: 3.057055736075923\n",
      "PDE Losses: [2.4880153953874924, 4.684557327609847e-6, 4.68984206812902e-6, 4.760013094202238e-6, 2.65465223951452e-5]\n",
      "BC Losses: [0.01808037567191255, 0.01338908543078076, 0.013918419288752357, 0.018033477141174193, 0.013696502950093776, 0.018237919725228764, 0.0180895507337316, 0.018100487056435063, 0.01807442414738342]\n",
      "Iteration: 19, Total Loss: 3.057055736075923\n",
      "PDE Losses: [2.4880153953874924, 4.684557327609847e-6, 4.68984206812902e-6, 4.760013094202238e-6, 2.65465223951452e-5]\n",
      "BC Losses: [0.01808037567191255, 0.01338908543078076, 0.013918419288752357, 0.018033477141174193, 0.013696502950093776, 0.018237919725228764, 0.0180895507337316, 0.018100487056435063, 0.01807442414738342]\n",
      "Iteration: 20, Total Loss: 2.5316419207332252\n",
      "PDE Losses: [2.05564107613132, 4.6481154006210755e-6, 4.715301724376961e-6, 4.583608091432849e-6, 2.6250758100653e-5]\n",
      "BC Losses: [0.015159129309634376, 0.010901281178070791, 0.011585065559756347, 0.014858992916375663, 0.011305336622700581, 0.015122550352245946, 0.015163535214484634, 0.015163448671823022, 0.015163268904737452]\n",
      "Iteration: 20, Total Loss: 2.5316419207332252\n",
      "PDE Losses: [2.05564107613132, 4.6481154006210755e-6, 4.715301724376961e-6, 4.583608091432849e-6, 2.6250758100653e-5]\n",
      "BC Losses: [0.015159129309634376, 0.010901281178070791, 0.011585065559756347, 0.014858992916375663, 0.011305336622700581, 0.015122550352245946, 0.015163535214484634, 0.015163448671823022, 0.015163268904737452]\n",
      "Iteration: 21, Total Loss: 2.087581849810044\n",
      "PDE Losses: [1.6946764474339342, 4.65432703143369e-6, 4.650224652604486e-6, 4.626405869331922e-6, 2.5826989670370496e-5]\n",
      "BC Losses: [0.01264236977282342, 0.008848379089686298, 0.009666170965461962, 0.012128949829242267, 0.009300261044524555, 0.01250414620427977, 0.012644677364419387, 0.012641013149231538, 0.012647604544950312]\n",
      "Iteration: 21, Total Loss: 2.087581849810044\n",
      "PDE Losses: [1.6946764474339342, 4.65432703143369e-6, 4.650224652604486e-6, 4.626405869331922e-6, 2.5826989670370496e-5]\n",
      "BC Losses: [0.01264236977282342, 0.008848379089686298, 0.009666170965461962, 0.012128949829242267, 0.009300261044524555, 0.01250414620427977, 0.012644677364419387, 0.012641013149231538, 0.012647604544950312]\n",
      "Iteration: 22, Total Loss: 1.7326281820461944\n",
      "PDE Losses: [1.3954616844605363, 4.606312571878016e-6, 4.510067830814026e-6, 4.621317723876848e-6, 2.5831425389540156e-5]\n",
      "BC Losses: [0.010499200109738139, 0.007184059549960261, 0.008095745270361774, 0.009827399698731963, 0.007678242148118747, 0.010227199761695312, 0.01049957141569902, 0.010504587808774129, 0.010511249687636162]\n",
      "Iteration: 22, Total Loss: 1.7326281820461944\n",
      "PDE Losses: [1.3954616844605363, 4.606312571878016e-6, 4.510067830814026e-6, 4.621317723876848e-6, 2.5831425389540156e-5]\n",
      "BC Losses: [0.010499200109738139, 0.007184059549960261, 0.008095745270361774, 0.009827399698731963, 0.007678242148118747, 0.010227199761695312, 0.01049957141569902, 0.010504587808774129, 0.010511249687636162]\n",
      "Iteration: 23, Total Loss: 1.4305813072172007\n",
      "PDE Losses: [1.1461224422697294, 4.5206461915881525e-6, 4.595944614450202e-6, 4.5159950850419505e-6, 2.5089449588058266e-5]\n",
      "BC Losses: [0.008714913694418692, 0.0058705582599500265, 0.006875822617525383, 0.007888971074297958, 0.006388310706516422, 0.008371426114678067, 0.00870191093058791, 0.008705923018174536, 0.008710798681916598]\n",
      "Iteration: 23, Total Loss: 1.4305813072172007\n",
      "PDE Losses: [1.1461224422697294, 4.5206461915881525e-6, 4.595944614450202e-6, 4.5159950850419505e-6, 2.5089449588058266e-5]\n",
      "BC Losses: [0.008714913694418692, 0.0058705582599500265, 0.006875822617525383, 0.007888971074297958, 0.006388310706516422, 0.008371426114678067, 0.00870191093058791, 0.008705923018174536, 0.008710798681916598]\n",
      "Iteration: 24, Total Loss: 1.192056146182413\n",
      "PDE Losses: [0.9457642051336947, 4.530110903215101e-6, 4.56811774693438e-6, 4.658434806185908e-6, 2.4477789002787858e-5]\n",
      "BC Losses: [0.00721636827192741, 0.0048743469160593186, 0.005923119320828985, 0.006273340266069094, 0.005378352098163877, 0.006790840792798871, 0.007217335739794731, 0.007215443115514669, 0.007215459641812393]\n",
      "Iteration: 24, Total Loss: 1.192056146182413\n",
      "PDE Losses: [0.9457642051336947, 4.530110903215101e-6, 4.56811774693438e-6, 4.658434806185908e-6, 2.4477789002787858e-5]\n",
      "BC Losses: [0.00721636827192741, 0.0048743469160593186, 0.005923119320828985, 0.006273340266069094, 0.005378352098163877, 0.006790840792798871, 0.007217335739794731, 0.007215443115514669, 0.007215459641812393]\n",
      "Iteration: 25, Total Loss: 1.0036917494817315\n",
      "PDE Losses: [0.788285216081704, 4.440538744691414e-6, 4.5368666438669195e-6, 4.4495616256413926e-6, 2.4166007448155664e-5]\n",
      "BC Losses: [0.0059924246216622595, 0.004139903024817445, 0.0052129312726455004, 0.004958181261431339, 0.004632348796541613, 0.005533611687619204, 0.006000718327556885, 0.005994897488619364, 0.005985807930245534]\n",
      "Iteration: 25, Total Loss: 1.0036917494817315\n",
      "PDE Losses: [0.788285216081704, 4.440538744691414e-6, 4.5368666438669195e-6, 4.4495616256413926e-6, 2.4166007448155664e-5]\n",
      "BC Losses: [0.0059924246216622595, 0.004139903024817445, 0.0052129312726455004, 0.004958181261431339, 0.004632348796541613, 0.005533611687619204, 0.006000718327556885, 0.005994897488619364, 0.005985807930245534]\n",
      "Iteration: 26, Total Loss: 0.8584323276573012\n",
      "PDE Losses: [0.6695853688603651, 4.557463277433809e-6, 4.537785531910789e-6, 4.546811647444051e-6, 2.416478548116992e-5]\n",
      "BC Losses: [0.0050192447338248776, 0.0036229165539025253, 0.004710630493461787, 0.0038905508791816914, 0.004088656482666134, 0.004532169062119999, 0.005016286417462261, 0.00501464128950375, 0.005017701110831162]\n",
      "Iteration: 26, Total Loss: 0.8584323276573012\n",
      "PDE Losses: [0.6695853688603651, 4.557463277433809e-6, 4.537785531910789e-6, 4.546811647444051e-6, 2.416478548116992e-5]\n",
      "BC Losses: [0.0050192447338248776, 0.0036229165539025253, 0.004710630493461787, 0.0038905508791816914, 0.004088656482666134, 0.004532169062119999, 0.005016286417462261, 0.00501464128950375, 0.005017701110831162]\n",
      "Iteration: 27, Total Loss: 0.752579938914558\n",
      "PDE Losses: [0.5797359634972231, 4.4816431114863475e-6, 4.547809213173084e-6, 4.471044056741407e-6, 2.373011696280464e-5]\n",
      "BC Losses: [0.004248104089536459, 0.003285409499755078, 0.004376447578731268, 0.003059422423549229, 0.003708867462736146, 0.0037350877988863653, 0.004247148849635415, 0.004248729303223733, 0.004246662243325164]\n",
      "Iteration: 27, Total Loss: 0.752579938914558\n",
      "PDE Losses: [0.5797359634972231, 4.4816431114863475e-6, 4.547809213173084e-6, 4.471044056741407e-6, 2.373011696280464e-5]\n",
      "BC Losses: [0.004248104089536459, 0.003285409499755078, 0.004376447578731268, 0.003059422423549229, 0.003708867462736146, 0.0037350877988863653, 0.004247148849635415, 0.004248729303223733, 0.004246662243325164]\n",
      "Iteration: 28, Total Loss: 0.6768055485701447\n",
      "PDE Losses: [0.5163664352537323, 4.447718822130881e-6, 4.5608280509853275e-6, 4.483432977798805e-6, 2.336285972386511e-5]\n",
      "BC Losses: [0.0036576651212368175, 0.0030811827888914223, 0.004183385286834857, 0.0024073355711507153, 0.003469365025733761, 0.0031448586791127425, 0.003657462003534768, 0.0036589795831023955, 0.0036621785463099234]\n",
      "Iteration: 28, Total Loss: 0.6768055485701447\n",
      "PDE Losses: [0.5163664352537323, 4.447718822130881e-6, 4.5608280509853275e-6, 4.483432977798805e-6, 2.336285972386511e-5]\n",
      "BC Losses: [0.0036576651212368175, 0.0030811827888914223, 0.004183385286834857, 0.0024073355711507153, 0.003469365025733761, 0.0031448586791127425, 0.003657462003534768, 0.0036589795831023955, 0.0036621785463099234]\n",
      "Iteration: 29, Total Loss: 0.6263111955776516\n",
      "PDE Losses: [0.47355066178082084, 4.4863043412279816e-6, 4.4400782272959245e-6, 4.470439424361745e-6, 2.3286947258342377e-5]\n",
      "BC Losses: [0.0032185804208124404, 0.002991223042322457, 0.004090779408816183, 0.0019239584021470977, 0.0033317067255833658, 0.0027162464524777864, 0.0032144722598798636, 0.0032158697204424567, 0.003217776097619371]\n",
      "Iteration: 29, Total Loss: 0.6263111955776516\n",
      "PDE Losses: [0.47355066178082084, 4.4863043412279816e-6, 4.4400782272959245e-6, 4.470439424361745e-6, 2.3286947258342377e-5]\n",
      "BC Losses: [0.0032185804208124404, 0.002991223042322457, 0.004090779408816183, 0.0019239584021470977, 0.0033317067255833658, 0.0027162464524777864, 0.0032144722598798636, 0.0032158697204424567, 0.003217776097619371]\n",
      "Iteration: 30, Total Loss: 0.593285855255927\n",
      "PDE Losses: [0.44652953023631536, 4.439123676710578e-6, 4.42360031107174e-6, 4.459716492299067e-6, 2.283326732636971e-5]\n",
      "BC Losses: [0.002904944857395608, 0.0029684779681114, 0.004068376972504735, 0.0015782243148029338, 0.003259362439325982, 0.002416375933152978, 0.002900686934173737, 0.002897892324924556, 0.002900412418483611]\n",
      "Iteration: 30, Total Loss: 0.593285855255927\n",
      "PDE Losses: [0.44652953023631536, 4.439123676710578e-6, 4.42360031107174e-6, 4.459716492299067e-6, 2.283326732636971e-5]\n",
      "BC Losses: [0.002904944857395608, 0.0029684779681114, 0.004068376972504735, 0.0015782243148029338, 0.003259362439325982, 0.002416375933152978, 0.002900686934173737, 0.002897892324924556, 0.002900412418483611]\n",
      "Iteration: 31, Total Loss: 0.5762580109761043\n",
      "PDE Losses: [0.43220629139525385, 4.414641791372555e-6, 4.406304469938158e-6, 4.382590704363795e-6, 2.2299892488890983e-5]\n",
      "BC Losses: [0.0026942651921183355, 0.0030096876902469365, 0.004104346612274533, 0.0013380974629269688, 0.0032465251551603517, 0.0022202000693392057, 0.00268377532167717, 0.0026919346460145457, 0.002688334883399112]\n",
      "Iteration: 31, Total Loss: 0.5762580109761043\n",
      "PDE Losses: [0.43220629139525385, 4.414641791372555e-6, 4.406304469938158e-6, 4.382590704363795e-6, 2.2299892488890983e-5]\n",
      "BC Losses: [0.0026942651921183355, 0.0030096876902469365, 0.004104346612274533, 0.0013380974629269688, 0.0032465251551603517, 0.0022202000693392057, 0.00268377532167717, 0.0026919346460145457, 0.002688334883399112]\n",
      "Iteration: 32, Total Loss: 0.5690548187064611\n",
      "PDE Losses: [0.42788793576196016, 4.388843264903869e-6, 4.329094865166923e-6, 4.35570786155607e-6, 2.199487832686582e-5]\n",
      "BC Losses: [0.0025691694644494213, 0.0030757349162624636, 0.004163335679194066, 0.0011947957407267562, 0.0032628610715305854, 0.0021276072778878144, 0.0025585666527909957, 0.0025611812692236664, 0.0025613326980025016]\n",
      "Iteration: 32, Total Loss: 0.5690548187064611\n",
      "PDE Losses: [0.42788793576196016, 4.388843264903869e-6, 4.329094865166923e-6, 4.35570786155607e-6, 2.199487832686582e-5]\n",
      "BC Losses: [0.0025691694644494213, 0.0030757349162624636, 0.004163335679194066, 0.0011947957407267562, 0.0032628610715305854, 0.0021276072778878144, 0.0025585666527909957, 0.0025611812692236664, 0.0025613326980025016]\n",
      "Iteration: 33, Total Loss: 0.576084065299193\n",
      "PDE Losses: [0.42942692378220626, 4.341881583046836e-6, 4.327926728968352e-6, 4.375230334722278e-6, 2.1523507583752438e-5]\n",
      "BC Losses: [0.002505980826404271, 0.003162449367703828, 0.004253326458218066, 0.0011197445165289249, 0.0032931874015203876, 0.0020900922819012922, 0.002496488286696497, 0.0024985733586364994, 0.0025014220281178675]\n",
      "Iteration: 33, Total Loss: 0.576084065299193\n",
      "PDE Losses: [0.42942692378220626, 4.341881583046836e-6, 4.327926728968352e-6, 4.375230334722278e-6, 2.1523507583752438e-5]\n",
      "BC Losses: [0.002505980826404271, 0.003162449367703828, 0.004253326458218066, 0.0011197445165289249, 0.0032931874015203876, 0.0020900922819012922, 0.002496488286696497, 0.0024985733586364994, 0.0025014220281178675]\n",
      "Iteration: 34, Total Loss: 0.5843599880962131\n",
      "PDE Losses: [0.43700640754376635, 4.250729028874866e-6, 4.2928753900811965e-6, 4.302068239761888e-6, 2.1661556164572656e-5]\n",
      "BC Losses: [0.002488313877286228, 0.0032681436950749102, 0.004340700210659601, 0.0011037425456791533, 0.0033518285418930732, 0.0021214434871329353, 0.002490266520047856, 0.0024876575255227923, 0.0024892356418391116]\n",
      "Iteration: 34, Total Loss: 0.5843599880962131\n",
      "PDE Losses: [0.43700640754376635, 4.250729028874866e-6, 4.2928753900811965e-6, 4.302068239761888e-6, 2.1661556164572656e-5]\n",
      "BC Losses: [0.002488313877286228, 0.0032681436950749102, 0.004340700210659601, 0.0011037425456791533, 0.0033518285418930732, 0.0021214434871329353, 0.002490266520047856, 0.0024876575255227923, 0.0024892356418391116]\n",
      "Iteration: 35, Total Loss: 0.6010811434410077\n",
      "PDE Losses: [0.4452656286924769, 4.270855094734779e-6, 4.2776416600033494e-6, 4.26268250414186e-6, 2.1040505739252585e-5]\n",
      "BC Losses: [0.002519621400830427, 0.0033627292076611093, 0.004435393536731811, 0.0011183572873395046, 0.00340414549940203, 0.0021877793586098484, 0.002505172729685599, 0.002503433555142874, 0.0025155738451990727]\n",
      "Iteration: 35, Total Loss: 0.6010811434410077\n",
      "PDE Losses: [0.4452656286924769, 4.270855094734779e-6, 4.2776416600033494e-6, 4.26268250414186e-6, 2.1040505739252585e-5]\n",
      "BC Losses: [0.002519621400830427, 0.0033627292076611093, 0.004435393536731811, 0.0011183572873395046, 0.00340414549940203, 0.0021877793586098484, 0.002505172729685599, 0.002503433555142874, 0.0025155738451990727]\n",
      "Iteration: 36, Total Loss: 0.6189539264701611\n",
      "PDE Losses: [0.45727193333960203, 4.2654216988892215e-6, 4.362821390727259e-6, 4.347234409701516e-6, 2.1276414645646056e-5]\n",
      "BC Losses: [0.0025439112665643013, 0.0034529737141415213, 0.004520615666591229, 0.0011730655199870808, 0.0034493841195186404, 0.002268912651389389, 0.0025534700360495995, 0.0025329694603816776, 0.0025470758811126032]\n",
      "Iteration: 36, Total Loss: 0.6189539264701611\n",
      "PDE Losses: [0.45727193333960203, 4.2654216988892215e-6, 4.362821390727259e-6, 4.347234409701516e-6, 2.1276414645646056e-5]\n",
      "BC Losses: [0.0025439112665643013, 0.0034529737141415213, 0.004520615666591229, 0.0011730655199870808, 0.0034493841195186404, 0.002268912651389389, 0.0025534700360495995, 0.0025329694603816776, 0.0025470758811126032]\n",
      "Iteration: 37, Total Loss: 0.6376661526528384\n",
      "PDE Losses: [0.4664202266447346, 4.2495380308541334e-6, 4.142642325912175e-6, 4.352957865421964e-6, 2.0775404910981657e-5]\n",
      "BC Losses: [0.0026148960378568472, 0.0035377894986704577, 0.004600380797000427, 0.0012274242245440712, 0.003489315457391083, 0.0023519264949814424, 0.0025988528863512862, 0.0026089542398485517, 0.0026074068147191624]\n",
      "Iteration: 37, Total Loss: 0.6376661526528384\n",
      "PDE Losses: [0.4664202266447346, 4.2495380308541334e-6, 4.142642325912175e-6, 4.352957865421964e-6, 2.0775404910981657e-5]\n",
      "BC Losses: [0.0026148960378568472, 0.0035377894986704577, 0.004600380797000427, 0.0012274242245440712, 0.003489315457391083, 0.0023519264949814424, 0.0025988528863512862, 0.0026089542398485517, 0.0026074068147191624]\n",
      "Iteration: 38, Total Loss: 0.655496116774828\n",
      "PDE Losses: [0.47835044357720835, 4.245714173189461e-6, 4.179394912379501e-6, 4.268512059587681e-6, 2.0651597719583663e-5]\n",
      "BC Losses: [0.0026573338605078304, 0.0035992210180926278, 0.004650822128213589, 0.0012884049653005773, 0.003516596627286459, 0.002435620301659073, 0.0026584845870256417, 0.0026484358302425607, 0.0026559287283024775]\n",
      "Iteration: 38, Total Loss: 0.655496116774828\n",
      "PDE Losses: [0.47835044357720835, 4.245714173189461e-6, 4.179394912379501e-6, 4.268512059587681e-6, 2.0651597719583663e-5]\n",
      "BC Losses: [0.0026573338605078304, 0.0035992210180926278, 0.004650822128213589, 0.0012884049653005773, 0.003516596627286459, 0.002435620301659073, 0.0026584845870256417, 0.0026484358302425607, 0.0026559287283024775]\n",
      "Iteration: 39, Total Loss: 0.673378018178182\n",
      "PDE Losses: [0.48157280715763223, 4.287906321756475e-6, 4.205238280883473e-6, 4.213548240670447e-6, 2.0319840203513883e-5]\n",
      "BC Losses: [0.0026942311642313118, 0.003638102465701497, 0.004684005531113144, 0.0013410567187764977, 0.003529351651171012, 0.002507236146520782, 0.0026888667287796983, 0.0027011181455783937, 0.002695084249963695]\n",
      "Iteration: 39, Total Loss: 0.673378018178182\n",
      "PDE Losses: [0.48157280715763223, 4.287906321756475e-6, 4.205238280883473e-6, 4.213548240670447e-6, 2.0319840203513883e-5]\n",
      "BC Losses: [0.0026942311642313118, 0.003638102465701497, 0.004684005531113144, 0.0013410567187764977, 0.003529351651171012, 0.002507236146520782, 0.0026888667287796983, 0.0027011181455783937, 0.002695084249963695]\n",
      "Iteration: 40, Total Loss: 0.6887591110181673\n",
      "PDE Losses: [0.48816142067037915, 4.168598002353233e-6, 4.181948744398503e-6, 4.199606208825819e-6, 2.0300706304191104e-5]\n",
      "BC Losses: [0.002709261588752447, 0.0036581163739364923, 0.00469606408064591, 0.0013835713475759059, 0.0035271525047827794, 0.0025469452628396265, 0.002719099937658796, 0.0027060630986667986, 0.002698710008616177]\n",
      "Iteration: 40, Total Loss: 0.6887591110181673\n",
      "PDE Losses: [0.48816142067037915, 4.168598002353233e-6, 4.181948744398503e-6, 4.199606208825819e-6, 2.0300706304191104e-5]\n",
      "BC Losses: [0.002709261588752447, 0.0036581163739364923, 0.00469606408064591, 0.0013835713475759059, 0.0035271525047827794, 0.0025469452628396265, 0.002719099937658796, 0.0027060630986667986, 0.002698710008616177]\n",
      "Iteration: 41, Total Loss: 0.6962741721503964\n",
      "PDE Losses: [0.4874250955962505, 4.238537814947322e-6, 4.11903837490107e-6, 4.154965864116502e-6, 2.011143781535943e-5]\n",
      "BC Losses: [0.0027244889273520595, 0.0036537136149905093, 0.004664944792046248, 0.0014048887952556495, 0.0035077161790880245, 0.0025584141080572716, 0.0027126657454530816, 0.0027124597082476536, 0.002712033354908141]\n",
      "Iteration: 41, Total Loss: 0.6962741721503964\n",
      "PDE Losses: [0.4874250955962505, 4.238537814947322e-6, 4.11903837490107e-6, 4.154965864116502e-6, 2.011143781535943e-5]\n",
      "BC Losses: [0.0027244889273520595, 0.0036537136149905093, 0.004664944792046248, 0.0014048887952556495, 0.0035077161790880245, 0.0025584141080572716, 0.0027126657454530816, 0.0027124597082476536, 0.002712033354908141]\n",
      "Iteration: 42, Total Loss: 0.702750513780189\n",
      "PDE Losses: [0.4839194019130061, 4.149520131183879e-6, 4.26344480388011e-6, 4.130524967652795e-6, 2.017342987602215e-5]\n",
      "BC Losses: [0.0026834090413122916, 0.003618107239661151, 0.004607752041128097, 0.0014128070026688704, 0.003474451652460717, 0.0025434805080156602, 0.0026841775815794194, 0.0026915476797670177, 0.0026817357039667948]\n",
      "Iteration: 42, Total Loss: 0.702750513780189\n",
      "PDE Losses: [0.4839194019130061, 4.149520131183879e-6, 4.26344480388011e-6, 4.130524967652795e-6, 2.017342987602215e-5]\n",
      "BC Losses: [0.0026834090413122916, 0.003618107239661151, 0.004607752041128097, 0.0014128070026688704, 0.003474451652460717, 0.0025434805080156602, 0.0026841775815794194, 0.0026915476797670177, 0.0026817357039667948]\n",
      "Iteration: 43, Total Loss: 0.7063556153809536\n",
      "PDE Losses: [0.47266754819611717, 4.16857157059769e-6, 4.162471872296895e-6, 4.173554396253385e-6, 1.9442241176324982e-5]\n",
      "BC Losses: [0.0026303157357136396, 0.003567248252828536, 0.0045285780457817336, 0.0014029301728921387, 0.003403531604821229, 0.0025081158933208877, 0.002642347899645088, 0.002640600469620111, 0.0026317070209963683]\n",
      "Iteration: 43, Total Loss: 0.7063556153809536\n",
      "PDE Losses: [0.47266754819611717, 4.16857157059769e-6, 4.162471872296895e-6, 4.173554396253385e-6, 1.9442241176324982e-5]\n",
      "BC Losses: [0.0026303157357136396, 0.003567248252828536, 0.0045285780457817336, 0.0014029301728921387, 0.003403531604821229, 0.0025081158933208877, 0.002642347899645088, 0.002640600469620111, 0.0026317070209963683]\n",
      "Iteration: 44, Total Loss: 0.7018760367998673\n",
      "PDE Losses: [0.4620050912143629, 4.174913448040367e-6, 4.222373771007094e-6, 4.098454093192053e-6, 1.9267451460474714e-5]\n",
      "BC Losses: [0.0025593101414788117, 0.00348516576331693, 0.00440900595447374, 0.001369615034018771, 0.0033193350003927454, 0.0024482868553054094, 0.0025683208721672696, 0.002551257251050042, 0.002554662051497798]\n",
      "Iteration: 44, Total Loss: 0.7018760367998673\n",
      "PDE Losses: [0.4620050912143629, 4.174913448040367e-6, 4.222373771007094e-6, 4.098454093192053e-6, 1.9267451460474714e-5]\n",
      "BC Losses: [0.0025593101414788117, 0.00348516576331693, 0.00440900595447374, 0.001369615034018771, 0.0033193350003927454, 0.0024482868553054094, 0.0025683208721672696, 0.002551257251050042, 0.002554662051497798]\n",
      "Iteration: 45, Total Loss: 0.6934415193776501\n",
      "PDE Losses: [0.44836123258594274, 4.240709198648123e-6, 4.082182497711086e-6, 4.1140303909089174e-6, 1.9284512250959634e-5]\n",
      "BC Losses: [0.0024691234206847866, 0.003379448619750124, 0.004268748152495691, 0.0013279800610330893, 0.003227610909410228, 0.002367854435487957, 0.002464908332395839, 0.0024657491524028964, 0.0024692762565602417]\n",
      "Iteration: 45, Total Loss: 0.6934415193776501\n",
      "PDE Losses: [0.44836123258594274, 4.240709198648123e-6, 4.082182497711086e-6, 4.1140303909089174e-6, 1.9284512250959634e-5]\n",
      "BC Losses: [0.0024691234206847866, 0.003379448619750124, 0.004268748152495691, 0.0013279800610330893, 0.003227610909410228, 0.002367854435487957, 0.002464908332395839, 0.0024657491524028964, 0.0024692762565602417]\n",
      "Iteration: 46, Total Loss: 0.6836906133166384\n",
      "PDE Losses: [0.4286842614070834, 4.050727101283864e-6, 4.109930695614112e-6, 4.1302018683887e-6, 1.8946481555210636e-5]\n",
      "BC Losses: [0.002352435593668254, 0.0032514037003450215, 0.004097046615639051, 0.0012649974596150744, 0.0031003478031256244, 0.002253614157588086, 0.0023588618683551884, 0.0023488700333831737, 0.0023664305757365037]\n",
      "Iteration: 46, Total Loss: 0.6836906133166384\n",
      "PDE Losses: [0.4286842614070834, 4.050727101283864e-6, 4.109930695614112e-6, 4.1302018683887e-6, 1.8946481555210636e-5]\n",
      "BC Losses: [0.002352435593668254, 0.0032514037003450215, 0.004097046615639051, 0.0012649974596150744, 0.0031003478031256244, 0.002253614157588086, 0.0023588618683551884, 0.0023488700333831737, 0.0023664305757365037]\n",
      "Iteration: 47, Total Loss: 0.6658019551587219\n",
      "PDE Losses: [0.40708572209705246, 4.064012486365335e-6, 4.1920115004042326e-6, 4.068365194291812e-6, 1.8701256047889227e-5]\n",
      "BC Losses: [0.002229508447792502, 0.003106930831267621, 0.003906876878062619, 0.0012005573682818125, 0.002952687532035362, 0.002139801856560289, 0.0022090193209656018, 0.0022261445226363294, 0.002226982865294845]\n",
      "Iteration: 47, Total Loss: 0.6658019551587219\n",
      "PDE Losses: [0.40708572209705246, 4.064012486365335e-6, 4.1920115004042326e-6, 4.068365194291812e-6, 1.8701256047889227e-5]\n",
      "BC Losses: [0.002229508447792502, 0.003106930831267621, 0.003906876878062619, 0.0012005573682818125, 0.002952687532035362, 0.002139801856560289, 0.0022090193209656018, 0.0022261445226363294, 0.002226982865294845]\n",
      "Iteration: 48, Total Loss: 0.6506227172786996\n",
      "PDE Losses: [0.3873908616318149, 4.109486740627342e-6, 4.064338969714729e-6, 4.005060268961725e-6, 1.8881731537195445e-5]\n",
      "BC Losses: [0.002094587374280551, 0.0029572158475984133, 0.0037055426595075727, 0.001116952714174131, 0.0028111134719071623, 0.0020118192712963905, 0.0021093728691406782, 0.002090400866675788, 0.002107227957923654]\n",
      "Iteration: 48, Total Loss: 0.6506227172786996\n",
      "PDE Losses: [0.3873908616318149, 4.109486740627342e-6, 4.064338969714729e-6, 4.005060268961725e-6, 1.8881731537195445e-5]\n",
      "BC Losses: [0.002094587374280551, 0.0029572158475984133, 0.0037055426595075727, 0.001116952714174131, 0.0028111134719071623, 0.0020118192712963905, 0.0021093728691406782, 0.002090400866675788, 0.002107227957923654]\n",
      "Iteration: 49, Total Loss: 0.6298381372062577\n",
      "PDE Losses: [0.36418536693807574, 4.084901095770664e-6, 4.055532354786228e-6, 4.008229245453432e-6, 1.871170910458023e-5]\n",
      "BC Losses: [0.001960115458041224, 0.002795175539517113, 0.0035003597735128707, 0.0010359242302828769, 0.002647717284010108, 0.0018763964341439606, 0.0019503549062993752, 0.0019643660309817974, 0.001963949046384594]\n",
      "Iteration: 49, Total Loss: 0.6298381372062577\n",
      "PDE Losses: [0.36418536693807574, 4.084901095770664e-6, 4.055532354786228e-6, 4.008229245453432e-6, 1.871170910458023e-5]\n",
      "BC Losses: [0.001960115458041224, 0.002795175539517113, 0.0035003597735128707, 0.0010359242302828769, 0.002647717284010108, 0.0018763964341439606, 0.0019503549062993752, 0.0019643660309817974, 0.001963949046384594]\n",
      "Iteration: 50, Total Loss: 0.6103555652380157\n",
      "PDE Losses: [0.34060137688164505, 4.0099569074103055e-6, 4.068799484434235e-6, 4.054565117732561e-6, 1.8446240354523494e-5]\n",
      "BC Losses: [0.0018150146491746656, 0.002622555786894418, 0.0032824909396196285, 0.0009536034489442886, 0.002489575115602876, 0.0017439256488164588, 0.0018142885005267132, 0.0018190034210464243, 0.0018231767855783798]\n",
      "Iteration: 50, Total Loss: 0.6103555652380157\n",
      "PDE Losses: [0.34060137688164505, 4.0099569074103055e-6, 4.068799484434235e-6, 4.054565117732561e-6, 1.8446240354523494e-5]\n",
      "BC Losses: [0.0018150146491746656, 0.002622555786894418, 0.0032824909396196285, 0.0009536034489442886, 0.002489575115602876, 0.0017439256488164588, 0.0018142885005267132, 0.0018190034210464243, 0.0018231767855783798]\n",
      "Iteration: 51, Total Loss: 0.5875931202408009\n",
      "PDE Losses: [0.3130275204480336, 3.997171787252567e-6, 4.053122271652522e-6, 4.064127773238376e-6, 1.8040265525153233e-5]\n",
      "BC Losses: [0.0016868656591391158, 0.0024400758054721073, 0.003077440447306198, 0.0008682103010921732, 0.002327899898723247, 0.0016136751471154986, 0.0016886481913388788, 0.0016865692470509589, 0.0016784941359426673]\n",
      "Iteration: 51, Total Loss: 0.5875931202408009\n",
      "PDE Losses: [0.3130275204480336, 3.997171787252567e-6, 4.053122271652522e-6, 4.064127773238376e-6, 1.8040265525153233e-5]\n",
      "BC Losses: [0.0016868656591391158, 0.0024400758054721073, 0.003077440447306198, 0.0008682103010921732, 0.002327899898723247, 0.0016136751471154986, 0.0016886481913388788, 0.0016865692470509589, 0.0016784941359426673]\n",
      "Iteration: 52, Total Loss: 0.5649123860673089\n",
      "PDE Losses: [0.2901295044961522, 4.038955484111779e-6, 4.045305993447885e-6, 4.026088636043116e-6, 1.793467637264366e-5]\n",
      "BC Losses: [0.0015696388178777498, 0.002276813011169023, 0.0028792650485098543, 0.0007839286541741223, 0.0021698531908410875, 0.0014771804753430688, 0.0015583774487148913, 0.0015636298965605129, 0.0015699853761904044]\n",
      "Iteration: 52, Total Loss: 0.5649123860673089\n",
      "PDE Losses: [0.2901295044961522, 4.038955484111779e-6, 4.045305993447885e-6, 4.026088636043116e-6, 1.793467637264366e-5]\n",
      "BC Losses: [0.0015696388178777498, 0.002276813011169023, 0.0028792650485098543, 0.0007839286541741223, 0.0021698531908410875, 0.0014771804753430688, 0.0015583774487148913, 0.0015636298965605129, 0.0015699853761904044]\n",
      "Iteration: 53, Total Loss: 0.5439489962844044\n",
      "PDE Losses: [0.26956314811773174, 4.024249046109067e-6, 4.013576606410371e-6, 4.0587216861794625e-6, 1.7825619705229118e-5]\n",
      "BC Losses: [0.0014462190342285684, 0.0021096883433292892, 0.002687508273419432, 0.0007013338371078882, 0.002021960980794702, 0.0013515887600152542, 0.0014484328407860802, 0.0014457865504646605, 0.0014487604782532433]\n",
      "Iteration: 53, Total Loss: 0.5439489962844044\n",
      "PDE Losses: [0.26956314811773174, 4.024249046109067e-6, 4.013576606410371e-6, 4.0587216861794625e-6, 1.7825619705229118e-5]\n",
      "BC Losses: [0.0014462190342285684, 0.0021096883433292892, 0.002687508273419432, 0.0007013338371078882, 0.002021960980794702, 0.0013515887600152542, 0.0014484328407860802, 0.0014457865504646605, 0.0014487604782532433]\n",
      "Iteration: 54, Total Loss: 0.5230361797393208\n",
      "PDE Losses: [0.24853283834348983, 4.034506618929254e-6, 3.945654013349541e-6, 3.944395301481951e-6, 1.7042564222733812e-5]\n",
      "BC Losses: [0.0013469177568947563, 0.0019569656945224953, 0.002516091605567209, 0.0006326048409730531, 0.0018868609993772604, 0.0012418650121292884, 0.0013368231402295604, 0.0013465594483289423, 0.0013469373628018037]\n",
      "Iteration: 54, Total Loss: 0.5230361797393208\n",
      "PDE Losses: [0.24853283834348983, 4.034506618929254e-6, 3.945654013349541e-6, 3.944395301481951e-6, 1.7042564222733812e-5]\n",
      "BC Losses: [0.0013469177568947563, 0.0019569656945224953, 0.002516091605567209, 0.0006326048409730531, 0.0018868609993772604, 0.0012418650121292884, 0.0013368231402295604, 0.0013465594483289423, 0.0013469373628018037]\n",
      "Iteration: 55, Total Loss: 0.5020600830983469\n",
      "PDE Losses: [0.2309956711930503, 3.892258013310601e-6, 3.986331043396282e-6, 3.967945065523958e-6, 1.7619046161803257e-5]\n",
      "BC Losses: [0.0012526136145151014, 0.001816041253872508, 0.002355011273823531, 0.000571301659247331, 0.0017694296886857596, 0.001144308310311578, 0.001258508326879864, 0.0012594424255420776, 0.001252996606282375]\n",
      "Iteration: 55, Total Loss: 0.5020600830983469\n",
      "PDE Losses: [0.2309956711930503, 3.892258013310601e-6, 3.986331043396282e-6, 3.967945065523958e-6, 1.7619046161803257e-5]\n",
      "BC Losses: [0.0012526136145151014, 0.001816041253872508, 0.002355011273823531, 0.000571301659247331, 0.0017694296886857596, 0.001144308310311578, 0.001258508326879864, 0.0012594424255420776, 0.001252996606282375]\n",
      "Iteration: 56, Total Loss: 0.48486166191867197\n",
      "PDE Losses: [0.21594757481962026, 3.949600790329304e-6, 3.918820312275358e-6, 3.8975915186400525e-6, 1.7121431684080122e-5]\n",
      "BC Losses: [0.0011851851179172082, 0.0016875814453489834, 0.0022133526775670004, 0.0005176373096013187, 0.0016630110767940694, 0.0010497345523269716, 0.0011749015926336938, 0.0011809045694457215, 0.0011825403433347917]\n",
      "Iteration: 56, Total Loss: 0.48486166191867197\n",
      "PDE Losses: [0.21594757481962026, 3.949600790329304e-6, 3.918820312275358e-6, 3.8975915186400525e-6, 1.7121431684080122e-5]\n",
      "BC Losses: [0.0011851851179172082, 0.0016875814453489834, 0.0022133526775670004, 0.0005176373096013187, 0.0016630110767940694, 0.0010497345523269716, 0.0011749015926336938, 0.0011809045694457215, 0.0011825403433347917]\n",
      "Iteration: 57, Total Loss: 0.4688791921616063\n",
      "PDE Losses: [0.2016093309599962, 3.969055387454108e-6, 3.950658548032066e-6, 3.91517729387819e-6, 1.6887387575390384e-5]\n",
      "BC Losses: [0.0011132305575790407, 0.001574625000031032, 0.002090255023168273, 0.00047899349570594964, 0.0015743749502780192, 0.0009732038359151862, 0.0011168852794713902, 0.0011178354727162118, 0.0011169431592677223]\n",
      "Iteration: 57, Total Loss: 0.4688791921616063\n",
      "PDE Losses: [0.2016093309599962, 3.969055387454108e-6, 3.950658548032066e-6, 3.91517729387819e-6, 1.6887387575390384e-5]\n",
      "BC Losses: [0.0011132305575790407, 0.001574625000031032, 0.002090255023168273, 0.00047899349570594964, 0.0015743749502780192, 0.0009732038359151862, 0.0011168852794713902, 0.0011178354727162118, 0.0011169431592677223]\n",
      "Iteration: 58, Total Loss: 0.4532566076834826\n",
      "PDE Losses: [0.19048469327017967, 3.928511554633768e-6, 3.947379293530572e-6, 3.8732078668017505e-6, 1.691256361257541e-5]\n",
      "BC Losses: [0.001064936858552031, 0.0014714295885763502, 0.0019793714573166027, 0.00045020641334012025, 0.0015020364084807596, 0.0009124781188566847, 0.0010660015046841504, 0.0010653296679304012, 0.001067234135658966]\n",
      "Iteration: 58, Total Loss: 0.4532566076834826\n",
      "PDE Losses: [0.19048469327017967, 3.928511554633768e-6, 3.947379293530572e-6, 3.8732078668017505e-6, 1.691256361257541e-5]\n",
      "BC Losses: [0.001064936858552031, 0.0014714295885763502, 0.0019793714573166027, 0.00045020641334012025, 0.0015020364084807596, 0.0009124781188566847, 0.0010660015046841504, 0.0010653296679304012, 0.001067234135658966]\n",
      "Iteration: 59, Total Loss: 0.4419136551379239\n",
      "PDE Losses: [0.18187061027486828, 3.927538478960369e-6, 3.8037944575007147e-6, 3.889627025107673e-6, 1.6549691451911956e-5]\n",
      "BC Losses: [0.0010327437075321835, 0.001390292791084578, 0.0018852201115252603, 0.0004358455182828867, 0.0014361662885247557, 0.0008558401862659066, 0.001032311678769034, 0.001030036806084916, 0.0010281156952676954]\n",
      "Iteration: 59, Total Loss: 0.4419136551379239\n",
      "PDE Losses: [0.18187061027486828, 3.927538478960369e-6, 3.8037944575007147e-6, 3.889627025107673e-6, 1.6549691451911956e-5]\n",
      "BC Losses: [0.0010327437075321835, 0.001390292791084578, 0.0018852201115252603, 0.0004358455182828867, 0.0014361662885247557, 0.0008558401862659066, 0.001032311678769034, 0.001030036806084916, 0.0010281156952676954]\n",
      "Iteration: 60, Total Loss: 0.4305932273700739\n",
      "PDE Losses: [0.17521267780216326, 3.870899095589223e-6, 3.82366970873806e-6, 3.843069963833829e-6, 1.6766761624815094e-5]\n",
      "BC Losses: [0.001004431647905923, 0.0013199441293796326, 0.0018024477121326846, 0.00042917492364809046, 0.0013827406641650644, 0.0008226750110013156, 0.001005045630471611, 0.0010079223761539971, 0.0010084655560698551]\n",
      "Iteration: 60, Total Loss: 0.4305932273700739\n",
      "PDE Losses: [0.17521267780216326, 3.870899095589223e-6, 3.82366970873806e-6, 3.843069963833829e-6, 1.6766761624815094e-5]\n",
      "BC Losses: [0.001004431647905923, 0.0013199441293796326, 0.0018024477121326846, 0.00042917492364809046, 0.0013827406641650644, 0.0008226750110013156, 0.001005045630471611, 0.0010079223761539971, 0.0010084655560698551]\n",
      "Iteration: 61, Total Loss: 0.42339324952008267\n",
      "PDE Losses: [0.1701343884176963, 3.8162257197278755e-6, 3.834118518970027e-6, 3.822447174033862e-6, 1.6451555611295893e-5]\n",
      "BC Losses: [0.0009861775846140698, 0.0012606457897285446, 0.0017348708573089648, 0.00043283732512377446, 0.0013498390385207918, 0.0007914967102588892, 0.0009912289346507197, 0.000989676829731067, 0.000996582377263224]\n",
      "Iteration: 61, Total Loss: 0.42339324952008267\n",
      "PDE Losses: [0.1701343884176963, 3.8162257197278755e-6, 3.834118518970027e-6, 3.822447174033862e-6, 1.6451555611295893e-5]\n",
      "BC Losses: [0.0009861775846140698, 0.0012606457897285446, 0.0017348708573089648, 0.00043283732512377446, 0.0013498390385207918, 0.0007914967102588892, 0.0009912289346507197, 0.000989676829731067, 0.000996582377263224]\n",
      "Iteration: 62, Total Loss: 0.4171888391970109\n",
      "PDE Losses: [0.16534014777850184, 3.816803697251459e-6, 3.852423180922935e-6, 3.7934295296314286e-6, 1.6447071912965986e-5]\n",
      "BC Losses: [0.0009863861867020528, 0.001211427976340813, 0.0016830749747167794, 0.00044903484121302693, 0.0013178650019415599, 0.0007779990150480531, 0.0009933832967054896, 0.0009900268726773479, 0.0009875718227294415]\n",
      "Iteration: 62, Total Loss: 0.4171888391970109\n",
      "PDE Losses: [0.16534014777850184, 3.816803697251459e-6, 3.852423180922935e-6, 3.7934295296314286e-6, 1.6447071912965986e-5]\n",
      "BC Losses: [0.0009863861867020528, 0.001211427976340813, 0.0016830749747167794, 0.00044903484121302693, 0.0013178650019415599, 0.0007779990150480531, 0.0009933832967054896, 0.0009900268726773479, 0.0009875718227294415]\n",
      "Iteration: 63, Total Loss: 0.4126952094042029\n",
      "PDE Losses: [0.1647989727068888, 3.7714325001616335e-6, 3.872028761555404e-6, 3.84730454514749e-6, 1.6177088178999954e-5]\n",
      "BC Losses: [0.0009925222843906272, 0.0011784437232915243, 0.0016341072858536041, 0.00046926003566739275, 0.001302200130069439, 0.000772780653103673, 0.0009844929552357555, 0.0009928239555354883, 0.000999583393167297]\n",
      "Iteration: 63, Total Loss: 0.4126952094042029\n",
      "PDE Losses: [0.1647989727068888, 3.7714325001616335e-6, 3.872028761555404e-6, 3.84730454514749e-6, 1.6177088178999954e-5]\n",
      "BC Losses: [0.0009925222843906272, 0.0011784437232915243, 0.0016341072858536041, 0.00046926003566739275, 0.001302200130069439, 0.000772780653103673, 0.0009844929552357555, 0.0009928239555354883, 0.000999583393167297]\n",
      "Iteration: 64, Total Loss: 0.4094525725984144\n",
      "PDE Losses: [0.1637182351137585, 3.837710590943437e-6, 3.812962241269107e-6, 3.87501979341309e-6, 1.5557573281749553e-5]\n",
      "BC Losses: [0.001006814817595938, 0.0011502313254820316, 0.0015987362530130089, 0.0004951632204704972, 0.0012846929509455342, 0.0007704053111954113, 0.0009967327311472675, 0.0009982652341661057, 0.0010010818164499654]\n",
      "Iteration: 64, Total Loss: 0.4094525725984144\n",
      "PDE Losses: [0.1637182351137585, 3.837710590943437e-6, 3.812962241269107e-6, 3.87501979341309e-6, 1.5557573281749553e-5]\n",
      "BC Losses: [0.001006814817595938, 0.0011502313254820316, 0.0015987362530130089, 0.0004951632204704972, 0.0012846929509455342, 0.0007704053111954113, 0.0009967327311472675, 0.0009982652341661057, 0.0010010818164499654]\n",
      "Iteration: 65, Total Loss: 0.4077770245835233\n",
      "PDE Losses: [0.1626161783151195, 3.783639268136652e-6, 3.7653217573191927e-6, 3.7816768081943617e-6, 1.5873564369453188e-5]\n",
      "BC Losses: [0.001010295378954073, 0.001127814004137505, 0.001570606859390655, 0.0005241774676991654, 0.0012804277041728472, 0.0007798603564888719, 0.001007762395046801, 0.0010090711898380874, 0.0010154479760208183]\n",
      "Iteration: 65, Total Loss: 0.4077770245835233\n",
      "PDE Losses: [0.1626161783151195, 3.783639268136652e-6, 3.7653217573191927e-6, 3.7816768081943617e-6, 1.5873564369453188e-5]\n",
      "BC Losses: [0.001010295378954073, 0.001127814004137505, 0.001570606859390655, 0.0005241774676991654, 0.0012804277041728472, 0.0007798603564888719, 0.001007762395046801, 0.0010090711898380874, 0.0010154479760208183]\n",
      "Iteration: 66, Total Loss: 0.40612558966724943\n",
      "PDE Losses: [0.16339895975198365, 3.7863887407118606e-6, 3.7334963093007403e-6, 3.7875741490023726e-6, 1.571184063160547e-5]\n",
      "BC Losses: [0.001031774468555579, 0.001109669556677032, 0.0015491209859197779, 0.0005528559459542082, 0.0012782369145643909, 0.0007861332574989458, 0.0010283406085442237, 0.0010285011126456196, 0.0010312543894748863]\n",
      "Iteration: 66, Total Loss: 0.40612558966724943\n",
      "PDE Losses: [0.16339895975198365, 3.7863887407118606e-6, 3.7334963093007403e-6, 3.7875741490023726e-6, 1.571184063160547e-5]\n",
      "BC Losses: [0.001031774468555579, 0.001109669556677032, 0.0015491209859197779, 0.0005528559459542082, 0.0012782369145643909, 0.0007861332574989458, 0.0010283406085442237, 0.0010285011126456196, 0.0010312543894748863]\n",
      "Iteration: 67, Total Loss: 0.4046015228187524\n",
      "PDE Losses: [0.16338785296981517, 3.7794788509617366e-6, 3.7139209364553046e-6, 3.7746361346025913e-6, 1.5670106708090725e-5]\n",
      "BC Losses: [0.0010385647860482001, 0.0011022713279294637, 0.0015267512673960567, 0.0005812521532643357, 0.0012743718924859188, 0.0007922429333251891, 0.0010347612004879179, 0.0010407140339554243, 0.0010425353719751536]\n",
      "Iteration: 67, Total Loss: 0.4046015228187524\n",
      "PDE Losses: [0.16338785296981517, 3.7794788509617366e-6, 3.7139209364553046e-6, 3.7746361346025913e-6, 1.5670106708090725e-5]\n",
      "BC Losses: [0.0010385647860482001, 0.0011022713279294637, 0.0015267512673960567, 0.0005812521532643357, 0.0012743718924859188, 0.0007922429333251891, 0.0010347612004879179, 0.0010407140339554243, 0.0010425353719751536]\n",
      "Iteration: 68, Total Loss: 0.40479960367759527\n",
      "PDE Losses: [0.16362030271443984, 3.7529815420447992e-6, 3.7561520355463726e-6, 3.7716436174943748e-6, 1.5239334685831804e-5]\n",
      "BC Losses: [0.0010501482783753862, 0.0010935675025173814, 0.0015090612913103514, 0.0006058292767289434, 0.001270350015296468, 0.0008021330363142932, 0.0010557973286951304, 0.0010496267401064725, 0.0010508125218405251]\n",
      "Iteration: 68, Total Loss: 0.40479960367759527\n",
      "PDE Losses: [0.16362030271443984, 3.7529815420447992e-6, 3.7561520355463726e-6, 3.7716436174943748e-6, 1.5239334685831804e-5]\n",
      "BC Losses: [0.0010501482783753862, 0.0010935675025173814, 0.0015090612913103514, 0.0006058292767289434, 0.001270350015296468, 0.0008021330363142932, 0.0010557973286951304, 0.0010496267401064725, 0.0010508125218405251]\n",
      "Iteration: 69, Total Loss: 0.40517085633056815\n",
      "PDE Losses: [0.16287492919487917, 3.736914012352511e-6, 3.7383459172524635e-6, 3.715978621016219e-6, 1.543879090842175e-5]\n",
      "BC Losses: [0.001062685453577912, 0.0010871626468663444, 0.0014898029539046394, 0.0006281404909858456, 0.0012703045321537903, 0.0008086107438507275, 0.0010577100319218227, 0.001054570784989043, 0.0010547620418823545]\n",
      "Iteration: 69, Total Loss: 0.40517085633056815\n",
      "PDE Losses: [0.16287492919487917, 3.736914012352511e-6, 3.7383459172524635e-6, 3.715978621016219e-6, 1.543879090842175e-5]\n",
      "BC Losses: [0.001062685453577912, 0.0010871626468663444, 0.0014898029539046394, 0.0006281404909858456, 0.0012703045321537903, 0.0008086107438507275, 0.0010577100319218227, 0.001054570784989043, 0.0010547620418823545]\n",
      "Iteration: 70, Total Loss: 0.4047879063987748\n",
      "PDE Losses: [0.1627361618202283, 3.762411920628195e-6, 3.76804677161528e-6, 3.750407853960808e-6, 1.529742954941891e-5]\n",
      "BC Losses: [0.0010537854472729602, 0.0010810675495061808, 0.0014730115460782837, 0.0006466557313752341, 0.0012634736979471926, 0.0008070838801627564, 0.001061641700881927, 0.0010609924108043237, 0.0010628327053388553]\n",
      "Iteration: 70, Total Loss: 0.4047879063987748\n",
      "PDE Losses: [0.1627361618202283, 3.762411920628195e-6, 3.76804677161528e-6, 3.750407853960808e-6, 1.529742954941891e-5]\n",
      "BC Losses: [0.0010537854472729602, 0.0010810675495061808, 0.0014730115460782837, 0.0006466557313752341, 0.0012634736979471926, 0.0008070838801627564, 0.001061641700881927, 0.0010609924108043237, 0.0010628327053388553]\n",
      "Iteration: 71, Total Loss: 0.4053938310337288\n",
      "PDE Losses: [0.16266266988158712, 3.699387060058871e-6, 3.796807518597288e-6, 3.6392431390754085e-6, 1.5025538266228098e-5]\n",
      "BC Losses: [0.001055776936366044, 0.0010738772176846884, 0.001458488933817593, 0.0006584600709275647, 0.0012600803077343057, 0.0008167777364828829, 0.0010597910893233948, 0.0010595870873615343, 0.0010573168730085875]\n",
      "Iteration: 71, Total Loss: 0.4053938310337288\n",
      "PDE Losses: [0.16266266988158712, 3.699387060058871e-6, 3.796807518597288e-6, 3.6392431390754085e-6, 1.5025538266228098e-5]\n",
      "BC Losses: [0.001055776936366044, 0.0010738772176846884, 0.001458488933817593, 0.0006584600709275647, 0.0012600803077343057, 0.0008167777364828829, 0.0010597910893233948, 0.0010595870873615343, 0.0010573168730085875]\n",
      "Iteration: 72, Total Loss: 0.4056391925832129\n",
      "PDE Losses: [0.16325503368967131, 3.720591904009446e-6, 3.675899801804124e-6, 3.734308006830979e-6, 1.4882309077862046e-5]\n",
      "BC Losses: [0.001059531230683803, 0.001065480145753232, 0.001435903294334534, 0.0006700934226080931, 0.0012516110381679548, 0.0008106999672716586, 0.001053675529290857, 0.0010536382552182194, 0.0010554400985321253]\n",
      "Iteration: 72, Total Loss: 0.4056391925832129\n",
      "PDE Losses: [0.16325503368967131, 3.720591904009446e-6, 3.675899801804124e-6, 3.734308006830979e-6, 1.4882309077862046e-5]\n",
      "BC Losses: [0.001059531230683803, 0.001065480145753232, 0.001435903294334534, 0.0006700934226080931, 0.0012516110381679548, 0.0008106999672716586, 0.001053675529290857, 0.0010536382552182194, 0.0010554400985321253]\n",
      "Iteration: 73, Total Loss: 0.4056219378031198\n",
      "PDE Losses: [0.16022778407038407, 3.668526073656883e-6, 3.662752672537384e-6, 3.6876956897430328e-6, 1.489952051852678e-5]\n",
      "BC Losses: [0.001043003988913851, 0.0010574312680818342, 0.0014166327683740056, 0.0006742521729285788, 0.0012413287800767704, 0.0008033520812576452, 0.0010442868575584671, 0.0010435159674870077, 0.0010409280592610227]\n",
      "Iteration: 73, Total Loss: 0.4056219378031198\n",
      "PDE Losses: [0.16022778407038407, 3.668526073656883e-6, 3.662752672537384e-6, 3.6876956897430328e-6, 1.489952051852678e-5]\n",
      "BC Losses: [0.001043003988913851, 0.0010574312680818342, 0.0014166327683740056, 0.0006742521729285788, 0.0012413287800767704, 0.0008033520812576452, 0.0010442868575584671, 0.0010435159674870077, 0.0010409280592610227]\n",
      "Iteration: 74, Total Loss: 0.40567538592770636\n",
      "PDE Losses: [0.15882028173977872, 3.6319342146680495e-6, 3.6387852107657205e-6, 3.6977631177255154e-6, 1.4509903937660622e-5]\n",
      "BC Losses: [0.0010261621983735203, 0.001054666132456106, 0.0013934561148766524, 0.0006778237632416265, 0.0012310770789009764, 0.0007914593538569532, 0.0010244950205965239, 0.0010222437740334935, 0.0010253305582266098]\n",
      "Iteration: 74, Total Loss: 0.40567538592770636\n",
      "PDE Losses: [0.15882028173977872, 3.6319342146680495e-6, 3.6387852107657205e-6, 3.6977631177255154e-6, 1.4509903937660622e-5]\n",
      "BC Losses: [0.0010261621983735203, 0.001054666132456106, 0.0013934561148766524, 0.0006778237632416265, 0.0012310770789009764, 0.0007914593538569532, 0.0010244950205965239, 0.0010222437740334935, 0.0010253305582266098]\n",
      "Iteration: 75, Total Loss: 0.4055648769018466\n",
      "PDE Losses: [0.1563435669395055, 3.6349888748890128e-6, 3.6691218059695956e-6, 3.715353184806882e-6, 1.4447462554795684e-5]\n",
      "BC Losses: [0.0010081392654200604, 0.0010433118101977343, 0.0013681896071281842, 0.0006717922612775838, 0.0012131966686732222, 0.0007839617428429281, 0.0010037734047018138, 0.0010060200435536139, 0.0010074371518011777]\n",
      "Iteration: 75, Total Loss: 0.4055648769018466\n",
      "PDE Losses: [0.1563435669395055, 3.6349888748890128e-6, 3.6691218059695956e-6, 3.715353184806882e-6, 1.4447462554795684e-5]\n",
      "BC Losses: [0.0010081392654200604, 0.0010433118101977343, 0.0013681896071281842, 0.0006717922612775838, 0.0012131966686732222, 0.0007839617428429281, 0.0010037734047018138, 0.0010060200435536139, 0.0010074371518011777]\n",
      "Iteration: 76, Total Loss: 0.40371452131854024\n",
      "PDE Losses: [0.154922712283074, 3.625303910248011e-6, 3.649898675615427e-6, 3.607116314767672e-6, 1.439028656080092e-5]\n",
      "BC Losses: [0.000983159831517442, 0.001031470187109238, 0.0013420859222616273, 0.0006652938192471553, 0.001199773501329536, 0.000768571634522535, 0.0009839413518444593, 0.000987685844855537, 0.000987416806024552]\n",
      "Iteration: 76, Total Loss: 0.40371452131854024\n",
      "PDE Losses: [0.154922712283074, 3.625303910248011e-6, 3.649898675615427e-6, 3.607116314767672e-6, 1.439028656080092e-5]\n",
      "BC Losses: [0.000983159831517442, 0.001031470187109238, 0.0013420859222616273, 0.0006652938192471553, 0.001199773501329536, 0.000768571634522535, 0.0009839413518444593, 0.000987685844855537, 0.000987416806024552]\n",
      "Iteration: 77, Total Loss: 0.40204272954090026\n",
      "PDE Losses: [0.15125725521889463, 3.6142108184705375e-6, 3.6413554317827713e-6, 3.6668873824532712e-6, 1.4332967743127476e-5]\n",
      "BC Losses: [0.0009642741862141746, 0.0010145623302308517, 0.0013169425546508205, 0.0006579283213065848, 0.0011817470289598616, 0.0007494282743462557, 0.000964812854462032, 0.0009568818343359504, 0.0009650498480300213]\n",
      "Iteration: 77, Total Loss: 0.40204272954090026\n",
      "PDE Losses: [0.15125725521889463, 3.6142108184705375e-6, 3.6413554317827713e-6, 3.6668873824532712e-6, 1.4332967743127476e-5]\n",
      "BC Losses: [0.0009642741862141746, 0.0010145623302308517, 0.0013169425546508205, 0.0006579283213065848, 0.0011817470289598616, 0.0007494282743462557, 0.000964812854462032, 0.0009568818343359504, 0.0009650498480300213]\n",
      "Iteration: 78, Total Loss: 0.40090646299833765\n",
      "PDE Losses: [0.14836623841787888, 3.66278498577688e-6, 3.683885672308115e-6, 3.6284243981280795e-6, 1.4090396855945076e-5]\n",
      "BC Losses: [0.000939085489387317, 0.0010014125885410704, 0.0012917754100392027, 0.0006474148563264169, 0.0011646116105026357, 0.000729435128257313, 0.0009396693005102061, 0.0009377157683694854, 0.0009368931077304399]\n",
      "Iteration: 78, Total Loss: 0.40090646299833765\n",
      "PDE Losses: [0.14836623841787888, 3.66278498577688e-6, 3.683885672308115e-6, 3.6284243981280795e-6, 1.4090396855945076e-5]\n",
      "BC Losses: [0.000939085489387317, 0.0010014125885410704, 0.0012917754100392027, 0.0006474148563264169, 0.0011646116105026357, 0.000729435128257313, 0.0009396693005102061, 0.0009377157683694854, 0.0009368931077304399]\n",
      "Iteration: 79, Total Loss: 0.3995873067678267\n",
      "PDE Losses: [0.14515553841475842, 3.6321066738065027e-6, 3.6865664480265967e-6, 3.6617084404009864e-6, 1.3933391101481459e-5]\n",
      "BC Losses: [0.0009144115132111309, 0.0009918365451584213, 0.0012646395846054998, 0.0006290991093923047, 0.001143492877532573, 0.0007109989744283629, 0.0009133082356489921, 0.0009150228229765742, 0.0009105613720325286]\n",
      "Iteration: 79, Total Loss: 0.3995873067678267\n",
      "PDE Losses: [0.14515553841475842, 3.6321066738065027e-6, 3.6865664480265967e-6, 3.6617084404009864e-6, 1.3933391101481459e-5]\n",
      "BC Losses: [0.0009144115132111309, 0.0009918365451584213, 0.0012646395846054998, 0.0006290991093923047, 0.001143492877532573, 0.0007109989744283629, 0.0009133082356489921, 0.0009150228229765742, 0.0009105613720325286]\n",
      "Iteration: 80, Total Loss: 0.3984409789419179\n",
      "PDE Losses: [0.1429181000495161, 3.6664021942371843e-6, 3.642794011445151e-6, 3.5590341123385347e-6, 1.3686474856488775e-5]\n",
      "BC Losses: [0.0008866176857226691, 0.0009709348737464496, 0.0012418855334718943, 0.0006145821251354523, 0.0011288566586223534, 0.0006926785984144521, 0.0008890037065656021, 0.000891575164327028, 0.0008892376839849841]\n",
      "Iteration: 80, Total Loss: 0.3984409789419179\n",
      "PDE Losses: [0.1429181000495161, 3.6664021942371843e-6, 3.642794011445151e-6, 3.5590341123385347e-6, 1.3686474856488775e-5]\n",
      "BC Losses: [0.0008866176857226691, 0.0009709348737464496, 0.0012418855334718943, 0.0006145821251354523, 0.0011288566586223534, 0.0006926785984144521, 0.0008890037065656021, 0.000891575164327028, 0.0008892376839849841]\n",
      "Iteration: 81, Total Loss: 0.3965127570533814\n",
      "PDE Losses: [0.13919783132807612, 3.560414916315835e-6, 3.5603602845456037e-6, 3.537832502669623e-6, 1.3659934902238834e-5]\n",
      "BC Losses: [0.0008676391531795199, 0.0009579096151494347, 0.0012219190908235565, 0.0005960999547890758, 0.0011040813807204595, 0.0006707263931661538, 0.0008699882761583196, 0.0008643358866093753, 0.0008649354407918623]\n",
      "Iteration: 81, Total Loss: 0.3965127570533814\n",
      "PDE Losses: [0.13919783132807612, 3.560414916315835e-6, 3.5603602845456037e-6, 3.537832502669623e-6, 1.3659934902238834e-5]\n",
      "BC Losses: [0.0008676391531795199, 0.0009579096151494347, 0.0012219190908235565, 0.0005960999547890758, 0.0011040813807204595, 0.0006707263931661538, 0.0008699882761583196, 0.0008643358866093753, 0.0008649354407918623]\n",
      "Iteration: 82, Total Loss: 0.39510877741758266\n",
      "PDE Losses: [0.13577092884935826, 3.5657418407853903e-6, 3.570861581742203e-6, 3.5991458067346536e-6, 1.3583657926438311e-5]\n",
      "BC Losses: [0.0008451990038635424, 0.0009393844408740371, 0.0011999009666983907, 0.0005804941983506294, 0.0010879721797497212, 0.0006539390828416683, 0.0008435849931506817, 0.0008421686920544138, 0.000848112472014541]\n",
      "Iteration: 82, Total Loss: 0.39510877741758266\n",
      "PDE Losses: [0.13577092884935826, 3.5657418407853903e-6, 3.570861581742203e-6, 3.5991458067346536e-6, 1.3583657926438311e-5]\n",
      "BC Losses: [0.0008451990038635424, 0.0009393844408740371, 0.0011999009666983907, 0.0005804941983506294, 0.0010879721797497212, 0.0006539390828416683, 0.0008435849931506817, 0.0008421686920544138, 0.000848112472014541]\n",
      "Iteration: 83, Total Loss: 0.3930328570041239\n",
      "PDE Losses: [0.13373281283006158, 3.575303712321555e-6, 3.5501054387193213e-6, 3.5724131040520904e-6, 1.3636278566057297e-5]\n",
      "BC Losses: [0.0008273325989040784, 0.0009280789565992586, 0.0011835886536927325, 0.0005599691733816087, 0.001069904713222224, 0.0006333227941758525, 0.0008224597000932975, 0.0008227748190269893, 0.0008261166080655812]\n",
      "Iteration: 83, Total Loss: 0.3930328570041239\n",
      "PDE Losses: [0.13373281283006158, 3.575303712321555e-6, 3.5501054387193213e-6, 3.5724131040520904e-6, 1.3636278566057297e-5]\n",
      "BC Losses: [0.0008273325989040784, 0.0009280789565992586, 0.0011835886536927325, 0.0005599691733816087, 0.001069904713222224, 0.0006333227941758525, 0.0008224597000932975, 0.0008227748190269893, 0.0008261166080655812]\n",
      "Iteration: 84, Total Loss: 0.39139950115933625\n",
      "PDE Losses: [0.13152055492027015, 3.5596178799780363e-6, 3.583990532035052e-6, 3.508156244192899e-6, 1.3435511421661448e-5]\n",
      "BC Losses: [0.0008097627510598318, 0.0009111143138630304, 0.001167321479468692, 0.0005452278007306478, 0.0010555479490472139, 0.0006197794847687203, 0.0008081675140663956, 0.0008081701127357089, 0.0008101977520955741]\n",
      "Iteration: 84, Total Loss: 0.39139950115933625\n",
      "PDE Losses: [0.13152055492027015, 3.5596178799780363e-6, 3.583990532035052e-6, 3.508156244192899e-6, 1.3435511421661448e-5]\n",
      "BC Losses: [0.0008097627510598318, 0.0009111143138630304, 0.001167321479468692, 0.0005452278007306478, 0.0010555479490472139, 0.0006197794847687203, 0.0008081675140663956, 0.0008081701127357089, 0.0008101977520955741]\n",
      "Iteration: 85, Total Loss: 0.38967439351758437\n",
      "PDE Losses: [0.12950689959498551, 3.5452176816711894e-6, 3.5603525275425145e-6, 3.464065150622068e-6, 1.3066271037578405e-5]\n",
      "BC Losses: [0.0007925757862884106, 0.0008967420009372833, 0.0011552979803732587, 0.0005282273293586029, 0.0010378996170339206, 0.0006023589679672474, 0.0007913858647676697, 0.0007986345308855844, 0.0007920440851783368]\n",
      "Iteration: 85, Total Loss: 0.38967439351758437\n",
      "PDE Losses: [0.12950689959498551, 3.5452176816711894e-6, 3.5603525275425145e-6, 3.464065150622068e-6, 1.3066271037578405e-5]\n",
      "BC Losses: [0.0007925757862884106, 0.0008967420009372833, 0.0011552979803732587, 0.0005282273293586029, 0.0010378996170339206, 0.0006023589679672474, 0.0007913858647676697, 0.0007986345308855844, 0.0007920440851783368]\n",
      "Iteration: 86, Total Loss: 0.3885826713432665\n",
      "PDE Losses: [0.12701643744876373, 3.554428933881576e-6, 3.5511330256661673e-6, 3.5757731110600463e-6, 1.3367270575882174e-5]\n",
      "BC Losses: [0.000781191612540383, 0.0008845213227752484, 0.001145576962492355, 0.0005134631809324342, 0.001024398094750044, 0.0005918980750576649, 0.000780939242731721, 0.0007847667012334681, 0.0007827659833775709]\n",
      "Iteration: 86, Total Loss: 0.3885826713432665\n",
      "PDE Losses: [0.12701643744876373, 3.554428933881576e-6, 3.5511330256661673e-6, 3.5757731110600463e-6, 1.3367270575882174e-5]\n",
      "BC Losses: [0.000781191612540383, 0.0008845213227752484, 0.001145576962492355, 0.0005134631809324342, 0.001024398094750044, 0.0005918980750576649, 0.000780939242731721, 0.0007847667012334681, 0.0007827659833775709]\n",
      "Iteration: 87, Total Loss: 0.38617486580224836\n",
      "PDE Losses: [0.12549463091809032, 3.5162371613499643e-6, 3.4931029606904168e-6, 3.5662802021960043e-6, 1.3165693188844465e-5]\n",
      "BC Losses: [0.0007708396539551449, 0.0008749291417778759, 0.001134115080324317, 0.0005050444449155964, 0.001009312846803077, 0.0005901401027730399, 0.0007698597731562185, 0.0007714098321400002, 0.0007727509842052362]\n",
      "Iteration: 87, Total Loss: 0.38617486580224836\n",
      "PDE Losses: [0.12549463091809032, 3.5162371613499643e-6, 3.4931029606904168e-6, 3.5662802021960043e-6, 1.3165693188844465e-5]\n",
      "BC Losses: [0.0007708396539551449, 0.0008749291417778759, 0.001134115080324317, 0.0005050444449155964, 0.001009312846803077, 0.0005901401027730399, 0.0007698597731562185, 0.0007714098321400002, 0.0007727509842052362]\n",
      "Iteration: 88, Total Loss: 0.384317796066871\n",
      "PDE Losses: [0.12555930164590437, 3.5195613765179876e-6, 3.5266498049424314e-6, 3.4973500869129403e-6, 1.3094902434167989e-5]\n",
      "BC Losses: [0.0007614394389225552, 0.0008680892510515582, 0.0011280810060096097, 0.0004931711569942737, 0.001001011704479917, 0.0005808065584276524, 0.0007642996675357903, 0.0007664310372233704, 0.0007641549432162868]\n",
      "Iteration: 88, Total Loss: 0.384317796066871\n",
      "PDE Losses: [0.12555930164590437, 3.5195613765179876e-6, 3.5266498049424314e-6, 3.4973500869129403e-6, 1.3094902434167989e-5]\n",
      "BC Losses: [0.0007614394389225552, 0.0008680892510515582, 0.0011280810060096097, 0.0004931711569942737, 0.001001011704479917, 0.0005808065584276524, 0.0007642996675357903, 0.0007664310372233704, 0.0007641549432162868]\n",
      "Iteration: 89, Total Loss: 0.38296238830123086\n",
      "PDE Losses: [0.124333134732773, 3.4639365881222795e-6, 3.489469160941551e-6, 3.5011476451379577e-6, 1.2865383877253015e-5]\n",
      "BC Losses: [0.0007552920099275051, 0.0008597783698843558, 0.0011220927675233438, 0.0004837648515374596, 0.0009931104176792635, 0.0005751113128979422, 0.000760077620715595, 0.0007547663048398872, 0.0007594461193442281]\n",
      "Iteration: 89, Total Loss: 0.38296238830123086\n",
      "PDE Losses: [0.124333134732773, 3.4639365881222795e-6, 3.489469160941551e-6, 3.5011476451379577e-6, 1.2865383877253015e-5]\n",
      "BC Losses: [0.0007552920099275051, 0.0008597783698843558, 0.0011220927675233438, 0.0004837648515374596, 0.0009931104176792635, 0.0005751113128979422, 0.000760077620715595, 0.0007547663048398872, 0.0007594461193442281]\n",
      "Iteration: 90, Total Loss: 0.3823969636737448\n",
      "PDE Losses: [0.12303443332859412, 3.5055766087154534e-6, 3.5374871940239972e-6, 3.496562212736965e-6, 1.2633910198820613e-5]\n",
      "BC Losses: [0.0007531268799393829, 0.0008577397718490958, 0.0011233026423337234, 0.00047977186880574906, 0.000991069374755867, 0.0005718378661380807, 0.000753831593245288, 0.0007559383651634937, 0.0007496715475278322]\n",
      "Iteration: 90, Total Loss: 0.3823969636737448\n",
      "PDE Losses: [0.12303443332859412, 3.5055766087154534e-6, 3.5374871940239972e-6, 3.496562212736965e-6, 1.2633910198820613e-5]\n",
      "BC Losses: [0.0007531268799393829, 0.0008577397718490958, 0.0011233026423337234, 0.00047977186880574906, 0.000991069374755867, 0.0005718378661380807, 0.000753831593245288, 0.0007559383651634937, 0.0007496715475278322]\n",
      "Iteration: 91, Total Loss: 0.3809000701690881\n",
      "PDE Losses: [0.12300529261408247, 3.485480424751961e-6, 3.4308697342553357e-6, 3.4998091437540065e-6, 1.2539028116875378e-5]\n",
      "BC Losses: [0.0007456282661191329, 0.0008558890290319028, 0.0011248391529459702, 0.0004723884337941379, 0.0009897569035366665, 0.000568741128999661, 0.0007510931934034551, 0.0007458436315746582, 0.0007495579388011873]\n",
      "Iteration: 91, Total Loss: 0.3809000701690881\n",
      "PDE Losses: [0.12300529261408247, 3.485480424751961e-6, 3.4308697342553357e-6, 3.4998091437540065e-6, 1.2539028116875378e-5]\n",
      "BC Losses: [0.0007456282661191329, 0.0008558890290319028, 0.0011248391529459702, 0.0004723884337941379, 0.0009897569035366665, 0.000568741128999661, 0.0007510931934034551, 0.0007458436315746582, 0.0007495579388011873]\n",
      "Iteration: 92, Total Loss: 0.37986352130083795\n",
      "PDE Losses: [0.1229645587947157, 3.4957544163881582e-6, 3.460424140292333e-6, 3.49157754269067e-6, 1.246414637398475e-5]\n",
      "BC Losses: [0.0007461725115486762, 0.0008605943026581235, 0.0011235565959306845, 0.0004700416905218491, 0.000987563882402087, 0.0005646920200568202, 0.00074801304792538, 0.0007421324510333383, 0.0007478253977751068]\n",
      "Iteration: 92, Total Loss: 0.37986352130083795\n",
      "PDE Losses: [0.1229645587947157, 3.4957544163881582e-6, 3.460424140292333e-6, 3.49157754269067e-6, 1.246414637398475e-5]\n",
      "BC Losses: [0.0007461725115486762, 0.0008605943026581235, 0.0011235565959306845, 0.0004700416905218491, 0.000987563882402087, 0.0005646920200568202, 0.00074801304792538, 0.0007421324510333383, 0.0007478253977751068]\n",
      "Iteration: 93, Total Loss: 0.37889359410376194\n",
      "PDE Losses: [0.1232870511644243, 3.5016215611229505e-6, 3.494357872949839e-6, 3.4646155994542504e-6, 1.2380767608703429e-5]\n",
      "BC Losses: [0.0007439894589109868, 0.00086543719147869, 0.00113189381522876, 0.00046453246277244594, 0.0009895939411830206, 0.0005641946571885709, 0.0007403883216696638, 0.0007439145592536633, 0.0007446141644994223]\n",
      "Iteration: 93, Total Loss: 0.37889359410376194\n",
      "PDE Losses: [0.1232870511644243, 3.5016215611229505e-6, 3.494357872949839e-6, 3.4646155994542504e-6, 1.2380767608703429e-5]\n",
      "BC Losses: [0.0007439894589109868, 0.00086543719147869, 0.00113189381522876, 0.00046453246277244594, 0.0009895939411830206, 0.0005641946571885709, 0.0007403883216696638, 0.0007439145592536633, 0.0007446141644994223]\n",
      "Iteration: 94, Total Loss: 0.3781490406903663\n",
      "PDE Losses: [0.12382798321811654, 3.4830284081245647e-6, 3.515693478558789e-6, 3.4795275224275034e-6, 1.2235317953073149e-5]\n",
      "BC Losses: [0.0007431134274727043, 0.0008692840289577862, 0.0011318201232747443, 0.0004617955938286469, 0.0009931613030270707, 0.0005642073617026295, 0.0007425211294158071, 0.0007398943811671415, 0.0007412549091563378]\n",
      "Iteration: 94, Total Loss: 0.3781490406903663\n",
      "PDE Losses: [0.12382798321811654, 3.4830284081245647e-6, 3.515693478558789e-6, 3.4795275224275034e-6, 1.2235317953073149e-5]\n",
      "BC Losses: [0.0007431134274727043, 0.0008692840289577862, 0.0011318201232747443, 0.0004617955938286469, 0.0009931613030270707, 0.0005642073617026295, 0.0007425211294158071, 0.0007398943811671415, 0.0007412549091563378]\n",
      "Iteration: 95, Total Loss: 0.3771034770970134\n",
      "PDE Losses: [0.12408359785442834, 3.4762009711038857e-6, 3.494544004804495e-6, 3.4718349417699504e-6, 1.2107017430451018e-5]\n",
      "BC Losses: [0.0007417691388886807, 0.0008747626694886237, 0.0011435203189957585, 0.0004608373034256803, 0.0009959814448883462, 0.0005597052840675319, 0.0007452103068631649, 0.0007427606949704643, 0.0007393581387285131]\n",
      "Iteration: 95, Total Loss: 0.3771034770970134\n",
      "PDE Losses: [0.12408359785442834, 3.4762009711038857e-6, 3.494544004804495e-6, 3.4718349417699504e-6, 1.2107017430451018e-5]\n",
      "BC Losses: [0.0007417691388886807, 0.0008747626694886237, 0.0011435203189957585, 0.0004608373034256803, 0.0009959814448883462, 0.0005597052840675319, 0.0007452103068631649, 0.0007427606949704643, 0.0007393581387285131]\n",
      "Iteration: 96, Total Loss: 0.3762191641185991\n",
      "PDE Losses: [0.12491304551397943, 3.437156415262464e-6, 3.438644170031978e-6, 3.4547869724974825e-6, 1.1901710397790672e-5]\n",
      "BC Losses: [0.0007425610056007038, 0.0008813862586662914, 0.001145719449169226, 0.00046150452308590776, 0.001002591168374962, 0.0005626283668673984, 0.0007419192612207256, 0.0007407865381266081, 0.0007452703865951657]\n",
      "Iteration: 96, Total Loss: 0.3762191641185991\n",
      "PDE Losses: [0.12491304551397943, 3.437156415262464e-6, 3.438644170031978e-6, 3.4547869724974825e-6, 1.1901710397790672e-5]\n",
      "BC Losses: [0.0007425610056007038, 0.0008813862586662914, 0.001145719449169226, 0.00046150452308590776, 0.001002591168374962, 0.0005626283668673984, 0.0007419192612207256, 0.0007407865381266081, 0.0007452703865951657]\n",
      "Iteration: 97, Total Loss: 0.375470958470694\n",
      "PDE Losses: [0.12604523938656043, 3.437641020780993e-6, 3.4531916512402284e-6, 3.44580002261651e-6, 1.181543581145924e-5]\n",
      "BC Losses: [0.00074203991216298, 0.0008869710227404177, 0.0011515451867750222, 0.00046169831804595944, 0.0010080775303436323, 0.0005619090544959785, 0.0007428212941015833, 0.0007416486498009584, 0.0007386170372683209]\n",
      "Iteration: 97, Total Loss: 0.375470958470694\n",
      "PDE Losses: [0.12604523938656043, 3.437641020780993e-6, 3.4531916512402284e-6, 3.44580002261651e-6, 1.181543581145924e-5]\n",
      "BC Losses: [0.00074203991216298, 0.0008869710227404177, 0.0011515451867750222, 0.00046169831804595944, 0.0010080775303436323, 0.0005619090544959785, 0.0007428212941015833, 0.0007416486498009584, 0.0007386170372683209]\n",
      "Iteration: 98, Total Loss: 0.3747510998087349\n",
      "PDE Losses: [0.1252482793572891, 3.4223932434302917e-6, 3.430586954018599e-6, 3.408560731521962e-6, 1.1906256634661323e-5]\n",
      "BC Losses: [0.000740009335323622, 0.0008952159578727243, 0.0011534702076917848, 0.00046494706543693235, 0.0010139870500280917, 0.0005684103564096415, 0.000739043043284097, 0.0007383917662950253, 0.000738639577287183]\n",
      "Iteration: 98, Total Loss: 0.3747510998087349\n",
      "PDE Losses: [0.1252482793572891, 3.4223932434302917e-6, 3.430586954018599e-6, 3.408560731521962e-6, 1.1906256634661323e-5]\n",
      "BC Losses: [0.000740009335323622, 0.0008952159578727243, 0.0011534702076917848, 0.00046494706543693235, 0.0010139870500280917, 0.0005684103564096415, 0.000739043043284097, 0.0007383917662950253, 0.000738639577287183]\n",
      "Iteration: 99, Total Loss: 0.37464398142280786\n",
      "PDE Losses: [0.12633531912075574, 3.427338731857157e-6, 3.4428115376757046e-6, 3.2986611353871716e-6, 1.1640627845855533e-5]\n",
      "BC Losses: [0.0007422636780101562, 0.0009021665328598463, 0.001154862388908716, 0.0004663386508752016, 0.0010189760675131964, 0.0005685198364025167, 0.000740499992143818, 0.0007428038408367936, 0.000741298754517851]\n",
      "Iteration: 99, Total Loss: 0.37464398142280786\n",
      "PDE Losses: [0.12633531912075574, 3.427338731857157e-6, 3.4428115376757046e-6, 3.2986611353871716e-6, 1.1640627845855533e-5]\n",
      "BC Losses: [0.0007422636780101562, 0.0009021665328598463, 0.001154862388908716, 0.0004663386508752016, 0.0010189760675131964, 0.0005685198364025167, 0.000740499992143818, 0.0007428038408367936, 0.000741298754517851]\n",
      "Iteration: 100, Total Loss: 0.37418973026527325\n",
      "PDE Losses: [0.12744175064667318, 3.417187629396405e-6, 3.408840500537453e-6, 3.412860606616567e-6, 1.1889455131323121e-5]\n",
      "BC Losses: [0.0007454850595007071, 0.0009063358001128166, 0.0011595158597236491, 0.0004726367943218466, 0.0010184261893007329, 0.0005733246096348728, 0.0007466604991128161, 0.000747201469721257, 0.0007419371472941689]\n",
      "Iteration: 100, Total Loss: 0.37418973026527325\n",
      "PDE Losses: [0.12744175064667318, 3.417187629396405e-6, 3.408840500537453e-6, 3.412860606616567e-6, 1.1889455131323121e-5]\n",
      "BC Losses: [0.0007454850595007071, 0.0009063358001128166, 0.0011595158597236491, 0.0004726367943218466, 0.0010184261893007329, 0.0005733246096348728, 0.0007466604991128161, 0.000747201469721257, 0.0007419371472941689]\n",
      "Iteration: 101, Total Loss: 0.3737061112299132\n",
      "PDE Losses: [0.12813513668988513, 3.3882511663621188e-6, 3.4227792423407126e-6, 3.3989752763677814e-6, 1.1568107988455423e-5]\n",
      "BC Losses: [0.0007405955160528245, 0.0009090632437041884, 0.0011596602179989287, 0.00047525678382199686, 0.0010180237295430406, 0.000571561326979056, 0.0007459813459740905, 0.000736862224034354, 0.0007407445735023944]\n",
      "Iteration: 101, Total Loss: 0.3737061112299132\n",
      "PDE Losses: [0.12813513668988513, 3.3882511663621188e-6, 3.4227792423407126e-6, 3.3989752763677814e-6, 1.1568107988455423e-5]\n",
      "BC Losses: [0.0007405955160528245, 0.0009090632437041884, 0.0011596602179989287, 0.00047525678382199686, 0.0010180237295430406, 0.000571561326979056, 0.0007459813459740905, 0.000736862224034354, 0.0007407445735023944]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true)))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Решение\n",
    "res = solve(prob, opt; maxiters = 100, callback)\n",
    "phi = discretization.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2005704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0mComponentVector{Float32, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Axis{(layer_1 = ViewAxis(1:160, Axis(weight = ViewAxis(1:128, ShapedAxis((32, 4))), bias = ViewAxis(129:160, Shaped1DAxis((32,))))), layer_2 = ViewAxis(161:1216, Axis(weight = ViewAxis(1:1024, ShapedAxis((32, 32))), bias = ViewAxis(1025:1056, Shaped1DAxis((32,))))), layer_3 = ViewAxis(1217:2272, Axis(weight = ViewAxis(1:1024, ShapedAxis((32, 32))), bias = ViewAxis(1025:1056, Shaped1DAxis((32,))))), layer_4 = ViewAxis(2273:2536, Axis(weight = ViewAxis(1:256, ShapedAxis((8, 32))), bias = ViewAxis(257:264, Shaped1DAxis((8,))))))}}}(layer_1 = (weight = Float32[0.64270455 -0.69251525 -0.21865846 -0.6302313; 0.09410353 0.16299486 0.14028741 -0.17518775; … ; 0.6903682 -0.73030674 0.43923947 -0.6788331; 0.7310284 -0.6661543 0.18700586 0.3957257], bias = Float32[-0.05248393, -0.40303862, 0.29772493, 0.0049014185, 0.06712001, 0.38455158, 0.29028347, 0.46409968, -0.3953544, 0.27702054  …  0.038982, -0.45193848, -0.036569875, 0.4469578, 0.47885904, 0.2888665, -0.25860062, 0.24595322, 0.25356773, 0.27765563]), layer_2 = (weight = Float32[0.01627679 0.1528641 … -0.08143178 -0.288257; 0.078764014 0.06756507 … 0.27594027 0.25883135; … ; -0.06965304 0.019706406 … -0.04240495 -0.27363873; 0.12170299 0.25688598 … -0.027266914 0.16222368], bias = Float32[-0.03160845, -0.017639304, -0.09954848, -0.10780809, -0.18575655, -0.07849031, 0.11848624, -0.08460619, -0.0227239, 0.18239263  …  -0.18439247, -0.00228332, -0.08178482, 0.044443116, 0.11445515, 0.13380617, -0.07750891, -0.15786532, -0.08928284, 0.13948654]), layer_3 = (weight = Float32[-0.061428037 0.089511946 … -0.067124635 -0.16012782; -0.1227836 -0.13727874 … -0.03893358 -0.11695453; … ; -0.001707719 -0.2818155 … 0.3079905 -0.11503563; -0.2003858 0.1796535 … -0.17482454 0.08547127], bias = Float32[0.060295966, 0.009363603, 0.06781459, 0.13820069, 0.10801077, -0.070276365, 0.042567592, -0.10752039, 0.06483106, 0.016803754  …  0.09850284, 0.016590506, 0.08960887, -0.14650053, 0.047081713, -0.05925507, -0.02086509, 0.14938636, -0.15745836, -0.01166662]), layer_4 = (weight = Float32[-0.13850604 0.06414953 … 0.2059744 0.28575087; -0.2736686 -0.025503628 … -0.088670865 -0.01744351; … ; 0.11486 0.09209624 … -0.17203517 0.21064809; -0.23944661 -0.22826971 … -0.111391865 -0.064700626], bias = Float32[-0.04646103, 0.004854258, -0.02067637, -0.00805779, 0.03914437, -0.12154924, -0.16009347, 0.033037823]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377e30b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "SystemError: opening file \"/home/sasha/inverse-npde/experiments/base/figures/plot_phi.png\": Нет такого файла или каталога",
     "output_type": "error",
     "traceback": [
      "SystemError: opening file \"/home/sasha/inverse-npde/experiments/base/figures/plot_phi.png\": Нет такого файла или каталога",
      "",
      "Stacktrace:",
      "  [1] systemerror(p::String, errno::Int32; extrainfo::Nothing)",
      "    @ Base ./error.jl:176",
      "  [2] systemerror",
      "    @ ./error.jl:175 [inlined]",
      "  [3] open(fname::String; lock::Bool, read::Nothing, write::Nothing, create::Nothing, truncate::Bool, append::Nothing)",
      "    @ Base ./iostream.jl:295",
      "  [4] open",
      "    @ ./iostream.jl:277 [inlined]",
      "  [5] open(fname::String, mode::String; lock::Bool)",
      "    @ Base ./iostream.jl:358",
      "  [6] open(fname::String, mode::String)",
      "    @ Base ./iostream.jl:357",
      "  [7] open(::Plots.var\"#346#347\"{Plots.Plot{Plots.GRBackend}}, ::String, ::Vararg{String}; kwargs::@Kwargs{})",
      "    @ Base ./io.jl:408",
      "  [8] open",
      "    @ ./io.jl:407 [inlined]",
      "  [9] png(plt::Plots.Plot{Plots.GRBackend}, fn::String)",
      "    @ Plots ~/.julia/packages/Plots/Ec1L1/src/output.jl:6",
      " [10] savefig(plt::Plots.Plot{Plots.GRBackend}, fn::String)",
      "    @ Plots ~/.julia/packages/Plots/Ec1L1/src/output.jl:149",
      " [11] top-level scope",
      "    @ In[36]:23"
     ]
    }
   ],
   "source": [
    "using Plots\n",
    "\n",
    "phi = discretization.phi\n",
    "xs, ys, zs, ts = [infimum(d.domain):0.01:supremum(d.domain) for d in domains]\n",
    "\n",
    "minimizers_ = res.u|> cpud\n",
    "z_selected = 0.0\n",
    "t_selected = 0.0\n",
    "clip = 10\n",
    "u_real = [clamp(analytic_sol_func(0, xs, ys, z_selected), -clip, clip) for xs in xs for ys in ys]\n",
    "u_predict = [(phi([x, y, z_selected, t_selected], minimizers_))[1] for x in xs for y in ys ]\n",
    "diff_u = [abs.(u_real .- u_predict)]\n",
    "\n",
    "ps = []\n",
    "\n",
    "p1 = plot(xs, ys, u_real, linetype = :contourf, title = \"phi, analytic\")\n",
    "p2 = plot(xs, ys, u_predict, linetype = :contourf, title = \"phi, predict\")\n",
    "p3 = plot(xs, ys, diff_u, linetype = :contourf, title = \"phi, error\")\n",
    "push!(ps, plot(p1, p2, p3))\n",
    "\n",
    "\n",
    "# Сохранение графиков\n",
    "savefig(ps[1], \"../../figures/plot_phi.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b42ec3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/sasha/inverse-npde/figures/plot_phi.png\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a74093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
