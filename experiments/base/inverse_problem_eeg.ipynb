{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f32abb7",
   "metadata": {},
   "source": [
    "# Обратная задача ЭЭГ\n",
    "\n",
    "Обратная задача ЭЭГ заключается в восстановлении распределения источников (тока и заряда) внутри области (например, головы) на основе измерений электрического потенциала на границе.\n",
    "\n",
    "В данном ноутбуке мы используем нейросеть для моделирования распределения заряда и тока, а также обновляем функцию потерь и пайплайн для решения этой задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee54cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "using NeuralPDE, Lux, ModelingToolkit, Optimization, OptimizationOptimJL, LineSearches,\n",
    "      OptimizationOptimisers, LuxCUDA, Random, ComponentArrays\n",
    "using ModelingToolkit: Interval, infimum, supremum\n",
    "using Distributions, Plots, CUDA\n",
    "\n",
    "using Random\n",
    "using TensorBoardLogger\n",
    "using ProgressBars\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1339f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::CPUDevice) (generic function with 4 methods)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const gpud = gpu_device()\n",
    "const cpud = cpu_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c97391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dalembert_operator (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Определение прямой задачи\n",
    "@parameters x, y, z, t\n",
    "@variables φ(..), Ax(..),Ay(..),Az(..), ρ(..), jx(..), jy(..), jz(..)\n",
    "A = [Ax, Ay, Az]\n",
    "j = [jx, jy, jz]\n",
    "Dxx = Differential(x)^2\n",
    "Dyy = Differential(y)^2\n",
    "Dzz = Differential(z)^2\n",
    "\n",
    "# Определение физических постоянных\n",
    "const c = 2.99792458e10 # Скорость света в вакууме (см/с)\n",
    "const ε₀ = 1.0 # Диэлектрическая постоянная вакуума в СГС (размерность отсутствует)\n",
    "const ε = 1.0  # Диэлектрическая проницаемость (отн.)\n",
    "const μ₀ = 1.0 # Магнитная постоянная вакуума в СГС (размерность отсутствует)\n",
    "const μ = 1.0  # Магнитная проницаемость (отн.)\n",
    "\n",
    "\n",
    "# Определение оператора Лапласа как функции\n",
    "function laplacian(F, params)\n",
    "    return sum((Differential(param)^2)(F) for param in params)\n",
    "end\n",
    "\n",
    "# Определение оператора Даламбера как функции\n",
    "function dalembert_operator(F, params, ε, μ, c)\n",
    "    Δ = laplacian(F, params)\n",
    "    return Δ  - (ε * μ / c^2) * (Differential(t)^2)(F)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2eb18d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\varphi\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\varphi\\left( x, y, z, t \\right)\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "Differential(y)(Differential(y)(φ(x, y, z, t))) + Differential(x)(Differential(x)(φ(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(φ(x, y, z, t))) + Differential(z)(Differential(z)(φ(x, y, z, t)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dalembert_operator(φ(x,y,z,t), [x, y, z], ε, μ, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "988ba867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{align}\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\varphi\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\varphi\\left( x, y, z, t \\right) &=  - 12.566 \\rho\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ax}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Ax}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ax}\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Ax}\\left( x, y, z, t \\right) &=  - 4.1917 \\cdot 10^{-10} \\mathtt{jx}\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Ay}\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ay}\\left( x, y, z, t \\right) &=  - 4.1917 \\cdot 10^{-10} \\mathtt{jy}\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Az}\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Az}\\left( x, y, z, t \\right) &=  - 4.1917 \\cdot 10^{-10} \\mathtt{jz}\\left( x, y, z, t \\right) \\\\\n",
       "3.3356 \\cdot 10^{-11} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ax}\\left( x, y, z, t \\right) &= 0\n",
       "\\end{align}\n",
       " $$"
      ],
      "text/plain": [
       "5-element Vector{Equation}:\n",
       " Differential(y)(Differential(y)(φ(x, y, z, t))) + Differential(x)(Differential(x)(φ(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(φ(x, y, z, t))) + Differential(z)(Differential(z)(φ(x, y, z, t))) ~ -12.566370614359172ρ(x, y, z, t)\n",
       " Differential(x)(Differential(x)(Ax(x, y, z, t))) + Differential(z)(Differential(z)(Ax(x, y, z, t))) + Differential(y)(Differential(y)(Ax(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Ax(x, y, z, t))) ~ -4.191690043903363e-10jx(x, y, z, t)\n",
       " Differential(y)(Differential(y)(Ay(x, y, z, t))) + Differential(z)(Differential(z)(Ay(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Ay(x, y, z, t))) + Differential(x)(Differential(x)(Ay(x, y, z, t))) ~ -4.191690043903363e-10jy(x, y, z, t)\n",
       " Differential(z)(Differential(z)(Az(x, y, z, t))) + Differential(y)(Differential(y)(Az(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Az(x, y, z, t))) + Differential(x)(Differential(x)(Az(x, y, z, t))) ~ -4.191690043903363e-10jz(x, y, z, t)\n",
       " 3.33564095198152e-11Differential(t)(φ(x, y, z, t)) + Differential(y)(Ay(x, y, z, t)) + Differential(z)(Az(x, y, z, t)) + Differential(x)(Ax(x, y, z, t)) ~ 0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Уравнение\n",
    "eqs = [\n",
    "\n",
    "    [dalembert_operator(φ(x, y, z, t), [x, y, z], ε, μ, c) ~ -4 * pi * ρ(x, y, z, t) / ε];\n",
    "    [dalembert_operator(A[i](x, y, z, t), [x, y, z], ε, μ, c) ~ -μ * 4 * pi / c* j[i](x, y, z, t) for i in 1:3];\n",
    "    (Differential(x)(Ax(x, y, z, t)) + Differential(y)(Ay(x, y, z, t)) + Differential(z)(Az(x, y, z, t)) + (ε * μ / c) * Differential(t)(φ(x, y, z, t))) ~ 0.0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "694a6dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{align}\n",
       "\\varphi\\left( -10, y, z, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( 10, y, z, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( x, -10, z, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( x, 10, z, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( x, y, -10, t \\right) &= 0 \\\\\n",
       "\\varphi\\left( x, y, 10, t \\right) &= 0 \\\\\n",
       "\\mathtt{Ax}\\left( -10, y, z, t \\right) &= 0 \\\\\n",
       "\\mathtt{Ay}\\left( -10, y, z, t \\right) &= 0 \\\\\n",
       "\\mathtt{Az}\\left( -10, y, z, t \\right) &= 0\n",
       "\\end{align}\n",
       " $$"
      ],
      "text/plain": [
       "9-element Vector{Equation}:\n",
       " φ(-10.0, y, z, t) ~ 0.0\n",
       " φ(10.0, y, z, t) ~ 0.0\n",
       " φ(x, -10.0, z, t) ~ 0.0\n",
       " φ(x, 10.0, z, t) ~ 0.0\n",
       " φ(x, y, -10.0, t) ~ 0.0\n",
       " φ(x, y, 10.0, t) ~ 0.0\n",
       " Ax(-10.0, y, z, t) ~ 0.0\n",
       " Ay(-10.0, y, z, t) ~ 0.0\n",
       " Az(-10.0, y, z, t) ~ 0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Границы области\n",
    "const x_min, x_max = -10.0, 10.0\n",
    "const y_min, y_max = -10.0, 10.0\n",
    "const z_min, z_max = -10.0, 10.0\n",
    "const t_min, t_max = 0.0, 1.0\n",
    "# Область\n",
    "domains = [x ∈ Interval(x_min, x_max),\n",
    "           y ∈ Interval(y_min, y_max),\n",
    "           z ∈ Interval(z_min, z_max), \n",
    "           t ∈ Interval(t_min, t_max)]\n",
    "# Начальные условия\n",
    "\n",
    "function analytic_sol_func(t, x, y, z)\n",
    "    r = sqrt((x)^2 + (y)^2 + (z)^2)\n",
    "    (t + 1)^2 / r\n",
    "end\n",
    "\n",
    "# Генерация случайных точек в пределах домена\n",
    "num_points = 100\n",
    "measured_points = []\n",
    "for _ in 1:num_points\n",
    "    x_p = rand(x_min/2:x_max/2)\n",
    "    y_p = rand(y_min/2:y_max/2)\n",
    "    z_p = rand(z_min/2:z_max/2)\n",
    "    t_p = rand(t_min/2:t_max/2)\n",
    "    # Добавление случайной точки в массив measured_points\n",
    "    phi_p = analytic_sol_func(t_p, x_p, y_p, z_p)\n",
    "    push!(measured_points, [x_p, y_p, z_p, t_p, phi_p])\n",
    "end\n",
    "for _ in 1:num_points\n",
    "    x_p = rand(x_min/2:x_max/2)\n",
    "    y_p = rand(y_min/2:y_max/2)\n",
    "    z_p = rand(z_min/2:z_max/2)\n",
    "    t_p = 0.0\n",
    "    # Добавление случайной точки в массив measured_points\n",
    "    phi_p = analytic_sol_func(t_p, x_p, y_p, z_p)\n",
    "    push!(measured_points, [x_p, y_p, z_p, t_p, phi_p])\n",
    "end\n",
    "measured_points = measured_points |> gpud\n",
    "bcs = [\n",
    "    [φ(x_min, y, z, t) ~ 0.0, φ(x_max, y, z, t) ~ 0.0,\n",
    "    φ(x, y_min, z, t) ~ 0.0, φ(x, y_max, z, t) ~ 0.0,\n",
    "    φ(x, y, z_min, t) ~ 0.0, φ(x, y, z_max, t) ~ 0.0];\n",
    "    [A[i](x_min, y, z, t)  ~ 0.0 for i in 1:3]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94dcb1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200-element Vector{CuArray{Float32, 1, CUDA.DeviceMemory}}:\n",
       " Float32[-1.0, -1.0, 1.0, 0.0, 0.57735026]\n",
       " Float32[-1.0, -3.0, -2.0, 0.0, 0.26726124]\n",
       " Float32[-1.0, -4.0, -2.0, 0.0, 0.2182179]\n",
       " Float32[-1.0, 0.0, 2.0, 0.0, 0.4472136]\n",
       " Float32[-2.0, -2.0, 2.0, 0.0, 0.28867513]\n",
       " Float32[0.0, 4.0, 3.0, 0.0, 0.2]\n",
       " Float32[3.0, -5.0, 3.0, 0.0, 0.15249857]\n",
       " Float32[-3.0, -5.0, 5.0, 0.0, 0.13018891]\n",
       " Float32[0.0, -5.0, 1.0, 0.0, 0.19611613]\n",
       " Float32[2.0, 4.0, 4.0, 0.0, 0.16666667]\n",
       " Float32[5.0, 5.0, 2.0, 0.0, 0.13608277]\n",
       " Float32[5.0, 1.0, -4.0, 0.0, 0.15430336]\n",
       " Float32[1.0, 1.0, 3.0, 0.0, 0.30151135]\n",
       " ⋮\n",
       " Float32[-5.0, -5.0, -3.0, 0.0, 0.13018891]\n",
       " Float32[4.0, 4.0, 3.0, 0.0, 0.15617377]\n",
       " Float32[1.0, -2.0, 4.0, 0.0, 0.2182179]\n",
       " Float32[-2.0, -5.0, 4.0, 0.0, 0.1490712]\n",
       " Float32[-4.0, 4.0, 2.0, 0.0, 0.16666667]\n",
       " Float32[3.0, 4.0, -4.0, 0.0, 0.15617377]\n",
       " Float32[-4.0, -5.0, -4.0, 0.0, 0.13245323]\n",
       " Float32[-4.0, -3.0, -5.0, 0.0, 0.14142136]\n",
       " Float32[4.0, -2.0, 2.0, 0.0, 0.20412415]\n",
       " Float32[-2.0, 2.0, 2.0, 0.0, 0.28867513]\n",
       " Float32[4.0, 5.0, -1.0, 0.0, 0.15430336]\n",
       " Float32[-1.0, 2.0, 4.0, 0.0, 0.2182179]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measured_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f3a7fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "additional_loss_weightened (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function additional_loss_weightened(lambda)\n",
    "    \n",
    "    function additional_loss(phi_pred_fun, θ, p_)\n",
    "        CUDA.allowscalar() do\n",
    "            # phi is first output of phi_pred_fun\n",
    "            result = sum(abs2(phi_pred_fun([x, y, z, t]|>cpud, θ|>cpud)[1] - phi|>cpud) for (x, y, z, t, phi) in measured_points) / length(measured_points)|>cpud\n",
    "            result = result * lambda\n",
    "            return result\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return additional_loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8d660e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhysicsInformedNN{Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}, ComponentVector{Float32, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Axis{(layer_1 = ViewAxis(1:160, Axis(weight = ViewAxis(1:128, ShapedAxis((32, 4))), bias = ViewAxis(129:160, Shaped1DAxis((32,))))), layer_2 = ViewAxis(161:1216, Axis(weight = ViewAxis(1:1024, ShapedAxis((32, 32))), bias = ViewAxis(1025:1056, Shaped1DAxis((32,))))), layer_3 = ViewAxis(1217:2272, Axis(weight = ViewAxis(1:1024, ShapedAxis((32, 32))), bias = ViewAxis(1025:1056, Shaped1DAxis((32,))))), layer_4 = ViewAxis(2273:2536, Axis(weight = ViewAxis(1:256, ShapedAxis((8, 32))), bias = ViewAxis(257:264, Shaped1DAxis((8,))))))}}}, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, typeof(NeuralPDE.numeric_derivative), Bool, var\"#additional_loss#9\"{Int64}, Nothing, Nothing, Base.RefValue{Int64}, Base.Pairs{Symbol, Union{}, Tuple{}, @NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0), (layer_1 = (weight = Float32[0.43873644 0.5720638 -0.8534556 0.588361; -0.43472376 -0.10792436 0.5118949 -0.031731833; … ; -0.21277274 0.032084804 -0.44414806 0.69877607; -0.4684896 -0.47059092 -0.25818518 -0.7083163], bias = Float32[0.32510734, 0.07089245, 0.48741442, 0.32617354, 0.33878678, 0.115698636, 0.12690812, -0.431993, -0.09202111, 0.36180305  …  -0.36018068, -0.47118902, -0.3916126, -0.36790234, 0.21978456, -0.4440676, 0.07148701, -0.15191174, 0.4728768, 0.20038337]), layer_2 = (weight = Float32[0.305109 0.011728149 … -0.25716117 -0.023180647; -0.036541633 0.22429878 … 0.12862226 -0.27604216; … ; 0.15707372 -0.20166081 … 0.2844832 0.10532324; 0.15685391 -0.2732656 … -0.031734515 -0.047171745], bias = Float32[0.040045258, -0.011121499, 0.065936446, -0.061352093, -0.13736375, 0.05817993, 0.06048998, 0.10640311, -0.06193964, -0.059916444  …  -0.0049757096, 0.16494623, 0.06676269, 0.04628257, 0.16209547, -0.107444055, -0.1367068, -0.17330743, 0.04163466, 0.11180105]), layer_3 = (weight = Float32[0.13438141 0.23212479 … 0.27251062 -0.2955398; 0.032441925 -0.10686074 … -0.24451567 -0.09503006; … ; 0.12110478 -0.23036934 … -0.04904855 0.19023415; -0.23963697 0.106435366 … -0.20826784 0.15534227], bias = Float32[-0.06624182, -0.095770456, 0.10799203, -0.07918369, -0.015845403, -0.1325392, -0.0046769516, 0.018556036, -0.06739945, -0.14910282  …  -0.033076234, -0.08553459, -0.038971715, 0.071701206, -0.15196016, 0.13670887, 0.15056874, -0.054390635, 0.030673444, 0.15026498]), layer_4 = (weight = Float32[-0.2687029 -0.29890564 … -0.012840785 -0.007329869; -0.28946075 0.1485846 … -0.24432112 9.756515f-5; … ; 0.154684 -0.0772643 … -0.11497292 0.25088963; 0.10039508 -0.12201378 … -0.054656412 0.119655825], bias = Float32[-0.10505437, 0.06536462, -0.03577846, 0.15693052, -0.05609752, -0.101164915, 0.09227817, -0.079871505])), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), NeuralPDE.numeric_derivative, false, var\"#additional_loss#9\"{Int64}(10), nothing, nothing, LogOptions(50), Base.RefValue{Int64}(1), true, false, Base.Pairs{Symbol, Union{}, Tuple{}, @NamedTuple{}}())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Нейросеть\n",
    "# Определение новой нейросети для моделирования распределения заряда и тока\n",
    "input_ = 4  # x, y, z\n",
    "n = 32      # число нейронов в скрытых слоях\n",
    "lambda = 10 # вес дополнительной потерь\n",
    "# Функция для разделения выхода сети на переменные\n",
    "\"\"\"\n",
    "function split_outputs(out)\n",
    "    φ_pred = out[1]\n",
    "    A_pred = out[2:4]\n",
    "    ρ_pred = out[5]\n",
    "    j_pred = out[6:8]\n",
    "    return φ_pred, A_pred, ρ_pred, j_pred\n",
    "end\n",
    "\n",
    "chain = [Chain(\n",
    "    Dense(input_, n, σ),\n",
    "    Dense(n, n, σ),\n",
    "    Dense(n, 1)\n",
    ") for _ in 1:8] \n",
    "\n",
    "# Определение системы\n",
    "ps = [Lux.setup(Random.default_rng(), chain[i])[1] |> ComponentArray |> gpud .|> Float64 for i in 1:8]\n",
    "\"\"\"\n",
    "chain = Chain(\n",
    "    Dense(input_, n, σ),\n",
    "    Dense(n, n, σ),\n",
    "    Dense(n, n, σ),\n",
    "    Dense(n, 8)\n",
    ")\n",
    "\n",
    "# Определение системы\n",
    "ps = Lux.setup(Random.default_rng(), chain)[1] |> ComponentArray |> gpud .|> Float32\n",
    "\n",
    "strategy = QuasiRandomTraining(4096)\n",
    "discretization = PhysicsInformedNN(chain, strategy; init_params = ps, additional_loss = additional_loss_weightened(lambda), \n",
    "log_options = LogOptions(; log_frequency = 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9525824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10607222f0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_loss_weightened(lambda)(discretization.phi, ps, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e01addc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{c}\n",
       "\\varphi\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{Ax}\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{Ay}\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{Az}\\left( x, y, z, t \\right) \\\\\n",
       "\\rho\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{jx}\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{jy}\\left( x, y, z, t \\right) \\\\\n",
       "\\mathtt{jz}\\left( x, y, z, t \\right) \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "8-element Vector{Num}:\n",
       "  φ(x, y, z, t)\n",
       " Ax(x, y, z, t)\n",
       " Ay(x, y, z, t)\n",
       " Az(x, y, z, t)\n",
       "  ρ(x, y, z, t)\n",
       " jx(x, y, z, t)\n",
       " jy(x, y, z, t)\n",
       " jz(x, y, z, t)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allvars = [φ(x, y, z, t); [A_(x, y, z, t) for A_ in A]; ρ(x, y, z, t); [j_(x, y, z, t) for j_ in j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3610692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{align}\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\varphi\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\varphi\\left( x, y, z, t \\right) &=  - 12.566 \\rho\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ax}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Ax}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ax}\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Ax}\\left( x, y, z, t \\right) &=  - 4.1917 \\cdot 10^{-10} \\mathtt{jx}\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Ay}\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ay}\\left( x, y, z, t \\right) &=  - 4.1917 \\cdot 10^{-10} \\mathtt{jy}\\left( x, y, z, t \\right) \\\\\n",
       "\\frac{\\mathrm{d}}{\\mathrm{d}z} \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Az}\\left( x, y, z, t \\right) - 1.1127 \\cdot 10^{-21} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Az}\\left( x, y, z, t \\right) &=  - 4.1917 \\cdot 10^{-10} \\mathtt{jz}\\left( x, y, z, t \\right) \\\\\n",
       "3.3356 \\cdot 10^{-11} \\frac{\\mathrm{d}}{\\mathrm{d}t} \\varphi\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}y} \\mathtt{Ay}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}z} \\mathtt{Az}\\left( x, y, z, t \\right) + \\frac{\\mathrm{d}}{\\mathrm{d}x} \\mathtt{Ax}\\left( x, y, z, t \\right) &= 0\n",
       "\\end{align}\n",
       " $$"
      ],
      "text/plain": [
       "PDESystem\n",
       "Equations: Equation[Differential(y)(Differential(y)(φ(x, y, z, t))) + Differential(x)(Differential(x)(φ(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(φ(x, y, z, t))) + Differential(z)(Differential(z)(φ(x, y, z, t))) ~ -12.566370614359172ρ(x, y, z, t), Differential(x)(Differential(x)(Ax(x, y, z, t))) + Differential(z)(Differential(z)(Ax(x, y, z, t))) + Differential(y)(Differential(y)(Ax(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Ax(x, y, z, t))) ~ -4.191690043903363e-10jx(x, y, z, t), Differential(y)(Differential(y)(Ay(x, y, z, t))) + Differential(z)(Differential(z)(Ay(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Ay(x, y, z, t))) + Differential(x)(Differential(x)(Ay(x, y, z, t))) ~ -4.191690043903363e-10jy(x, y, z, t), Differential(z)(Differential(z)(Az(x, y, z, t))) + Differential(y)(Differential(y)(Az(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Az(x, y, z, t))) + Differential(x)(Differential(x)(Az(x, y, z, t))) ~ -4.191690043903363e-10jz(x, y, z, t), 3.33564095198152e-11Differential(t)(φ(x, y, z, t)) + Differential(y)(Ay(x, y, z, t)) + Differential(z)(Az(x, y, z, t)) + Differential(x)(Ax(x, y, z, t)) ~ 0.0]\n",
       "Boundary Conditions: Equation[φ(-10.0, y, z, t) ~ 0.0, φ(10.0, y, z, t) ~ 0.0, φ(x, -10.0, z, t) ~ 0.0, φ(x, 10.0, z, t) ~ 0.0, φ(x, y, -10.0, t) ~ 0.0, φ(x, y, 10.0, t) ~ 0.0, Ax(-10.0, y, z, t) ~ 0.0, Ay(-10.0, y, z, t) ~ 0.0, Az(-10.0, y, z, t) ~ 0.0]\n",
       "Domain: Symbolics.VarDomainPairing[Symbolics.VarDomainPairing(x, -10.0 .. 10.0), Symbolics.VarDomainPairing(y, -10.0 .. 10.0), Symbolics.VarDomainPairing(z, -10.0 .. 10.0), Symbolics.VarDomainPairing(t, 0.0 .. 1.0)]\n",
       "Dependent Variables: Num[φ(x, y, z, t), Ax(x, y, z, t), Ay(x, y, z, t), Az(x, y, z, t), ρ(x, y, z, t), jx(x, y, z, t), jy(x, y, z, t), jz(x, y, z, t)]\n",
       "Independent Variables: Num[x, y, z, t]\n",
       "Parameters: SciMLBase.NullParameters()\n",
       "Default Parameter ValuesDict{Any, Any}()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@named pde_system = PDESystem(eqs, bcs, domains, [x, y, z, t], allvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5817f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralPDE.PINNRepresentation(Equation[Differential(y)(Differential(y)(φ(x, y, z, t))) + Differential(x)(Differential(x)(φ(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(φ(x, y, z, t))) + Differential(z)(Differential(z)(φ(x, y, z, t))) ~ -12.566370614359172ρ(x, y, z, t), Differential(x)(Differential(x)(Ax(x, y, z, t))) + Differential(z)(Differential(z)(Ax(x, y, z, t))) + Differential(y)(Differential(y)(Ax(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Ax(x, y, z, t))) ~ -4.191690043903363e-10jx(x, y, z, t), Differential(y)(Differential(y)(Ay(x, y, z, t))) + Differential(z)(Differential(z)(Ay(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Ay(x, y, z, t))) + Differential(x)(Differential(x)(Ay(x, y, z, t))) ~ -4.191690043903363e-10jy(x, y, z, t), Differential(z)(Differential(z)(Az(x, y, z, t))) + Differential(y)(Differential(y)(Az(x, y, z, t))) - 1.1126500560536184e-21Differential(t)(Differential(t)(Az(x, y, z, t))) + Differential(x)(Differential(x)(Az(x, y, z, t))) ~ -4.191690043903363e-10jz(x, y, z, t), 3.33564095198152e-11Differential(t)(φ(x, y, z, t)) + Differential(y)(Ay(x, y, z, t)) + Differential(z)(Az(x, y, z, t)) + Differential(x)(Ax(x, y, z, t)) ~ 0.0], Equation[φ(-10.0, y, z, t) ~ 0.0, φ(10.0, y, z, t) ~ 0.0, φ(x, -10.0, z, t) ~ 0.0, φ(x, 10.0, z, t) ~ 0.0, φ(x, y, -10.0, t) ~ 0.0, φ(x, y, 10.0, t) ~ 0.0, Ax(-10.0, y, z, t) ~ 0.0, Ay(-10.0, y, z, t) ~ 0.0, Az(-10.0, y, z, t) ~ 0.0], Symbolics.VarDomainPairing[Symbolics.VarDomainPairing(x, -10.0 .. 10.0), Symbolics.VarDomainPairing(y, -10.0 .. 10.0), Symbolics.VarDomainPairing(z, -10.0 .. 10.0), Symbolics.VarDomainPairing(t, 0.0 .. 1.0)], SciMLBase.NullParameters(), Dict{Any, Any}(), nothing, false, var\"#additional_loss#9\"{Int64}(10), NonAdaptiveLoss{Float32}(Float32[1.0, 1.0, 1.0, 1.0, 1.0], Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], Float32[1.0]), [:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz], [:x, :y, :z, :t], Dict(:y => 2, :z => 3, :t => 4, :x => 1), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:φ => [:x, :y, :z, :t], :ρ => [:x, :y, :z, :t], :Az => [:x, :y, :z, :t], :jx => [:x, :y, :z, :t], :Ax => [:x, :y, :z, :t], :jz => [:x, :y, :z, :t], :jy => [:x, :y, :z, :t], :Ay => [:x, :y, :z, :t]), nothing, false, Base.RefValue{Int64}(1), (layer_1 = (weight = Float32[0.43873644 0.5720638 -0.8534556 0.588361; -0.43472376 -0.10792436 0.5118949 -0.031731833; … ; -0.21277274 0.032084804 -0.44414806 0.69877607; -0.4684896 -0.47059092 -0.25818518 -0.7083163], bias = Float32[0.32510734, 0.07089245, 0.48741442, 0.32617354, 0.33878678, 0.115698636, 0.12690812, -0.431993, -0.09202111, 0.36180305  …  -0.36018068, -0.47118902, -0.3916126, -0.36790234, 0.21978456, -0.4440676, 0.07148701, -0.15191174, 0.4728768, 0.20038337]), layer_2 = (weight = Float32[0.305109 0.011728149 … -0.25716117 -0.023180647; -0.036541633 0.22429878 … 0.12862226 -0.27604216; … ; 0.15707372 -0.20166081 … 0.2844832 0.10532324; 0.15685391 -0.2732656 … -0.031734515 -0.047171745], bias = Float32[0.040045258, -0.011121499, 0.065936446, -0.061352093, -0.13736375, 0.05817993, 0.06048998, 0.10640311, -0.06193964, -0.059916444  …  -0.0049757096, 0.16494623, 0.06676269, 0.04628257, 0.16209547, -0.107444055, -0.1367068, -0.17330743, 0.04163466, 0.11180105]), layer_3 = (weight = Float32[0.13438141 0.23212479 … 0.27251062 -0.2955398; 0.032441925 -0.10686074 … -0.24451567 -0.09503006; … ; 0.12110478 -0.23036934 … -0.04904855 0.19023415; -0.23963697 0.106435366 … -0.20826784 0.15534227], bias = Float32[-0.06624182, -0.095770456, 0.10799203, -0.07918369, -0.015845403, -0.1325392, -0.0046769516, 0.018556036, -0.06739945, -0.14910282  …  -0.033076234, -0.08553459, -0.038971715, 0.071701206, -0.15196016, 0.13670887, 0.15056874, -0.054390635, 0.030673444, 0.15026498]), layer_4 = (weight = Float32[-0.2687029 -0.29890564 … -0.012840785 -0.007329869; -0.28946075 0.1485846 … -0.24432112 9.756515f-5; … ; 0.154684 -0.0772643 … -0.11497292 0.25088963; 0.10039508 -0.12201378 … -0.054656412 0.119655825], bias = Float32[-0.10505437, 0.06536462, -0.03577846, 0.15693052, -0.05609752, -0.101164915, 0.09227817, -0.079871505])), (layer_1 = (weight = Float32[0.43873644 0.5720638 -0.8534556 0.588361; -0.43472376 -0.10792436 0.5118949 -0.031731833; … ; -0.21277274 0.032084804 -0.44414806 0.69877607; -0.4684896 -0.47059092 -0.25818518 -0.7083163], bias = Float32[0.32510734, 0.07089245, 0.48741442, 0.32617354, 0.33878678, 0.115698636, 0.12690812, -0.431993, -0.09202111, 0.36180305  …  -0.36018068, -0.47118902, -0.3916126, -0.36790234, 0.21978456, -0.4440676, 0.07148701, -0.15191174, 0.4728768, 0.20038337]), layer_2 = (weight = Float32[0.305109 0.011728149 … -0.25716117 -0.023180647; -0.036541633 0.22429878 … 0.12862226 -0.27604216; … ; 0.15707372 -0.20166081 … 0.2844832 0.10532324; 0.15685391 -0.2732656 … -0.031734515 -0.047171745], bias = Float32[0.040045258, -0.011121499, 0.065936446, -0.061352093, -0.13736375, 0.05817993, 0.06048998, 0.10640311, -0.06193964, -0.059916444  …  -0.0049757096, 0.16494623, 0.06676269, 0.04628257, 0.16209547, -0.107444055, -0.1367068, -0.17330743, 0.04163466, 0.11180105]), layer_3 = (weight = Float32[0.13438141 0.23212479 … 0.27251062 -0.2955398; 0.032441925 -0.10686074 … -0.24451567 -0.09503006; … ; 0.12110478 -0.23036934 … -0.04904855 0.19023415; -0.23963697 0.106435366 … -0.20826784 0.15534227], bias = Float32[-0.06624182, -0.095770456, 0.10799203, -0.07918369, -0.015845403, -0.1325392, -0.0046769516, 0.018556036, -0.06739945, -0.14910282  …  -0.033076234, -0.08553459, -0.038971715, 0.071701206, -0.15196016, 0.13670887, 0.15056874, -0.054390635, 0.030673444, 0.15026498]), layer_4 = (weight = Float32[-0.2687029 -0.29890564 … -0.012840785 -0.007329869; -0.28946075 0.1485846 … -0.24432112 9.756515f-5; … ; 0.154684 -0.0772643 … -0.11497292 0.25088963; 0.10039508 -0.12201378 … -0.054656412 0.119655825], bias = Float32[-0.10505437, 0.06536462, -0.03577846, 0.15693052, -0.05609752, -0.101164915, 0.09227817, -0.079871505])), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), NeuralPDE.numeric_derivative, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0), Vector{Any}[[:x, :y, :z, :t], [:x, :y, :z, :t], [:x, :y, :z, :t], [:x, :y, :z, :t], [:x, :y, :z, :t]], Vector{Any}[[:y, :z, :t], [:y, :z, :t], [:x, :z, :t], [:x, :z, :t], [:x, :y, :t], [:x, :y, :t], [:y, :z, :t], [:y, :z, :t], [:y, :z, :t]], [[:t, :x, :y, :z], [:t, :x, :y, :z], [:t, :x, :y, :z], [:t, :x, :y, :z], [:t, :x, :y, :z]], [[:t, :y, :z], [:t, :y, :z], [:t, :x, :z], [:t, :x, :z], [:t, :x, :y], [:t, :x, :y], [:t, :y, :z], [:t, :y, :z], [:t, :y, :z]], NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), Expr[:((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord5 = vcat(x, y, z, t)\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  (+).((+).((+).(derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord1, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")) .- (*).(-12.566370614359172, u(cord5, var\"##θ#230\", phi))\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord6 = vcat(x, y, z, t)\n",
       "                      cord2 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  (+).((+).((+).(derivative(phi, u, cord2, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))) .- (*).(-4.191690043903363e-10, u(cord6, var\"##θ#230\", phi))\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord7 = vcat(x, y, z, t)\n",
       "                      cord3 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  (+).((+).((+).(derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord3, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord7, var\"##θ#230\", phi))\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord4 = vcat(x, y, z, t)\n",
       "                      cord8 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  (+).((+).((+).(derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord4, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord8, var\"##θ#230\", phi))\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord4 = vcat(x, y, z, t)\n",
       "                      cord2 = vcat(x, y, z, t)\n",
       "                      cord3 = vcat(x, y, z, t)\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  (+).((+).((+).((*).(3.33564095198152e-11, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.0049215658]], 1, var\"##θ#230\")), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0049215658, 0.0, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0049215658, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0049215658, 0.0, 0.0, 0.0]], 1, var\"##θ#230\")) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end)], Expr[:((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord1 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord2 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord2, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord3 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord3, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end), :((cord, var\"##θ#230\", phi, derivative, integral, u, p)->begin\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "          \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "          begin\n",
       "              let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "                  begin\n",
       "                      cord4 = vcat(x, y, z, t)\n",
       "                  end\n",
       "                  u(cord4, var\"##θ#230\", phi) .- 0.0\n",
       "              end\n",
       "          end\n",
       "      end)], NeuralPDE.PINNLossFunctions(NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function[NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[10.0, -9.999756, -9.999756, 0.00024414062], Float32[10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -10.0, -9.999756, 0.00024414062], Float32[9.999756, -10.0, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, 10.0, -9.999756, 0.00024414062], Float32[9.999756, 10.0, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -10.0, 0.00024414062], Float32[9.999756, 9.999756, -10.0, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, 10.0, 0.00024414062], Float32[9.999756, 9.999756, 10.0, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord2, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord3, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord4, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()))], NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function[NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord5 = vcat(x, y, z, t)\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord1, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")) .- (*).(-12.566370614359172, u(cord5, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord6 = vcat(x, y, z, t)\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord2, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))) .- (*).(-4.191690043903363e-10, u(cord6, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord7 = vcat(x, y, z, t)\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord3, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord7, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "                cord8 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord4, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord8, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).((*).(3.33564095198152e-11, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.0049215658]], 1, var\"##θ#230\")), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0049215658, 0.0, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0049215658, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0049215658, 0.0, 0.0, 0.0]], 1, var\"##θ#230\")) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()))], NeuralPDE.var\"#full_loss_function#283\"{Returns{Nothing}, Vector{NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function}, Vector{NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function}, NeuralPDE.PINNRepresentation, Int64, Bool, Base.RefValue{Int64}, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, var\"#additional_loss#9\"{Int64}, Bool}(Returns{Nothing}(nothing), NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function[NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[10.0, -9.999756, -9.999756, 0.00024414062], Float32[10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -10.0, -9.999756, 0.00024414062], Float32[9.999756, -10.0, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, 10.0, -9.999756, 0.00024414062], Float32[9.999756, 10.0, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -10.0, 0.00024414062], Float32[9.999756, 9.999756, -10.0, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, 10.0, 0.00024414062], Float32[9.999756, 9.999756, 10.0, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord2, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord3, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord4, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-10.0, -9.999756, -9.999756, 0.00024414062], Float32[-10.0, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()))], NeuralPDE.var\"#94#97\"{loss_function, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample} where loss_function[NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord5 = vcat(x, y, z, t)\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord1, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")) .- (*).(-12.566370614359172, u(cord5, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord6 = vcat(x, y, z, t)\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord2, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))) .- (*).(-4.191690043903363e-10, u(cord6, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord7 = vcat(x, y, z, t)\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord3, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord7, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "                cord8 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord4, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord8, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG())), NeuralPDE.var\"#94#97\"{NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}, Tuple{Vector{Float32}, Vector{Float32}}, DataType, CUDADevice{CuDevice}, Int64, QuasiMonteCarlo.LatinHypercubeSample}(NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).((*).(3.33564095198152e-11, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.0049215658]], 1, var\"##θ#230\")), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0049215658, 0.0, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0049215658, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0049215658, 0.0, 0.0, 0.0]], 1, var\"##θ#230\")) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), (Float32[-9.999756, -9.999756, -9.999756, 0.00024414062], Float32[9.999756, 9.999756, 9.999756, 0.99975586]), Float32, CUDADevice{CuDevice}(CuDevice(0)), 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()))], NeuralPDE.PINNRepresentation(#= circular reference @-3 =#), Core.Box(NonAdaptiveLoss{Float32}(Float32[1.0, 1.0, 1.0, 1.0, 1.0], Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], Float32[1.0])), 50, true, Base.RefValue{Int64}(1), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), var\"#additional_loss#9\"{Int64}(10), false), var\"#additional_loss#9\"{Int64}(10), NeuralPDE.var\"#197#198\"{_loss_function, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing} where _loss_function[NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x5b2b209c, 0x0868d5a4, 0x3d4cef40, 0xc2f3327c, 0xac51a340), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord5 = vcat(x, y, z, t)\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord1, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")) .- (*).(-12.566370614359172, u(cord5, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x85f2ff1b, 0xb10a869a, 0x92ea17c2, 0x855ffd32, 0x095d9a2e), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord6 = vcat(x, y, z, t)\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord2, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord2, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))) .- (*).(-4.191690043903363e-10, u(cord6, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x1d17a2af, 0x1a25e961, 0xa221385d, 0x45a9b2fb, 0xdb8b3693), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord7 = vcat(x, y, z, t)\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord3, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord7, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a03b19c, 0xe4514e31, 0x714be584, 0x478ea9fc, 0x9607dd93), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "                cord8 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).(derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.01858136, 0.0], [0.0, 0.0, 0.01858136, 0.0]], 2, var\"##θ#230\"), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.01858136, 0.0, 0.0], [0.0, 0.01858136, 0.0, 0.0]], 2, var\"##θ#230\")), (*).(-1.1126500560536184e-21, derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0, 0.01858136], [0.0, 0.0, 0.0, 0.01858136]], 2, var\"##θ#230\"))), derivative(phi, u, cord4, Vector{Float32}[[0.01858136, 0.0, 0.0, 0.0], [0.01858136, 0.0, 0.0, 0.0]], 2, var\"##θ#230\")) .- (*).(-4.191690043903363e-10, u(cord8, var\"##θ#230\", phi))\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0xef957cc8, 0x7d27359e, 0x5ae49349, 0x1767cf17, 0x4e1429e5), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            (+).((+).((+).((*).(3.33564095198152e-11, derivative(phi, u, cord1, Vector{Float32}[[0.0, 0.0, 0.0, 0.0049215658]], 1, var\"##θ#230\")), derivative(phi, u, cord3, Vector{Float32}[[0.0, 0.0049215658, 0.0, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord4, Vector{Float32}[[0.0, 0.0, 0.0049215658, 0.0]], 1, var\"##θ#230\")), derivative(phi, u, cord2, Vector{Float32}[[0.0049215658, 0.0, 0.0, 0.0]], 1, var\"##θ#230\")) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing)], NeuralPDE.var\"#197#198\"{_loss_function, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing} where _loss_function[NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x3ff27045, 0xa0fd0e28, 0x1240535f, 0xe02ab7e0, 0x205a006c), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord1 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord1, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x66f13037, 0x5fcc5051, 0x386ee0de, 0x37396a0f, 0x7884cdc3), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord2 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord2, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x2e9fb24d, 0x0fe98539, 0x436aa1a0, 0xfcc34bb7, 0x9e3c00f0), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord3 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord3, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing), NeuralPDE.var\"#197#198\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}, Nothing}(RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6ab35d25, 0xd5c687c0, 0x3b8586db, 0x3474c683, 0x3951f605), Expr}(quote\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:129 =#\u001b[39m\n",
       "    \u001b[90m#= /home/sasha/.julia/packages/NeuralPDE/nYBAW/src/discretize.jl:130 =#\u001b[39m\n",
       "    begin\n",
       "        let (x, y, z, t) = (cord[[1], :], cord[[2], :], cord[[3], :], cord[[4], :])\n",
       "            begin\n",
       "                cord4 = vcat(x, y, z, t)\n",
       "            end\n",
       "            u(cord4, var\"##θ#230\", phi) .- 0.0\n",
       "        end\n",
       "    end\n",
       "end), NeuralPDE.var\"#7#8\"(), NeuralPDE.var\"#239#246\"{NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}}(NeuralPDE.var\"#239#240#247\"{typeof(NeuralPDE.numeric_derivative)}(NeuralPDE.numeric_derivative), Dict(:φ => 1, :ρ => 5, :Az => 4, :jx => 6, :Ax => 2, :jz => 8, :jy => 7, :Ay => 3), Dict(:y => 2, :z => 3, :t => 4, :x => 1), Core.Box([:φ, :Ax, :Ay, :Az, :ρ, :jx, :jy, :jz]), Core.Box([:x, :y, :z, :t]), QuasiRandomTraining{QuasiMonteCarlo.LatinHypercubeSample}(4096, 4096, QuasiMonteCarlo.LatinHypercubeSample(TaskLocalRNG()), true, 0)), NeuralPDE.numeric_derivative, NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}}(StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}, layer_4::@NamedTuple{}}}(Chain{@NamedTuple{layer_1::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_3::Dense{typeof(σ), Int64, Int64, Nothing, Nothing, Static.True}, layer_4::Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(4 => 32, σ), layer_2 = Dense(32 => 32, σ), layer_3 = Dense(32 => 32, σ), layer_4 = Dense(32 => 8)), nothing), nothing, (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple(), layer_4 = NamedTuple()), nothing, static(true))), nothing)]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = discretize(pde_system, discretization)\n",
    "sym_prob = symbolic_discretize(pde_system, discretization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21235add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_callback (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#phi = discretization.phi\n",
    "pde_inner_loss_functions = sym_prob.loss_functions.pde_loss_functions\n",
    "bcs_inner_loss_functions = sym_prob.loss_functions.bc_loss_functions\n",
    "add_functon = sym_prob.loss_functions.additional_loss_function\n",
    "\n",
    "\n",
    "\n",
    "# Создаем логгер для TensorBoard\n",
    "logger = TBLogger(\"../../logs/inverse_npde_exp\")\n",
    "\n",
    "function create_callback(maxiters)\n",
    "    iter = 0  # Локальный счетчик итераций\n",
    "    pbar = ProgressBar(1:maxiters, printing_delay=1.)\n",
    "    return function (p, l)\n",
    "        \n",
    "        iter += 1  # Увеличиваем номер итерации\n",
    "        \n",
    "        # Логируем общую потерю\n",
    "        log_value(logger, \"Loss/Total\", l; step=iter)\n",
    "        \n",
    "        # Логируем потери по PDE\n",
    "        pde_losses = map(l_ -> l_(p.u), pde_inner_loss_functions)\n",
    "        for (i, pde_loss) in enumerate(pde_losses)\n",
    "            log_value(logger, \"Loss/PDE_$i\", pde_loss; step=iter)\n",
    "        end\n",
    "        \n",
    "        # Логируем потери по граничным условиям\n",
    "        bcs_losses = map(l_ -> l_(p.u), bcs_inner_loss_functions)\n",
    "        for (i, bc_loss) in enumerate(bcs_losses)\n",
    "            log_value(logger, \"Loss/BC_$i\", bc_loss; step=iter)\n",
    "        end\n",
    "        \n",
    "        # Обновляем прогресс бар\n",
    "        ProgressBars.update(pbar)  \n",
    "        set_postfix(pbar,Loss = @sprintf(\"%.3f\", l|>Float32), \n",
    "                     PDE_losses=@sprintf(\"%.3f\",sum(pde_losses)|>Float32), BC_losses=@sprintf(\"%.3f\",sum(bcs_losses)|>Float32))\n",
    "        \n",
    "        return false\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f8d8b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam(0.001, (0.9, 0.999), 1.0e-8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оптимизация\n",
    "opt = OptimizationOptimisers.Adam(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0%┣                                         ┫ 1/3.0k [01:55<Inf:Inf, InfGs/it]\n",
      "0.1%┣┫ 2/3.0k [01:57<97:32:29, 117s/it, Loss: 39.717, PDE_losses: 37.527, BC_losses: 2.109]\n",
      "0.2%┣┫ 5/3.0k [01:58<24:38:18, 30s/it, Loss: 28.952, PDE_losses: 27.214, BC_losses: 1.526]\n",
      "0.3%┣┫ 8/3.0k [02:00<14:13:26, 17s/it, Loss: 20.307, PDE_losses: 18.925, BC_losses: 1.057]\n",
      "0.4%┣┫ 11/3.0k [02:01<10:04:03, 12s/it, Loss: 13.536, PDE_losses: 12.453, BC_losses: 0.692]\n",
      "0.4%┣┫ 13/3.0k [02:02<08:27:19, 10s/it, Loss: 9.952, PDE_losses: 9.069, BC_losses: 0.501]\n",
      "0.5%┣┫ 15/3.0k [02:03<07:18:13, 9s/it, Loss: 7.077, PDE_losses: 6.363, BC_losses: 0.349]\n",
      "0.6%┣┫ 18/3.0k [02:05<06:04:14, 7s/it, Loss: 3.936, PDE_losses: 3.449, BC_losses: 0.186]\n",
      "0.7%┣┫ 21/3.0k [02:06<05:12:47, 6s/it, Loss: 2.003, PDE_losses: 1.661, BC_losses: 0.087]\n",
      "0.8%┣┫ 24/3.0k [02:07<04:34:42, 6s/it, Loss: 0.966, PDE_losses: 0.691, BC_losses: 0.035]\n",
      "0.9%┣┫ 27/3.0k [02:09<04:05:02, 5s/it, Loss: 0.551, PDE_losses: 0.287, BC_losses: 0.015]\n",
      "1.0%┣┫ 30/3.0k [02:10<03:41:33, 4s/it, Loss: 0.518, PDE_losses: 0.230, BC_losses: 0.014]\n",
      "1.1%┣┫ 33/3.0k [02:11<03:22:23, 4s/it, Loss: 0.653, PDE_losses: 0.335, BC_losses: 0.021]\n",
      "1.2%┣┫ 36/3.0k [02:12<03:06:35, 4s/it, Loss: 0.798, PDE_losses: 0.466, BC_losses: 0.029]\n",
      "1.3%┣┫ 39/3.0k [02:13<02:53:17, 4s/it, Loss: 0.871, PDE_losses: 0.549, BC_losses: 0.034]\n",
      "1.4%┣┫ 42/3.0k [02:14<02:41:44, 3s/it, Loss: 0.860, PDE_losses: 0.554, BC_losses: 0.034]\n",
      "1.5%┣┫ 45/3.0k [02:16<02:31:46, 3s/it, Loss: 0.788, PDE_losses: 0.494, BC_losses: 0.031]\n",
      "1.6%┣┫ 48/3.0k [02:17<02:23:17, 3s/it, Loss: 0.686, PDE_losses: 0.395, BC_losses: 0.025]\n",
      "1.7%┣┫ 51/3.0k [02:19<02:16:35, 3s/it, Loss: 0.587, PDE_losses: 0.292, BC_losses: 0.018]\n",
      "1.8%┣┫ 54/3.0k [02:20<02:09:58, 3s/it, Loss: 0.508, PDE_losses: 0.209, BC_losses: 0.013]\n",
      "1.9%┣┫ 56/3.0k [02:21<02:06:04, 3s/it, Loss: 0.471, PDE_losses: 0.173, BC_losses: 0.010]\n",
      "2.0%┣┫ 59/3.0k [02:23<02:00:26, 2s/it, Loss: 0.437, PDE_losses: 0.143, BC_losses: 0.008]\n",
      "2.1%┣┫ 62/3.0k [02:24<01:55:28, 2s/it, Loss: 0.423, PDE_losses: 0.137, BC_losses: 0.007]\n",
      "2.2%┣┫ 65/3.0k [02:25<01:50:59, 2s/it, Loss: 0.422, PDE_losses: 0.141, BC_losses: 0.007]\n",
      "2.2%┣┫ 67/3.0k [02:26<01:48:22, 2s/it, Loss: 0.424, PDE_losses: 0.145, BC_losses: 0.007]\n",
      "2.3%┣┫ 70/3.0k [02:28<01:44:32, 2s/it, Loss: 0.428, PDE_losses: 0.146, BC_losses: 0.007]\n",
      "2.4%┣┫ 73/3.0k [02:29<01:41:05, 2s/it, Loss: 0.430, PDE_losses: 0.143, BC_losses: 0.007]\n",
      "2.5%┣┫ 76/3.0k [02:31<01:37:49, 2s/it, Loss: 0.427, PDE_losses: 0.139, BC_losses: 0.007]\n",
      "2.6%┣┫ 78/3.0k [02:32<01:35:51, 2s/it, Loss: 0.423, PDE_losses: 0.137, BC_losses: 0.007]\n",
      "2.7%┣┫ 81/3.0k [02:33<01:33:00, 2s/it, Loss: 0.417, PDE_losses: 0.133, BC_losses: 0.007]\n",
      "2.8%┣┫ 84/3.0k [02:34<01:30:15, 2s/it, Loss: 0.412, PDE_losses: 0.130, BC_losses: 0.007]\n",
      "2.9%┣┫ 87/3.0k [02:35<01:27:40, 2s/it, Loss: 0.408, PDE_losses: 0.126, BC_losses: 0.007]\n",
      "3.0%┣┫ 90/3.0k [02:36<01:25:12, 2s/it, Loss: 0.405, PDE_losses: 0.121, BC_losses: 0.007]\n",
      "3.1%┣┫ 93/3.0k [02:38<01:22:58, 2s/it, Loss: 0.403, PDE_losses: 0.120, BC_losses: 0.006]\n",
      "3.2%┣┫ 96/3.0k [02:39<01:20:53, 2s/it, Loss: 0.403, PDE_losses: 0.119, BC_losses: 0.006]\n",
      "3.3%┣┫ 99/3.0k [02:40<01:18:59, 2s/it, Loss: 0.402, PDE_losses: 0.119, BC_losses: 0.007]\n",
      "3.4%┣┫ 102/3.0k [02:41<01:17:09, 2s/it, Loss: 0.401, PDE_losses: 0.119, BC_losses: 0.007]\n",
      "3.5%┣┫ 105/3.0k [02:43<01:15:27, 2s/it, Loss: 0.400, PDE_losses: 0.118, BC_losses: 0.006]\n",
      "3.6%┣┫ 108/3.0k [02:44<01:13:49, 2s/it, Loss: 0.399, PDE_losses: 0.116, BC_losses: 0.006]\n",
      "3.7%┣┫ 111/3.0k [02:45<01:12:17, 2s/it, Loss: 0.397, PDE_losses: 0.115, BC_losses: 0.006]\n",
      "3.8%┣┫ 114/3.0k [02:47<01:10:55, 1s/it, Loss: 0.396, PDE_losses: 0.114, BC_losses: 0.006]\n",
      "3.9%┣┫ 117/3.0k [02:48<01:09:34, 1s/it, Loss: 0.395, PDE_losses: 0.114, BC_losses: 0.006]\n",
      "4.0%┣┫ 120/3.0k [02:49<01:08:15, 1s/it, Loss: 0.394, PDE_losses: 0.113, BC_losses: 0.006]\n",
      "4.1%┣┫ 123/3.0k [02:50<01:06:59, 1s/it, Loss: 0.393, PDE_losses: 0.112, BC_losses: 0.006]\n",
      "4.2%┣┫ 126/3.0k [02:52<01:05:48, 1s/it, Loss: 0.392, PDE_losses: 0.111, BC_losses: 0.006]\n",
      "4.3%┣┫ 129/3.0k [02:53<01:04:40, 1s/it, Loss: 0.391, PDE_losses: 0.111, BC_losses: 0.006]\n",
      "4.4%┣┫ 132/3.0k [02:54<01:03:38, 1s/it, Loss: 0.391, PDE_losses: 0.110, BC_losses: 0.006]\n",
      "4.5%┣┫ 135/3.0k [02:56<01:02:35, 1s/it, Loss: 0.390, PDE_losses: 0.109, BC_losses: 0.006]\n",
      "4.6%┣┫ 138/3.0k [02:57<01:01:34, 1s/it, Loss: 0.389, PDE_losses: 0.109, BC_losses: 0.006]\n",
      "4.7%┣┫ 141/3.0k [02:58<01:00:39, 1s/it, Loss: 0.388, PDE_losses: 0.108, BC_losses: 0.006]\n",
      "4.8%┣┫ 144/3.0k [03:00<59:46, 1s/it, Loss: 0.387, PDE_losses: 0.107, BC_losses: 0.006]\n",
      "4.9%┣┫ 147/3.0k [03:01<58:55, 1s/it, Loss: 0.387, PDE_losses: 0.107, BC_losses: 0.006]\n",
      "5.0%┣┫ 150/3.0k [03:02<58:05, 1s/it, Loss: 0.386, PDE_losses: 0.107, BC_losses: 0.006]\n",
      "5.1%┣┫ 152/3.0k [03:03<57:36, 1s/it, Loss: 0.386, PDE_losses: 0.106, BC_losses: 0.006]\n",
      "5.2%┣┫ 155/3.0k [03:05<56:51, 1s/it, Loss: 0.384, PDE_losses: 0.105, BC_losses: 0.006]\n",
      "5.3%┣┫ 158/3.0k [03:06<56:08, 1s/it, Loss: 0.384, PDE_losses: 0.104, BC_losses: 0.006]\n",
      "5.3%┣┫ 160/3.0k [03:07<55:41, 1s/it, Loss: 0.384, PDE_losses: 0.105, BC_losses: 0.006]\n",
      "5.4%┣┫ 163/3.0k [03:08<54:59, 1s/it, Loss: 0.384, PDE_losses: 0.104, BC_losses: 0.006]\n",
      "5.5%┣┫ 166/3.0k [03:10<54:18, 1s/it, Loss: 0.383, PDE_losses: 0.104, BC_losses: 0.006]\n",
      "5.6%┣┫ 169/3.0k [03:11<53:37, 1s/it, Loss: 0.382, PDE_losses: 0.103, BC_losses: 0.006]\n",
      "5.7%┣┫ 172/3.0k [03:12<52:59, 1s/it, Loss: 0.381, PDE_losses: 0.103, BC_losses: 0.006]\n",
      "5.8%┣┫ 175/3.0k [03:14<52:23, 1s/it, Loss: 0.381, PDE_losses: 0.102, BC_losses: 0.006]\n",
      "5.9%┣┫ 178/3.0k [03:15<51:45, 1s/it, Loss: 0.379, PDE_losses: 0.102, BC_losses: 0.006]\n",
      "6.0%┣┫ 181/3.0k [03:16<51:12, 1s/it, Loss: 0.379, PDE_losses: 0.102, BC_losses: 0.006]\n",
      "6.1%┣┫ 184/3.0k [03:18<50:39, 1s/it, Loss: 0.379, PDE_losses: 0.101, BC_losses: 0.005]\n",
      "6.2%┣┫ 187/3.0k [03:19<50:06, 1s/it, Loss: 0.379, PDE_losses: 0.101, BC_losses: 0.005]\n",
      "6.3%┣┫ 190/3.0k [03:20<49:35, 1s/it, Loss: 0.378, PDE_losses: 0.100, BC_losses: 0.005]\n",
      "6.4%┣┫ 193/3.0k [03:21<49:04, 1s/it, Loss: 0.377, PDE_losses: 0.100, BC_losses: 0.005]\n",
      "6.5%┣┫ 196/3.0k [03:23<48:34, 1s/it, Loss: 0.377, PDE_losses: 0.100, BC_losses: 0.005]\n",
      "6.6%┣┫ 199/3.0k [03:24<48:06, 1s/it, Loss: 0.376, PDE_losses: 0.099, BC_losses: 0.005]\n",
      "6.7%┣┫ 202/3.0k [03:25<47:37, 1s/it, Loss: 0.376, PDE_losses: 0.099, BC_losses: 0.005]\n",
      "6.8%┣┫ 205/3.0k [03:27<47:09, 1s/it, Loss: 0.375, PDE_losses: 0.099, BC_losses: 0.005]\n",
      "6.9%┣┫ 208/3.0k [03:28<46:42, 1s/it, Loss: 0.375, PDE_losses: 0.099, BC_losses: 0.005]\n",
      "7.0%┣┫ 211/3.0k [03:29<46:16, 1it/s, Loss: 0.374, PDE_losses: 0.098, BC_losses: 0.005]\n",
      "7.1%┣┫ 214/3.0k [03:30<45:51, 1it/s, Loss: 0.374, PDE_losses: 0.098, BC_losses: 0.005]\n",
      "7.2%┣┫ 217/3.0k [03:32<45:27, 1it/s, Loss: 0.373, PDE_losses: 0.098, BC_losses: 0.005]\n",
      "7.3%┣┫ 220/3.0k [03:33<45:03, 1it/s, Loss: 0.372, PDE_losses: 0.097, BC_losses: 0.005]\n",
      "7.4%┣┫ 223/3.0k [03:34<44:40, 1it/s, Loss: 0.372, PDE_losses: 0.097, BC_losses: 0.005]\n",
      "7.5%┣┫ 226/3.0k [03:36<44:19, 1it/s, Loss: 0.372, PDE_losses: 0.097, BC_losses: 0.005]\n",
      "7.6%┣┫ 229/3.0k [03:37<44:00, 1it/s, Loss: 0.371, PDE_losses: 0.096, BC_losses: 0.005]\n",
      "7.7%┣┫ 232/3.0k [03:38<43:38, 1it/s, Loss: 0.371, PDE_losses: 0.097, BC_losses: 0.005]\n",
      "7.8%┣┫ 235/3.0k [03:40<43:16, 1it/s, Loss: 0.371, PDE_losses: 0.096, BC_losses: 0.005]\n",
      "7.9%┣┫ 238/3.0k [03:41<42:55, 1it/s, Loss: 0.370, PDE_losses: 0.096, BC_losses: 0.005]\n",
      "8.0%┣┫ 241/3.0k [03:42<42:35, 1it/s, Loss: 0.369, PDE_losses: 0.096, BC_losses: 0.005]\n",
      "8.1%┣┫ 244/3.0k [03:43<42:14, 1it/s, Loss: 0.369, PDE_losses: 0.095, BC_losses: 0.005]\n",
      "8.2%┣┫ 247/3.0k [03:45<41:54, 1it/s, Loss: 0.369, PDE_losses: 0.095, BC_losses: 0.005]\n",
      "8.3%┣┫ 250/3.0k [03:46<41:34, 1it/s, Loss: 0.368, PDE_losses: 0.095, BC_losses: 0.005]\n",
      "8.4%┣┫ 253/3.0k [03:47<41:14, 1it/s, Loss: 0.368, PDE_losses: 0.095, BC_losses: 0.005]\n",
      "8.5%┣┫ 256/3.0k [03:48<40:57, 1it/s, Loss: 0.368, PDE_losses: 0.094, BC_losses: 0.005]\n",
      "8.6%┣┫ 259/3.0k [03:50<40:40, 1it/s, Loss: 0.367, PDE_losses: 0.094, BC_losses: 0.005]\n",
      "8.7%┣┫ 262/3.0k [03:51<40:22, 1it/s, Loss: 0.367, PDE_losses: 0.094, BC_losses: 0.005]\n",
      "8.8%┣┫ 265/3.0k [03:52<40:05, 1it/s, Loss: 0.366, PDE_losses: 0.094, BC_losses: 0.005]\n",
      "8.9%┣┫ 268/3.0k [03:54<39:50, 1it/s, Loss: 0.366, PDE_losses: 0.094, BC_losses: 0.005]\n",
      "9.0%┣┫ 270/3.0k [03:55<39:41, 1it/s, Loss: 0.365, PDE_losses: 0.093, BC_losses: 0.005]\n",
      "9.1%┣┫ 273/3.0k [03:56<39:25, 1it/s, Loss: 0.364, PDE_losses: 0.093, BC_losses: 0.005]\n",
      "9.2%┣┫ 276/3.0k [03:57<39:09, 1it/s, Loss: 0.364, PDE_losses: 0.094, BC_losses: 0.005]\n",
      "9.3%┣┫ 278/3.0k [03:58<39:00, 1it/s, Loss: 0.364, PDE_losses: 0.093, BC_losses: 0.005]\n",
      "9.4%┣┫ 281/3.0k [04:00<38:46, 1it/s, Loss: 0.363, PDE_losses: 0.093, BC_losses: 0.005]\n",
      "9.5%┣┫ 284/3.0k [04:01<38:30, 1it/s, Loss: 0.363, PDE_losses: 0.092, BC_losses: 0.005]\n",
      "9.6%┣┫ 287/3.0k [04:02<38:16, 1it/s, Loss: 0.362, PDE_losses: 0.092, BC_losses: 0.005]\n",
      "9.7%┣┫ 290/3.0k [04:04<38:04, 1it/s, Loss: 0.362, PDE_losses: 0.092, BC_losses: 0.005]\n",
      "9.8%┣┫ 293/3.0k [04:05<37:52, 1it/s, Loss: 0.362, PDE_losses: 0.092, BC_losses: 0.005]\n",
      "9.9%┣┫ 296/3.0k [04:07<37:40, 1it/s, Loss: 0.361, PDE_losses: 0.092, BC_losses: 0.005]\n",
      "10.0%┣┫ 299/3.0k [04:08<37:28, 1it/s, Loss: 0.361, PDE_losses: 0.092, BC_losses: 0.005]\n",
      "10.1%┣┫ 302/3.0k [04:09<37:15, 1it/s, Loss: 0.360, PDE_losses: 0.092, BC_losses: 0.005]\n",
      "10.2%┣┫ 305/3.0k [04:11<37:02, 1it/s, Loss: 0.360, PDE_losses: 0.091, BC_losses: 0.005]\n",
      "10.3%┣┫ 308/3.0k [04:12<36:49, 1it/s, Loss: 0.359, PDE_losses: 0.091, BC_losses: 0.005]\n",
      "10.4%┣┫ 311/3.0k [04:13<36:36, 1it/s, Loss: 0.359, PDE_losses: 0.091, BC_losses: 0.005]\n",
      "10.5%┣┫ 314/3.0k [04:15<36:24, 1it/s, Loss: 0.358, PDE_losses: 0.091, BC_losses: 0.005]\n",
      "10.5%┣┫ 316/3.0k [04:16<36:18, 1it/s, Loss: 0.358, PDE_losses: 0.090, BC_losses: 0.005]\n",
      "10.6%┣┫ 319/3.0k [04:17<36:06, 1it/s, Loss: 0.358, PDE_losses: 0.091, BC_losses: 0.005]\n",
      "10.7%┣┫ 322/3.0k [04:18<35:54, 1it/s, Loss: 0.357, PDE_losses: 0.091, BC_losses: 0.005]\n",
      "10.8%┣┫ 325/3.0k [04:19<35:41, 1it/s, Loss: 0.356, PDE_losses: 0.090, BC_losses: 0.005]\n",
      "10.9%┣┫ 328/3.0k [04:21<35:30, 1it/s, Loss: 0.356, PDE_losses: 0.090, BC_losses: 0.005]\n",
      "11.0%┣┫ 331/3.0k [04:22<35:18, 1it/s, Loss: 0.356, PDE_losses: 0.090, BC_losses: 0.005]\n",
      "11.1%┣┫ 334/3.0k [04:23<35:07, 1it/s, Loss: 0.355, PDE_losses: 0.089, BC_losses: 0.005]\n",
      "11.2%┣┫ 337/3.0k [04:25<34:57, 1it/s, Loss: 0.354, PDE_losses: 0.090, BC_losses: 0.005]\n",
      "11.3%┣┫ 340/3.0k [04:26<34:46, 1it/s, Loss: 0.354, PDE_losses: 0.090, BC_losses: 0.005]\n",
      "11.4%┣┫ 343/3.0k [04:27<34:36, 1it/s, Loss: 0.353, PDE_losses: 0.090, BC_losses: 0.005]\n",
      "11.5%┣┫ 346/3.0k [04:29<34:27, 1it/s, Loss: 0.352, PDE_losses: 0.089, BC_losses: 0.005]\n",
      "11.6%┣┫ 349/3.0k [04:30<34:16, 1it/s, Loss: 0.352, PDE_losses: 0.089, BC_losses: 0.005]\n",
      "11.7%┣┫ 352/3.0k [04:31<34:05, 1it/s, Loss: 0.352, PDE_losses: 0.089, BC_losses: 0.005]\n",
      "11.8%┣┫ 355/3.0k [04:32<33:55, 1it/s, Loss: 0.351, PDE_losses: 0.089, BC_losses: 0.005]\n",
      "11.9%┣┫ 358/3.0k [04:34<33:46, 1it/s, Loss: 0.351, PDE_losses: 0.088, BC_losses: 0.005]\n",
      "12.0%┣┫ 361/3.0k [04:35<33:37, 1it/s, Loss: 0.350, PDE_losses: 0.088, BC_losses: 0.005]\n",
      "12.1%┣┫ 364/3.0k [04:36<33:28, 1it/s, Loss: 0.349, PDE_losses: 0.088, BC_losses: 0.005]\n",
      "12.2%┣┫ 367/3.0k [04:38<33:19, 1it/s, Loss: 0.349, PDE_losses: 0.088, BC_losses: 0.005]\n",
      "12.3%┣┫ 370/3.0k [04:39<33:09, 1it/s, Loss: 0.348, PDE_losses: 0.088, BC_losses: 0.005]\n",
      "12.4%┣┫ 373/3.0k [04:40<33:01, 1it/s, Loss: 0.347, PDE_losses: 0.087, BC_losses: 0.005]\n",
      "12.5%┣┫ 376/3.0k [04:42<32:51, 1it/s, Loss: 0.347, PDE_losses: 0.088, BC_losses: 0.005]\n",
      "12.6%┣┫ 379/3.0k [04:43<32:42, 1it/s, Loss: 0.346, PDE_losses: 0.088, BC_losses: 0.005]\n",
      "12.7%┣┫ 382/3.0k [04:44<32:33, 1it/s, Loss: 0.345, PDE_losses: 0.087, BC_losses: 0.005]\n",
      "12.8%┣┫ 385/3.0k [04:45<32:24, 1it/s, Loss: 0.345, PDE_losses: 0.087, BC_losses: 0.005]\n",
      "12.9%┣┫ 388/3.0k [04:47<32:15, 1it/s, Loss: 0.345, PDE_losses: 0.087, BC_losses: 0.005]\n",
      "13.0%┣┫ 391/3.0k [04:48<32:07, 1it/s, Loss: 0.344, PDE_losses: 0.086, BC_losses: 0.005]\n",
      "13.1%┣┫ 394/3.0k [04:49<31:59, 1it/s, Loss: 0.343, PDE_losses: 0.086, BC_losses: 0.005]\n",
      "13.2%┣┫ 397/3.0k [04:51<31:51, 1it/s, Loss: 0.342, PDE_losses: 0.086, BC_losses: 0.005]\n",
      "13.3%┣┫ 400/3.0k [04:52<31:42, 1it/s, Loss: 0.341, PDE_losses: 0.085, BC_losses: 0.004]\n",
      "13.4%┣┫ 403/3.0k [04:53<31:34, 1it/s, Loss: 0.340, PDE_losses: 0.085, BC_losses: 0.004]\n",
      "13.5%┣┫ 406/3.0k [04:55<31:27, 1it/s, Loss: 0.340, PDE_losses: 0.085, BC_losses: 0.004]\n",
      "13.6%┣┫ 409/3.0k [04:56<31:20, 1it/s, Loss: 0.339, PDE_losses: 0.085, BC_losses: 0.004]\n",
      "13.7%┣┫ 411/3.0k [04:58<31:20, 1it/s, Loss: 0.339, PDE_losses: 0.085, BC_losses: 0.004]\n",
      "13.8%┣┫ 414/3.0k [04:59<31:11, 1it/s, Loss: 0.338, PDE_losses: 0.085, BC_losses: 0.004]\n",
      "13.9%┣┫ 417/3.0k [05:00<31:05, 1it/s, Loss: 0.337, PDE_losses: 0.084, BC_losses: 0.004]\n",
      "14.0%┣┫ 420/3.0k [05:02<30:57, 1it/s, Loss: 0.336, PDE_losses: 0.084, BC_losses: 0.004]\n",
      "14.1%┣┫ 423/3.0k [05:03<30:49, 1it/s, Loss: 0.335, PDE_losses: 0.084, BC_losses: 0.004]\n",
      "14.2%┣┫ 426/3.0k [05:04<30:41, 1it/s, Loss: 0.334, PDE_losses: 0.084, BC_losses: 0.004]\n",
      "14.3%┣┫ 429/3.0k [05:05<30:33, 1it/s, Loss: 0.333, PDE_losses: 0.084, BC_losses: 0.004]\n",
      "14.4%┣┫ 432/3.0k [05:06<30:26, 1it/s, Loss: 0.332, PDE_losses: 0.083, BC_losses: 0.004]\n",
      "14.5%┣┫ 435/3.0k [05:08<30:18, 1it/s, Loss: 0.332, PDE_losses: 0.083, BC_losses: 0.004]\n",
      "14.6%┣┫ 438/3.0k [05:09<30:10, 1it/s, Loss: 0.331, PDE_losses: 0.083, BC_losses: 0.004]\n",
      "14.7%┣┫ 441/3.0k [05:10<30:03, 1it/s, Loss: 0.329, PDE_losses: 0.083, BC_losses: 0.004]\n",
      "14.8%┣┫ 444/3.0k [05:11<29:55, 1it/s, Loss: 0.329, PDE_losses: 0.083, BC_losses: 0.004]\n",
      "14.9%┣┫ 447/3.0k [05:13<29:49, 1it/s, Loss: 0.328, PDE_losses: 0.082, BC_losses: 0.004]\n",
      "15.0%┣┫ 450/3.0k [05:14<29:42, 1it/s, Loss: 0.328, PDE_losses: 0.083, BC_losses: 0.004]\n",
      "15.1%┣┫ 453/3.0k [05:15<29:36, 1it/s, Loss: 0.326, PDE_losses: 0.082, BC_losses: 0.004]\n",
      "15.2%┣┫ 456/3.0k [05:16<29:29, 1it/s, Loss: 0.325, PDE_losses: 0.082, BC_losses: 0.004]\n",
      "15.3%┣┫ 459/3.0k [05:18<29:22, 1it/s, Loss: 0.324, PDE_losses: 0.082, BC_losses: 0.004]\n",
      "15.4%┣┫ 462/3.0k [05:19<29:15, 1it/s, Loss: 0.323, PDE_losses: 0.081, BC_losses: 0.004]\n",
      "15.5%┣┫ 465/3.0k [05:20<29:09, 1it/s, Loss: 0.322, PDE_losses: 0.081, BC_losses: 0.004]\n",
      "15.6%┣┫ 468/3.0k [05:21<29:03, 1it/s, Loss: 0.321, PDE_losses: 0.080, BC_losses: 0.004]\n",
      "15.7%┣┫ 471/3.0k [05:23<28:56, 1it/s, Loss: 0.320, PDE_losses: 0.080, BC_losses: 0.004]\n",
      "15.8%┣┫ 474/3.0k [05:24<28:49, 1it/s, Loss: 0.319, PDE_losses: 0.080, BC_losses: 0.004]\n",
      "15.9%┣┫ 477/3.0k [05:25<28:43, 1it/s, Loss: 0.317, PDE_losses: 0.080, BC_losses: 0.004]\n",
      "16.0%┣┫ 480/3.0k [05:26<28:37, 1it/s, Loss: 0.316, PDE_losses: 0.079, BC_losses: 0.004]\n",
      "16.1%┣┫ 483/3.0k [05:28<28:31, 1it/s, Loss: 0.315, PDE_losses: 0.079, BC_losses: 0.004]\n",
      "16.2%┣┫ 486/3.0k [05:29<28:26, 1it/s, Loss: 0.313, PDE_losses: 0.079, BC_losses: 0.004]\n",
      "16.3%┣┫ 489/3.0k [05:30<28:19, 1it/s, Loss: 0.312, PDE_losses: 0.079, BC_losses: 0.004]\n",
      "16.4%┣┫ 492/3.0k [05:31<28:13, 1it/s, Loss: 0.311, PDE_losses: 0.078, BC_losses: 0.004]\n",
      "16.5%┣┫ 495/3.0k [05:33<28:07, 1it/s, Loss: 0.310, PDE_losses: 0.078, BC_losses: 0.004]\n",
      "16.6%┣┫ 498/3.0k [05:34<28:01, 1it/s, Loss: 0.308, PDE_losses: 0.077, BC_losses: 0.004]\n",
      "16.7%┣┫ 501/3.0k [05:35<27:55, 1it/s, Loss: 0.307, PDE_losses: 0.078, BC_losses: 0.004]\n",
      "16.8%┣┫ 504/3.0k [05:36<27:49, 1it/s, Loss: 0.305, PDE_losses: 0.077, BC_losses: 0.004]\n",
      "16.9%┣┫ 507/3.0k [05:38<27:45, 1it/s, Loss: 0.304, PDE_losses: 0.076, BC_losses: 0.004]\n",
      "17.0%┣┫ 510/3.0k [05:39<27:39, 2it/s, Loss: 0.302, PDE_losses: 0.076, BC_losses: 0.004]\n",
      "17.1%┣┫ 513/3.0k [05:40<27:33, 2it/s, Loss: 0.301, PDE_losses: 0.076, BC_losses: 0.004]\n",
      "17.2%┣┫ 516/3.0k [05:42<27:29, 2it/s, Loss: 0.300, PDE_losses: 0.076, BC_losses: 0.004]\n",
      "17.3%┣┫ 519/3.0k [05:43<27:23, 2it/s, Loss: 0.298, PDE_losses: 0.075, BC_losses: 0.004]\n",
      "17.4%┣┫ 522/3.0k [05:44<27:17, 2it/s, Loss: 0.296, PDE_losses: 0.075, BC_losses: 0.004]\n",
      "17.5%┣┫ 525/3.0k [05:46<27:13, 2it/s, Loss: 0.294, PDE_losses: 0.075, BC_losses: 0.004]\n",
      "17.6%┣┫ 528/3.0k [05:47<27:08, 2it/s, Loss: 0.292, PDE_losses: 0.074, BC_losses: 0.004]\n",
      "17.7%┣┫ 531/3.0k [05:48<27:03, 2it/s, Loss: 0.291, PDE_losses: 0.074, BC_losses: 0.004]\n",
      "17.8%┣┫ 534/3.0k [05:50<26:59, 2it/s, Loss: 0.290, PDE_losses: 0.073, BC_losses: 0.004]\n",
      "17.9%┣┫ 537/3.0k [05:51<26:54, 2it/s, Loss: 0.288, PDE_losses: 0.072, BC_losses: 0.004]\n",
      "18.0%┣┫ 540/3.0k [05:53<26:50, 2it/s, Loss: 0.285, PDE_losses: 0.073, BC_losses: 0.004]\n",
      "18.1%┣┫ 543/3.0k [05:54<26:45, 2it/s, Loss: 0.284, PDE_losses: 0.073, BC_losses: 0.003]\n",
      "18.2%┣┫ 546/3.0k [05:55<26:40, 2it/s, Loss: 0.282, PDE_losses: 0.071, BC_losses: 0.003]\n",
      "18.3%┣┫ 549/3.0k [05:57<26:35, 2it/s, Loss: 0.280, PDE_losses: 0.071, BC_losses: 0.003]\n",
      "18.4%┣┫ 552/3.0k [05:58<26:29, 2it/s, Loss: 0.278, PDE_losses: 0.072, BC_losses: 0.003]\n",
      "18.5%┣┫ 555/3.0k [05:59<26:24, 2it/s, Loss: 0.276, PDE_losses: 0.070, BC_losses: 0.003]\n",
      "18.6%┣┫ 558/3.0k [06:00<26:19, 2it/s, Loss: 0.274, PDE_losses: 0.071, BC_losses: 0.003]\n",
      "18.7%┣┫ 561/3.0k [06:01<26:14, 2it/s, Loss: 0.272, PDE_losses: 0.070, BC_losses: 0.003]\n",
      "18.8%┣┫ 564/3.0k [06:03<26:09, 2it/s, Loss: 0.270, PDE_losses: 0.070, BC_losses: 0.003]\n",
      "18.9%┣┫ 567/3.0k [06:04<26:04, 2it/s, Loss: 0.268, PDE_losses: 0.069, BC_losses: 0.003]\n",
      "19.0%┣┫ 570/3.0k [06:05<25:58, 2it/s, Loss: 0.266, PDE_losses: 0.069, BC_losses: 0.003]\n",
      "19.1%┣┫ 573/3.0k [06:06<25:54, 2it/s, Loss: 0.264, PDE_losses: 0.069, BC_losses: 0.003]\n",
      "19.2%┣┫ 576/3.0k [06:07<25:49, 2it/s, Loss: 0.262, PDE_losses: 0.068, BC_losses: 0.003]\n",
      "19.3%┣┫ 579/3.0k [06:09<25:44, 2it/s, Loss: 0.260, PDE_losses: 0.069, BC_losses: 0.003]\n",
      "19.4%┣┫ 582/3.0k [06:10<25:40, 2it/s, Loss: 0.258, PDE_losses: 0.068, BC_losses: 0.003]\n",
      "19.5%┣┫ 585/3.0k [06:11<25:36, 2it/s, Loss: 0.256, PDE_losses: 0.068, BC_losses: 0.003]\n",
      "19.6%┣┫ 588/3.0k [06:13<25:31, 2it/s, Loss: 0.253, PDE_losses: 0.067, BC_losses: 0.003]\n",
      "19.7%┣┫ 591/3.0k [06:14<25:27, 2it/s, Loss: 0.251, PDE_losses: 0.067, BC_losses: 0.003]\n",
      "19.8%┣┫ 594/3.0k [06:15<25:23, 2it/s, Loss: 0.250, PDE_losses: 0.066, BC_losses: 0.003]\n",
      "19.9%┣┫ 597/3.0k [06:17<25:18, 2it/s, Loss: 0.247, PDE_losses: 0.066, BC_losses: 0.003]\n",
      "20.0%┣┫ 600/3.0k [06:18<25:16, 2it/s, Loss: 0.245, PDE_losses: 0.066, BC_losses: 0.003]\n",
      "20.1%┣┫ 603/3.0k [06:20<25:12, 2it/s, Loss: 0.243, PDE_losses: 0.066, BC_losses: 0.003]\n",
      "20.2%┣┫ 606/3.0k [06:21<25:08, 2it/s, Loss: 0.241, PDE_losses: 0.065, BC_losses: 0.003]\n",
      "20.3%┣┫ 609/3.0k [06:22<25:03, 2it/s, Loss: 0.238, PDE_losses: 0.065, BC_losses: 0.003]\n",
      "20.4%┣┫ 612/3.0k [06:23<24:59, 2it/s, Loss: 0.236, PDE_losses: 0.065, BC_losses: 0.003]\n",
      "20.5%┣┫ 615/3.0k [06:25<24:54, 2it/s, Loss: 0.234, PDE_losses: 0.065, BC_losses: 0.003]\n",
      "20.6%┣┫ 618/3.0k [06:26<24:50, 2it/s, Loss: 0.231, PDE_losses: 0.064, BC_losses: 0.003]\n",
      "20.7%┣┫ 621/3.0k [06:27<24:46, 2it/s, Loss: 0.229, PDE_losses: 0.064, BC_losses: 0.003]\n",
      "20.8%┣┫ 624/3.0k [06:28<24:41, 2it/s, Loss: 0.226, PDE_losses: 0.064, BC_losses: 0.003]\n",
      "20.9%┣┫ 627/3.0k [06:30<24:37, 2it/s, Loss: 0.224, PDE_losses: 0.064, BC_losses: 0.003]\n",
      "21.0%┣┫ 630/3.0k [06:31<24:32, 2it/s, Loss: 0.222, PDE_losses: 0.063, BC_losses: 0.003]\n",
      "21.1%┣┫ 633/3.0k [06:32<24:29, 2it/s, Loss: 0.219, PDE_losses: 0.064, BC_losses: 0.003]\n",
      "21.2%┣┫ 636/3.0k [06:34<24:25, 2it/s, Loss: 0.219, PDE_losses: 0.064, BC_losses: 0.003]\n",
      "21.3%┣┫ 639/3.0k [06:35<24:21, 2it/s, Loss: 0.215, PDE_losses: 0.063, BC_losses: 0.003]\n",
      "21.4%┣┫ 642/3.0k [06:36<24:16, 2it/s, Loss: 0.214, PDE_losses: 0.064, BC_losses: 0.003]\n",
      "21.5%┣┫ 645/3.0k [06:37<24:12, 2it/s, Loss: 0.211, PDE_losses: 0.063, BC_losses: 0.003]\n",
      "21.6%┣┫ 648/3.0k [06:38<24:08, 2it/s, Loss: 0.208, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "21.7%┣┫ 651/3.0k [06:40<24:04, 2it/s, Loss: 0.206, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "21.8%┣┫ 654/3.0k [06:41<24:00, 2it/s, Loss: 0.203, PDE_losses: 0.062, BC_losses: 0.002]\n",
      "21.9%┣┫ 657/3.0k [06:42<23:55, 2it/s, Loss: 0.201, PDE_losses: 0.062, BC_losses: 0.002]\n",
      "22.0%┣┫ 660/3.0k [06:43<23:51, 2it/s, Loss: 0.199, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "22.1%┣┫ 663/3.0k [06:44<23:47, 2it/s, Loss: 0.198, PDE_losses: 0.062, BC_losses: 0.002]\n",
      "22.2%┣┫ 666/3.0k [06:45<23:42, 2it/s, Loss: 0.195, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "22.3%┣┫ 669/3.0k [06:47<23:39, 2it/s, Loss: 0.194, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "22.4%┣┫ 672/3.0k [06:48<23:35, 2it/s, Loss: 0.192, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "22.5%┣┫ 675/3.0k [06:49<23:31, 2it/s, Loss: 0.189, PDE_losses: 0.062, BC_losses: 0.002]\n",
      "22.6%┣┫ 678/3.0k [06:50<23:27, 2it/s, Loss: 0.187, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "22.7%┣┫ 681/3.0k [06:52<23:24, 2it/s, Loss: 0.185, PDE_losses: 0.062, BC_losses: 0.002]\n",
      "22.8%┣┫ 684/3.0k [06:53<23:21, 2it/s, Loss: 0.183, PDE_losses: 0.062, BC_losses: 0.002]\n",
      "22.9%┣┫ 687/3.0k [06:54<23:17, 2it/s, Loss: 0.181, PDE_losses: 0.062, BC_losses: 0.002]\n",
      "23.0%┣┫ 690/3.0k [06:56<23:13, 2it/s, Loss: 0.180, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "23.1%┣┫ 693/3.0k [06:57<23:10, 2it/s, Loss: 0.177, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "23.2%┣┫ 696/3.0k [06:58<23:06, 2it/s, Loss: 0.176, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "23.3%┣┫ 698/3.0k [06:59<23:04, 2it/s, Loss: 0.173, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "23.3%┣┫ 700/3.0k [07:00<23:02, 2it/s, Loss: 0.173, PDE_losses: 0.062, BC_losses: 0.002]\n",
      "23.4%┣┫ 703/3.0k [07:01<22:59, 2it/s, Loss: 0.171, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "23.5%┣┫ 706/3.0k [07:03<22:55, 2it/s, Loss: 0.170, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "23.6%┣┫ 709/3.0k [07:04<22:52, 2it/s, Loss: 0.168, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "23.7%┣┫ 712/3.0k [07:05<22:48, 2it/s, Loss: 0.167, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "23.8%┣┫ 715/3.0k [07:06<22:45, 2it/s, Loss: 0.163, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "23.9%┣┫ 718/3.0k [07:08<22:41, 2it/s, Loss: 0.163, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "24.0%┣┫ 721/3.0k [07:09<22:37, 2it/s, Loss: 0.160, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "24.1%┣┫ 724/3.0k [07:10<22:34, 2it/s, Loss: 0.160, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "24.2%┣┫ 726/3.0k [07:11<22:32, 2it/s, Loss: 0.158, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "24.3%┣┫ 729/3.0k [07:12<22:29, 2it/s, Loss: 0.157, PDE_losses: 0.061, BC_losses: 0.002]\n",
      "24.4%┣┫ 732/3.0k [07:14<22:26, 2it/s, Loss: 0.156, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "24.5%┣┫ 735/3.0k [07:15<22:22, 2it/s, Loss: 0.155, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "24.6%┣┫ 738/3.0k [07:16<22:19, 2it/s, Loss: 0.153, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "24.7%┣┫ 741/3.0k [07:17<22:15, 2it/s, Loss: 0.151, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "24.8%┣┫ 744/3.0k [07:19<22:12, 2it/s, Loss: 0.149, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "24.9%┣┫ 747/3.0k [07:20<22:08, 2it/s, Loss: 0.149, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "25.0%┣┫ 750/3.0k [07:21<22:05, 2it/s, Loss: 0.147, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "25.1%┣┫ 753/3.0k [07:22<22:02, 2it/s, Loss: 0.146, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "25.2%┣┫ 756/3.0k [07:24<21:58, 2it/s, Loss: 0.146, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "25.3%┣┫ 759/3.0k [07:25<21:55, 2it/s, Loss: 0.144, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "25.4%┣┫ 762/3.0k [07:26<21:51, 2it/s, Loss: 0.145, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "25.5%┣┫ 765/3.0k [07:27<21:48, 2it/s, Loss: 0.143, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "25.6%┣┫ 768/3.0k [07:28<21:45, 2it/s, Loss: 0.142, PDE_losses: 0.067, BC_losses: 0.002]\n",
      "25.7%┣┫ 771/3.0k [07:30<21:41, 2it/s, Loss: 0.140, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "25.8%┣┫ 774/3.0k [07:31<21:38, 2it/s, Loss: 0.139, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "25.9%┣┫ 777/3.0k [07:32<21:35, 2it/s, Loss: 0.137, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "26.0%┣┫ 780/3.0k [07:33<21:32, 2it/s, Loss: 0.137, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "26.1%┣┫ 783/3.0k [07:35<21:29, 2it/s, Loss: 0.135, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "26.2%┣┫ 786/3.0k [07:36<21:26, 2it/s, Loss: 0.134, PDE_losses: 0.068, BC_losses: 0.002]\n",
      "26.3%┣┫ 789/3.0k [07:37<21:23, 2it/s, Loss: 0.135, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "26.4%┣┫ 792/3.0k [07:38<21:20, 2it/s, Loss: 0.133, PDE_losses: 0.067, BC_losses: 0.002]\n",
      "26.5%┣┫ 795/3.0k [07:39<21:16, 2it/s, Loss: 0.132, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "26.6%┣┫ 798/3.0k [07:41<21:13, 2it/s, Loss: 0.134, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "26.7%┣┫ 801/3.0k [07:42<21:09, 2it/s, Loss: 0.130, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "26.8%┣┫ 804/3.0k [07:43<21:06, 2it/s, Loss: 0.127, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "26.9%┣┫ 807/3.0k [07:44<21:03, 2it/s, Loss: 0.129, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "27.0%┣┫ 810/3.0k [07:46<21:00, 2it/s, Loss: 0.127, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "27.1%┣┫ 813/3.0k [07:47<20:57, 2it/s, Loss: 0.129, PDE_losses: 0.067, BC_losses: 0.002]\n",
      "27.2%┣┫ 816/3.0k [07:48<20:55, 2it/s, Loss: 0.127, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "27.3%┣┫ 819/3.0k [07:49<20:52, 2it/s, Loss: 0.124, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "27.4%┣┫ 822/3.0k [07:51<20:48, 2it/s, Loss: 0.124, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "27.5%┣┫ 825/3.0k [07:52<20:45, 2it/s, Loss: 0.124, PDE_losses: 0.067, BC_losses: 0.002]\n",
      "27.6%┣┫ 828/3.0k [07:53<20:42, 2it/s, Loss: 0.123, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "27.7%┣┫ 831/3.0k [07:54<20:39, 2it/s, Loss: 0.124, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "27.8%┣┫ 834/3.0k [07:56<20:37, 2it/s, Loss: 0.123, PDE_losses: 0.068, BC_losses: 0.002]\n",
      "27.9%┣┫ 837/3.0k [07:57<20:34, 2it/s, Loss: 0.120, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "28.0%┣┫ 840/3.0k [07:58<20:32, 2it/s, Loss: 0.122, PDE_losses: 0.067, BC_losses: 0.002]\n",
      "28.1%┣┫ 843/3.0k [08:00<20:29, 2it/s, Loss: 0.121, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "28.2%┣┫ 846/3.0k [08:01<20:26, 2it/s, Loss: 0.121, PDE_losses: 0.067, BC_losses: 0.002]\n",
      "28.3%┣┫ 849/3.0k [08:02<20:23, 2it/s, Loss: 0.118, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "28.4%┣┫ 852/3.0k [08:04<20:20, 2it/s, Loss: 0.116, PDE_losses: 0.068, BC_losses: 0.002]\n",
      "28.5%┣┫ 855/3.0k [08:05<20:18, 2it/s, Loss: 0.116, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "28.6%┣┫ 858/3.0k [08:06<20:14, 2it/s, Loss: 0.116, PDE_losses: 0.067, BC_losses: 0.002]\n",
      "28.7%┣┫ 861/3.0k [08:07<20:12, 2it/s, Loss: 0.116, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "28.8%┣┫ 864/3.0k [08:08<20:09, 2it/s, Loss: 0.116, PDE_losses: 0.067, BC_losses: 0.002]\n",
      "28.9%┣┫ 867/3.0k [08:10<20:06, 2it/s, Loss: 0.117, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "29.0%┣┫ 869/3.0k [08:11<20:06, 2it/s, Loss: 0.115, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "29.1%┣┫ 872/3.0k [08:12<20:03, 2it/s, Loss: 0.114, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "29.2%┣┫ 875/3.0k [08:14<20:00, 2it/s, Loss: 0.115, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "29.3%┣┫ 878/3.0k [08:15<19:57, 2it/s, Loss: 0.113, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "29.4%┣┫ 881/3.0k [08:16<19:54, 2it/s, Loss: 0.113, PDE_losses: 0.067, BC_losses: 0.002]\n",
      "29.5%┣┫ 884/3.0k [08:17<19:52, 2it/s, Loss: 0.110, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "29.6%┣┫ 887/3.0k [08:19<19:49, 2it/s, Loss: 0.111, PDE_losses: 0.068, BC_losses: 0.002]\n",
      "29.7%┣┫ 890/3.0k [08:20<19:47, 2it/s, Loss: 0.110, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "29.8%┣┫ 893/3.0k [08:21<19:44, 2it/s, Loss: 0.110, PDE_losses: 0.067, BC_losses: 0.002]\n",
      "29.9%┣┫ 896/3.0k [08:23<19:42, 2it/s, Loss: 0.109, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "30.0%┣┫ 899/3.0k [08:24<19:39, 2it/s, Loss: 0.108, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "30.1%┣┫ 902/3.0k [08:25<19:36, 2it/s, Loss: 0.108, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "30.2%┣┫ 905/3.0k [08:26<19:33, 2it/s, Loss: 0.107, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "30.3%┣┫ 908/3.0k [08:27<19:31, 2it/s, Loss: 0.107, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "30.4%┣┫ 911/3.0k [08:29<19:28, 2it/s, Loss: 0.105, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "30.5%┣┫ 914/3.0k [08:30<19:25, 2it/s, Loss: 0.107, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "30.6%┣┫ 917/3.0k [08:31<19:22, 2it/s, Loss: 0.105, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "30.7%┣┫ 920/3.0k [08:32<19:20, 2it/s, Loss: 0.103, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "30.8%┣┫ 923/3.0k [08:34<19:17, 2it/s, Loss: 0.105, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "30.9%┣┫ 926/3.0k [08:35<19:14, 2it/s, Loss: 0.105, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "31.0%┣┫ 929/3.0k [08:36<19:12, 2it/s, Loss: 0.108, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "31.1%┣┫ 932/3.0k [08:38<19:10, 2it/s, Loss: 0.101, PDE_losses: 0.067, BC_losses: 0.002]\n",
      "31.1%┣┫ 934/3.0k [08:39<19:08, 2it/s, Loss: 0.104, PDE_losses: 0.067, BC_losses: 0.002]\n",
      "31.2%┣┫ 937/3.0k [08:40<19:06, 2it/s, Loss: 0.103, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "31.3%┣┫ 940/3.0k [08:41<19:04, 2it/s, Loss: 0.103, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "31.4%┣┫ 943/3.0k [08:43<19:01, 2it/s, Loss: 0.101, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "31.5%┣┫ 946/3.0k [08:44<18:59, 2it/s, Loss: 0.102, PDE_losses: 0.062, BC_losses: 0.002]\n",
      "31.6%┣┫ 949/3.0k [08:45<18:56, 2it/s, Loss: 0.102, PDE_losses: 0.064, BC_losses: 0.002]\n",
      "31.7%┣┫ 952/3.0k [08:46<18:53, 2it/s, Loss: 0.100, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "31.8%┣┫ 955/3.0k [08:47<18:50, 2it/s, Loss: 0.100, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "31.9%┣┫ 958/3.0k [08:48<18:48, 2it/s, Loss: 0.098, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "32.0%┣┫ 961/3.0k [08:50<18:45, 2it/s, Loss: 0.100, PDE_losses: 0.066, BC_losses: 0.002]\n",
      "32.1%┣┫ 964/3.0k [08:51<18:43, 2it/s, Loss: 0.099, PDE_losses: 0.062, BC_losses: 0.002]\n",
      "32.2%┣┫ 967/3.0k [08:52<18:40, 2it/s, Loss: 0.096, PDE_losses: 0.063, BC_losses: 0.002]\n",
      "32.3%┣┫ 970/3.0k [08:54<18:38, 2it/s, Loss: 0.098, PDE_losses: 0.062, BC_losses: 0.002]\n",
      "32.4%┣┫ 973/3.0k [08:55<18:35, 2it/s, Loss: 0.099, PDE_losses: 0.065, BC_losses: 0.002]\n",
      "32.5%┣┫ 976/3.0k [08:56<18:33, 2it/s, Loss: 0.097, PDE_losses: 0.065, BC_losses: 0.001]\n",
      "32.6%┣┫ 979/3.0k [08:57<18:30, 2it/s, Loss: 0.098, PDE_losses: 0.062, BC_losses: 0.001]\n",
      "32.7%┣┫ 982/3.0k [08:58<18:27, 2it/s, Loss: 0.095, PDE_losses: 0.063, BC_losses: 0.001]\n",
      "32.8%┣┫ 985/3.0k [09:00<18:25, 2it/s, Loss: 0.095, PDE_losses: 0.061, BC_losses: 0.001]\n",
      "32.9%┣┫ 988/3.0k [09:01<18:23, 2it/s, Loss: 0.096, PDE_losses: 0.063, BC_losses: 0.001]\n",
      "33.0%┣┫ 991/3.0k [09:02<18:20, 2it/s, Loss: 0.098, PDE_losses: 0.063, BC_losses: 0.001]\n",
      "33.1%┣┫ 994/3.0k [09:04<18:18, 2it/s, Loss: 0.094, PDE_losses: 0.064, BC_losses: 0.001]\n",
      "33.2%┣┫ 997/3.0k [09:05<18:16, 2it/s, Loss: 0.094, PDE_losses: 0.063, BC_losses: 0.001]\n",
      "33.3%┣┫ 1.0k/3.0k [09:06<18:13, 2it/s, Loss: 0.095, PDE_losses: 0.061, BC_losses: 0.001]\n",
      "33.4%┣┫ 1.0k/3.0k [09:07<18:11, 2it/s, Loss: 0.094, PDE_losses: 0.062, BC_losses: 0.001]\n",
      "33.5%┣┫ 1.0k/3.0k [09:08<18:08, 2it/s, Loss: 0.093, PDE_losses: 0.064, BC_losses: 0.001]\n",
      "33.6%┣┫ 1.0k/3.0k [09:10<18:06, 2it/s, Loss: 0.093, PDE_losses: 0.064, BC_losses: 0.001]\n",
      "33.7%┣┫ 1.0k/3.0k [09:11<18:03, 2it/s, Loss: 0.092, PDE_losses: 0.067, BC_losses: 0.001]\n",
      "33.8%┣┫ 1.0k/3.0k [09:12<18:01, 2it/s, Loss: 0.099, PDE_losses: 0.061, BC_losses: 0.001]\n",
      "33.9%┣┫ 1.0k/3.0k [09:13<17:59, 2it/s, Loss: 0.092, PDE_losses: 0.060, BC_losses: 0.001]\n",
      "34.0%┣┫ 1.0k/3.0k [09:15<17:56, 2it/s, Loss: 0.091, PDE_losses: 0.062, BC_losses: 0.001]\n",
      "34.1%┣┫ 1.0k/3.0k [09:16<17:54, 2it/s, Loss: 0.091, PDE_losses: 0.065, BC_losses: 0.001]\n",
      "34.2%┣┫ 1.0k/3.0k [09:17<17:52, 2it/s, Loss: 0.091, PDE_losses: 0.062, BC_losses: 0.001]\n",
      "34.3%┣┫ 1.0k/3.0k [09:19<17:49, 2it/s, Loss: 0.092, PDE_losses: 0.063, BC_losses: 0.001]\n",
      "34.4%┣┫ 1.0k/3.0k [09:20<17:47, 2it/s, Loss: 0.095, PDE_losses: 0.063, BC_losses: 0.001]\n",
      "34.5%┣┫ 1.0k/3.0k [09:21<17:45, 2it/s, Loss: 0.089, PDE_losses: 0.064, BC_losses: 0.001]\n",
      "34.6%┣┫ 1.0k/3.0k [09:23<17:43, 2it/s, Loss: 0.088, PDE_losses: 0.063, BC_losses: 0.001]\n",
      "34.7%┣┫ 1.0k/3.0k [09:24<17:40, 2it/s, Loss: 0.091, PDE_losses: 0.062, BC_losses: 0.001]\n",
      "34.8%┣┫ 1.0k/3.0k [09:25<17:38, 2it/s, Loss: 0.095, PDE_losses: 0.064, BC_losses: 0.001]\n",
      "34.9%┣┫ 1.0k/3.0k [09:26<17:36, 2it/s, Loss: 0.089, PDE_losses: 0.060, BC_losses: 0.001]\n",
      "35.0%┣┫ 1.1k/3.0k [09:27<17:33, 2it/s, Loss: 0.087, PDE_losses: 0.063, BC_losses: 0.001]\n",
      "35.1%┣┫ 1.1k/3.0k [09:29<17:31, 2it/s, Loss: 0.092, PDE_losses: 0.064, BC_losses: 0.001]\n",
      "35.2%┣┫ 1.1k/3.0k [09:30<17:29, 2it/s, Loss: 0.090, PDE_losses: 0.061, BC_losses: 0.001]\n",
      "35.3%┣┫ 1.1k/3.0k [09:31<17:26, 2it/s, Loss: 0.092, PDE_losses: 0.064, BC_losses: 0.001]\n",
      "35.4%┣┫ 1.1k/3.0k [09:32<17:24, 2it/s, Loss: 0.088, PDE_losses: 0.061, BC_losses: 0.001]\n",
      "35.5%┣┫ 1.1k/3.0k [09:34<17:22, 2it/s, Loss: 0.089, PDE_losses: 0.062, BC_losses: 0.001]\n",
      "35.6%┣┫ 1.1k/3.0k [09:35<17:19, 2it/s, Loss: 0.092, PDE_losses: 0.064, BC_losses: 0.001]\n",
      "35.7%┣┫ 1.1k/3.0k [09:36<17:17, 2it/s, Loss: 0.089, PDE_losses: 0.062, BC_losses: 0.001]\n",
      "35.8%┣┫ 1.1k/3.0k [09:38<17:17, 2it/s, Loss: 0.089, PDE_losses: 0.064, BC_losses: 0.001]\n",
      "35.9%┣┫ 1.1k/3.0k [09:39<17:15, 2it/s, Loss: 0.087, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "36.0%┣┫ 1.1k/3.0k [09:40<17:14, 2it/s, Loss: 0.086, PDE_losses: 0.063, BC_losses: 0.001]\n",
      "36.1%┣┫ 1.1k/3.0k [09:41<17:11, 2it/s, Loss: 0.085, PDE_losses: 0.061, BC_losses: 0.001]\n",
      "36.2%┣┫ 1.1k/3.0k [09:43<17:09, 2it/s, Loss: 0.091, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "36.3%┣┫ 1.1k/3.0k [09:44<17:07, 2it/s, Loss: 0.085, PDE_losses: 0.061, BC_losses: 0.001]\n",
      "36.4%┣┫ 1.1k/3.0k [09:45<17:05, 2it/s, Loss: 0.089, PDE_losses: 0.060, BC_losses: 0.001]\n",
      "36.5%┣┫ 1.1k/3.0k [09:47<17:03, 2it/s, Loss: 0.089, PDE_losses: 0.063, BC_losses: 0.001]\n",
      "36.6%┣┫ 1.1k/3.0k [09:48<17:00, 2it/s, Loss: 0.089, PDE_losses: 0.062, BC_losses: 0.001]\n",
      "36.7%┣┫ 1.1k/3.0k [09:49<16:58, 2it/s, Loss: 0.085, PDE_losses: 0.060, BC_losses: 0.001]\n",
      "36.8%┣┫ 1.1k/3.0k [09:50<16:56, 2it/s, Loss: 0.085, PDE_losses: 0.064, BC_losses: 0.001]\n",
      "36.9%┣┫ 1.1k/3.0k [09:52<16:54, 2it/s, Loss: 0.087, PDE_losses: 0.062, BC_losses: 0.001]\n",
      "37.0%┣┫ 1.1k/3.0k [09:53<16:52, 2it/s, Loss: 0.085, PDE_losses: 0.064, BC_losses: 0.001]\n",
      "37.1%┣┫ 1.1k/3.0k [09:54<16:50, 2it/s, Loss: 0.087, PDE_losses: 0.062, BC_losses: 0.001]\n",
      "37.2%┣┫ 1.1k/3.0k [09:55<16:47, 2it/s, Loss: 0.087, PDE_losses: 0.060, BC_losses: 0.001]\n",
      "37.3%┣┫ 1.1k/3.0k [09:56<16:45, 2it/s, Loss: 0.084, PDE_losses: 0.064, BC_losses: 0.001]\n",
      "37.4%┣┫ 1.1k/3.0k [09:58<16:43, 2it/s, Loss: 0.083, PDE_losses: 0.062, BC_losses: 0.001]\n",
      "37.5%┣┫ 1.1k/3.0k [09:59<16:40, 2it/s, Loss: 0.084, PDE_losses: 0.056, BC_losses: 0.001]\n",
      "37.6%┣┫ 1.1k/3.0k [10:00<16:38, 2it/s, Loss: 0.083, PDE_losses: 0.060, BC_losses: 0.001]\n",
      "37.7%┣┫ 1.1k/3.0k [10:01<16:36, 2it/s, Loss: 0.082, PDE_losses: 0.060, BC_losses: 0.001]\n",
      "37.8%┣┫ 1.1k/3.0k [10:03<16:34, 2it/s, Loss: 0.085, PDE_losses: 0.063, BC_losses: 0.001]\n",
      "37.9%┣┫ 1.1k/3.0k [10:04<16:32, 2it/s, Loss: 0.088, PDE_losses: 0.061, BC_losses: 0.001]\n",
      "38.0%┣┫ 1.1k/3.0k [10:05<16:30, 2it/s, Loss: 0.081, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "38.1%┣┫ 1.1k/3.0k [10:06<16:28, 2it/s, Loss: 0.085, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "38.2%┣┫ 1.1k/3.0k [10:08<16:26, 2it/s, Loss: 0.085, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "38.3%┣┫ 1.1k/3.0k [10:09<16:24, 2it/s, Loss: 0.084, PDE_losses: 0.060, BC_losses: 0.001]\n",
      "38.4%┣┫ 1.2k/3.0k [10:11<16:22, 2it/s, Loss: 0.081, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "38.5%┣┫ 1.2k/3.0k [10:12<16:20, 2it/s, Loss: 0.083, PDE_losses: 0.061, BC_losses: 0.001]\n",
      "38.6%┣┫ 1.2k/3.0k [10:13<16:17, 2it/s, Loss: 0.085, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "38.7%┣┫ 1.2k/3.0k [10:14<16:15, 2it/s, Loss: 0.083, PDE_losses: 0.061, BC_losses: 0.001]\n",
      "38.8%┣┫ 1.2k/3.0k [10:16<16:13, 2it/s, Loss: 0.085, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "38.9%┣┫ 1.2k/3.0k [10:17<16:11, 2it/s, Loss: 0.082, PDE_losses: 0.061, BC_losses: 0.001]\n",
      "39.0%┣┫ 1.2k/3.0k [10:18<16:09, 2it/s, Loss: 0.083, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "39.1%┣┫ 1.2k/3.0k [10:19<16:07, 2it/s, Loss: 0.084, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "39.2%┣┫ 1.2k/3.0k [10:20<16:04, 2it/s, Loss: 0.082, PDE_losses: 0.055, BC_losses: 0.001]\n",
      "39.3%┣┫ 1.2k/3.0k [10:22<16:02, 2it/s, Loss: 0.083, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "39.4%┣┫ 1.2k/3.0k [10:23<16:00, 2it/s, Loss: 0.081, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "39.5%┣┫ 1.2k/3.0k [10:24<15:58, 2it/s, Loss: 0.082, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "39.6%┣┫ 1.2k/3.0k [10:25<15:56, 2it/s, Loss: 0.080, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "39.7%┣┫ 1.2k/3.0k [10:26<15:54, 2it/s, Loss: 0.082, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "39.8%┣┫ 1.2k/3.0k [10:28<15:51, 2it/s, Loss: 0.080, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "39.9%┣┫ 1.2k/3.0k [10:29<15:49, 2it/s, Loss: 0.081, PDE_losses: 0.060, BC_losses: 0.001]\n",
      "40.0%┣┫ 1.2k/3.0k [10:30<15:47, 2it/s, Loss: 0.083, PDE_losses: 0.060, BC_losses: 0.001]\n",
      "40.1%┣┫ 1.2k/3.0k [10:31<15:45, 2it/s, Loss: 0.078, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "40.2%┣┫ 1.2k/3.0k [10:33<15:43, 2it/s, Loss: 0.080, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "40.3%┣┫ 1.2k/3.0k [10:34<15:41, 2it/s, Loss: 0.084, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "40.4%┣┫ 1.2k/3.0k [10:35<15:39, 2it/s, Loss: 0.080, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "40.5%┣┫ 1.2k/3.0k [10:36<15:37, 2it/s, Loss: 0.081, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "40.6%┣┫ 1.2k/3.0k [10:38<15:35, 2it/s, Loss: 0.078, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "40.7%┣┫ 1.2k/3.0k [10:39<15:33, 2it/s, Loss: 0.079, PDE_losses: 0.055, BC_losses: 0.001]\n",
      "40.8%┣┫ 1.2k/3.0k [10:40<15:30, 2it/s, Loss: 0.081, PDE_losses: 0.061, BC_losses: 0.001]\n",
      "40.9%┣┫ 1.2k/3.0k [10:41<15:28, 2it/s, Loss: 0.077, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "41.0%┣┫ 1.2k/3.0k [10:42<15:26, 2it/s, Loss: 0.075, PDE_losses: 0.060, BC_losses: 0.001]\n",
      "41.1%┣┫ 1.2k/3.0k [10:43<15:24, 2it/s, Loss: 0.077, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "41.2%┣┫ 1.2k/3.0k [10:45<15:22, 2it/s, Loss: 0.076, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "41.3%┣┫ 1.2k/3.0k [10:46<15:20, 2it/s, Loss: 0.078, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "41.4%┣┫ 1.2k/3.0k [10:47<15:18, 2it/s, Loss: 0.082, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "41.5%┣┫ 1.2k/3.0k [10:48<15:16, 2it/s, Loss: 0.078, PDE_losses: 0.056, BC_losses: 0.001]\n",
      "41.6%┣┫ 1.2k/3.0k [10:50<15:14, 2it/s, Loss: 0.081, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "41.7%┣┫ 1.2k/3.0k [10:51<15:12, 2it/s, Loss: 0.078, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "41.8%┣┫ 1.3k/3.0k [10:52<15:10, 2it/s, Loss: 0.080, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "41.9%┣┫ 1.3k/3.0k [10:53<15:08, 2it/s, Loss: 0.075, PDE_losses: 0.060, BC_losses: 0.001]\n",
      "42.0%┣┫ 1.3k/3.0k [10:55<15:06, 2it/s, Loss: 0.081, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "42.1%┣┫ 1.3k/3.0k [10:56<15:04, 2it/s, Loss: 0.077, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "42.2%┣┫ 1.3k/3.0k [10:57<15:02, 2it/s, Loss: 0.074, PDE_losses: 0.061, BC_losses: 0.001]\n",
      "42.3%┣┫ 1.3k/3.0k [10:58<15:00, 2it/s, Loss: 0.078, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "42.4%┣┫ 1.3k/3.0k [10:59<14:58, 2it/s, Loss: 0.077, PDE_losses: 0.055, BC_losses: 0.001]\n",
      "42.5%┣┫ 1.3k/3.0k [11:00<14:56, 2it/s, Loss: 0.075, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "42.6%┣┫ 1.3k/3.0k [11:02<14:54, 2it/s, Loss: 0.081, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "42.7%┣┫ 1.3k/3.0k [11:03<14:52, 2it/s, Loss: 0.075, PDE_losses: 0.056, BC_losses: 0.001]\n",
      "42.8%┣┫ 1.3k/3.0k [11:04<14:50, 2it/s, Loss: 0.073, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "42.9%┣┫ 1.3k/3.0k [11:06<14:48, 2it/s, Loss: 0.075, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "43.0%┣┫ 1.3k/3.0k [11:07<14:46, 2it/s, Loss: 0.079, PDE_losses: 0.056, BC_losses: 0.001]\n",
      "43.1%┣┫ 1.3k/3.0k [11:08<14:44, 2it/s, Loss: 0.079, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "43.2%┣┫ 1.3k/3.0k [11:10<14:42, 2it/s, Loss: 0.081, PDE_losses: 0.060, BC_losses: 0.001]\n",
      "43.3%┣┫ 1.3k/3.0k [11:11<14:40, 2it/s, Loss: 0.075, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "43.4%┣┫ 1.3k/3.0k [11:12<14:39, 2it/s, Loss: 0.079, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "43.5%┣┫ 1.3k/3.0k [11:13<14:37, 2it/s, Loss: 0.076, PDE_losses: 0.056, BC_losses: 0.001]\n",
      "43.6%┣┫ 1.3k/3.0k [11:15<14:35, 2it/s, Loss: 0.077, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "43.7%┣┫ 1.3k/3.0k [11:16<14:33, 2it/s, Loss: 0.073, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "43.8%┣┫ 1.3k/3.0k [11:17<14:31, 2it/s, Loss: 0.079, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "43.9%┣┫ 1.3k/3.0k [11:19<14:29, 2it/s, Loss: 0.076, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "44.0%┣┫ 1.3k/3.0k [11:20<14:27, 2it/s, Loss: 0.076, PDE_losses: 0.060, BC_losses: 0.001]\n",
      "44.1%┣┫ 1.3k/3.0k [11:21<14:25, 2it/s, Loss: 0.075, PDE_losses: 0.052, BC_losses: 0.001]\n",
      "44.1%┣┫ 1.3k/3.0k [11:22<14:24, 2it/s, Loss: 0.074, PDE_losses: 0.055, BC_losses: 0.001]\n",
      "44.2%┣┫ 1.3k/3.0k [11:23<14:22, 2it/s, Loss: 0.076, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "44.3%┣┫ 1.3k/3.0k [11:25<14:20, 2it/s, Loss: 0.075, PDE_losses: 0.054, BC_losses: 0.001]\n",
      "44.4%┣┫ 1.3k/3.0k [11:26<14:18, 2it/s, Loss: 0.072, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "44.5%┣┫ 1.3k/3.0k [11:27<14:17, 2it/s, Loss: 0.076, PDE_losses: 0.056, BC_losses: 0.001]\n",
      "44.6%┣┫ 1.3k/3.0k [11:29<14:15, 2it/s, Loss: 0.077, PDE_losses: 0.055, BC_losses: 0.001]\n",
      "44.7%┣┫ 1.3k/3.0k [11:30<14:13, 2it/s, Loss: 0.074, PDE_losses: 0.056, BC_losses: 0.001]\n",
      "44.8%┣┫ 1.3k/3.0k [11:31<14:11, 2it/s, Loss: 0.073, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "44.9%┣┫ 1.3k/3.0k [11:33<14:10, 2it/s, Loss: 0.076, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "45.0%┣┫ 1.4k/3.0k [11:34<14:08, 2it/s, Loss: 0.077, PDE_losses: 0.055, BC_losses: 0.001]\n",
      "45.1%┣┫ 1.4k/3.0k [11:36<14:07, 2it/s, Loss: 0.076, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "45.2%┣┫ 1.4k/3.0k [11:37<14:05, 2it/s, Loss: 0.075, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "45.3%┣┫ 1.4k/3.0k [11:38<14:04, 2it/s, Loss: 0.073, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "45.4%┣┫ 1.4k/3.0k [11:39<14:02, 2it/s, Loss: 0.075, PDE_losses: 0.055, BC_losses: 0.001]\n",
      "45.5%┣┫ 1.4k/3.0k [11:41<14:00, 2it/s, Loss: 0.075, PDE_losses: 0.056, BC_losses: 0.001]\n",
      "45.6%┣┫ 1.4k/3.0k [11:42<13:58, 2it/s, Loss: 0.074, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "45.7%┣┫ 1.4k/3.0k [11:43<13:56, 2it/s, Loss: 0.073, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "45.8%┣┫ 1.4k/3.0k [11:44<13:54, 2it/s, Loss: 0.073, PDE_losses: 0.054, BC_losses: 0.001]\n",
      "45.9%┣┫ 1.4k/3.0k [11:46<13:52, 2it/s, Loss: 0.075, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "46.0%┣┫ 1.4k/3.0k [11:47<13:51, 2it/s, Loss: 0.075, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "46.1%┣┫ 1.4k/3.0k [11:48<13:49, 2it/s, Loss: 0.073, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "46.2%┣┫ 1.4k/3.0k [11:49<13:47, 2it/s, Loss: 0.073, PDE_losses: 0.058, BC_losses: 0.001]\n",
      "46.3%┣┫ 1.4k/3.0k [11:51<13:45, 2it/s, Loss: 0.069, PDE_losses: 0.059, BC_losses: 0.001]\n",
      "46.4%┣┫ 1.4k/3.0k [11:52<13:43, 2it/s, Loss: 0.074, PDE_losses: 0.055, BC_losses: 0.001]\n",
      "46.5%┣┫ 1.4k/3.0k [11:54<13:42, 2it/s, Loss: 0.077, PDE_losses: 0.057, BC_losses: 0.001]\n",
      "46.6%┣┫ 1.4k/3.0k [11:55<13:40, 2it/s, Loss: 0.070, PDE_losses: 0.056, BC_losses: 0.001]\n",
      "46.7%┣┫ 1.4k/3.0k [11:56<13:38, 2it/s, Loss: 0.072, PDE_losses: 0.059, BC_losses: 0.001]\n"
     ]
    }
   ],
   "source": [
    "maxiters = 3000\n",
    "callback = create_callback(maxiters)\n",
    "# Решение\n",
    "res = solve(prob, opt; maxiters = maxiters, callback)\n",
    "phi = discretization.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2005704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0mComponentVector{Float32, CuArray{Float32, 1, CUDA.DeviceMemory}, Tuple{Axis{(layer_1 = ViewAxis(1:160, Axis(weight = ViewAxis(1:128, ShapedAxis((32, 4))), bias = ViewAxis(129:160, Shaped1DAxis((32,))))), layer_2 = ViewAxis(161:1216, Axis(weight = ViewAxis(1:1024, ShapedAxis((32, 32))), bias = ViewAxis(1025:1056, Shaped1DAxis((32,))))), layer_3 = ViewAxis(1217:2272, Axis(weight = ViewAxis(1:1024, ShapedAxis((32, 32))), bias = ViewAxis(1025:1056, Shaped1DAxis((32,))))), layer_4 = ViewAxis(2273:2536, Axis(weight = ViewAxis(1:256, ShapedAxis((8, 32))), bias = ViewAxis(257:264, Shaped1DAxis((8,))))))}}}(layer_1 = (weight = Float32[0.64270455 -0.69251525 -0.21865846 -0.6302313; 0.09410353 0.16299486 0.14028741 -0.17518775; … ; 0.6903682 -0.73030674 0.43923947 -0.6788331; 0.7310284 -0.6661543 0.18700586 0.3957257], bias = Float32[-0.05248393, -0.40303862, 0.29772493, 0.0049014185, 0.06712001, 0.38455158, 0.29028347, 0.46409968, -0.3953544, 0.27702054  …  0.038982, -0.45193848, -0.036569875, 0.4469578, 0.47885904, 0.2888665, -0.25860062, 0.24595322, 0.25356773, 0.27765563]), layer_2 = (weight = Float32[0.01627679 0.1528641 … -0.08143178 -0.288257; 0.078764014 0.06756507 … 0.27594027 0.25883135; … ; -0.06965304 0.019706406 … -0.04240495 -0.27363873; 0.12170299 0.25688598 … -0.027266914 0.16222368], bias = Float32[-0.03160845, -0.017639304, -0.09954848, -0.10780809, -0.18575655, -0.07849031, 0.11848624, -0.08460619, -0.0227239, 0.18239263  …  -0.18439247, -0.00228332, -0.08178482, 0.044443116, 0.11445515, 0.13380617, -0.07750891, -0.15786532, -0.08928284, 0.13948654]), layer_3 = (weight = Float32[-0.061428037 0.089511946 … -0.067124635 -0.16012782; -0.1227836 -0.13727874 … -0.03893358 -0.11695453; … ; -0.001707719 -0.2818155 … 0.3079905 -0.11503563; -0.2003858 0.1796535 … -0.17482454 0.08547127], bias = Float32[0.060295966, 0.009363603, 0.06781459, 0.13820069, 0.10801077, -0.070276365, 0.042567592, -0.10752039, 0.06483106, 0.016803754  …  0.09850284, 0.016590506, 0.08960887, -0.14650053, 0.047081713, -0.05925507, -0.02086509, 0.14938636, -0.15745836, -0.01166662]), layer_4 = (weight = Float32[-0.13850604 0.06414953 … 0.2059744 0.28575087; -0.2736686 -0.025503628 … -0.088670865 -0.01744351; … ; 0.11486 0.09209624 … -0.17203517 0.21064809; -0.23944661 -0.22826971 … -0.111391865 -0.064700626], bias = Float32[-0.04646103, 0.004854258, -0.02067637, -0.00805779, 0.03914437, -0.12154924, -0.16009347, 0.033037823]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27568b",
   "metadata": {},
   "source": [
    "### График скалярного потенциала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377e30b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/sasha/inverse-npde/figures/plot_phi.png\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "\n",
    "phi = discretization.phi\n",
    "xs, ys, zs, ts = [infimum(d.domain):0.01:supremum(d.domain) for d in domains]\n",
    "\n",
    "minimizers_ = res.u|> cpud\n",
    "z_selected = 0.0\n",
    "t_selected = 0.0\n",
    "clip = 10\n",
    "u_real = [clamp(analytic_sol_func(0, xs, ys, z_selected), -clip, clip) for xs in xs for ys in ys]\n",
    "u_predict = [(phi([x, y, z_selected, t_selected], minimizers_))[1] for x in xs for y in ys ]\n",
    "diff_u = [abs.(u_real .- u_predict)]\n",
    "\n",
    "ps = []\n",
    "\n",
    "p1 = plot(xs, ys, u_real, linetype = :contourf, title = \"phi, analytic\")\n",
    "p2 = plot(xs, ys, u_predict, linetype = :contourf, title = \"phi, predict\")\n",
    "p3 = plot(xs, ys, diff_u, linetype = :contourf, title = \"phi, error\")\n",
    "push!(ps, plot(p1, p2, p3))\n",
    "\n",
    "\n",
    "# Сохранение графиков\n",
    "savefig(ps[1], \"../../figures/plot_phi.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9f3009",
   "metadata": {},
   "source": [
    "### График плотности заряда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d9179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#160 (generic function with 1 method)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Плотность заряда\n",
    "sigma = 1\n",
    "charge = Distributions.MvNormal([0.; 0.; 0.], [1. 0.0 0.0; 0.0 1. 0.0; 0.0 0.00 1.] * sigma)\n",
    "rho = (t, x, y, z) -> Distributions.pdf(charge, [x; y; z]) * ((t + 1)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b42ec3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/sasha/inverse-npde/figures/plot_rho.png\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "\n",
    "phi = discretization.phi\n",
    "xs, ys, zs, ts = [infimum(d.domain):0.01:supremum(d.domain) for d in domains]\n",
    "\n",
    "minimizers_ = res.u|> cpud\n",
    "z_selected = 0.0\n",
    "t_selected = 0.0\n",
    "clip = 10\n",
    "u_real = [clamp(rho(0, xs, ys, z_selected), -clip, clip) for xs in xs for ys in ys]\n",
    "u_predict = [(phi([x, y, z_selected, t_selected], minimizers_))[5] for x in xs for y in ys ]\n",
    "diff_u = [abs.(u_real .- u_predict)]\n",
    "\n",
    "ps = []\n",
    "\n",
    "p1 = plot(xs, ys, u_real, linetype = :contourf, title = \"rho, analytic\")\n",
    "p2 = plot(xs, ys, u_predict, linetype = :contourf, title = \"rho, predict\")\n",
    "p3 = plot(xs, ys, diff_u, linetype = :contourf, title = \"rho, error\")\n",
    "push!(ps, plot(p1, p2, p3))\n",
    "\n",
    "\n",
    "# Сохранение графиков\n",
    "savefig(ps[1], \"../../figures/plot_rho.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a74093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
