{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, mne, glob, natsort, pdb\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "mne.set_log_level('error')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mne_apply(func, raw, verbose=\"WARNING\"):\n",
    "    \"\"\"\n",
    "    Apply function to data of `mne.io.RawArray`.\n",
    "    From braindecode toolbox: https://github.com/robintibor/braindecode/blob/master/braindecode/mne_ext/signalproc.py#L75-L93\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func: function\n",
    "        Should accept 2d-array (channels x time) and return modified 2d-array\n",
    "    raw: `mne.io.RawArray`\n",
    "    verbose: bool\n",
    "        Whether to log creation of new `mne.io.RawArray`.\n",
    "    Returns\n",
    "    -------\n",
    "    transformed_set: Copy of `raw` with data transformed by given function.\n",
    "    \"\"\"\n",
    "    new_data = func(raw.get_data())\n",
    "    return mne.io.RawArray(new_data, raw.info, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет из https://bnci-horizon-2020.eu/database/data-sets\n",
    "\n",
    "Всего 15 субъектов от S01 до S15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp = '../.data/brunton_uw_bio'\n",
    "sp = '../.data/brunton_uw_bio'\n",
    "tlims = [-2,2] # seconds\n",
    "tlims_handpos = [0,4] # seconds\n",
    "filt_freqs = [1,None] # Hz (low, high cutoffs)\n",
    "n_splits = 4 # number of splits per subject\n",
    "sbj_id = 'S15'\n",
    "n_chans = 61 # number of EEG channels\n",
    "event_dict = {'move':0x600,'rest':0x606}\n",
    "# event labels: elbow flexion (0x600), elbow extension (0x601), supination (0x602),\n",
    "#               pronation (0x603), hand close (0x604), hand open (0x605),\n",
    "#               rest (0x606)\n",
    "sfreq_new = 250 # Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для создания таблицы расположения датчиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_chan_pos_file = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../.data/brunton_uw_bioroi_proj/eeg_elec_mni_pos.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m create_chan_pos_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m create_chan_pos_file:\n\u001b[0;32m----> 5\u001b[0m     chan_pos \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(lp\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroi_proj/eeg_elec_mni_pos.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m     ch_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFz\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF4\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFFC5h\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFFC3h\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFFC1h\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFFC2h\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFFC4h\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFFC6h\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFC5\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFC3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFC1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFCz\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFC2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFC4\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFC6\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFTT7h\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPP5h\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPP3h\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPP1h\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPP2h\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPP4h\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPP6h\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPz\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP4\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPPO1h\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPPO2h\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m     chan_locs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros([\u001b[38;5;28mlen\u001b[39m(ch_names),\u001b[38;5;241m3\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/inverse-pde/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/inverse-pde/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/inverse-pde/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/envs/inverse-pde/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/inverse-pde/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../.data/brunton_uw_bioroi_proj/eeg_elec_mni_pos.csv'"
     ]
    }
   ],
   "source": [
    "# Create txt file with electrode MNI positions (mirrored to left hemisphere)\n",
    "if create_chan_pos_file:\n",
    "    chan_pos = pd.read_csv(lp+'roi_proj/eeg_elec_mni_pos.csv',index_col=0)\n",
    "    ch_names = ['F3','F1','Fz','F2','F4',\n",
    "                'FFC5h','FFC3h','FFC1h','FFC2h','FFC4h','FFC6h',\n",
    "                'FC5','FC3','FC1','FCz','FC2','FC4','FC6','FTT7h',\n",
    "                'FCC5h','FCC3h','FCC1h','FCC2h','FCC4h','FCC6h','FTT8h',\n",
    "                'C5','C3','C1','Cz','C2','C4','C6','TTP7h',\n",
    "                'CCP5h','CCP3h','CCP1h','CCP2h','CCP4h','CCP6h','TTP8h',\n",
    "                'CP5','CP3','CP1','CPz','CP2','CP4','CP6',\n",
    "                'CPP5h','CPP3h','CPP1h','CPP2h','CPP4h','CPP6h',\n",
    "                'P3','P1','Pz','P2','P4','PPO1h','PPO2h']\n",
    "\n",
    "    chan_locs = np.zeros([len(ch_names),3])\n",
    "    for s,chan in enumerate(ch_names):\n",
    "        curr_pos = chan_pos.loc[chan].values\n",
    "        # Mirror to left hemisphere\n",
    "#         if curr_pos[0] > 0:\n",
    "#             curr_pos[0] = -curr_pos[0]\n",
    "        chan_locs[s,:] = curr_pos\n",
    "    \n",
    "    chan_info = pd.DataFrame(chan_locs,columns=['X','Y','Z'])\n",
    "    chan_info.to_csv(lp+'roi_proj/eeg_elec_mni_pos_bothH.txt', header=None, index=None, na_rep='nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(sp):\n",
    "    os.mkdir(sp)\n",
    "\n",
    "fnames_all = natsort.natsorted(glob.glob(lp+sbj_id+'_ME/*.gdf'))\n",
    "\n",
    "for s,fname_curr in enumerate(fnames_all):\n",
    "    print(fname_curr)\n",
    "    # Load datafile\n",
    "    dat_load = mne.io.read_raw_edf(fname_curr,preload=True)\n",
    "    dat_hand_pos = dat_load.copy()\n",
    "    \n",
    "    ch_labels = dat_load.info['ch_names']\n",
    "    dat = dat_load.drop_channels(ch_labels[n_chans:])\n",
    "    assert len(dat.ch_names) == n_chans\n",
    "    \n",
    "    # Convert to millvolt for numerical stability of next operations\n",
    "    dat = mne_apply(lambda a: a * 1e6, dat)\n",
    "    \n",
    "    # Common average reference\n",
    "    dat.set_eeg_reference(ref_channels='average')\n",
    "    \n",
    "    # High-pass filter\n",
    "    dat.filter(filt_freqs[0], filt_freqs[1])\n",
    "    \n",
    "    # Find events (769, 770, 771, 772)\n",
    "    events,ev_dic_orig = mne.events_from_annotations(dat_load)\n",
    "    ev_dic_orig[str(int(event_dict['move']))]\n",
    "    \n",
    "    # Epoch data around events\n",
    "    event_id = {'rest': ev_dic_orig[str(int(event_dict['rest']))],\n",
    "                'move': ev_dic_orig[str(int(event_dict['move']))]}\n",
    "    \n",
    "    drop_chan_pos = [val for val in ch_labels if val not in ['handPosX', 'handPosY', 'handPosZ']]\n",
    "    dat_hand_pos.drop_channels(drop_chan_pos)\n",
    "    dat_hand_pos._data[0,:] = np.sqrt(np.square(dat_hand_pos._data).sum(axis=0))\n",
    "    dat_hand_pos.drop_channels(['handPosY', 'handPosZ'])\n",
    "    ep_hand_pos = mne.Epochs(dat_hand_pos, events, event_id, tlims_handpos[0],\n",
    "                             tlims_handpos[1], baseline=None, preload=True)\n",
    "#     plt.plot(ep_hand_pos['move']._data[0,0,:].squeeze())\n",
    "#     plt.show()\n",
    "    move_ev_inds = np.nonzero(events[:,2]==event_id['move'])[0]\n",
    "    print(events[move_ev_inds,0])\n",
    "    for i in range(ep_hand_pos['move']._data.shape[0]):\n",
    "        curr_trace = ep_hand_pos['move']._data[i,...].squeeze()\n",
    "        curr_trace = np.abs(curr_trace-curr_trace[0])\n",
    "        thresh=min(curr_trace.max()*.75,1)\n",
    "        events[move_ev_inds[i],0] += np.nonzero(curr_trace>thresh)[0][0]\n",
    "    print(events[move_ev_inds,0])\n",
    "    \n",
    "    if s==0:\n",
    "        epochs = mne.Epochs(dat, events, event_id, tlims[0], tlims[1], baseline=None, preload=True)\n",
    "    else:\n",
    "        epochs_tmp = mne.Epochs(dat, events, event_id, tlims[0], tlims[1], baseline=None, preload=True)\n",
    "        epochs = mne.concatenate_epochs([epochs,epochs_tmp])\n",
    "print(epochs._data.shape[0])\n",
    "\n",
    "# Resample epochs to match ECoG inputs\n",
    "epochs.resample(sfreq_new)\n",
    "    \n",
    "# Add labels to data\n",
    "event_id_labs = list(event_id.keys())\n",
    "days_start = (np.arange(n_splits)+1).tolist()\n",
    "recording_day,labels = [],[]\n",
    "for i,lab_curr in enumerate(event_id_labs):\n",
    "    ep_tmp = epochs[lab_curr]\n",
    "    n_tmp = int(ep_tmp._data.shape[0])//n_splits\n",
    "    days_curr = np.asarray(days_start * n_tmp)\n",
    "    np.random.shuffle(days_curr)\n",
    "    recording_day.extend(days_curr.tolist()) \n",
    "    if i==0:\n",
    "        ecog_dat_sbj = ep_tmp.get_data().copy()\n",
    "    else:\n",
    "        ecog_dat_sbj = np.concatenate((ecog_dat_sbj,ep_tmp.get_data().copy()),axis=0)\n",
    "    labels.extend([i+1]*ep_tmp.get_data().shape[0])\n",
    "\n",
    "# Add labels to ECoG data\n",
    "labels_arr = np.tile(np.expand_dims(np.asarray(labels),1),(1,ecog_dat_sbj.shape[2]))\n",
    "labels_arr = np.expand_dims(labels_arr,1)\n",
    "ecog_dat_sbj = np.concatenate((ecog_dat_sbj,labels_arr),axis=1)\n",
    "\n",
    "# Convert to xarray and save\n",
    "da_ecog = xr.DataArray(ecog_dat_sbj,\n",
    "                  [('events', recording_day),\n",
    "                   ('channels', np.arange(ecog_dat_sbj.shape[1])),\n",
    "                   ('time', epochs.times)])\n",
    "pdb.set_trace()\n",
    "da_ecog.to_netcdf(sp+sbj_id+'_ecog_data.nc')\n",
    "    \n",
    "print('Sampling rate: '+str(epochs.info['sfreq'])+' Hz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inverse-pde",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
